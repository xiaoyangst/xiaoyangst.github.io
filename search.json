[{"title":"226. 翻转二叉树","url":"/2024/10/11/226-翻转二叉树/","content":"\n```c++\nclass Solution {\npublic:\n    TreeNode* invertTree(TreeNode* root) {\n        if (root == nullptr){\n            return root;\n        }\n        TreeNode* tmp = root->right; // 保存 右节点\n        root->right = root->left;\n        root->left = tmp;\n        invertTree(root->left);\n        invertTree(root->right);\n\n        return root;\n    }\n};\n```\n\n如果你明白二叉树就是多条链表，就明白在赋值之前，应该保存好要被修改的节点，来保证原始数据不会丢失。\n","tags":["树"],"categories":["leetcode"]},{"title":"epoll的使用","url":"/2024/10/10/epoll的使用/","content":"\n<!-- toc -->\n\n## 系统调用\n\n`epoll_create`：创建一个 epoll 实例\n\n```c++\n#include <sys/epoll.h>\n\nint epoll_create(int size);\n```\n\nepoll_create 中的参数 size 已被忽略，但它必须是大于零的值。\n\n---\n\n` epoll_ctl`：用于在 epoll 实例中添加、修改或删除文件描述符\n\n```c++\n#include <sys/epoll.h>\n\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);\n```\n\n**`epfd`**: epoll_create 返回的 epoll 实例的文件描述符\n\n**`op`**: 操作类型，指定你想要执行的操作，可以是以下之一：\n\n- EPOLL_CTL_ADD：**添加**文件描述符到 epoll 实例中\n- EPOLL_CTL_MOD：**修改**已存在的文件描述符的事件\n- EPOLL_CTL_DEL：从 epoll 实例中**删除**文件描述符\n\n**`fd`**: 需要添加（监视）、修改或删除（不再监视）的文件描述符\n\n**`event`**: 指向 `epoll_event` 结构体的指针，定义了你希望监视的事件（读写事件）及事件发生时的处理方式\n\n---\n\n`epoll_wait`：等待 epoll 实例中的事件发生\n\n```c++\n#include <sys/epoll.h>\n\n int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);\n```\n\n**`epfd`**: epoll_create 返回的 epoll 实例的文件描述符\n\n**`events`**: 指向 epoll_event 结构体数组的指针。epoll_wait 会将发生的事件填充到这个数组中\n\n**`maxevents`**: events 数组的大小，表示最多可以返回多少个事件\n\n**`timeout`**: 超时时间（以毫秒为单位）。如果设置为 -1，epoll_wait 会无限等待直到有事件发生；如果设置为 0，epoll_wait 会立即返回，不会阻塞；其他值表示超时时间\n\n当你调用 `epoll_wait` 时，它会阻塞，直到有事件发生，或者超时，或者被中断。调用成功的返回值是返回实际发生的事件数，这些实际发生的事件存储在 events 事件数组中，从这里取出来事件并处理。\n\n---\n\nepoll_ctl 和 epoll_wait 都出现 epoll_event 结构体\n\n```c++\nstruct epoll_event {\n    uint32_t events;  // 事件类型\n    epoll_data_t data;  // 用户数据\n};\n```\n\n**`events`**: 你希望监视的事件类型，可以是以下之一（或者它们的组合）：\n\n- EPOLLIN：可读事件（常用）\n- EPOLLOUT：可写事件（常用）\n- EPOLLERR：错误事件\n- EPOLLHUP：挂起事件\n- EPOLLET：边缘触发模式（不设置默认是水平触发）\n- EPOLLONESHOT：一次性事件\n\n**`data`**: 你可以用来存储用户数据，通常是一个 union，可以存储 int、ptr 或其他数据类型\n\n代码地址：[群聊](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/epoll/%E7%BE%A4%E8%81%8A)\n\n## 原理\n\n```c++\nint epfd = epoll_create(EPOLL_SIZE);\n```\n\nepoll_create 完成两项工作：\n\n- 创建并初始化一个 `eventpoll` 对象。\n- 把 `eventpoll` 对象映射到一个文件句柄，并返回这个文件句柄。\n\n![epollcreate.png](/images/2024/10/10/62153e00-86fa-11ef-82f8-bfede75268b2.png)\n\n我们实际看看内核中 evnetpoll 对象的核心成员：\n\n```c++\nstruct eventpoll {\n    ...\n    wait_queue_head_t wq;\t\t\t\t// 等待队列\n    ...\n    struct list_head rdllist;\t// 就绪集合（双向链表）\n    struct rb_root rbr;\t\t\t\t\t// 监听集合（红黑树）\n    ...\n};\n```\n\nepoll_ctl 操作 rbr 来管理节点，epoll_wait 就是拷贝 rallist 得到就绪集合。\n\n![epoll节点.png](/images/2024/10/10/5e258d40-86fa-11ef-82f8-bfede75268b2.png)\n\n可以看到 rbr 上是一个一个的 epitem，但我们监听 文件描述符的时候，需要封装为 epitem。\n\n```c++\nstruct epoll_event listen_ep;\nlisten_ep.data.fd = sock_fd;\nlisten_ep.events = EPOLLIN; \nepoll_ctl(epfd,EPOLL_CTL_ADD,sock_fd,&listen_ep);\n```\n\n通过 epoll_ctl 中的 EPOLL_CTL_ADD 操作把 epitem 添加到监听集合中，并且设置一个回调函数。当 socket 状态发生变化时，会触发调用这个回调函数，主要工作是把就绪的文件描述符添加到 eventpool 的就绪集合中，然后唤醒调用 epoll_wait 阻塞的进程。\n\n哪个文件描述符触发，就会加入到就绪集合，内核也就知道具体是哪个文件描述符有变化，而之前的 select 方法是无法做到这点的。\n\n![epollctladd.png](/images/2024/10/10/592ad520-86fa-11ef-82f8-bfede75268b2.png)\n\n我们要把内核中的就绪集合拷贝到用户态，需要创建一个 epoll_event 用以接收，然后调用 epoll_wait 来完成拷贝。\n\n```c++\nstruct epoll_event events[BUFFER_SIZE];\n\nint ep_num = epoll_wait(epfd,events,MAX_EVENTS,-1);\n```\n\nepoll_wait 接触阻塞有三种情况：\n\n1. 被监听的文件集合中有就绪的文件\n2. 设置了超时时间并且超时了\n3. 接收到信号\n\n![epollwait.png](/images/2024/10/10/5531fca0-86fa-11ef-82f8-bfede75268b2.png)\n\n至此，[归档](https://www.jxhs.me/2021/04/08/linux%E5%86%85%E6%A0%B8Epoll-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/)如下：\n\n1. 通过调用 `epoll_create()` 函数创建并初始化一个 `eventpoll` 对象。\n2. 通过调用 `epoll_ctl()` 函数把被监听的文件句柄 (如socket句柄) 封装成 `epitem` 对象并且添加到 `eventpoll` 对象的红黑树中进行管理。\n3. 通过调用 `epoll_wait()` 函数等待被监听的文件状态发生改变。\n4. 当被监听的文件状态发生改变时（如socket接收到数据），会把文件句柄对应 `epitem` 对象添加到 `eventpoll` 对象的就绪队列 `rdllist` 中。并且把就绪队列的文件列表复制到 `epoll_wait()` 函数的 `events` 参数中。\n5. 唤醒调用 `epoll_wait()` 函数被阻塞（睡眠）的进程。\n\n![epoll总结.jpg](/images/2024/10/10/511d5ec0-86fa-11ef-82f8-bfede75268b2.jpg)\n\n## 注意点\n\n1. 我们要监听一个文件描述符，一定要封装成 epoll_event，再加入监听。\n2. epoll_wait 需要提供一个 epoll_event 数组，用来存储 内核中的就绪集合。\n3. 对于不需要监听的文件描述符，记得通过 EPOLL_CTL_DEL 移除。尽管不移除好像也没关系，按理不被关心的它永远不会被触发了，但基于代码的严谨，应该移除。\n4. [水平触发和边缘触发](https://xiaoyangst.github.io/2024/08/10/%E6%B0%B4%E5%B9%B3%E8%A7%A6%E5%8F%91%E5%92%8C%E8%BE%B9%E7%BC%98%E8%A7%A6%E5%8F%91/)。\n\n","tags":["Linux","网络编程"],"categories":["technology"]},{"title":"select的使用","url":"/2024/10/09/select的使用/","content":"\n<!-- toc -->\n\n## 接口\n\n通过 fd_set 创建一个文件描述符集合，通过下面的方法可以对该集合进行操作：\n\n`FD_ZERO(&fdset)`：将文件描述符集合清空。\n\n`FD_SET(fd, &fdset)`：将文件描述符 `fd` 添加到集合中。\n\n`FD_CLR(fd, &fdset)`：将文件描述符 `fd` 从集合中移除。\n\n`FD_ISSET(fd, &fdset)`：检查 `fd` 是否在集合中。\n\n从参数类型就可以知道，fd_set 中可以添加多个文件描述符（通常是 1024 个），而后面介绍的 select 就是 监听 fd_set 集合中的所有文件描述符，即 select 不只可以监听 socket 文件描述符。\n\n接着，我们看看 select 接口：\n\n```c++\nint select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);\n\n```\n\n参数说明：\n\n- **nfds**：文件描述符的数量，通常是待监控的文件描述符中最大值加 1。\n- **readfds**：指向一个 `fd_set` 集合，用于监控是否有数据可读的文件描述符。如果不关心可读事件，可以传递 `NULL`。\n- **writefds**：指向一个 `fd_set` 集合，用于监控是否可以写入的文件描述符。如果不关心可写事件，可以传递 `NULL`。\n- **exceptfds**：指向一个 `fd_set` 集合，用于监控异常事件的文件描述符。如果不关心异常事件，可以传递 `NULL`。\n- **timeout**：指向一个 `timeval` 结构体，用于指定 `select` 调用的超时时间。如果传递 `NULL`，`select` 将无限期等待；如果传递一个超时值，`select` 会在超时后返回。\n\n返回值：\n\n- 成功时，返回**准备就绪的文件描述符数量**。\n- 返回 0 表示超时。\n- 返回 -1 表示出错。\n\n由于 select 不知道是哪些文件描述符的事件有发生，所以每次都是通过遍历，再利用 FD_ISSET 判断具体的文件描述符发生的事件，再进行后续处理。\n\nselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。\n\n所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一次是在用户态里，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。\n\n## select 注意点\n\n### 清空 fd_set 集合\n\nfd_set 集合**必须在下次使用前利用 FD_ZERO 清空**，否则该集合中将会继续记录着上一次触发的事件，可不代表我们还关心这些文件描述符，唯有清空才能保证本次的文件描述符集合是我们关心的。\n\n### 时刻记录监听的文件描述符个数\n\n由于 select 不知道具体的文件描述符发生的事件，只能通过遍历的方式去做。那么为了保证不会遗漏触发事件的文件描述符，就需要时刻记录。这个记录值往往就是   我们着重填写的 select 的第一个参数，它代表内核遍历的范围。\n\n### select 的 第一个参数\n\nselect 的 第一个参数往往容易被错误使用，它代表着要监控的 fd_set 数组中的最大范围。Linux 中有三个文件描述符的下标是固定的，见下图：\n\n![默认文件描述符.png](/images/2024/10/10/45278310-86d8-11ef-a116-296dc0f7b0ab.png)\n\n因此，监听的其他文件描述符，最小也是为 3。所以我们会初始化 max_fd = 3 作为初值。\n\n再通过 FD_SET 添加文件描述符的时候，随时更新 max_fd 为最大的文件描述符值即可，然后传入 select 作为第一个参数的时候，记得是 max_fd + 1。至于后续有些文件描述符不再监听，我们也不用再意，只要确保待监听的文件描述符在范围以内即可。\n\n### 同一个文件描述符同一时刻不可以多次加入 fd_set 集合中\n\n同一个文件描述符**不能也不需要**多次加入到 `fd_set` 中。即使多次调用 `FD_SET()`，最终只会在 `fd_set` 中保留一个，不会起到任何额外的作用。\n\n每个文件描述符在 `fd_set` 中**对应一个唯一的比特位**，`FD_SET()` 只是设置该位为 1。多次调用 `FD_SET()` 对同一个文件描述符只是重复设置相同的位，没有任何附加效果。\n\n文件描述符是唯一的，通过公式计算得到的下标作为在 fd_set 集合中的索引也是唯一，同一个文件描述符多次加入到 fd_set 中也就属于重复的无意义行为。\n\n## 疑问\n\n### 会出现某个文件描述符覆盖另一个文件描述符吗？\n\n不会出现某个文件描述符覆盖另一个文件描述符的情况，因为在 `fd_set` 中，每个文件描述符都有一个唯一的比特位对应它的状态，且这些比特位的分配是基于文件描述符的值精确计算的。\n\n```c++\nindex = fd / (8 * sizeof(unsigned long));   // 数组索引\n\nbit   = fd % (8 * sizeof(unsigned long));   // 比特位\n\n```\n\n所谓 fd_set 就是一个位图：\n\n![bit.png](/images/2024/10/10/3dc34500-86d8-11ef-a116-296dc0f7b0ab.png)\n\n假设你有两个文件描述符，`fd1 = 130` 和 `fd2 = 135`，让我们计算它们在 `fds_bits` 中的位置：相同的数组下标，不同的 bit 位。\n\n```tex\nindex = 130 / 64 = 2;    // 130 映射到 fds_bits[2]\n\nbit   = 130 % 64 = 2;    // 130 位于 fds_bits[2] 的第 2 位\n\n```\n\n```tex\nindex = 135 / 64 = 2;    // 135 也映射到 fds_bits[2] （同一个数组元素）\n\nbit   = 135 % 64 = 7;    // 135 位于 fds_bits[2] 的第 7 位\n```\n\n### select 一次能够监听多少客户端建立连接的请求？\n\n实际上这个问题是不正确的，select 是监听文件描述符，比方说我们用以监听客户端是否有连接的 sock_fd。对于 select 而言，如果你有状态变化，select 至少保证有一条建立连接请求的到来。\n\n至于你要和多少个客户端建立连接，得看 sock_fd 中的全连接队列的连接对象数量以及你调用 accept 的次数。但我们通常是不建议调用多次 accept ，而是选择调用一次。\n\n```c++\nif (FD_ISSET(sock_fd, &read_fds)) {\n    int client_fd = accept(sock_fd, NULL, NULL);\n    // ...\n}\n```\n\n等你 accept 连接之后，再次来到 select 会立即触发，因为 sock_fd  的全连接队列还有连接对象（select 默认是水平触发，也只有水平触发），接着往下执行。效率上并无二致，而且逻辑更加合理。\n\n代码地址：[全连接队列有连接对象，select 立即返回](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/select/%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E6%9C%89%E8%BF%9E%E6%8E%A5%E5%AF%B9%E8%B1%A1)\n\n## 实战代码\n\n代码地址：[群聊](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/select/%E7%BE%A4%E8%81%8A)\n\n下面这个代码单独拎出来说：\n\n```c++\nfor (int i = 0; i < HOME_SIZE; ++i) {\n    if (home[i] > 0) {\n        FD_SET(home[i], &read_fds);\n        if (home[i] > max_fd) {\n            max_fd = home[i];\n        }\n    }\n}\n```\n\n由于每次必须清空 fd_set 集合，那么每次清空之后又必须 把所有连接的客户端对应的 socket 文件描述符加入到 fd_set 集合中，监听对应的读事件。\n\n还有一个问题，accept 和 select 都是阻塞函数。如果想要 accept 不阻塞，需要将 accept 的第一个参数，即套接字设置为非阻塞。如果想要 select 不阻塞，需要设置超时时间。实际情况我们都不会让它们阻塞。\n\n代码地址：[select 监听 sock_fd](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/select/%E4%B9%9F%E7%9B%91%E5%90%ACsock_fd)\n\n让 select 监听 socket_fd 套接字，等到有事件触发就往下走，等判断是新连接建立的事件再去调用 accept 更加合理。而不是像前面那样，不管有没有都去调用一次。\n\n```c++\n// 处理新连接\nif (FD_ISSET(sock_fd, &read_fds)) {\n    int client_fd = accept(sock_fd, NULL, NULL);\n    // 后续处理逻辑\n}\n\n// 处理客户端的读事件\nfor (int i = 0; i < HOME_SIZE; ++i) {\n    if (home[i] > 0 && FD_ISSET(home[i], &read_fds)) {\n        // 后续处理逻辑\n    }\n}\n```\n\n## select 的缺陷\n\n**文件描述符限制**：`select` 的最大文件描述符数量通常受系统限制（通常为 1024），这使得它不适合处理大量连接。\n\n**性能问题**：在每次调用时，`select` 需要遍历所有的文件描述符，这可能导致性能下降，尤其是在文件描述符数量很大时。\n\n**状态重置**：每次调用 `select` 前，必须重置监视的文件描述符集合，这增加了额外的开销。\n\n**不支持边缘触发**：`select` 仅支持水平触发模式，不支持边缘触发，这可能导致不必要的重复事件处理。\n\n**扩展性差**：由于使用线性扫描，`select` 难以扩展到更高的并发连接数。\n\n由于监听集合 和 就绪集合是同一个，耦合度高，这在 epoll 中得到解决。\n\n## select 原理\n\n```c++\nfd_set read_fds;\n\nFD_ZERO(&read_fds);\n```\n\n得到如下位图：\n\n![select代码过程1.png](/images/2024/10/10/33ef6680-86d8-11ef-a116-296dc0f7b0ab.png)\n\n添加我们关心的文件描述符到 read_fds 集合中\n\n```\nFD_SET(sock_fd, &read_fds);\n\nFD_SET(STDIN_FILENO, &read_fds);\n```\n\n最新的位图：\n\n![select代码过程2.png](/images/2024/10/10/2fc56be0-86d8-11ef-a116-296dc0f7b0ab.png)\n\n调用 select 方法，把 read_fds 集合 从用户态拷贝到内核态，内核态维护着相同的但属于自己的 read_fds 集合。如果集合中有事件发生，内核就会遍历 read_fds 集合，关心的文件描述符且发生事件的位置设置为1，其余设置为0。内核接着就把自己维护的 read_fds 拷贝到用户态度 read_fds 集合中。select 此刻就解除阻塞，接下来的代码就会遍历 read_fds 来判断哪个文件描述符触发，然后执行相应的处理逻辑。\n\n![select流程.png](/images/2024/10/10/2bb513c0-86d8-11ef-a116-296dc0f7b0ab.png)\n\n为什么再次使用 fd_set 都得 清空 一次 ？\n\n从图中就可以看到答案，早先监听的文件描述符因为在内核中没有被触发过，导致被置为 0，如果不重置为 0 并且 再次把监听的文件描述符加入其中，而是选择继续拿来使用，那就会导致原先我们关心的部分文件描述符不会被触发，只是监听上次触发的文件描述符，并且会越来越少，毕竟不能保证每次都能触发上次的文件描述符。\n\n说到这里，你就会提出这样一个问题，即 FD_SET 是把标志位置为 1。那么，为什么每次都需要 FD_ZERO，直接调用 FD_SET 把关心的文件描述符添加一下，一样实现让 fd_set 中包含所有关心的文件描述符。\n\n这确实是一个好问题，但是依旧应该选择 再次使用 FD_ZERO 把 fd_set 清空 一次，因为之前触发的文件描述符我们不一定还感兴趣。每次清空，可以保证加入到 fd_set 中的文件描述符是我们当前感兴趣的。\n\n```c++\nfor (int i = 0; i < HOME_SIZE; ++i) {\n    if (home[i] > 0) {\n        FD_SET(home[i], &read_fds);\n        if (home[i] > max_fd) {\n            max_fd = home[i];\n        }\n    }\n}\n```\n\n就拿这份代码举例，home 数组记录连接服务器的客户端文件描述符。如果某个客户端断开连接，我们自然是要将它从数组中移除，那么你要是不使用 FD_ZERO 把 fd_set 清空，fd_set 集合中不就可能包含已经被移除的文件描述符吗？关心一个不该关心或不存在的文件描述符，这是多么荒唐的事情。\n\n至此，我们再次强调，务必每次使用 fd_set 之前，用 FD_ZERO 清空一次。","tags":["Linux","网络编程"],"categories":["technology"]},{"title":"冯·诺依曼体系结构","url":"/2024/10/09/冯·诺依曼体系结构/","content":"\n<!-- toc -->\n\n## 不可编程\n\n计算机是由各种门电路组合而成的，然后通过组装出一个固定的电路版，来完成一个特定的计算程序。一旦需要修改功能，就要重新组装电路。这样的话，计算机就是“不可编程”的，因为程序在计算机硬件层面是“写死”的。最常见的就是[老式计算器]()，电路板设好了加减乘除，做不了任何计算逻辑固定之外的事情。\n\n## 不可存储\n\n典型的就是早年的 “Plugboard” 这样的插线板式的计算机。整个计算机就是一个巨大的插线板，通过在板子上不同的插头或者接口的位置插入线路，来实现不同的功能。这样的计算机自然是“可编程”的，但是编写好的程序不能存储下来供下一次加载使用，不得不每次要用到和当前不同的“程序”的时候，重新插板子，重新“编程”。\n\n![Plugboard.jpg](/images/2024/10/09/633378f0-862e-11ef-9dc8-d75cb81020a6.jpg)\n\n## 冯·诺依曼体系结构\n\n冯·诺依曼体系结构又名存储程序计算机，这里面其实暗含了两个概念，一个是“可编程”计算机，一个是“存储”计算机。\n\n![冯诺依曼.png](/images/2024/10/09/5fe5d490-862e-11ef-9dc8-d75cb81020a6.png)\n\n任何一台计算机的任何一个部件都可以归到运算器、控制器、存储器、输入设备和输出设备中，而所有的现代计算机也都是基于这个基础架构来设计开发的。而所有的计算机程序，也都可以抽象为从输入设备读取输入信息，通过运算器和控制器来执行存储在存储器里的程序，最终把结果输出到输出设备中。而我们所有撰写的无论高级还是低级语言的程序，也都是基于这样一个抽象框架来进行运作的。\n\n- 控制器：负责管理和协调计算机内部各个部件的工作。它获取指令，并决定如何执行这些指令，包括数据流的控制和指令的顺序执行。中央处理器（CPU）通常包含一个控制单元。\n- 运算器：负责执行算术和逻辑运算的硬件单元。它能够进行加、减、乘、除等基本运算，以及与、或、非等逻辑运算。运算器的输出可以用来更新寄存器或存储器中的数据。\n- 存储器：存储器用于存放数据和指令。\n- 输入设备：用于将用户输入的数据或指令传输到计算机。常见的输入设备包括键盘、鼠标、扫描仪、麦克风等。\n- 输出设备：用于将计算机处理后的数据以可读的形式呈现给用户。常见的输出设备包括显示器、打印机、音响等。\n\n存储器分为三种类型：\n\n- **随机存取存储器（RAM）**：临时存储数据和程序，断电后内容丢失。\n- **只读存储器（ROM）**：永久存储固化程序和数据，通常在启动时使用。\n- **缓存（Cache）**：高速存储器，用于提高访问速度，存储常用数据和指令。\n\n---\n\n⭐️内容取自极课时间《深入浅出计算机组成原理》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议购买原课程。","tags":["计算机组成原理"],"categories":["technology"]},{"title":"数据库和缓存如何保持一致性？","url":"/2024/10/08/数据库和缓存如何保持一致性？/","content":"\n<!-- toc -->\n\n## 先更新数据库，还是先更新缓存？\n\n「请求 A 」和「请求 B 」两个请求，同时更新「同一条」数据。\n\n### 先更新数据库，再更新缓存\n\n用户肯定先访问缓存，如果更新数据库的顺序和更新缓存的顺序不同，那就会导致命中的缓存不是最新的数据。\n\n如下图所示，数据库中的数据是 2，但是缓存中的数据却是 1。\n\n![先更新数据库再更新缓存.png](/images/2024/10/08/0f4d3380-856a-11ef-99f7-f1acdd0d8718.png)\n\n### 先更新缓存，再更新数据库\n\n如果更新缓存的顺序和更新数据库的顺序不同，那就会导致数据库中存储的不是最新的数据，这比上面那种情况还要糟糕。\n\n如下图所示，缓冲中的数据是 2，这是没有问题，但是数据库中存储的数据居然是 1，这是严重的错误。\n\n数据库作为实际存储数据的地方，绝不能有错，因为它是数据的本源。\n\n![先更新缓存再更新数据库.png](/images/2024/10/08/08ace1b0-856a-11ef-99f7-f1acdd0d8718.png)\n\n## 先更新数据库，还是先删除缓存？\n\n不管是【先更新数据库，再更新缓存】，还是【先更新缓存，再更新数据库】，都不能保证，我们还是另寻它路吧。\n\n先更新数据库，再把缓存删除。等到客户端访问的时候，发现没有命中缓存，就从数据库中读取数据给到客户端，再把该数据会写到缓存中，保证下一次可以命中。就可以避免前面讨论的并发问题。\n\n![读写策略.png](/images/2024/10/08/009ad770-856a-11ef-99f7-f1acdd0d8718.png)\n\n### 先删除缓存，再更新数据库\n\n如果先删除缓存，但还没有来得及更新数据库，此时客户端访问就会无法命中缓存，就会读取数据库的数据（旧数据），返回给客户端之后，再把这个数据回写到缓存中，下次访问还是命中，依旧不是最新的数据。此时，更新数据库的命令才执行完成，可谓姗姗来迟。\n\n如下图所示，按理应该读取最新数据 21，但是由于此期间客户端请求数据，导致返回旧数据，并且还更新到缓存中，下次命中还是属于旧数据。\n\n![先删除缓存再更新数据库.png](/images/2024/10/08/fc01ee60-8569-11ef-99f7-f1acdd0d8718.png)\n\n### 先更新数据库，再删除缓存\n\n假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。\n\n最终，该用户年龄在缓存中是20（旧值），在数据库中是21（新值），缓存和数据库数据不一致。\n\n![先更新数据库再删除缓存.png](/images/2024/10/08/f6fc12b0-8569-11ef-99f7-f1acdd0d8718.png)\n\n从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，但是在实际中，这个问题出现的概率并不高。因为**缓存的写入通常要远远快于数据库的写入**，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。\n\n因此，我们认为【先更新数据库，再删除缓存】的方案，是可以保证数据一致性的。我想我们应该先保证源头的正确性，才是最重要的。\n\n## 如何保证两个操作都能执行成功？\n\n我们已经确定【先更新数据库，再删除缓存】作为保证数据一致性的方案，这是两个独立的操作，必须确保两个操作都能执行成功。\n\n下面介绍两种方案，归根结底就是把操作的数据行为另存一份，直到保证两个操作成功再移除，否则多次重试。\n\n（一）消息队列重试机制\n\n引入消息队列，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据：\n\n- 如果应用**删除缓存失败**，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。当然，如果重试超过的一定次数，还是没有成功，我们就需要先业务层发送报错信息了。\n- 如果**删除缓存成功**，就要把数据从消息队列中移除，避免重复操作，否则继续重试。\n\n![消息队列.png](/images/2024/10/08/efe8b3c0-8569-11ef-99f7-f1acdd0d8718.png)\n\n这个方案的缺点是，对代码入侵性比较强，需要改造原本业务的代码。\n\n（二）订阅 MySQL binlog，再操作缓存\n\n【先更新数据库，再删除缓存】的策略第一步是更新数据库，那么更新数据库成功，就会产生对应的日志，记录在 binlog 里。\n\n于是，我们可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除。\n\n![binlog.png](/images/2024/10/08/ea4c3d60-8569-11ef-99f7-f1acdd0d8718.png)\n\nCanal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。\n\nCanal 方案不会对代码造成入侵，因为它是直接订阅 binlog 日志，和业务代码没有耦合关系，因此我们可以通过 Canal + 消息队列的方案来保证数据缓存的一致性。\n\n具体的做法是：将 binlog 日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅 binlog 根据更新 log 删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性。\n\n日志这里有一个很关键的点，必须是删除缓存成功，再回 ACK 机制给消息队列，否则可能会造成消息丢失的问题。比如消费服务从消息队列拿到事件之后，直接回了 ACK，然后再执行删除缓存操作的话，如果删除缓存的操作还是失败了，那么因为提前给消息队列回 ACK 了，就没办重试了。\n\n---\n\n⭐️内容取自《小林Coding》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议访问[官方网站](https://xiaolincoding.com/)。","tags":["Redis"],"categories":["technology"]},{"title":"HTTPS通信流程","url":"/2024/10/08/HTTPS通信流程/","content":"\n对称加密用同一个密钥进行加解密，非对称加密用公钥加密私钥解密。因此，非对称加密流程要比对称加密复杂，效率就比对称加密低效。网络通信的数据要进行加密，而对称加密和非对称加密都是一种加密方式，对称加密相较于非对称加密不安全，是因为加解密都是同一个密钥，一旦在网络中被截获就会被破解，消息传输不再安全。非对称加密的私钥是不会在网络中传输的，不存在被截获的可能，而共享的公钥本来就是给别人看，无所谓安全不安全。既要安全性，又要加密数据的高效率，HTTPS的加密流程就达到这两个目标了。\n\n简单来讲，非对称加密完成客户端对称加密的密钥交换，双方后续就用对称加密的方式进行通信。\n\n![HTTPS通信流程.png](/images/2024/10/08/68c48b10-8525-11ef-b74c-af302144fe57.png)\n\n大致流程如下：\n\n1. 客户端向服务器发起 HTTPS 请求，服务器返回数字证书（证书包含**服务器的公钥**、服务器的域名信息以及证书的颁发机构等）。\n2. 客户端检验数字证书的合法性（包括检查证书的颁发机构是否受信任、证书是否过期、证书中的域名是否与服务器的域名匹配等），验证通过之后，取出服务器的公钥。\n3. 客户端生成一个随机数，用于生成对称加密的会话密钥，并且用服务器的公钥对其加密，传输给服务器。\n4. 服务器收到客户端消息，用私钥进行解密，得到客户端的密钥信息。\n5. 从此，服务器和客户端都将采用对称加密的方式加密数据并进行通信。","tags":["Linux","网络编程"],"categories":["technology"]},{"title":"底层基于TCP协议的Socket通信流程","url":"/2024/10/08/底层基于TCP协议的Socket通信流程/","content":"\n![通信流程.png](/images/2024/10/08/3b7e6990-8521-11ef-945d-63472fad4b44.png)\n\n通过 socket 函数创建 Socket 套接字对象，核心的组成部分是输入缓冲区和输出缓冲区。该对象的指针记录在一个内核维护的文件描述符数组中，对应的数组下标将作为返回值 fd 用以给用户态使用。\n\n![socket对象.png](/images/2024/10/08/42119c00-8521-11ef-945d-63472fad4b44.png)\n\n通常，我们让服务端监听在某个【IP,PORT】上，用以给客户端连接。\n\n服务端创建 Socket 对象，还用不到输入输出缓冲区，因此会将其 free 掉，维护半连接队列和全连接队列处理客户端的连接请求。\n\n![处理连接.png](/images/2024/10/08/49db52a0-8521-11ef-945d-63472fad4b44.png)\n\nbind 绑定【IP,PORT】，listen 监听在【IP,PORT】，客户端 connect 到服务器，三次握手在由内核来完成。其流程为：\n\n1. 客户端发起第一次握手，服务器把本次请求维护在半连接队列中。\n2. 服务器回复客户端的请求，完成第二次握手。\n3. 客户端发起第三次握手，三次握手完成，服务器就视为连接成功，将其从半连接队列移除，移动到全连接队列中维护。\n\n当三次握手完成，连接对象移入全连接队列。accept 方法就是从全连接队列中取出一个已经成功建立的连接对象，**内核会为该连接对象分配一个新的套接字文件描述符**，对应的数组下标将作为返回值 fd 用以给用户态使用。这个新的文件描述符是与特定的客户端连接关联，它含有输入缓冲区和输出缓冲区，专用于与对应客户端进行数据传输。\n\n![通信连接.png](/images/2024/10/08/4e0e7500-8521-11ef-945d-63472fad4b44.png)\n\n简单回顾，客户端创建的 Socket 对象就是用以与服务器通信，但是服务器创建的 Socket 对象并不是，而是用以完成监听客户端连接并成功建立连接的任务。\n\n成功连接的对象维护在服务器 Socket 对象的全连接队列中，调用 accept 函数，内核就会从全连接队列中取出一个连接对象，为其创建 Socket 对象，此前的 Socket 对象是用以监听客户端连接，当前创建的 新的 Socket 对象是用以实际通信。\n\n调用 send 发送消息，recv 接受消息。\n\n- send 本质上是把应用程序数据拷贝到 Socket 对象的 输出缓冲区，仅此而已，至于如何在网络数据传输，已经何时把数据放在网络上传输，都与 send 接口无关。\n- recv 本质上是把 Socket 对象的 输入缓冲区 的数据拷贝到应用程序中。\n\n说到底，send 和 recv 依旧还是在和本机打交道，网络上的事情是交由操作系统去完成。\n\n等到无需通信，就会选择关闭套接字，四次挥手的过程也是由内核完成。\n\n推荐阅读：[Linux-收发网络数据包的过程](https://xiaoyangst.github.io/2024/09/25/Linux-%E6%94%B6%E5%8F%91%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E5%8C%85%E7%9A%84%E8%BF%87%E7%A8%8B/#%E6%8E%A5%E6%94%B6%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E5%8C%85)","tags":["Linux","网络编程"],"categories":["technology"]},{"title":"缓存雪崩、缓存击穿和缓存穿透","url":"/2024/10/06/缓存雪崩、缓存击穿和缓存穿透/","content":"\n<!-- toc -->\n\nRedis 缓存的数据来源于 MySQL数据库，前者作用于内存，后者作用于磁盘，内存访问比磁盘快很多。\n\n那么会出现哪些故障或问题？我们的应对策略是什么？继续往下读吧。\n\n![读取缓存流程.png](/images/2024/10/06/e0bbbeb0-83e3-11ef-9c4b-5b387296a9ff.png)\n\n## 缓存雪崩\n\nRedis 是为了方便快速访问从而缓存的 MySQL 数据库中的数据，那么数据的更新是在 MySQL 数据库中，所以 Redis 要对缓存的数据设置一个过期时间。如果缓存数据过期就会从缓存中移除，用户来访问数据就无法立即命中，会直接访问 MySQL 数据库获得最新数据。最新的数据会缓存到 Redis 中，好让用户下次访问直接命中，这样就让用户既可以快速访问数据，还可以访问到最新的数据。\n\n![缓存同步.png](/images/2024/10/06/dd75bb70-83e3-11ef-9c4b-5b387296a9ff.png)\n\n那如果 Redis 缓存全部失效呢？大量请求访问 MySQL 数据库，不但速度慢，而且还会因为大量请求而崩溃。\n\n我们称之为 缓存雪崩。\n\n![缓存雪崩.png](/images/2024/10/06/d9aea150-83e3-11ef-9c4b-5b387296a9ff.png)\n\n那有哪些情况会导致大量请求绕过 Redis 缓存而来到 MySQL 数据库？\n\n1. Redis 缓存大量失效。\n2. Redis 缓存没有失效，但是宕机导致无法提供服务。\n\n### 大量数据同时失效\n\n（一）随机设置过期时间\n\n避免将大量数据设置相同的过期时间，采用随机数，这可避免大量数据同时失效问题。\n\n（二）互斥锁\n\n如果缓存中的数据有效，但是用户需要的数据不在其中，也就无法命中缓冲，依旧可能会导致大量的请求到 MySQL 数据。为了避免这个问题发生，可以选择加互斥锁。\n\n但业务线程在处理用户请求时，**如果发现访问的数据不在 Redis 中，就加个互斥锁，保证同一时间内只有一个请求来构建缓存**（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完后，再释放锁。\n\n实现互斥锁的时候，最好设置**超时时间**，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。\n\n（三）后台更新缓存\n\n业务线程不再负责更新缓存，缓存也不设置有效期，即“永久有效”，并将更新缓存的工作交由后台行程定时更新。\n\n事实上，缓存数据不设置有效期，并不是意味着数据一直能在内存里，因为当系统内存紧张的时候，有些缓存数据会被“淘汰”，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。\n\n解决上面问题的方式：\n\n1. 后台线程不仅负责定时更新缓存，而且也负责**频繁地检测缓存是否有效**，检测到缓存失效，原因可能是系统紧张而被淘汰，于是马上从数据库读取数据，并更新到缓存。这种方式检测时间不能太长，太长会导致用户获取的数据是一个空值而不是真正的数据，所以检测间隔最好是毫秒级，但是总归是有个间隔时间，用户体验一般。\n2. 业务线程发现缓存数据失效后，通过消息队列发送一条消息通知后台线程更新缓存，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式想必第一种方式缓存的更新会更及时，用户体验也比较好。\n\n### Redis 宕机\n\n（一）服务熔断或请求限流机制\n\n服务熔断就是暂停业务应用对缓存服务的访问，直接返回错误，不用再继续访问数据库。等到 Redis 恢复，再允许业务应用访问缓存服务。\n\n但如果就这样处理，会对业务有影响，为避免如此，可以开启请求限流机制，只处理少量的请求，直到 Redis 恢复正常并且预热完后，再解除请求限流的机制。\n\n（二）构建 Redis 缓存高可用集群\n\n如果访问的 Redis 宕机，可以立即选择其他有效的 Redis 服务器进行替代，保证服务不会中断。\n\n## 缓存击穿\n\n![缓存击穿.png](/images/2024/10/06/d3b2f3f0-83e3-11ef-9c4b-5b387296a9ff.png)\n\n如果某个热点数据过期，此时大量请求来访问（比方说秒杀活动），却无法命中缓存，导致大量请求去到 MySQL 数据库，MySQL 数据库很容易崩溃，这就是缓存击穿。\n\n解决方案可以参考之前的，你可以认为 缓存击穿是 缓存雪崩的一个子集。\n\n互斥锁方案：保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。\n\n不给热点数据设置过期时间：由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间。\n\n## 缓存穿透\n\n当用户访问的数据，**既不在缓存中，也不在数据库中**（前面的讨论至少保证数据库是有有效数据，但这里不再是），导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也有没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透问题。\n\n![缓存穿透.png](/images/2024/10/06/cee4a300-83e3-11ef-9c4b-5b387296a9ff.png)\n\n缓存穿透的发生一般有两种情况：\n\n- 业务误操作，缓存中的数据和数据库中的数据都被误删，导致缓存和数据库中都没有数据。\n- 黑客恶意攻击，故意大量访问本不存在数据的业务。\n\n解决方案：\n\n1. 非法请求的限制： API 入口处判断请求参数是否合理，是否还有非法数据等，如果存在就直接拒绝接下来的访问。\n2. 缓存空值或默认值：出现缓存穿透现象，可以针对查询的数据设置一个空值或者默认值，这样后续请求就可以从缓存中读取到控制或者默认值并返回给应用，而不会继续查询数据库。\n3. **布隆过滤器**：快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。\n\n---\n\n⭐️内容取自《小林Coding》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议访问[官方网站](https://xiaolincoding.com/)。\n\n","tags":["Redis"],"categories":["technology"]},{"title":"Linux线程操作","url":"/2024/10/03/Linux线程操作/","content":"\n<!-- toc -->\n\n由于在 C++ 阶段就已经深刻学习过 线程相关的知识，但是 C 语言的线程操作繁琐且难用，就算以后要用也必然是用封装过的线程，我们需要做这个工作。总的来讲，我们要显示三个内容：银行存钱取钱，阻塞队列，生产者消费者模型。\n\n## 线程的基本操作\n\n### pthread_self--获取线程ID\n\n每个线程都有一个唯一的ID。\n\n在 Linux 中， pthread_t 类型定义为无符号长整型 ( unsigned long ) 。\n\n```c++\npthread_t pthread_self(void);\n```\n\n### pthread_create--创建线程\n\n```c++\nint pthread_create(pthread_t *thread, const pthread_attr_t *attr,\n                          void *(*start_routine) (void *), void *arg);\n```\n\nthread：pthread_t* 定义，用于接收创建的线程的标识符。\n\nattr：线程属性，通常是 NULL ，采用默认属性。\n\nstart_routine：函数指针。\n\narg：传递给函数指针的形参。如果不传递任何参数，填 NULL。\n\n代码：[C 语言线程的基本使用](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/C%E8%AF%AD%E8%A8%80%E7%BA%BF%E7%A8%8B%E6%93%8D%E4%BD%9C/%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C)\n\n实际上这并不难，重点还是要演示如果传递更多的参数，已经如何获取线程的返回值。后者需要等到介绍后面的接口才能做，这里重点谈一谈前者。\n\n我们看传递给函数指针的参数只有一个，理论上也只能传递一个。但是 void* 代表可以传递任何类型，结构体是一个类型，并且支持存储多个不同类型的参数，因此C 语言线程如何突破只能传递一个参数的限制？用结构体！\n\n代码：[C 语言线程如何突破只能传递一个参数的限制](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/C%E8%AF%AD%E8%A8%80%E7%BA%BF%E7%A8%8B%E6%93%8D%E4%BD%9C/%E4%BC%A0%E9%80%92%E5%A4%9A%E4%B8%AA%E5%8F%82%E6%95%B0)\n\n### pthread_exit--终止线程\n\n```c++\nvoid pthread_exit(void *retval);\n```\n\n我们通过这个函数可以传递线程的返回值，即 retval 参数。然后其他线程就可以通过 pthread_join() 获取该返回值。等到我们讲完 pthread_join() 就实现获取返回值的代码。\n\n让线程终止的方式，还要很多，下面列举：\n\n1. 进程终止 (比如调用 exit() ，从 main() 函数返回)，那么该进程的所有线程都会立即终止。\n2. 从线程的入口函数返回。\n3. 线程调用 pthread_exit() 。\n4. 响应 pthread_cancel() 的取消请求。\n\n### pthread_join--连接已终止的线程\n\n```c++\nint pthread_join(pthread_t thread, void **retval);\n```\n\n如果我们 detach 或者 等待 线程终止，主线程可能早早结束，会导致线程没有被执行的机会，或者执行到途中异常终止，主线程结束意味着进程结束，其他线程依赖于该进程，也就随之消亡。\n\n但它还有一个作用，就是获取返回值。\n\n代码地址：[C 语言线程获取返回值](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/C%E8%AF%AD%E8%A8%80%E7%BA%BF%E7%A8%8B%E6%93%8D%E4%BD%9C/%E8%8E%B7%E5%8F%96%E8%BF%94%E5%9B%9E%E5%80%BC)\n\n### pthread_detach--分离线程\n\n```c++\nint pthread_detach(pthread_t thread);\n```\n\n有时，我们并不关心线程的返回状态，反而希望在线程终止时系统能够自动清理并移除它。在这种情况下，我们可以调用 pthread_detach() 将线程标记为处于分离（detached）状态。一旦线程处于分离状态，就不能再使用 pthread_join() 来获取其返回状态了，也无法再回到可连接（joinable）状态了。\n\n### pthread_cancel--取消线程（了解）\n\n通常情况下，程序中的多个线程会并发执行，每个线程各司其职。 但有时候，需要取消一个线程的执行。\n\n与 pthread_exit 只能终止本线程不同。pthread_cancel 可以由其他线程调用以显式地向目标线程发起取消请求，且 pthread_cancel 不是强制的，是一种协商机制，目标线程可以选择是否响应这次取消操作。\n\n```c++\nint pthread_cancel(pthread_t thread);\n```\n\n发送取消请求后，pthread_cancel() 函数会立即返回，不会等待目标线程退出 。\n\n目标线程会不会响应取消请求？以及何时响应？这取决于目标线程的两个属性：取消状态和取消类型。\n\n（一）取消状态\n\n目标线程会不会响应取消请求，是由目标线程的取消状态决定的，它有两个取值：\n\n- PTHREAD_CANCEL_ENABLE ：线程可以取消。这是默认值。\n- PTHREAD_CANCEL_DISABLE ：线程不可取消。如果此类线程收到取消请求，则会**将取消请求挂起，直到线程的取消状态设置为启用**。\n\n下面是设置取消状态的方法：\n\n```c++\nint pthread_setcancelstate(int state, int *oldstate);\n```\n\nstate ：取消状态，可取下面两个值：\n\n- PTHREAD_CANCEL_ENABLE ：线程可以取消。这是默认值。\n- PTHREAD_CANCEL_DISABLE ：线程不可取消。如果此类线程收到取消请求，则会将取消请求挂起，直到线程的取消状态设置为启用。\n\noldstate ：传出参数，用来保存以前的取消状态。\n\n（二）取消类型\n\n目标线程**何时响应取消请求**，是由目标线程的取消类型决定的，它也有两个取值：\n\n- PTHREAD_CANCEL_DEFERRED ：延迟响应，挂起取消请求，直到下一个取消点才响应。这是默认值。\n- PTHREAD_CANCEL_ASYNCHRONOUS ：异步响应，可以在任意时间点响应取消请求 (未必是立即响应)。异步响应在实际应用中很少使用。\n\n设置线程的取消类型：\n\n```c++\nint pthread_setcanceltype(int type, int *oldtype);\n```\n\ntype ：取消类型，可取下面两个值：\n\n- PTHREAD_CANCEL_DEFERRED ：延迟响应，挂起取消请求，直到下一个取消点才响应。这是默认值。\n- PTHREAD_CANCEL_ASYNCHRONOUS ：异步响应，可以在任意时间点响应取消请求 (未必是立即响应)。异步响应在实际应用中很少使用。\n\noldtype ：传出参数，用来保存以前的取消类型。\n\n（三）取消点\n\n若将线程的取消性状态和类型分别置为 ENABLE 和 DEFERRED（默认状态），那么只有当线程执行到某个取消点 时，取消请求才会起生效。取消点是一组函数，这些函数往往可以让线程陷入无限期的阻塞。\n\n![取消点.png](/images/2024/10/03/9c1a21d0-8180-11ef-b9cc-9d1a3128f314.png)\n\n如果线程的取消类型为 DEFERRED ，当线程收到取消请求后，它会在下次抵达取消点时终止。如果该线程尚未分离，其它线程调用 pthread_join() 进行连接，会收到一个特殊的返回值 PTHREAD_CANCELED 。\n\n（四）设置取消点\n\n线程如果有挂起的取消请求，只要调用这个函数，线程就会终止。\n\n```c++\nvoid pthread_testcancel(void);\n```\n\n如果线程执行的代码中不包含取消点，可以周期性地调用 pthread_testcancel() ，以确保对取消请求做出及时响应。\n\n### 线程清理函数（了解）\n\n线程收到取消请求后，会执行到下一个取消点终止。如果线程只是草草地直接终止，可能会让程序处于不一致的状态，比如：对共享变量的修改只进行了一半啦，没有释放互斥锁啦...... 这样的错误轻则导致其他线程产生错误的结果、发生死锁，重则让进程直接崩溃。\n\n为了规避这一问题，线程可以设置一个或多个清理函数。当线程响应取消请求时，会自动执行这些清理函数。每个线程都拥有一个清理函数栈。当线程响应取消请求时，会依次执行栈中的清理函数 (从栈顶到栈底)。当执行完所有的清理函数后，线程终止。\n\n```c++\n会将函数指针 routine 添加到清理函数栈的栈顶\nvoid pthread_cleanup_push(void (*routine)(void *), void *arg);\n\n从调用线程的清理函数栈的栈顶删除一个清理函数\nvoid pthread_cleanup_pop(int execute);\n```\n\n## 线程同步\n\n### 互斥锁\n\n（一）初始化\n\n下面有两种方式：\n\n```c++\npthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER; // 静态初始化，仅适用于静态变量\n\nint pthread_mutex_init(pthread_mutex_t* mutex, const pthread_mutexattr_t* attr);\n```\n\n（二）上锁\n\n```c++\nint pthread_mutex_lock(pthread_mutex_t* mutex);\t\nint pthread_mutex_trylock(pthread_mutex_t* mutex);\nint pthread_mutex_timedlock(pthread_mutex_t* mutex, const struct timespec* abstime);\n```\n\n如果已经没有上锁，上面就会锁住。如果已经上锁，就会：按顺序注释\n\n1. 一直阻塞，直到等待的互斥量解锁\n2. 立即失败，并返回状态码 EBUSY\n3. 如果在超时时间内，调用线程没能获得互斥量的所有权，那么函数 pthread_mutex_timedlock() 会返回错误码 ETIMEDOUT\n\n（三）释放锁\n\n```c++\nint pthread_mutex_unlock(pthread_mutex_t *mutex);\n```\n\n（四）销毁\n\n```c++\nint pthread_mutex_destroy(pthread_mutex_t *mutex);\n```\n\n只有当互斥量处于未锁定状态，且后续不再使用它时，才应将其销毁。\n\n（五）实战\n\n代码地址：[10个线程从银行取钱](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/C%E8%AF%AD%E8%A8%80%E7%BA%BF%E7%A8%8B%E6%93%8D%E4%BD%9C/%E5%A4%9A%E4%B8%AA%E7%BA%BF%E7%A8%8B%E9%93%B6%E8%A1%8C%E5%8F%96%E9%92%B1)\n\n代码地址：[两个银行用户互相转账](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/C%E8%AF%AD%E8%A8%80%E7%BA%BF%E7%A8%8B%E6%93%8D%E4%BD%9C/%E4%B8%A4%E4%B8%AA%E8%B4%A6%E6%88%B7%E8%BD%AC%E8%B4%A6)\n\n### 条件变量\n\n（一）初始化\n\n```c++\npthread_cond_t cond = PTHREAD_COND_INITIALIZER; // 静态初始化，仅适用于静态变量\nint pthread_cond_init(pthread_cond_t* cond, const pthread_condattr_t* attr);\n```\n\n（二）等待\n\n```c++\nint pthread_cond_wait(pthread_cond_t* cond, pthread_mutex_t* mutex);\nint pthread_cond_timedwait(pthread_cond_t* cond, pthread_mutex_t* mutex, const struct timespec* abstime);\n```\n\npthread_cond_wait() 函数的语义如下：\n\n1. 释放所持有的互斥量 mutex 。\n2. 陷入阻塞状态。\n3. 当 pthread_cond_wait() 返回时，调用线程一定再一次获取了互斥量 mutex 。\n\n如果不然，就会一直阻塞。而 pthread_cond_timedwait 可以在哪怕是在指定时间内没有满足要求，也会自动解除阻塞。\n\n（三）唤醒\n\n```c++\nint pthread_cond_signal(pthread_cond_t *cond);\t// 唤醒一个线程\nint pthread_cond_broadcast(pthread_cond_t *cond);\t// 唤醒多个线程\n```\n\n（四）销毁\n\n```c++\nint pthread_cond_destroy(pthread_cond_t *cond);\n```\n\n当后续不再使用条件变量时，才应调用 pthread_cond_destroy() 将其销毁。\n\n（五）实战\n\n代码地址：[阻塞队列](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/C%E8%AF%AD%E8%A8%80%E7%BA%BF%E7%A8%8B%E6%93%8D%E4%BD%9C/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97)\n\n代码地址：[生产者消费者](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/C%E8%AF%AD%E8%A8%80%E7%BA%BF%E7%A8%8B%E6%93%8D%E4%BD%9C/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B)\n","tags":["Linux"],"categories":["technology"]},{"title":"分布式架构设计","url":"/2024/10/03/分布式架构设计/","content":"\n<!-- toc -->\n\n## 分布式架构扩展立方体模型\n\n![立方体模型.png](/images/2024/10/03/ef748a60-8125-11ef-b7ac-25da9940d0fb.png)\n\n扩展立方体模型从三个维度对分布式系统架构提出具体的要求，下面我们详细讲一讲：\n\n（一）X轴扩展--水平复制\n\n![X.png](/images/2024/10/03/ea468d40-8125-11ef-b7ac-25da9940d0fb.png)\n\n性能不够，设备来凑。通过 Nginx 负载均衡实现服务器集群，提高系统的高可用。因为其中任何一个服务器宕机，会有其他可用的服务器顶上，继续提供服务。\n\n（二）Z轴扩展--数据分区\n\n![Z.png](/images/2024/10/03/e660c790-8125-11ef-b7ac-25da9940d0fb.png)\n\n按照用户属性对应用/数据进行分组，比方说深圳的用户发起服务请求，经过网关路由器，网关路由器会优先选择将其转发到深圳应用实例，因为我们提前把深圳用户的信息存储到深圳应用实例当中，数据的访问和服务的处理速度会得到提升，提高了吞吐量。\n\n（三）Y轴扩展--功能性分解\n\n![Y.png](/images/2024/10/03/e1c6cd10-8125-11ef-b7ac-25da9940d0fb.png)\n\n将单体应用拆分层一个一个独立的功能模块，耦合性降低，各小组维护好自己的功能模块即可。这些拆出来的功能模块可以在单独的服务器上运行，再结合利用前面的 XZ 轴提高 高可用/高并发。\n\n## 分布式架构演化过程\n\n（一）单点式架构\n\n![单点.png](/images/2024/10/03/dd38e080-8125-11ef-b7ac-25da9940d0fb.png)\n\n所有服务全部在一台服务器上，耦合度极高。\n\n| 优点               | 缺点             |\n| ------------------ | ---------------- |\n| 开发迅速，成本低廉 | 性能差，并发量低 |\n| 结构简单，维护方便 | 不具备可用性     |\n| 事务强一致性       | 功能模块耦合严重 |\n\n（二）应用集群架构\n\n![集群.png](/images/2024/10/03/d8542160-8125-11ef-b7ac-25da9940d0fb.png)\n\n集群的后端服务器和集群的数据库解耦，我们还可以利用 MySQL 主从复制以及读写分离来提高数据一致性和性能提升，再不济还可以进行分库分表处理。这的确突破了单体服务架构的不可用性，引出的数据库相关问题也有对应的解决方案。\n\n| 优点             | 缺点                                                         |\n| ---------------- | ------------------------------------------------------------ |\n| 突破单点性能瓶颈 | 功能模块耦合严重，即所有功能全部部署在一个服务器上，每个服务器都是如此 |\n| 应用扩展方便     | 共用数据库，数据严重耦合，即读服务器虽然有多个，但是共用同一个写服务器 |\n| 用户与后端解耦   | 数据库服务器成为瓶颈                                         |\n| 事务强一致性     |                                                              |\n\n痛点 1：代码难以复制、难以同步\n\n痛点 2：过分关注细节、开发复杂性过高\n\n痛点 3：SQL 质量无法保证\n\n痛点 4：基础数据与业务数据耦合严重\n\n将功能进行模块划分，分散给各小组负责，同事每个功能模块维护自己的数据库，可以对上述问题进行应对。\n\n（三）服务化架构\n\n![服务化.png](/images/2024/10/03/d07e35c0-8125-11ef-b7ac-25da9940d0fb.png)\n\n服务化架构单独剥离出服务层， 将上层应用抽象出可通用的功能、数据模型与储存设施， 使应用模块间实现彻底解耦。\n\n- 消除代码级别重用，改用远程调用（RPC）\n- 屏蔽实现细节，让业务开发更简单\n- SQL 可用，专人负责更易维护\n- 分工明确，数据解耦\n\n那服务化架构就没有它的问题？按照当前发展，服务化架构的下一个发展就是微服务化，微服务的整体架构就是为了应对服务化架构引入更多服务存在的问题。\n\n![也有缺陷.png](/images/2024/10/03/cc328250-8125-11ef-b7ac-25da9940d0fb.png)\n\n## 如何评估系统流量\n\n哪些指标需要进行容量评估？\n\n![容量.png](/images/2024/10/03/c7926d50-8125-11ef-b7ac-25da9940d0fb.png)\n\n不同的服务容量评估方向不同，要发觉系统的复杂性和主要矛盾。比方说某鱼与某牙直播核心就是用户流畅观察直播，重点关注对象就是活动带宽；外贸交易系统核心就是资金的转移，核心就是交易的安全性和实时性。\n\n下面用一个具体的案例进行分析：\n\n![案例.png](/images/2024/10/03/c2fd2dc0-8125-11ef-b7ac-25da9940d0fb.png)\n\n因此，我们需要评估 QPS 即可。我们可以从产品经理那里拿到过往的业务访问趋势图，来看看哪个时间段是 QPS 最高，最高到多少。如果没有这份资料，可以根据二八原则。\n\n![28.png](/images/2024/10/03/bd9709a0-8125-11ef-b7ac-25da9940d0fb.png)\n\n计算出 QPS 峰值之后，需要对单机的能力进行测试，用压力测试工具，再进行必要的调整，有时候不一定就是服务器本身的局限性。\n\n![压力测试.png](/images/2024/10/03/b9a1daa0-8125-11ef-b7ac-25da9940d0fb.png)\n\n对此，我们评估计算如下：\n\n- 无历史数据，按二八定理，预期QPS峰值不低于 2220\n- 单点设备QPS极限为 400\n- 假设采用IDC LBS负载均衡，不考虑带宽等因素\n- 假设生产性能基线为80%\n- 服务器应准备 2220 / (400 * 80%) ≈ 6.93\n- 为此准备7台应用服务器即可\n\n## 如何发现与分析架构核心复杂度\n\n（一）案例一：公司内部推行物联网建设\n\n![e1.png](/images/2024/10/03/b4223b10-8125-11ef-b7ac-25da9940d0fb.png)\n\n（二）案例二：X电商门户\n\n![e2.png](/images/2024/10/03/b0b59d00-8125-11ef-b7ac-25da9940d0fb.png)\n\n数字 16 代表一个每天可能的访问时间为 16 小时，排除 8 小时睡眠之后的结果。\n\n计算出平均 QPS 为 694，但是电商访问有高峰期，我们 乘以 4 来应对这种情况。然后 除以 1000 * 0.8，这 0.8 代表单台服务器的极限，我们不希望服务器的极限是 满的，不然服务器随时处在崩溃边缘并不好。\n\n最终计算出结果为部署 3 台。实际情况中，我们还会额外提供 1~2台备用，来提高高可用性。\n\n（三）案例三：联通系统与XX银行平台问题\n\n![e3.png](/images/2024/10/03/acb21620-8125-11ef-b7ac-25da9940d0fb.png)\n\n可见有时候不单是技术上的问题，架构设计是一个全局的考量，人员也在考量以内。\n\n（四）思考题\n\n![e4.png](/images/2024/10/03/a83d2fd0-8125-11ef-b7ac-25da9940d0fb.png)\n\n（五）常见核心复杂性总结\n\n![核心复杂性.png](/images/2024/10/03/a4501720-8125-11ef-b7ac-25da9940d0fb.png)\n\n## 优秀架构设计的指导原则\n\n- 没有**场景**的架构设计就是耍流氓\n- 发现**问题的复杂性**是根本，这些包含在用户关键需求中\n- **“解耦”**是架构设计无时无刻考虑的事情\n- 不要脱裤子放屁，好的架构设计一定是**简单粗暴**的\n- 尊重”爬->走->跑->跳”的自然规律，架构一定是**演化**而来的\n- **没有任何一个架构是”万金油”** ，架构成长没有捷径\n- 架构师千万**不能为了”炫技”进行设计**，否则整个公司要为之埋单\n- 好的架构师一定是一个**”聆听”**的高手，跟客户交流要说人话\n\n[京东商城架构设计分享](https://github.com/xiaoyangst/Article-collection/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8A%80%E6%9C%AF/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%EF%BC%88%E4%BA%AC%E4%B8%9C%E5%95%86%E5%9F%8E%EF%BC%89.pdf)\n\n","tags":["分布式"],"categories":["technology"]},{"title":"《此文件不属于任何项目目标 代码洞察功能可能无法正常工作》解决方案","url":"/2024/10/01/《此文件不属于任何项目目标-代码洞察功能可能无法正常工作》解决方案/","content":"\n我的 CMake 里面已经用 include_directories 包含头文件，按理重新加载 CMakeLists.txt 会有成效，但实际上不是缓存问题。\n\n解决链接：https://segmentfault.com/q/1010000042694658\n\nClion 从 CMake 构建系统获取有关源文件的信息。当您将任何 cpp 文件添加到源列表时，CMake 会自动告知具有相同名称的标头。因此，如果 cpp/h 名称不同（或者您根本没有 cpp 文件），您应该手动包含标题。\n\n由于我这里是只实现头文件，并且没有在任何地方包含这个头文件，所以你即便是重新加载缓存也没有用，需要你在其他地方 include 这个头文件才可以。这个时候你再重新更新缓存，Clion 就能识别到这个头文件，也不会出现那个提示了。","tags":["Clion"],"categories":["technology"]},{"title":"Clion远程Linux找不到第三方库头文件？","url":"/2024/10/01/Clion远程Linux找不到第三方库头文件？/","content":"\nClion 远程连接 Linux没有问题，并且早先已经在 Linux编译安装 Boost 库，但是 Clion 这边没有代码提示，原因是没有找到头文件。也就是 Clion 没有把 远端的 Boost 库的头文件下载下来，但明显我们的 Boost 库的头文件就是在 /usr/include 下面的。\n\n解决方案：https://www.cnblogs.com/ryzemagic/p/16930646.html\n\n## 找不到头文件 但是可以编译 但不能补全代码\n\n尝试 Tools（工具） | Resync with Remote Hosts（与远程主机重新同步） \n\n![boostHead.png](/images/2024/10/01/9d545e00-7fa8-11ef-a78b-0f8f664f475f.png)\n\n## 远程运行程序时提示找不到库文件，并且不能编译\n\n查看 CMakeList.txt 文件中链接库是否配置正确。\n\n关于如何找到库文件，请看此文：[CMake 找库文件的两种方式](https://xiaoyangst.github.io/2024/09/20/第六章：CMake-找库文件的两种方式/)\n\n","tags":["Clion"],"categories":["technology"]},{"title":"RDB 持久化","url":"/2024/10/01/RDB-持久化/","content":"\n<!-- toc -->\n\n前面介绍的 AOF 是存储操作指令，而 RDB 是存储二进制数据。\n\n我不知道你有没有使用过 Vmware 的虚拟机快照，它就是记录一瞬间的状态，从这个瞬间到此前的所有全部都保存下来。尽管这是一瞬间的定格，但是占用的空间也是相当不小，所以拍摄的快照越多，占用的磁盘空间也会很大，但是却不会比虚拟机本身大，甚至要小很多。\n\n所以，RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。\n\n因此，在 Redis 恢复数据时，RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不用像 AOF 那样通过执行命令来恢复数据，明显多个步骤。\n\n## ROD 原理\n\nRedis 提供两个命令来生成 RDB 文件，分别是 save 和 bgsave，区别就在于是否在【主线程】执行：\n\n- save 会在主线程执行，由于 Redis 执行命令也是在主线程，save 就会阻塞主线程，这并不好。\n- bgsave 不会在主线程，而是会创建一个子进程去生成 RDB 文件，这样就可以避免阻塞主线程。\n\nRedis 是【全量快照】，也就是说每次执行快照，都是把内存中【所有数据】都记录到磁盘中，这就和前面我讲虚拟机快照一个道理。\n\n所以可以认为，执行快照是一个比较重的操作（因为内存中的命令越来越多），如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。通常可能设置至少5分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失5分钟数据。\n\n这就是 RDB 快照的缺点，在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少。\n\n## 执行快照时，数据能否被修改？\n\n执行 bgsave 过程中，Redis 依然可以继续处理操作命令，毕竟主线程也没有被阻塞，还是可以修改数据的（执行写命令）。\n\n如果共享的数据（父子进程没有修改数据，会共享同一块物理内存）没有被修改，那么正常写入到 RDB 文件中。如果有修改，修改者重新分配一块物理内存，这块被修改的物理内存的数据将不会被写入 RDB 文件中，只能等到下一次 启动 bgsave 才有机会写入 RDB 文件中了。\n\n如果机器突然崩溃，内存的数据全部丢失，意味着最新的数据没有被保存到 RDB 文件中，我们还指望下一次再把最新的数据写入 到 RDB 文件中，也成一场幻梦了。\n\n再有，父子进程共享同一块物理内存时，父进程把这些物理内存的数据全修改了，那么内存就是原先的两倍（父子各占一份）。而这些内容又不会在本次写入 RDB 文件中，如果反复如此，没有一次会写入 RDB 文件中，这是一种极端情况的考虑。\n\n## ROD 和 AOF 混合\n\nROD 和 AOF 各有优缺点，如果能将两个优点结合将再好不过了。\n\n![混合.png](/images/2024/10/01/22153b90-7f9b-11ef-ae18-0f309765e4c5.png)\n\n当开启混合持久化，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录到重写缓冲区，重写缓冲区的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的 AOF 文件。\n\n前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。当 Redis 重启加载数据时，先加载 RDB 内容，这个地方会很快。后续的内容是后台子进程重写 AOF 期间主线程执行的写命令，可以使得数据更少的丢失。\n\n---\n\n⭐️内容取自《小林Coding》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议访问[官方网站](https://xiaolincoding.com/)。","tags":["Redis"],"categories":["technology"]},{"title":"AOF持久化","url":"/2024/09/30/AOF持久化/","content":"\n<!-- toc -->\n\n## AOF 日志\n\n![存储写命令的流程.png](/images/2024/09/30/1f673860-7f34-11ef-808b-3d65a27dc1d6.png)\n\nRedis 日志中只需要存储写命令，不需要存储读命令，因为读命令不会对数据进行修改，没有存储价值。\n\nRedis 存储写命令的时候，会优先写入内存中，接下来才会写入磁盘。内存中的数据访问快，但是如果机器关机，里面存储的数据立马清空；磁盘中的数据访问就比内存慢许多，但存储的数据是持久化的，不会因为计算机重启导致数据丢失。\n\nRedis 并非直接就把用户发送的写命令直接存储起来，而是要先执行用户的指令，如果出现错误将不会存储。这样提前检查命令的可行性，能够保证存储的写命令必然是正确可行，后续无需承担检查命令是否可行的成本。再有一个好处是不会阻塞当前写命令的执行，毕竟只有成功执行写命令之后才有可能写入日志，先后顺序保证着不会阻塞当前写命令的执行。\n\n先执行命令，再写入日志的这两个操作是在主线程中同步执行，只有这两个动作全部完成，才可以继续下一个命令执行和写入日志的操作。\n\n![同步执行.png](/images/2024/09/30/1a88e1e0-7f34-11ef-808b-3d65a27dc1d6.png)\n\n那么先写入内存，再写入磁盘的这种简单机制肯定是存在问题的：\n\n1. 如果写入内存之后，还没有来得及写入磁盘，机器宕机，那就意味着刚刚写入内存的指令会丢失。\n2. 写操作成功执行才写入 AOF 日志，不会阻塞主线程，但是下一个命令的执行被阻塞了，因为执行命令和写入日志是同步执行。\n\n如果在将日志内容写入到磁盘时，服务器的硬盘的I/O压力太大，就会导致写磁盘的速度很慢，进而阻塞住了，也就会导致后续的命令无法执行。\n\n你还发现，问题就卡在【写入磁盘】这个位置，这个写入的时机很重要，下面谈一谈三种写回策略。\n\n## 三种写回策略\n\n三种写回策略，对应两个极端，一个折中，太经典的思考方式了。没有谁对谁错，各有各自的应用场景。如果你熟悉 [Linux文件操作](https://xiaoyangst.github.io/2024/09/26/Linux%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/)中 如何把一个文件写入到磁盘的过程，你并不会对 Redis 的写入策略有何惊叹，别无二致。\n\nLinux 把要写入的数据先写到（fwrite） 用户态缓冲区，用户缓冲区再把里面的数据拷贝（fflush）到内核态缓冲区，内核缓冲区再把数据写入（fsync）磁盘。如果你不调用 fsync 的话，将会由内核自己决定写入时机，否则立即写入磁盘。\n\n![fflsh和fsync区别.png](/images/2024/09/30/14898b00-7f34-11ef-808b-3d65a27dc1d6.png)\n\n尽管 Redis 写入日志的过程与之极其相似，但还是有必要阐述流程和绘制图形，以便后续逻辑的展开。\n\n1. Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区。\n2. 然后通过 write 系统调用，将 server.aof_buf 缓冲区 的数据写入到 AOF 文件中，此时的数据并没有写入到磁盘，而是拷贝到内核缓冲区中，等待内核自行决定何时写入磁盘，当然也可以调用 fsync 让内核立即写入磁盘。\n\n![Redis写入日志.png](/images/2024/09/30/105a8750-7f34-11ef-808b-3d65a27dc1d6.png)\n\nRedis 有三种写入磁盘的策略：两个极端一个折中\n\n- Always：数据拷贝到内核后，立即写入磁盘。很大程度上保证数据的不丢失，但是如此频繁的写入磁盘会影响到主线程性能。\n- No：数据拷贝到内核后，由内核自行决定写入磁盘时机。对数据的持久性没有太大的保障，完全看内核的心情，但是性能要好很多。\n- Everysec：数据拷贝到内核后，每秒写入一次磁盘。算是一种折中策略，性能和数据的保障介于上面二者之间。\n\n![总结.png](/images/2024/09/30/0b1c5d90-7f34-11ef-808b-3d65a27dc1d6.png)\n\n## AOF 重写机制\n\nAOF 日志本质上就是一个文件，里面记录 Redis 执行的写命令，可是伴随着命令越来越多，文件也会越来越大，因此Redis 提供重写机制。\n\n对于同一个 key，但是有着多个修改 value 的指令，那么就应该存储最后一个写指令（修改指令），因为前面的数据可以被视为无效数据了。这样就起到压缩作用了。\n\n![重写.png](/images/2024/09/30/06c55f80-7f34-11ef-808b-3d65a27dc1d6.png)\n\nAOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到【新的 AOF 文件中】，等到全部记录完后，就将新的 AOF 文件替换掉之前的 AOF 文件。\n\n你可能会问，为什么不复用旧的 AOF 文件（即后面压缩的指令从旧的 AOF 文件开头进行覆盖，而不用新创建 AOF 文件），而是写入到一个新的 AOF 文件，然后再进行替换呢？我不知道你有没有用过 realloc 函数，它用来调整空间的大小，如果失败就会返回 NULL。很多人在使用的时候，会像下面这样：\n\n```c\np = (int *)realloc(p, 10 * sizeof(int));\n```\n\n如果 realloc 创建成功会返回内存的首地址，可是你保不准会创建失败，你这个时候就把 源数据 p 用来接收返回值，那不是有把源数据污染的可能吗？你应该创建一个临时指针变量来接收返回值，再判断返回值没有问题之后，再赋值给源数据 p。\n\n回到这里来，如果我们再重写的过程中，机器出现问题，我原有的 AOF 文件亦不会有损。等到我真的压缩成功之后，再删除原来的 AOF 文件也不迟。\n\n## AOF 后台重写\n\nAOF 重写是对大文件进行操作，是个相当耗时的操作，绝不可让它在主线程中执行，否则性能大大降低。Redis 是把这个工作交给子**进程** bgrewriteaof 来完成的，这样主线程和子线程互不干扰，各司其职。\n\n特别注意是进程，而不是线程，因为进程要比线程稳定，还不用考虑多线程下的并发问题。子进程会拷贝父进程的页表等数据结构，会在发生写操作的时候，触发【写时复制】。那么这里就有个问题，如果父进程的物理页很大怎么办？\n\n其中有两个阶段会导致阻塞父进程：\n\n- 创建子进程，子进程会复制父进程的页表等数据结构，尽管共享的同一块物理内存。页表等内容越大，阻塞时间越长。\n- 触发写时复制，子进程会拷贝修改部分的物理内存出来，得到属于自己的物理内存，未修改部分继续和父进程共享。拷贝的内存越大，阻塞时间越长。\n\n触发重写机制后，主线程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据（即共享的数据），并逐一把内存数据的键值对转换成一条命令（压缩），再将命令记录到重写日志（新的 AOF 文件）。\n\n但我们现在要明确如下两个观点：\n\n- 写时复制只会把修改的那块内存复制一份出来，其余没有修改的部分父子进程继续共享。\n- 主进程可以继续执行命令和写入内存，子进程 bgrewriteaof  的任务就是执行重写机制。\n\n那么这里就有几个问题：\n\n- 写时复制的时候，如果这个阶段修改的是一个 bigkey，也就是数据量比较大的 key-value 的时候，这时复制的物理内存数据的过程会比较耗时，有阻塞主进程的风险。\n- 子进程在重写，但是主进程又写入新的指令，并且还是已重写中的一个指令，这就导致数据不是最新的，出现数据不一致的问题。\n\nRedis 为了解决数据不一致性问题，设置了一个 AOF 重写缓冲区，这个缓冲区在创建 bgrewriteaof  子进程之后开始使用。在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会同时将这个写命令写入到【AOF缓冲区】和【AOF重写缓冲区】。\n\n![重写缓冲区.png](/images/2024/09/30/012fee00-7f34-11ef-808b-3d65a27dc1d6.png)\n\n在子进程 bgrewriteaof 执行 AOF 重写期间，主进程要执行下面三个任务：\n\n1. 执行客户端发来的命令。\n2. 将执行后的写命令追加到【AOF 缓冲区】。\n3. 将执行后的写命令追加到【AOF 重写缓冲区】。\n\n1 和 2 的操作是之前就有，即 执行命令和写入日志。3 是为了解决一致性问题新加入的缓冲区，并且只会在子进程 bgrewriteaof 执行 AOF 重写期间有存在的必要。当子进程完成 AOF 重写工作后，会向主进程发生一条信号（进程间通信的方式，且是异步）。\n\n主进程收到信号后，会调用信号处理函数，这个期间主线程阻塞，即不允许再执行指令和写入指令操作，否则每次都无法保证数据的一致性。整个流程如下：\n\n- 将 AOF 重写缓冲区中的所有内容追加到 刚刚的 AOF 的文件中（也就是最新的 AOF 文件），使得新旧两个 AOF 文件所保存的数据库状态一致（解决一致性问题）。\n- 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件（保持最新的数据状态，所以覆盖现有的）。\n\n信号函数执行完成后，主进程就可以继续像往常一样处理命令了。\n\n在整个 AOF 后台重写过程中，除了发生写时复制会对主进程造成阻塞，还有信号处理函数执行时也会对主进程造成阻塞，在其他时候，AOF 后台重写都不会阻塞主线程。\n\n---\n\n⭐️内容取自《小林Coding》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议访问[官方网站](https://xiaolincoding.com/)。","tags":["Redis"],"categories":["technology"]},{"title":"入门微服务","url":"/2024/09/29/入门微服务/","content":"\n<!-- toc -->\n\n## 微服务简介\n\n我们暂时不去考虑复杂的架构，仅仅以讲清楚什么是微服务为目的，因为拆分成微服务最为敏感的就是数据库，但我们暂时不考虑这个问题。\n\n下面给出微服务的定义：由单一应用程序构成的小服务，拥有自己的进程与轻量化处理，服务依业务功能设计，以全自动的方式部署，与其他服务使用 HTTP API 通讯。同时，服务会使用最小规模的集中管理 （例如 Docker）技术，服务可以用不同的编程语言与数据库等。  \n\n### 单体应用\n\n早些年，各大互联网公司的应用技术栈大致可分为 LAMP和 MVC两大流派。无论是 LAMP 还是MVC，都是为单体应用架构设计的，其优点是学习成本低，开发上手快，测试、部署、运维也比较方便，甚至一个人就可以完成一个网站的开发与部署。\n\n![单体服务.png](/images/2024/09/29/329a7cd0-7e30-11ef-abda-0dceb9679f79.png)\n\n### 服务化\n\n互联网早期肯定没有问题，但随着网民增多，流量越来越大，这种架构方式肯定不可取，它的耦合度实在太高了。将功能模块进行拆分，独立成一个服务进行部署，这样可以让各团队只负责好自己的模块。\n\n为此，首先可以把用户模块从单体应用中拆分出来，独立成一个服务部署，以 **RPC** 接口的形式对外提供服务。微博和消息模块调用用户接口，就从进程内的调用变成远程 RPC 调用。这样，用户模块就可以独立开发、测试、上线和运维，可以交由专门的团队来做，与主模块不耦合。进一步的可以再把消息模块也拆分出来作为独立的模块，交由专门的团队来开发和维护。  \n\n![服务化.png](/images/2024/09/29/367ff460-7e30-11ef-abda-0dceb9679f79.png)\n\n### 微服务\n\n微服务就是把服务化继续进行更粒度的拆分，这得益于以 Docker 为代表的容器化技术的成熟以及 DevOps 文化的兴起。\n\n进一步对内容模块的功能进行拆分，比如内容模块又包含了 Feed 模块、评论模块和个人页模块。通过微服务化，将这三个模块变成三个独立的服务，每个服务依赖各自的资源，并独立部署在不同的服务池中，可以由不同的开发人员进行维护。当评论服务需求变更时，只需要修改评论业务相关的代码，并独立上线发布；而 Feed 服务和个人页服务不需要变更，也不会受到发布可能带来的变更影响。\n\n![微服务化.png](/images/2024/09/29/3ae4fc30-7e30-11ef-abda-0dceb9679f79.png)\n\n## 从单体应用走向服务化\n\n### 什么时候进行服务化拆分？\n\n项目第一阶段的主要目标是快速开发和验证想法，证明产品思路是否可行。这个阶段功能设计一般不会太复杂，开发采取快速迭代的方式，架构也不适合过度设计。所以将所有功能打包部署在一起，集中地进行开发、测试和运维，对于项目起步阶段，是最高效也是最节省成本的方式。当可行性验证通过，功能进一步迭代，就可以加入越来越多的新特性。\n\n根据实际项目经验，一旦单体应用同时进行开发的人员超过 10 人，就会遇到上面的问题，这个时候就该考虑进行服务化拆分了。\n\n### 服务化拆分的两种姿势\n\n实际生产中，下面两种划分方式是结合应用的。\n\n纵向划分：从业务维度进行拆分。标准是按照业务的关联程度来决定，关联比较密切的业务适合拆分为一个微服务，而功能相对比较独立的业务适合单独拆分为一个微服务。\n\n横向划分：从公共且独立功能维度拆分。标准是按照是否有公共的被多个其他服务调用，且依赖的资源独立不与其他业务耦合。\n\n以社交 App 举例，无论是首页信息流、评论、消息箱还是个人主页，都需要显示用户的昵称。假如用户的昵称功能有产品需求的变更，你需要上线几乎所有的服务，这个成本就有点高了。显而易见，如果我把用户的昵称功能单独部署成一个独立的服务，那么有什么变更我只需要上线这个服务即可，其他服务不受影响，开发和上线成本就大大降低了。\n\n## 初探微服务架构\n\n![微服务架构.png](/images/2024/09/29/2d61aa40-7e30-11ef-abda-0dceb9679f79.png)\n\n首先服务提供者（就是提供服务的一方）**按照一定格式**的服务描述，**向注册中心注册**服务，声明自己能够提供哪些服务以及服务的地址是什么，完成服务发布。\n\n接下来服务消费者（就是调用服务的一方）**请求注册中心**，查询所需要调用服务的地址，然后**以约定的通信协议向服务提供者发起请求**，得到请求结果后再按照约定的协议解析结果。\n\n而且在服务的调用过程中，服务的请求耗时、调用量以及成功率等指标都会被记录下来用作监控，调用经过的链路信息会被记录下来，用于故障定位和问题追踪。在这期间，如果调用失败，可以通过重试等服务治理手段来保证成功率。\n\n（一）服务描述\n\n服务调用首先要解决的问题就是服务如何对外描述。比如，你对外提供了一个服务，那么这个服务的服务名叫什么？调用这个服务需要提供哪些信息？调用这个服务返回的结果是什么格式的？该如何解析？这些就是服务描述要解决的问题。如果你写过网络库和业务代码（比方说聊天服务器）就应该能明白这个含义。\n\n常见的方式有：RESTful API、XML 配置以及 IDL 文件三种。\n\n（二）注册中心\n\n一般来讲，注册中心的工作流程是：\n\n1. 服务提供者在启动时，根据服务发布文件中配置的发布信息向注册中心注册自己的服务。\n2. 服务消费者在启动时，根据消费者配置文件中配置的服务信息向注册中心订阅自己所需要的服务。\n3. 注册中心返回服务提供者地址列表给服务消费者。\n4. 当服务提供者发生变化，比如有节点新增或者销毁，注册中心将变更通知给服务消费者。\n\n（三）服务框架\n\n通过注册中心，服务消费者就可以获取到服务提供者的地址，有了地址后就可以发起调用。但在发起调用之前你还需要解决以下几个问题：\n\n- 服务通信采用什么协议？\n- 数据传输采用什么方式？\n- 数据压缩采用什么格式？\n\n这是一个网络库应该去考虑的问题，即主机间互相通信的问题。\n\n（四）服务监控\n\n一旦服务消费者与服务提供者之间能够正常发起服务调用，你就需要对调用情况进行监控，以了解服务是否正常。通常来讲，服务监控主要包括三个流程：\n\n1. 指标收集。就是要把每一次服务调用的请求耗时以及成功与否收集起来，并上传到集中的数据处理中心。\n2. 数据处理。有了每次调用的请求耗时以及成功与否等信息，就可以计算每秒服务请求量、平均耗时以及成功率等指标。\n3. 数据展示。数据收集起来，经过处理之后，还需要以友好的方式对外展示，才能发挥价值。通常都是将数据展示在 Dashboard 面板上，并且每隔 10s 等间隔自动刷新，用作业务监控和报警等。\n\n这让我想到 Prometheus，它已经普遍被应用起来。\n\n（五）服务追踪\n\n除了需要对服务调用情况进行监控之外，你还需要记录服务调用经过的每一层链路，以便进行问题追踪和故障定位。服务追踪的工作原理大致如下：\n\n1. 服务消费者发起调用前，会在本地按照一定的规则生成一个 requestID，发起调用时，将 requestID 当作请求参数的一部分，传递给服务提供者。\n2. 服务提供者接收到请求后，记录下这次请求的 requestID，然后处理请求。如果服务提供者继续请求其他服务，会在本地再生成一个自己的 requestID，然后把这两个 requestID 都当作请求参数继续往下传递。\n\n以此类推，通过这种层层往下传递的方式，一次请求，无论最后依赖多少次服务调用、经过多少服务节点，都可以通过最开始生成的 requestID 串联所有节点，从而达到服务追踪的目的。\n\n（六）服务治理\n\n服务监控能够发现问题，服务追踪能够定位问题所在，而解决问题就得靠服务治理了。服务治理就是通过一系列的手段来保证在各种意外情况下，服务调用仍然能够正常进行。\n\n## 发布和引用服务\n\n（一）RESTful API\n\n主要被用作 HTTP 或者 HTTPS 协议的接口定义，即使在非微服务架构体系下，也被广泛采用。\n\n因为 HTTP 协议本身是一个公开的协议，对于服务消费者来说几乎没有学习成本，所以比较适合用作跨业务平台之间的服务协议。比如你有一个服务，不仅需要在业务部门内部提供服务，还需要向其他业务部门提供服务，甚至开放给外网提供服务，这时候采用 HTTP 协议就比较合适，也省去了沟通服务协议的成本。\n\n（二）XML 配置\n\n这种方式的服务发布和引用主要分三个步骤：\n\n1. 服务提供者定义接口，并实现接口。\n2. 服务提供者进程启动时，通过加载 server.xml 配置文件将接口暴露出去。\n3. 服务消费者进程启动时，通过加载 client.xml 配置文件来引入要调用的接口。\n\n一般是私有 RPC 框架会选择 XML 配置这种方式来描述接口，因为私有 RPC 协议的性能要比 HTTP 协议高，所以在对性能要求比较高的场景下，采用 XML 配置的方式比较合适。但这种方式对业务代码侵入性比较高，XML 配置有变更的时候，服务消费者和服务提供者都要更新，所以适合公司内部联系比较紧密的业务之间采用。如果要应用到跨部门之间的业务调用，一旦有 XML 配置变更，需要花费大量精力去协调不同部门做升级工作。\n\n（三）IDL 配置\n\n即 Grpc + Protobuf 常用组合方式。\n\ngRPC 协议的服务描述是通过 proto 文件来定义接口的，然后再使用 protoc 来生成不同语言平台的客户端和服务端代码，从而具备**跨语言**服务调用能力。\n\n有一点特别需要注意的是，在描述接口定义时，IDL 文件需要对接口返回值进行详细定义。如果接口返回值的字段比较多，并且经常变化时，采用 IDL 文件方式的接口定义就不太合适了。一方面可能会造成 IDL 文件过大难以维护，另一方面只要 IDL 文件中定义的接口返回值有变更，都需要同步所有的服务消费者都更新，管理成本就太高了。\n\n## 注册和发现服务\n\n注册中心可以说是实现服务化的关键，因为服务化之后，服务提供者和服务消费者不在同一个进程中运行，实现了解耦，这就需要一个纽带去连接服务提供者和服务消费者，而注册中心就正好承担了这一角色。此外，服务提供者可以任意伸缩即增加节点或者减少节点，通过服务健康状态检测，注册中心可以保持最新的服务节点信息，并将变化通知给订阅服务的服务消费者。\n\n## RPC远程服务调用\n\n把服务消费者叫作客户端，服务提供者叫作服务端，两者通常位于网络上两个不同的地址，要完成一次 RPC 调用，就必须先建立网络连接。建立连接后，双方还必须按照某种约定的协议进行网络通信，这个协议就是通信协议。双方能够正常通信后，服务端接收到请求时，需要以某种方式进行处理，处理成功后，把请求结果返回给客户端。为了减少传输的数据大小，还要对数据进行压缩，也就是对数据进行序列化。\n\nRPC 就是基于网络库规定通信的格式的协议，格式通常就是服务调用的规则。\n\n## 监控微服务调用\n\n搭建一个服务监控系统，涉及数据采集、数据传输、数据处理、数据展示等多个环节，Prometheus 已经包含这些内容。因此，后续会出一个这块专题的教程。\n\n## 追踪微服务调用\n\n### 服务追踪的作用\n\n（一）优化系统瓶颈\n\n通过记录调用经过的每一条链路上的耗时，我们能快速定位整个系统的瓶颈点在哪里。比如你访问微博首页发现很慢，肯定是由于某种原因造成的，有可能是运营商网络延迟，有可能是网关系统异常，有可能是某个服务异常，还有可能是缓存或者数据库异常。通过服务追踪，可以从全局视角上去观察，找出整个系统的瓶颈点所在，然后做出针对性的优化。\n\n（二）优化链路调用\n\n通过服务追踪可以分析调用所经过的路径，然后评估是否合理。比如一个服务调用下游依赖了多个服务，通过调用链分析，可以评估是否每个依赖都是必要的，是否可以通过业务优化来减少服务依赖。\n\n还有就是，一般业务都会在多个数据中心都部署服务，以实现异地容灾，这个时候经常会出现一种状况就是服务 A 调用了另外一个数据中心的服务 B，而没有调用同处于一个数据中心的服务 B。\n\n（三）生成网络拓扑\n\n通过服务追踪系统中记录的链路信息，可以生成一张系统的网络调用拓扑图，它可以反映系统都依赖了哪些服务，以及服务之间的调用关系是什么样的，可以一目了然。除此之外，在网络拓扑图上还可以把服务调用的详细信息也标出来，也能起到服务监控的作用。\n\n（四）透明传输数据\n\n除了服务追踪，业务上经常有一种需求，期望能把一些用户数据，从调用的开始一直往下传递，以便系统中的各个服务都能获取到这个信息。比如业务想做一些 A/B 测试，这时候就想通过服务追踪系统，把 A/B 测试的开关逻辑一直往下传递，经过的每一层服务都能获取到这个开关值，就能够统一进行 A/B 测试。\n\n### 服务追踪系统的实现原理\n\n![服务追踪原理.png](/images/2024/09/29/2552fb60-7e30-11ef-abda-0dceb9679f79.png)\n\n- traceId：用于标识某一次具体的请求 ID。当用户的请求进入系统后，会在 RPC 调用网络的第一层生成一个全局唯一的 traceId，并且会随着每一层的 RPC 调用，不断往后传递，这样的话通过 traceId 就可以把一次用户请求在系统中调用的路径串联起来。\n- spanId：用于标识一次 RPC 调用在分布式请求中的位置。当用户的请求进入系统后，处在 RPC 调用网络的第一层 A 时 spanId 初始值是 0，进入下一层 RPC 调用 B 的时候spanId 是 0.1，继续进入下一层 RPC 调用 C 时 spanId 是 0.1.1，而与 B 处在同一层的RPC 调用 E 的 spanId 是 0.2，这样的话通过 spanId 就可以定位某一次 RPC 请求在系统调用中所处的位置，以及它的上下游依赖分别是谁。\n- annotation：用于业务自定义埋点数据，可以是业务感兴趣的想上传到后端的数据，比如一次请求的用户 UID。\n\n上面这三段内容用通俗语言再给小结一下：traceId 是用于串联某一次请求在系统中经过的所有路径，spanId 是用于区分系统不同服务之间调用的先后关系，而 annotation 是用于业务自定义一些自己感兴趣的数据，在上传 traceId 和 spanId 这些基本信息之外，添加一些自己感兴趣的信息。\n\n## 微服务常见的治理手段\n\n### 节点管理\n\n服务调用失败一般是由两类原因引起的，一类是服务提供者自身出现问题，如服务器宕机、进程意外退出等；一类是网络问题，如服务提供者、注册中心、服务消费者这三者任意两者之间的网络出现问题。\n\n无论是服务提供者自身出现问题还是网络发生问题，都有两种节点管理手段：\n\n（一）注册中心主动摘除机制\n\n这种机制要求服务提供者定时的主动向注册中心汇报心跳，注册中心根据服务提供者节点最近一次汇报心跳的时间与上一次汇报心跳时间做比较，如果超出一定时间，就认为服务提供者出现问题，继而把节点从服务列表中摘除，并把最近的可用服务节点列表推送给服务消费者。\n\n（二）服务消费者摘除机制\n\n虽然注册中心主动摘除机制可以解决服务提供者节点异常的问题，但如果是因为注册中心与服务提供者之间的网络出现异常，最坏的情况是注册中心会把服务节点全部摘除，导致服务消费者没有可用的服务节点调用，但其实这时候服务提供者本身是正常的。所以，将存活探测机制用在服务消费者这一端更合理，如果服务消费者调用服务提供者节点失败，就将这个节点从内存中保存的可用服务提供者节点列表中移除。\n\n### 负载均衡\n\n一般情况下，服务提供者节点不是唯一的，多是以集群的方式存在，尤其是对于大规模的服务调用来说，服务提供者节点数目可能有上百上千个。由于机器采购批次的不同，不同服务节点本身的配置也可能存在很大差异，新采购的机器 CPU 和内存配置可能要高一些，同等请求量情况下，性能要好于旧的机器。对于服务消费者而言，在从服务列表中选取可用节点时，如果能让配置较高的新机器多承担一些流量的话，就能充分利用新机器的性能。这就需要对负载均衡算法做一些调整。\n\n### 服务路由\n\n对于服务消费者而言，在内存中的可用服务节点列表中选择哪个节点不仅由负载均衡算法决定，还由路由规则确定。所谓的路由规则，就是通过一定的规则如条件表达式或者正则表达式来限定服务节点的选择范围。\n\n为什么要制定路由规则呢？主要有两个原因：\n\n- 业务存在灰度发布的需求。比如，服务提供者做了功能变更，但希望先只让部分人群使用，然后根据这部分人群的使用反馈，再来决定是否做全量发布。这个时候，就可以通过类似按尾号进行灰度的规则限定只有一定比例的人群才会访问新发布的服务节点。\n- 多机房就近访问需求。\n\n### 服务容错\n\n服务调用并不总是一定成功的，前面我讲过，可能因为服务提供者节点自身宕机、进程异常退出或者服务消费者与提供者之间的网络出现故障等原因。对于服务调用失败的情况，需要有手段自动恢复，来保证调用成功。常用的手段主要有以下几种：\n\n- FailOver：失败自动切换。就是服务消费者发现调用失败或者超时后，自动从可用的服务节点列表总选择下一个节点重新发起调用，也可以设置重试的次数。这种策略要求服务调用的操作必须是幂等的，也就是说无论调用多少次，只要是同一个调用，返回的结果都是相同的，一般适合服务调用是读请求的场景。\n- FailBack：失败通知。就是服务消费者调用失败或者超时后，不再重试，而是根据失败的详细信息，来决定后续的执行策略。比如对于非幂等的调用场景，如果调用失败后，不能简单地重试，而是应该查询服务端的状态，看调用到底是否实际生效，如果已经生效了就不能再重试了；如果没有生效可以再发起一次调用。\n- FailCache：失败缓存。就是服务消费者调用失败或者超时后，不立即发起重试，而是隔一段时间后再次尝试发起调用。比如后端服务可能一段时间内都有问题，如果立即发起重试，可能会加剧问题，反而不利于后端服务的恢复。如果隔一段时间待后端节点恢复后，再次发起调用效果会更好。\n- FailFast：快速失败。就是服务消费者调用一次失败后，不再重试。实际在业务执行时，一般非核心业务的调用，会采用快速失败策略，调用失败后一般就记录下失败日志就返回了。\n\n---\n\n⭐️内容取自极课时间《从0开始学微服务》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议购买原课程。","tags":["微服务"],"categories":["technology"]},{"title":"Linux进程","url":"/2024/09/28/Linux进程/","content":"\n<!-- toc -->\n\n## 获取子进程和父进程的PID\n\n```c++\npid_t getpid(void);\t// 当前进程 ID\n\npid_t getppid(void); // 父进程 ID\n```\n\n## fork--创建一个子进程\n\n```c++\npid_t fork(void);\n\n// 成功：父进程返回子进程的 pid；子进程返回 0\n// 失败：父进程返回 -1，不会创建子进程，并且设置 errno\n```\n\n当 fork 成功返回，父子进程就创建成功了。但是，关于 fork 这个方法要讲得东西还是蛮多的，下面逐一介绍：\n\n（一）父子进程的创建遵循写时复制\n\n```c\nvoid Demo(){\n  int public_var = 10;\n  pid_t pid = fork();\n  switch (pid) {\n    case -1:\n      perror(\"Fork failed\");\n      exit(1);\n    case 0: // Child process\n      public_var = 20;\n      printf(\"Child process: public_var = %d\\n\", public_var);\n      break;\n    default: // Parent process\n      sleep(3);\n      printf(\"Parent process: public_var = %d\\n\", public_var);\n      break;\n  }\n}\n/*\nChild process: public_var = 20\nParent process: public_var = 10\n*/\n```\n\n在这个程序中，可以让父进程睡眠 3s ，让子进程有机会修改 public_var 变量。如果父进程输出结果为 20，说明父子进程共享变量；如果父进程输出结果为 10，说明父子进程不共享变量。\n\n子进程创建成功，此时父子进程是共用物理内存页的，对应下图中左半部分。可是当子进程开始修改对应物理页的数据，就会触发这块被修改的物理页写时复制机制（没有修改的物理页继续共享，谁修改谁拥有一块新的物理页并脱离原来的物理页），对应下图中右半部分。这就合理解释上述变量变与不变的现象了。\n\n![父子进程.png](/images/2024/09/28/5a41a110-7d9e-11ef-b348-95e5e18530fa.png)\n\n（二）fork 与 用户态缓冲区的数据\n\n![fork与缓冲区.png](/images/2024/09/28/3834e4b0-7d9e-11ef-b348-95e5e18530fa.png)\n\n代码 A 和 代码 B 唯一的代码不同是 第一行的输出一个有换行符，一个没有换行符。\n\n我们前面学习到，printf 函数是行缓冲区，即遇到换行符才会清空缓冲区。由于代码 A 没有换行符，导致用户态文件缓冲区中留有数据，那么 fork() 时，这部分数据也会复制，并且父子进程各自拥有自己的副本。\n\n用两道面试题检验你：\n\n```c++\nvoid Demo(){\n  for(int i = 0; i < 3; i++){\n    pid_t pid = fork();\n    printf(\"a\");\n  }\n}\n// 24 个 a，缓存到最后才会输出。缓存 3 个 a，最后有8个进程，所以 3 * 8 = 24\n\nvoid Demo(){\n  for(int i = 0; i < 3; i++){\n    pid_t pid = fork();\n    printf(\"a\\n\");\n  }\n}\n\n// 14 个 a，直接打印。第一次有两个进程，所以打印 2 个 a；第一次有死个进程，所以打印 4 个 a；第一次有八个进程，所以打印 8 个 a；合起来，就是 14 个 a\n```\n\n（三）父子进程的文件描述符\n\nfork() 时，子进程会复制父进程的 PCB ，其中 PCB 中含有打开的文件描述符列表。因此，父子进程拥有各自的打开文件描述符列表。但是，它们共享同一个打开文件。\n\n所以，当你父进程修改文件偏移量，子进程同样受影响，尽管它们是不同的文件描述符，但是指向相同的文件。\n\n![文件描述符.png](/images/2024/09/28/f0ccb620-7d9d-11ef-b348-95e5e18530fa.png)\n\n下面看代码示例：\n\n```c++\nvoid Demo() {\n  int fd = open(\"demo.txt\", O_RDWR | O_CREAT | O_TRUNC, 0666);\n  printf(\"public pos: %ld\\n\", lseek(fd, 0, SEEK_CUR));\n\n  pid_t pid = fork();\n\n  int newfd;\n  switch (pid) {\n    case -1:\n      perror(\"Fork failed\");\n      exit(1);\n    case 0: // Child process\n      write(fd,\"Hello world\\n\", 11);\n      close(STDERR_FILENO);\n      newfd = dup(fd);\n      printf(\"Child process: newfd = %d\\n\", newfd);\n      break;\n    default: // Parent process\n      sleep(2);\n      printf(\"parent pos: %ld\\n\", lseek(fd, 0, SEEK_CUR));\n      newfd = dup(fd);\n      printf(\"Parent process: newfd = %d\\n\", newfd);\n      break;\n  }\n}\n/*\npublic pos: 0\nChild process: newfd = 2\nparent pos: 11\nParent process: newfd = 4\n*\n```\n\n让父进程休眠 2s，以让子进程修改偏移量。如果最后父进程文件描述符的偏移量为 0 表明不会被子进程影响，如果不是就代表子进程和父进程虽然是不同的文件描述符，但是指向同一个文件，互相影响。\n\n## 终止进程\n\n### 正常终止\n\n（一）_exit\n\n```c++\nvoid _exit(int status);\n```\n\nstatus 表示程序的终止状态，父经常可以调用 wait() 获取该状态。\n\n（二）exit\n\n程序一般不会直接调用 _exit() ，而是调用库函数 exit() ，它会在调用 _exit() 前执行各种动作。\n\n```c++\nvoid exit(int status);\n```\n\n执行动作如下：\n\n1. 调用退出处理程序 (通过 atexit() 和 on_exit() 注册的函数)，其执行顺序与注册顺序相反。\n2. 刷新 stdio 流缓冲区。\n3. 将 status 作为参数，调用 _exit() 系统调用。\n\n退出处理函数由用户事先注册，当进程调用 exit() 正常终止时，会自动执行事先注册的退出处理函数。\n\n```c++\nint atexit(void (*function)(void));\n\nint on_exit(void (*function)(int , void *), void *arg);\t// 可以传递进程 状态（status）\n```\n\n它们的第一个参数就是用来提交的回调函数，并且可以提交多个回调函数，但是函数列表被执行是按照注册的顺序的相反顺序来执行。\n\n### 异常终止\n\n```c++\nvoid abort(void);\n```\n\n会给调用进程 (自己) 发送 SIGABRT 信号，该信号会导致进程终止，并**产生 core 文件**。\n\n## 监控子进程\n\n孤儿进程是父进程先于子进程结束的一种状态，但是不会对操作系统造成危害，因为会有 init 进程托管。\n\n僵尸进程是子进程结束但是附近成没有感知到的一种状态，这种状态的进程不会被回收，会对操作系统造成影响，因为操作系统可以创建的进程数量是有限的。我们得确保父进程调用 wait 或 waitpid。\n\n### wait--等待子进程终止\n\n```c++\npid_t wait(int *status);\n```\n\n调用 wait 的进程，会阻塞在 wait 方法处，直到有一个进程终止才解除阻塞，返回值是子进程的 PID。\n\nstatus 参数是一个传出参数，<sys/wait.h> 头文件中定义了一组宏用于解析 status。\n\n`WIFEXITED(status)` 宏用于检查子进程是否正常结束。\n\n`WEXITSTATUS(status)` 宏用于获取正常结束时的退出码。\n\n`WCOREDUMP(status)` 宏用于检查子进程产生 core 文件。这个宏并没有在 POSIX.1- 2001 标准中规定。因此，使用的时候，应该用 #ifdef WCOREDUMP ... #endif 包裹起来。\n\n```c++\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <errno.h>\n#include <error.h>\n\nvoid print_wstatus(int status) {\n    if (WIFEXITED(status)) {\n        int exit_code = WEXITSTATUS(status);\n        printf(\"exit_code = %d\", exit_code);\n    } else if (WIFSIGNALED(status)) {\n        int signo = WTERMSIG(status);\n        printf(\"term_sig = %d\", signo);\n#ifdef WCOREDUMP\n        if (WCOREDUMP(status)) {\n            printf(\" (core dump)\");\n        }\n#endif\n    }\n    printf(\"\\n\");\n}\n\nint main(int argc, char* argv[]) {\n    pid_t pid = fork();\n    switch (pid) {\n    case -1:\n        error(1, errno, \"fork\");\n    case 0:\n        // 子进程\n        printf(\"CHILD: pid = %d\\n\", getpid());\n        for(;;); // 使子进程进入无限循环\n    default:\n        // 父进程\n        int status; // 保存子进程的终止状态信息\n        pid_t childPid = wait(&status); // 阻塞点：一直等待，直到有子进程终止\n        if (childPid > 0) {\n            printf(\"PARENT: %d terminated\\n\", childPid);\n            print_wstatus(status);\n        }\n        exit(0);\n    }\n    return 0;\n}\n\n```\n\nwait 存在的一些限制：\n\n- 如果有多个子进程， wait() 是无法等待某个特定子进程终止的， 只能依次等待每一个子进程终止。\n- 如果没有子进程终止， wait() 会一直阻塞。有时候会希望非阻塞的等待：如果没有子进程终止，立刻返回。\n- 只能监控子进程是否终止。对于子进程因某个信号 (如 SIGSTOP 或 SIGTTIN ) 而停止，或是已停止子进程收到 SIGCONT 信号后恢复执行， wait() 是无法监控这些情况的。\n\n### waitpid--等待子进程状态发生改变\n\n```c++\npid_t waitpid(pid_t pid, int *status, int options);\n```\n\npid 参数：\n\n- pid > 0，表示等待进程 ID 为 pid 的子进程。\n- pid = 0，表示等待同进程组的所有子进程。\n- pid = -1，表示等待任意子进程。 wait(&status) 与 waitpid(-1, &status, 0) 等价。\n- pid < -1，表示等待进程组 ID 为 |pid| 的所有子进程。\n\noptions 参数：\n\n- WNOHANG 不阻塞。如果参数 pid 指定的子进程没有一个发生状态改变，则立即返回， waitpid()的返回值为 0。\n- WUNTRACED 监控子进程是否因为某个信号而停止。\n- WCONTINUED 监控已停止的子进程是否收到 SIGCONT 信号而恢复执行。\n\n明显看到 waitpid 要比 wait 功能丰富，它可以突破 wait 存在的一些限制。\n\n## 执行程序\n\n### execve()\n\n可以将新程序加载到当前进程的内存空间。在这一过程中，会执行如下操作：\n\n1. 清楚当前进程的代码段、数据段、堆、栈、上下文...\n2. 加载新的可执行程序，设置代码段，数据段等\n3. 从新可执行程序 main() 的第一行开始执行\n\n```c++\nint execve(const char *pathname, char *const argv[], char *const envp[]);\n\npathname：可执行程序路径\nargv：可执行程序的参数，记得以NULL结尾\nenvp：环境变量，记得以NULL结尾\n```\n\n### exec函数簇\n\n下面这些库函数都是建立在系统调用 execve() 之上的，它们为执行新可执行程序提供了多种 API 选择。这些函数只是在指定程序名、命令行参数列表以及环境变量的方式上有所不同。\n\n![execve.png](/images/2024/09/28/c9316610-7d9d-11ef-b348-95e5e18530fa.png)\n\n### system--执行 shell 命令\n\n```c++\nint system(const char *command);\n```","tags":["Linux"],"categories":["technology"]},{"title":"三种用户态网络缓冲区设计方案","url":"/2024/09/28/三种用户态网络缓冲区设计方案/","content":"\n<!-- toc -->\n\n## 固定缓冲区大小\n\n申请固定内存作为缓冲区，用一个写指针进行标识。\n\n![固定缓冲区.png](/images/2024/09/28/2eafb120-7d4b-11ef-a6c8-3b1c773d33d6.png)\n\n- 起始下标读取数据的起始地址，写指针是读取数据的结束地址。\n- 如果写指针已经指向缓冲区末尾，将不允许写入。\n- 读指针需要判断数据的完整性方可实际去读。通常我们采用 TLV 协议来解决网络传输中存在的[粘包问题](https://xiaoyangst.github.io/2024/09/08/%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E7%B2%98%E5%8C%85%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/#%E5%A4%84%E7%90%86%E7%BD%91%E7%BB%9C%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98)。\n\n这种简单的方案在实际的生产中也是很常见的，如果你严格限制传输的数据大小，并且让自己的网络库足够的高性能，用户请求量不大的情况下，也是相当不错。**`Redis` 的接收缓冲区，使用的是定长 `buffer`**。\n\n那么它的缺点是什么？尽管这些缺点我们也有优化方案。\n\n1. **需要频繁腾挪数据**，只要界定成功一个完整数据包，就需要把后面的数据挪到前面，以空余更多的空间供生产者往里面填充数据。\n2. **需要实现扩缩容机制**，如果缓冲区剩余空间不足以存放数据，需要对缓冲区进行扩容，并且将旧缓冲区中的数据挪到新缓冲区中。\n\n第一个缺点的解决方案在下一个缓冲区设计中可以解决，如果各位用数组写过环形队列，你应该明白我们不需要每次在界定成功一个完整数据包，就把后面的数据挪到前面。\n\n第二个缺点的解决方案在 C++ 中又有何难？vector 容器就是动态数组，但是我们通常不建议如此，因为扩容会导致数据的频繁移动，这实在是不可取。在最后一个缓冲区介绍中，我们可以利用 链表 设计出一个扩容但不必因为数据过大而频繁移动数据的缓冲区。\n\n## 环形缓冲区 ringBuffer\n\n用数组形成的环形缓冲区只是一种抽象，本质上还是一块连续的内存空间。用读指针（read pointer）和写指针（write pointer）进行标识。\n\n下面简单演示环形数组如何解决固定缓冲区的第一个不足：\n\n![环形缓冲区1.png](/images/2024/09/28/28c9fcc0-7d4b-11ef-a6c8-3b1c773d33d6.png)\n\n红色块代表已处理的无效数据，绿色块代表待处理的有效数据。此前的固定缓冲区会选择先清理无效数据，再把有效数据往前挪动。但是既然已经是垃圾数据，又何必管它呢？我们只需要管理好有效数据即可。\n\n接下来又有新数据到来，这个时候的指针和数据存储是怎样？\n\n![环形缓冲区2.png](/images/2024/09/28/24c56470-7d4b-11ef-a6c8-3b1c773d33d6.png)\n\n它无需移动任何数据，只是通过写指针指向有效数据的末尾即可。Linux 网络数据的处理就用到固定大小的环形缓冲区，名字就叫 ringBuffer。\n\n但我们明显也看到它由于固定缓冲区大小还是面临相同的问题，如果数据量过大，将会导致之前传输过来的数据被覆盖，这是相当糟糕的。之前的固定缓冲器是容纳不下后来的数据，可以选择丢弃，至少保证之前的连接的消息能够正确处理。而环形缓冲区会导致数据混乱，即得到的数据很有可能不是自己应该处理的数据。\n\n可以考虑用 vector，只需要合理更新下标的范围，以及应该设置一个最大空间的阈值和恰当时刻的缩容机制。\n\n还有这般设计又出现另一个值得考虑的问题，即数据不再像前面的固定缓冲区那样必然连续，因为我们现在的数据有可能前面有一部分，后面有一部分，基于操作系统的空间局部性原理，这个带来的性能损失也是应当考虑的。同样地，原先只需要调用一次 read，而这次将需要调用两次 read 才可以把数据完整的读取并存储下来，系统调用多一次。\n\n可以更换系统调用函数来进行优化，即`readv` 和 `writev` 。用于处理向量 I/O，允许一次性读写多个非连续的内存区域。尤其在网络编程中，可以减少系统调用次数，提高性能，特别是在需要处理大量小数据块时。\n\n```c++\nssize_t readv(int fd, const struct iovec *iov, int iovcnt);\nssize_t writev(int fd, const struct iovec *iov, int iovcnt);\n```\n\n我们用核心代码简单看看两者之间的区别，这里就以 read 和 readv 来举例说明：\n\n```c++\n// read\n\n    char buf[100];\n    ssize_t bytesRead = read(fd, buf, sizeof(buf) - 1);\n    if (bytesRead < 0) {\n        perror(\"read\");\n        close(fd);\n        return 1;\n    }\n\n    buf[bytesRead] = '\\0'; // Null-terminate the string\n\n// readv\n\n    char buf1[50];\n    char buf2[50];\n    struct iovec iov[2];\n\n    iov[0].iov_base = buf1;\n    iov[0].iov_len = sizeof(buf1) - 1;\n    iov[1].iov_base = buf2;\n    iov[1].iov_len = sizeof(buf2) - 1;\n\n    ssize_t bytesRead = readv(fd, iov, 2);\n    if (bytesRead < 0) {\n        perror(\"readv\");\n        close(fd);\n        return 1;\n    }\n\n    buf1[iov[0].iov_len] = '\\0'; // Null-terminate buf1\n    buf2[iov[1].iov_len] = '\\0'; // Null-terminate buf2\n```\n\n只不过我们这里的 Buffer 指定一个就可以，但是起始下标和实际长度要指清楚，不要让数据被污染了。\n\n## 优化 ringBuffer 之 chainBuffer\n\n我们总是难以避免这个问题，即 vector 容器扩容导致的数据大量移动，可是我们又不得不避免固定缓冲区大小的局限。消息要尽可能多的存储起来（尽量不丢失用户的请求），需要避免固定缓冲区大小的局限，又不想承担扩容导致的数据大量移动。我们设计出下面这个缓冲区：\n\n![chainBuffer.png](/images/2024/09/28/1e5b3dd0-7d4b-11ef-a6c8-3b1c773d33d6.png)\n\n- start 指向缓冲区的头指针，end 指向缓冲区的尾指针。\n- next 指向下一个缓冲区的节点，home 代表数据的起始地址，offert 代表数据的长度，Buffer 代表数据。\n- 处理完数据更新头指针，添加新数据更新尾指针。\n- 链表既解决扩容问题，也解决缩容问题（不需要就会被移除）。\n\n我们的 Buffer 也是有大小限制的，如果不足以存储新来的数据就创建一个新的节点存储。在处理数据时，只有这个节点被合理的处理才可以移除，比方说当前节点的数据和下一个节点联合才是完整数据，务必处理为一个完整数据才进行移除。\n\n链表的扩容方式的不足就是空间不连续，这在操作系统层面确实是一个不可忽视的缺点，如果你听说过空间局部性原理的话。再者也是和环形缓冲区一样，存在多次调用系统调用的情况。可采用之前提到的优化系统调用的方案。\n\n## 总结\n\n![Buffer总结.png](/images/2024/09/28/1a4b5ae0-7d4b-11ef-a6c8-3b1c773d33d6.png)","tags":["Linux","基础组件"],"categories":["technology"]},{"title":"Linux 五种 IO 模型","url":"/2024/09/27/Linux-五种-IO-模型/","content":"\n<!-- toc -->\n\n## 阻塞 IO 模型\n\n![同步IO.png](/images/2024/09/27/32b9ce80-7cd9-11ef-a65d-c764aa3c1fbb.png)\n\n注：网上的经典图是从左往右，但是不容易理解，特画此图，但后续的几张图就还是得借用了。\n\n用户发起系统调用 recvform 进入内核，直到内核把数据拷贝到用户态为止才解除阻塞。进入内核之后，内核还没有数据也不会把数据拷贝到用户态去，既然该进程已阻塞，操作系统就会把 CPU 分配给其他进程。等到内核得到数据，并拷贝到用户态去，即 recvform 成功返回之后，CPU 又返回到当前进程，解除阻塞，继续往下执行业务代码。\n\n## 非阻塞 IO 模型\n\n![非阻塞IO.png](/images/2024/09/27/369e0d90-7cd9-11ef-a65d-c764aa3c1fbb.png)\n\n与阻塞 IO 不同的是，非阻塞 IO 调用 recvfrom 之后立即返回，没过多久又去探测内核是否已经有数据了。如果没有，当前进程继续往下执行代码；如果有，就会阻塞并等待内核把数据拷贝到用户态，即 recvform 成功返回之后，解除阻塞，继续往下执行业务代码。\n\n## IO 复用模型\n\n![IO多路复用.png](/images/2024/09/27/3adc5380-7cd9-11ef-a65d-c764aa3c1fbb.png)\n\n前面的阻塞 IO 和 非阻塞 IO 都只可以监听 1 个文件描述符，而 IO 多路复用可以监听多个文件描述符的状态。但凡有一个 fd 有关注的事件发生，就会直接返回，返回值是同一时刻触发的被内核监视的那些文件描述符的个数。这个时候，程序才发起真正的 IO 操作，直接阻塞在等待内核把数据拷贝到用户态，即 recvform 成功返回之后，解除阻塞，继续往下执行业务代码。\n\n这么看来我们的 select（暂时以它举例） IO 多路复用并没有那么 NB？从 select 把感兴趣的事件注册到内核之后，就一直阻塞，直到有哪怕一个感兴趣的事件返回才进入下一阶段。下一阶段就是真正开始发起 IO 操作，早前的阻塞 IO 与非阻塞 IO 是直接发起 IO 操作，这点二者有些不同之处。可是不管怎样，select 依旧是阻塞在事件返回阶段和内核把数据拷贝到用户态阶段。\n\n那么 select IO 多路复用究竟有哪些提升？\n\n1. 可以监听多个文件描述符，阻塞 IO 与非阻塞 IO 只可以监听一个文件描述符。\n2. 监听多个文件描述符的事件，但凡有一个就会直接返回，往往就要比 阻塞 IO 与非阻塞 IO 快，因为更容易快速返回。毕竟，人多中奖的概率更大，但凡一个中奖就会解除阻塞了。\n3. 接着处理文件描述符对应的业务代码，这个期间，这些文件描述符如果继续触发事件，内核帮我们监视着，只要后面这边业务处理完，我们又可以继续处理了。但是 阻塞 IO 与非阻塞 IO 就不行，必须等到业务完成，才可以继续等待内核有数据并拷贝到用户态为止，这在效率上就拉开了。\n\n## 信号驱动 IO 模型\n\n![信号IO.png](/images/2024/09/27/3f820dd0-7cd9-11ef-a65d-c764aa3c1fbb.png)\n\n发起信号之后，不会阻塞，直到内核有数据才会继续阻塞，阻塞在等待内核把数据拷贝到用户态，即 recvform 成功返回之后，解除阻塞，继续往下执行业务代码。\n\n## 异步 IO 模型\n\n![异步IO.png](/images/2024/09/27/432a5550-7cd9-11ef-a65d-c764aa3c1fbb.png)\n\n发起异步请求之后，前面介绍的两个阶段都不会阻塞，即等到 recvform 成功返回之后才回来继续处理。\n\n早前我用送外卖来形容同步IO ，信号驱动 IO 和 异步 IO 。放到这里记录：\n\n1. 同步IO：我本来在打电动，顿感饥饿，就决定打电话点外卖，点完就一直等外卖，啥事也不干。\n2. 信号驱动 IO：我本来在打电动，顿感饥饿，就决定打电话点外卖，点完继续打电动。直到外卖员打电话说外卖送到楼下门口了，我就在家门口等待外卖员把外卖送上来。\n3. 信号驱动 IO：我本来在打电动，顿感饥饿，就决定打电话点外卖，点完继续打电动。直到外卖员打电话说外卖送到楼下门口了，我继续打电动。最后外卖员把外卖送到家门口，我才停止打电动，开始吃外卖。\n\n明显看到，发起点外卖这个命令，我只关心外卖本身，这个过程与我无关，哪怕这个过程出现问题，也与我无关，外卖什么时候亲手送到我的手里我才吃，否则我就继续干其他任务。","tags":["Linux"],"categories":["technology"]},{"title":"Linux目录操作","url":"/2024/09/26/Linux目录操作/","content":"\n<!-- toc -->\n\n## getcwd--获取当前工作目录\n\n获取的路径是绝对路径。\n\n```c++\nchar *getcwd(char *buf, size_t size);\n```\n\n但如果我们希望根据路径的实际长度来申请合适的空间，可以如下作：\n\n```c++\nchar* cwd = getcwd(NULL,0);\n```\n\n## chdir--改变当前工作目录\n\n你可以填绝对路径，如果是相对路径就是基于当前路径的。\n\n```c++\nint chdir(const char *path);\n```\n\n## mkdir--创建目录\n\n```c++\nint mkdir(const char *pathname, mode_t mode);\n```\n\nmode: 目录的权限位，会受文件创建掩码 umask 的影响，实际的权限为（mode & ~umask & 0777）返回值。\n\n这很正常，不可能你一个没有写权限的用户，你执行这个函数就能让你创建有写权限的文件夹吧？这不合理。\n\n## rmdir--删除空目录\n\n```c++\nint rmdir(const char *path);\n```\n\n删除**空**目录，因此后面我们实现如果递归删除目录和文件。\n\n## opendir--打开一个目录\n\n```c++\nDIR *opendir(const char *name);\n```\n\n打开成功会返回一个指向目录流的指针 DIR*。\n\n## closedir--关闭目录流\n\n```c++\nint closedir(DIR *dirp);\n```\n\n## readdir--读目录流（核心）\n\n```c++\nstruct dirent* readdir(DIR *dirp);\n```\n\n返回值是一个结构体，里面记录的信息是非常关键的，我们后面提供的三个核心小程序就是基于此操作的。\n\n```c++\n#include <sys/types.h>\n\nstruct dirent {\n    ino_t d_ino;           // inode 编号\n    off_t d_off;           // 下一条目在目录中的偏移\n    unsigned short d_reclen; // 结构体的长度\n    unsigned char d_type;   // 文件类型\n    char d_name[256];      // 文件名\n};\n```\n\n其中，常用以区分文件和文件夹的关键字就是 d_type，这是相当关键点。\n\n```c++\nDT_BLK：块设备。\nDT_CHR：字符设备。\nDT_DIR：目录。\nDT_FIFO：命名管道（FIFO）。\nDT_LNK：符号链接。\nDT_REG：常规文件。\nDT_SOCK：UNIX 域套接字。\nDT_UNKNOWN：无法确定文件类型。\n```\n\n## 实例代码\n\n实际上，上述接口并不难，最为核心的是 readdir 函数。而目录有关的操作就是递归遍历文件夹和文件，至于递归删除也就不在话下了。整个核心就是深度搜索，我们这里是前序遍历。\n\n[递归打印目录结构--青春版tree命令](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/%E9%80%92%E5%BD%92%E6%89%93%E5%8D%B0%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84--%E9%9D%92%E6%98%A5%E7%89%88tree%E5%91%BD%E4%BB%A4)\n\n[递归复制目录](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/%E9%80%92%E5%BD%92%E5%A4%8D%E5%88%B6%E7%9B%AE%E5%BD%95)\n\n[递归删除目录](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/%E9%80%92%E5%BD%92%E5%88%A0%E9%99%A4%E7%9B%AE%E5%BD%95)","tags":["Linux"],"categories":["technology"]},{"title":"Linux文件操作","url":"/2024/09/26/Linux文件操作/","content":"\n<!-- toc -->\n\n## 什么是文件描述符？\n\n![fd.png](/images/2024/09/26/bf6616d0-7b9f-11ef-bdbc-45eba982e11c.png)\n\nopen 的返回值就是一个文件描述符，没有对文件进行任何操作，只是建立上面的三个数据结构。后续只需要拿文件描述符就等价于操作文件，从磁盘读入到内存的数据（这个动作不是 open做的）。\n\n- 进程级 **文件描述符表** ( file descriptor table )\n- 系统级 **打开文件表** ( open file table )\n- 文件系统 **i-node表** ( i-node table )\n\n（一）文件描述符表\n\n内核为每个进程维护一个 **文件描述符表** ，该表每一条目都记录了单个文件描述符的相关信息，包括：\n\n- **控制标志** ( flags )，目前内核仅定义了一个，即 `close-on-exec`\n- **打开文件描述体指针**\n\n（二）打开文件表\n\n内核对所有打开的文件维护一个系统级别的 **打开文件描述表** ，简称 **打开文件表** 。 表中条目称为 **打开文件描述体**，存储了与一个打开文件相关的全部信息，包括：\n\n- **文件偏移量**，调用 read() 和 write() 更新，调用 lseek() 直接修改\n- **访问模式** ，由 open() 调用设置，例如：只读、只写或读写等\n- **i-node 对象指针**\n\n（三）i-node表\n\n每个文件系统会为存储于其上的所有文件(包括目录)维护一个 i-node 表，单个 i-node 包含以下信息：\n\n- **文件类型**，可以是常规文件、目录、套接字或 FIFO\n- **访问权限**\n- **文件锁列表**\n- **文件大小**\n- 等等\n\ni-node 存储在磁盘设备上，内核在内存中维护了一个副本，这里的 i-node 表为后者。 副本除了原有信息，还包括： **引用计数** (从打开文件描述体)、所在 **设备号** 以及一些临时属性，例如文件锁。\n\n## 对文件描述符的操作\n\n### open--打开文件描述符\n\n```c\nint open(const char *pathname, int flags);\nint open(const char *pathname, int flags, mode_t mode);\n```\n\nflags 是标志位，常见如下：\n\n![文件标志位.png](/images/2024/09/26/b65d2970-7b9f-11ef-bdbc-45eba982e11c.png)\n\nO_RDONLY、O_WRONLY、O_RDWR 中必须选择一个，且只能选择一个。\n\n如果有 O_CREAT 标志位，必须填写第三个参数 mode。mode 用来指定文件的权限，会受 umask 的影响，实际权限为 （mode & ~umask）。\n\n打开文件成功之后，得到文件描述符，后续利用该文件描述符就可以对文件进行操作了\n\n### close--关闭文件描述符\n\n```c++\nint close(int fd);\n```\n\n### read--读文件描述符\n\n把文件描述符 fd 中的数据读取到 buf 中，预读取长度为 count。\n\n```c++\nssize_t read(int fd, void *buf, size_t count);\n```\n\n实际读取的数据长度为 read 调用成功的返回值。\n\n### write--写文件描述符\n\n把文件描述符 fd 中的数据写入到 buf 中，预写入长度为 count。\n\n```c++\nssize_t write(int fd, const void *buf, size_t count);\n```\n\n实际写入的数据长度为 write 调用成功的返回值。\n\n### lseek--移动文件位置\n\noffset 代表移动的偏移量，就是你实际想要移动的长度\n\n```c++\noff_t lseek(int fd, off_t offset, int whence);\n```\n\nwhence 是参照点，有三个取值：\n\n![文件参照点.png](/images/2024/09/26/aed5d300-7b9f-11ef-bdbc-45eba982e11c.png)\n\n调用成功的返回值代表 移动后文件的位置。\n\n### fsync--持久化到磁盘\n\n前面调用 write 之后，并不会立即写入磁盘，写入的数据会由内核管理，由内核决定何时写入磁盘。\n\n如果你想立即写入，调用 fsync 即可。\n\n```c++\nint fsync(int fd);\n```\n\n这里要把 fsync 和 fflush 做个区分。fflush 是把用户态缓冲区数据 刷入到 内核缓冲区中，至于何时写入磁盘由内核决定。fsync 会把内核缓存区的数据立即写入磁盘。\n\n![fflsh和fsync区别.png](/images/2024/09/26/a57e5070-7b9f-11ef-bdbc-45eba982e11c.png)\n\n### ftruncate--截断文件\n\n```c++\nint ftruncate(int fd, off_t length);\n```\n\n将文件截断为指定长度。分两种情况讨论：\n\n- 如果 length < 源文件大小，那么超出部分的数据会丢失。\n- 如果 length > 源文件大小，那么扩展的部分会填充空字符，甚至可能出现文件空洞。\n\n![截断.png](/images/2024/09/26/9e3bcb30-7b9f-11ef-bdbc-45eba982e11c.png)\n\n### fstat--获取文件的元数据\n\n可以获取文件的元数据信息，这些信息来自于 i-node。我们也可以利用 stat 命令查看文件的元数据信息。\n\n```c++\nint fstat(int fd, struct stat *statbuf);\n```\n\n先创建结构体 struct stat，调用 fstat 成功之后，元数据信息就会存储在 stat 结构体中。\n\n```c\nstruct stat sb; // 存储文件元数据信息\nif (fstat(fd, &sb) == -1) {\n\terror(1, errno, \"fstat %d\", fd);\n}\n```\n\n那么结构体 stat 存储哪些信息呢 ？\n\n```tex\nst_dev: 文件所在设备的ID\nst_ino: 文件的inode号码\nst_mode: 文件的类型和权限信息（如文件类型、读/写/执行权限）\nst_nlink: 文件的硬链接数量\nst_uid: 文件所有者的用户ID\nst_gid: 文件所属组的组ID\nst_rdev: 设备文件的设备ID（对于设备文件）\nst_size: 文件大小（以字节为单位）\nst_atime: 文件最后访问时间\nst_mtime: 文件最后修改时间\nst_ctime: 文件状态最后更改时间（包括文件元数据的修改）\n```\n\n### dup2--复制文件描述符\n\n不建议使用 dup，因为它不是原子操作，我们直接学 dup2 即可。\n\n```c\nint dup2(int oldfd, int newfd);\n```\n\n从参数就能看出来，就是把 oldfd 复制给 newfd。\n\n## 文件描述符和文件流\n\n文件流是库函数，可移植性强；文件描述符是操作系统的系统调用，可移植性差。\n\n![文件流和文件描述符.png](/images/2024/09/26/97083a10-7b9f-11ef-bdbc-45eba982e11c.png)\n\n文件流有用户态缓冲区，而文件描述符没有用户态缓冲区，所以文件流比文件描述符多复制一次。那么它们各自的应用场景呢？\n\n- 如果我们对文本操作，可以选择文件流进行操作，它更适合以人类的方式读写数据。\n- 如果我们需要传输文件，可以选择文件描述符，它更适合以机器的方式读写数据。\n\n特别是涉及大文件操作，必然要用文件描述符，毕竟要少拷贝一次。如果文件小用文本操作就方便，因为代码写起来比文件描述符容易。\n\n## 内存映射I/O\n\n内存映射可以将文件内容直接映射到进程的虚拟地址空间。当警察访问映射区域时，操作系统会负责将相应的文件部分加载到内存中。这种机制利用了操作系统的页面管理技术，可以高效管理内存和文件I/O。\n\n内存映射的主要区别在于这两种类型：\n\n1. **MAP_PRIVATE**：创建一个私有的映射，任何对映射区域的修改不会影响到原始文件，也不会被其他进程看到。\n2. **MAP_SHARED**：创建一个共享的映射，任何对映射区域的修改会直接反映到原始文件，并且其他进程可以看到这些修改。\n\nMAP_SHARED 状态下，两个进程共享同一块物理内存，即两个进程各自的虚拟内存映射到相同的物理内存。这两个进程在读写操作的情况下，都是直接作用于这块物理内存的（通过虚拟内存访问）。\n\n![shared.png](/images/2024/09/26/9014e640-7b9f-11ef-bdbc-45eba982e11c.png)\n\nMAP_PRIVATE 状态下，依旧是和上面的情景一致，但如果有任意一个进程发生写操作，操作系统就会为这个经常重新分配一块内存（拷贝原来的内容，再让其修改），让其不对之前共享的内存进行操作，从此这个进程拥有这块属于自己的独立的物理内存，不与任何进程共享。\n\n![private.png](/images/2024/09/26/8aa83270-7b9f-11ef-bdbc-45eba982e11c.png)\n\n你可能会问，那么当进程 B 对其修改，操作系统会为其重新分配一块内存吗？不会，因为这块之前的共享内存知道只有一个进程指向它了，也就直接让它操作了。\n\n### mmap--创建内存映射\n\n`mmap` 函数的返回值是一个指向映射区域的指针，如果映射成功，则返回指向映射区域的起始地址。如果映射失败，则返回 `MAP_FAILED`。\n\n```c++\nvoid *mmap(void *addr, size_t length, int prot, int flags,\n                  int fd, off_t offset);\n```\n\n**addr**：建议的映射起始地址（通常为 `NULL`，这样内核会为我们自动找到合适的地址）。\n\n**length**：映射区域的大小，以字节为单位。\n\n**prot**：映射区的访问权限。\n\n![权限.png](/images/2024/10/12/dbd6f4a0-887a-11ef-939c-5b7b2e2f646d.png)\n\n**flags**：映射的类型和选项，如 `MAP_PRIVATE` 或 `MAP_SHARED`。\n\n**fd**：要映射的文件描述符。\n\n**offset**：文件中开始映射的偏移量，它必须是页大小的整数倍。\n\n### munmap--解除内存映射\n\n```c++\nint munmap(void *addr, size_t length);\n```\n\n对于共享映射，数据在解除映射时会被写入文件（磁盘）；对于私有映射，数据则不会被保存，即不会持久化到文件中（磁盘）。\n\n### 实战：两个文件的零拷贝\n\n文件从磁盘拷贝到内核缓冲区，是DMA操作：当从磁盘读取数据时，磁盘控制器通常会使用直接内存访问（DMA）技术，将数据从磁盘直接传输到内核缓冲区中，而无需 CPU 介入。这样做的好处是可以释放 CPU 去处理其他任务，提高系统的整体效率。\n\n从内核缓冲区拷贝到用户缓冲区，是CPU操作： 从内核缓冲区将数据传输到用户空间缓冲区时，需要 CPU 介入。这个过程通常涉及系统调用（比如 `read()`），在内核态和用户态之间进行数据拷贝。这一步之所以需要 CPU 是因为内核需要进行内存访问权限的检查，并确保内核空间数据的安全性。\n\n代码地址：[系统调用 read 和 write 实现文件的复制](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%20read%20%20%E5%92%8C%20write%20%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E7%9A%84%E5%A4%8D%E5%88%B6)\n\n![writereadProcess.png](/images/2024/09/26/826b2090-7b9f-11ef-bdbc-45eba982e11c.png)\n\n传统的 IO 读写方式，如上图中把 src 文件 读取并写入到 dst 文件中，整个过程就包括了四次用户态/内核态的上下文切换，四次数据的拷贝（DMA拷贝是读写，CPU拷贝是复制）。\n\n代码地址：[使用 mmap 实现文件的复制](https://github.com/xiaoyangst/Code/tree/master/%E6%9D%82%E9%A1%B9/%E4%BD%BF%E7%94%A8%20mmap%20%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E7%9A%84%E5%A4%8D%E5%88%B6)\n\n![mmapProcess.png](/images/2024/09/26/7a340220-7b9f-11ef-bdbc-45eba982e11c.png)\n\nmmap 将用户空间的虚拟地址和内核空间的虚拟地址映射成同一个物理地址。调用 mmap 的时候，也就是开始把磁盘中的数据 DMA 拷贝到内核缓冲区，通过内核态的虚拟内存地址可以访问到这块物理内存。然后 mmap 成功之后，就是把 用户态的虚拟地址（你问它从何而来？第一个参数为NULL，操作系统会自动帮我们找好，最后映射物理内存的首地址作为返回值）和 内核态的虚拟内存地址 映射到同一个物理地址，这样通过用户态的虚拟地址访问物理内存，就等价于原先通过内核态的虚拟地址访问物理内存。\n\n至此，我们不需要把内核缓冲区的数据拷贝到用户态的 Buffer 中。因为用户态的虚拟内存地址和内核态的虚拟内存地址是指向同一块物理内存的，那通过 memcpy 操作用户态的两个虚拟内存地址，就是将实际指向的物理内存 src 拷贝到 物理内存 dst。以此实现文件拷贝。\n\n我们创建的映射是有大小的，所以是先映射文件的一部分（mmap 第三个参数 length），完成拷贝之后，接着继续映射下一部分。图中没有体现，而是直接映射整个完整的文件了，实际并非如此。\n\n---\n\n参考链接见下：\n\n[零拷贝技术第一篇：综述](https://colobu.com/2022/11/19/zero-copy-and-how-to-use-it-in-go/)\n\n[文件描述符](https://linux.fasionchan.com/zh_CN/latest/system-programming/file-io/file-descriptor.html)","tags":["Linux"],"categories":["technology"]},{"title":"Linux 收发网络数据包的过程","url":"/2024/09/25/Linux-收发网络数据包的过程/","content":"\n<!-- toc -->\n\n## 网络数据帧是什么？\n\n应用层要传输的数据需要封装成网络数据帧，才可以在物理介质上传输。我们先看网络帧的模样，再谈它是如何一步一步形成这般。下图就是网络数据帧。\n\n![网络帧.png](/images/2024/09/25/1fc41f00-7b0e-11ef-b257-21ef1724fa3f.png)\n\n用户在应用层把数据传递给其他主机，肯定不可能直接把这个数据发过去，网络传输介质都不认识这个，故对其进行封装，这个任务由网络协议栈来做，下图就是封装用户数据到网络数据帧的流程。如果网卡接收到网络数据帧，交给协议栈处理之时，协议栈会由下往上来进行拆解，从而留下应用层能够处理的用户数据。\n\n![封装数据为网络帧的过程.png](/images/2024/09/25/1ccefae0-7b0e-11ef-b257-21ef1724fa3f.png)\n\n注：网络接口层 = 数据链路层 + 物理层\n\n## DMA 技术\n\nDMA 的作用就是实现数据的直接传输，而去掉了传统数据传输需要 CPU 参与的环节。下图中内存读取外设的数据，这个过程不再先之前那样需要 CPU 的参与，而是利用 DMA 这个通道，直接读取。\n\n![DMA.png](/images/2024/09/25/1923cd30-7b0e-11ef-b257-21ef1724fa3f.png)\n\n1. **请求阶段**: 外设发出 DMA 请求给 DMA 控制器，表明其需要进行数据传输。\n2. **仲裁阶段**: DMA 控制器决定是否接受该请求，并与 CPU 进行总线控制权的仲裁（若 CPU 正在使用总线，则需要等待）。\n3. **数据传输阶段**: 一旦获得总线控制权，DMA 控制器**直接将数据从源地址传输到目的地址，而无需经过 CPU**。\n4. **完成阶段**: 数据传输完成后，DMA 控制器会发送传输完成信号给外设，并向 CPU 发出中断信号，通知数据传输已经完成。\n\n## DMA 和 CPU主导的数据拷贝到区别\n\nCPU 明显是可以进行数据拷贝，但是 DMA 设计出来就是为了接受这份“无聊”的工作，让 CPU 专注于计算相关的工作。因此，DMA 在针对数据拷贝这块的设计上，究竟有哪些优势？\n\n（一）工作方式的不同\n\n- CPU：当没有 DMA 时，CPU 需要逐字节（或逐字）地读取数据源，然后将其写入目标地址。这种操作会消耗 CPU 的大量时钟周期，因为 CPU 需要从 I/O 设备（如磁盘、网卡）读取数据、处理数据再写入内存，每次数据读写都涉及 CPU 指令、总线操作、缓存管理等，效率低下。\n- DMA：DMA 控制器负责数据的传输，它可以独立于 CPU 进行内存和 I/O 设备之间的数据搬移。\n\n（二）总线的利用率不同\n\n- CPU：CPU 每次进行读写操作时都需要占用系统总线（如 PCI 总线、内存总线），每次传输的过程包括 CPU 发出指令、读取数据、写入数据等，导致总线效率较低，传输延迟较大。\n- DMA：DMA 控制器能够**直接管理总线**，并且以突发模式（Burst Mode）一次性传输大量数据，从而提高总线利用率，减少 CPU 和设备之间来回切换的开销。\n\n（三）传输效率和吞吐量\n\n- CPU：数据传输速率受限于 CPU 指令处理速度、总线速度和系统中断延迟等因素。当有大量数据传输时，CPU 会被大量的中断请求打断，导致系统性能下降。\n- DMA：DMA 传输速度通常比 CPU 主导的传输更快，因为它可以**直接与内存或外设通信**，并且支持大块数据一次性搬移。尤其是高速外设（如硬盘、网卡）和内存之间的传输，DMA 可以大幅提升吞吐量。\n\n（四）零拷贝机制的支持\n\n- CPU：通常需要在不同存储空间（如用户空间、内核空间）之间进行多次拷贝，每次拷贝都意味着额外的内存操作和时间开销。\n- DMA：DMA 控制器可以直接将数据从外设搬移到目标存储空间（如内核缓冲区、用户内存），甚至通过 Scatter-Gather DMA 直接分发到多个目标内存块，实现零拷贝或最小化拷贝次数的优化。\n\n## 接收网络数据包\n\n只需要讲清楚 接受网络数据包的过程，就可以轻松理解 发送用户数据包的过程了。\n\n![收发.png](/images/2024/09/25/14980380-7b0e-11ef-b257-21ef1724fa3f.png)\n\n1. 网络数据帧到达网卡，按照 FIFO 顺序被存入网卡的接收队列。网卡通过 DMA 技术，将网络包写入到环形缓冲区（Ring Buffer）的一个空闲位置。\n2. 当缓冲区中存有一定数量的网络包时，或者某个时间间隔内到达的网络包数达到阈值，网卡会触发一个硬件中断。当 CPU 收到硬件中断请求后，根据中断注册表，找到注册的中断处理函数。\n3. 中断处理函数会屏蔽网卡的中断。目的是避免CPU被频繁中断而无法处理其他任务，屏蔽中断是告诉网卡已经知道内存中有数据了，下次再收到数据包直接写内存就可以了，不要再通知 CPU 了。然后发起软中断，恢复刚才屏蔽的中断。内核中的 ksoftirqd 线程收到软中断后，就会调用相应软中断的处理函数来轮询处理数据，即：从Ring Buffer 中获取一个数据帧，用 sk_buff 表示，作为一个网络包交给网络协议栈从下到上进行逐层处理。\n4. 经由网络协议栈层层剥离出来的对端的用户数据给到 Socket（由四元组标识，即源端口+源IP+目标端口+目标IP） 的接收缓冲区中（内核态），应用层再从 Socket 的接收缓冲区中拷贝到应用层的接收缓冲区中（用户态），应用就从接收缓冲区中读取数据了。\n\n---\n\n参考链接见下：\n\n[Linux系统收发网络数据包的过程](https://wiki.deepin.org/zh/04_%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98FAQ/Linux%E7%B3%BB%E7%BB%9F%E6%94%B6%E5%8F%91%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E5%8C%85%E7%9A%84%E8%BF%87%E7%A8%8B)\n\n[Linux 系统是如何收发网络包的？](https://www.xiaolincoding.com/network/1_base/how_os_deal_network_package.html#%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B)\n\n[Linux网路包收发流程](https://www.xudj.top/archives/linux-pkg-recv)","tags":["Linux","网络编程"],"categories":["technology"]},{"title":"初章：初识Vim","url":"/2024/09/24/初章：初识Vim/","content":"\n<!-- toc -->\n\n有安装 Vimplus 第三方插件让 Vim 更方便运用，但我因为个人开发习惯，选择在 Clion 上安装对应的 Vim 插件：\n\n![vim插件.png](/images/2024/09/24/d6279710-7a17-11ef-90be-0b70ce246133.png)\n\n## 认识 . 命令\n\n我们将看到 Vim 可以录制任意数目的按键操作，然后在以后重复执行它们。这让我们可以把最常重复的工作流程录制下来，并用一个按键重放它们。可以把 . 命令当成一个很小的宏。\n\n总的来讲，`.` 就是重复你上次的行为：\n\n- `.` 在普通模式下的功能是重复 **最后一次修改操作**\n- 在插入模式下，执行所有修改操作都会被记录，直到你保存并返回到普通模式。如果你这个时候执行 `.` 就会重复从进入到插入模式到退回到普通模式所有的行为（包括插入命令本身哦！）。\n\n有点需要特别说明，我们知道普通模式下 A 代表在当前行的末尾插入。那么这个命令不是单纯的插入，它实际由两部分组成，即跳转到当前行的尾部+插入。它应该被视为插入。举个例子说明：\n\n1. 你在普通模式下，光标位于一行的开头，按下 `A`，跳转到行末，进入插入模式\n2. 在行末插入了 \"Hello\"，然后按 `Esc` 回到普通模式\n3. 按下 `.`，光标会移动到当前行的末尾，进入插入模式，并插入 \"Hello\"\n\n##  以退为进\n\n```tex\nvar foo = \"method(\"+argument1+\",\"+argument2+\")\";\n\nvim 之后成为如下形式\n\nvar foo = \"method(\" + argument1 + \",\" + argument2 + \")\";\n```\n\n为了应用 `.` ，我们务必使用这样一种命令，即带有某个功能的插入模式，这里选择 s，即删除一个字符并插入。执行之后，输入`_+_ `，保存并到普通模式，然后就可以找到到 + 字符那里，执行 `.` 即可。\n\n存储这系列操作之后，我们应该查找所有字符进行逐一替换，而不是进行光标移动去一个一个找。f{char} 就能查找某个字符，查找到之后，执行 `.` 即可。\n\n可是每次输入 f{char} 查找相当费时，当你第一次执行 f{char} 之后，下次输入 ; 就可以代表再次执行  f{char}。\n\n注：_ 代表空格\n\n## 执行、重复、回退\n\n当 Vim 让一个操作或移动可以很方便地重复时， 它总是会提供某种方式， 让我们在不小心做过头时能回退回来。 对 . 命令而言， 我们永远可以按 u 键撤销上次的修改。 如果在使用 f{char} 命令后， 不小心按了太多次 ; 键， 就会偏离我们的目标。 不过可以再按 , 键跳回去。\n\n![重复与回退.png](/images/2024/09/24/d24553d0-7a17-11ef-90be-0b70ce246133.png)\n\n---\n\n⭐️内容取自著者Drew Neil《Vim实用技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书","tags":["Vim"],"categories":["technology"]},{"title":"24. 两两交换链表中的节点","url":"/2024/09/23/24-两两交换链表中的节点/","content":"\n```c++\nclass Solution {\npublic:\n    ListNode* swapPairs(ListNode* head) {\n        if(head == nullptr || head->next == nullptr) return head;\n\n        ListNode* first = head;\n        ListNode* second = head->next;\n        while(second){\n            swap(first->val,second->val);\n            first = first->next->next;\n            if(!second->next) break;\n            second = second->next->next;\n        }\n\n        return head;\n    }\n};\n```\n\n由于 second 比 first 快，哪怕是进入循环内，也要时刻保证在用 second 多级指向的时候（多次next），不再某个以 NULL 节点去 next，这在循环链表的时候务必谨记的。","tags":["链表"],"categories":["leetcode"]},{"title":"203. 移除链表元素","url":"/2024/09/23/203-移除链表元素/","content":"\n```c++\nclass Solution {\npublic:\n    ListNode* removeElements(ListNode* head, int val) {\n\n        ListNode* virtualHead = new ListNode(-1);\t// 虚拟头结点\n        virtualHead->next = head;\n\n        ListNode* prev = virtualHead;\n        while(head){\n            if(head->val == val){    \n                prev->next = head->next;\n            }else{\n                prev = prev->next;\n            }\n            head = head->next;\n        }\n\n        return virtualHead->next;\n    }\n};\n```\n\n既然删除，那就要得到删除节点的前一个节点。\n\n如果删除的节点是第一个节点，怎么办？看来需要虚拟头结点。","tags":["链表"],"categories":["leetcode"]},{"title":"160. 相交链表","url":"/2024/09/23/160-相交链表/","content":"\n```c++\nclass Solution {\npublic:\n    ListNode* getIntersectionNode(ListNode* headA, ListNode* headB) {\n        // 求两个链表长度的差 len\n        ListNode* Aindex = headA;\n        int ALen = 0;\n        while (Aindex) {\n            ALen++;\n            Aindex = Aindex->next;\n        }\n        ListNode* Bindex = headB;\n        int BLen = 0;\n        while (Bindex) {\n            BLen++;\n            Bindex = Bindex->next;\n        }\n\n        // 让最长的链表 移动 len\n        int len = abs(ALen - BLen);\n        Aindex = headA;\n        Bindex = headB;\n        if(ALen < BLen){\n            swap(Aindex,Bindex);\n        }\n\n        for(int i = 0; i < len; i++){\n            Aindex = Aindex->next;\n        }\n\n        // 齐头并进，地址相等即为第一次交汇点\n        while(Aindex){\n            if(Aindex == Bindex){\n                return Aindex;\n            }\n            Aindex = Aindex->next;\n            Bindex = Bindex->next;\n        }\n\n        return NULL;\n    }\n};\n```\n\n交互点指的是比较两个节点的地址是否相等，而不是元素相等，务必弄清楚。\n\n解此题的步骤：\n\n1. 求两个链表长度的差 len\n2. 让最长的链表 移动 len\n3. 齐头并进，地址相等即为第一次交汇点","tags":["链表"],"categories":["leetcode"]},{"title":"485.最大连续1的个数","url":"/2024/09/23/485-最大连续1的个数/","content":"\n```c++\nclass Solution {\npublic:\n    int findMaxConsecutiveOnes(vector<int>& nums) {\n        int max_len = 0;\n        int start_index = 0;\n        for(int i = 0; i < nums.size(); i++){\n            if(nums[i]){\n                start_index++;\n            }else{\n                max_len = max(max_len,start_index);\n                start_index = 0;\n            }\n        }\n        \n        return max(max_len,start_index);\n    }\n};\n```\n\n记录 1 的个数来获取最终的最大值，并且要在最后再次 max 一下。这是为了避免因为最后一个元素不是 0 ，但是前面有一连串的 1，且该被选为 最大长度返回。\n\n![485.最大连续1的个数.png](/images/2024/09/23/7af114f0-794c-11ef-a3d7-ad2b3d89cbb8.png)","tags":["数组"],"categories":["leetcode"]},{"title":"283.移动零","url":"/2024/09/23/283-移动零/","content":"\n```c++\nclass Solution {\npublic:\n    void moveZeroes(vector<int>& nums) {\n        int cover_index = 0;\n        for (int i = 0; i < nums.size(); i++) {\n            if (nums[i] != 0) {\n                nums[cover_index++] = nums[i];\n            }\n        }\n\n        for (; cover_index < nums.size(); cover_index++) {\n            nums[cover_index] = 0;\n        }\n    }\n};\n```\n\ncover_index 指向接下来要被覆盖的下标，只需要把遇到的非0在存放在该下标即可，记得更新 cover_index 。完成元素移动之后，此刻 cover_index 指向的下标到结尾全部置为 0。","tags":["数组"],"categories":["leetcode"]},{"title":"27.移除元素","url":"/2024/09/22/27-移除元素/","content":"\n```c++\nclass Solution {\npublic:\n    int removeElement(vector<int>& nums, int val) {\n        int cover_index = 0;\n        for(int i = 0; i < nums.size(); i++){\n            if(nums[i] != val){\n                nums[cover_index++] = nums[i];\n            }\n        }\n\n        return cover_index;\n    }\n};\n```\n\n如果你有看我 [26. 删除有序数组中的重复项](https://xiaoyangst.github.io/2024/08/08/26-%E5%88%A0%E9%99%A4%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/) 这道题二刷的记录，你就会明白这道题到底有多简单。核心就是 维护好 cover_index 下标，即指向接下来要被覆盖的下标。","tags":["数组"],"categories":["leetcode"]},{"title":"HTTP 网络的请求发送和响应处理","url":"/2024/09/22/HTTP-网络的请求发送和响应处理/","content":"\n<!-- toc -->\n\n通常需要包含以下头文件：\n\n1. **`QNetworkAccessManager`**: 用于管理网络请求\n2. **`QNetworkRequest`**: 用于构建并发送请求（例如设置URL、HTTP头等）\n3. **`QNetworkReply`**: 用于接收响应\n4. **`QUrl`**: 用于处理请求的URL\n\n注：qmake 中添加 QT += network\n\n![运行演示.gif](/images/2024/09/22/d2a19700-788a-11ef-9d1d-2119386dba73.gif)\n\n代码地址：[HTTP 和 JSON](https://github.com/xiaoyangst/Code/tree/master/Qt%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/HTTP%20%E5%92%8C%20JSON)\n\n文章指引：[JSON 处理](https://xiaoyangst.github.io/2024/09/22/Json-%E7%9A%84%E5%A4%84%E7%90%86/) \n\n## finished 信号意味着什么 ？\n\n待我们发送请求之后，直到对端响应才会继续往下执行代码：\n\n```c++\nQNetworkReply* response_ = httpManager_->get(request_);\n```\n\n响应之后，QNetworkReply 会发出 finished 信号，这个信号的触发**并不意味着请求一定成功**，它只是表示网络请求的处理已经完成，所有数据都已接收，无论请求的结果是成功还是失败。要判断请求是否成功，需要检查 QNetworkReply 对象的状态。\n\n我们先判断此次请求是否有错误（QNetworkReply::NoError），如果有就打印错误情况，否则就继续我们的代码逻辑。\n\n```c++\n    connect(response_,&QNetworkReply::finished,this,[response_,this](){\n        if(response_->error() == QNetworkReply::NoError){   // 没有发送错误\n            emit http_finished(response_);\n        }else{\n            qDebug()<<response_->error();   // 打印失败情况\n        }\n    });\n```\n\n## 读取对端响应\n\n此代码中是 readAll 读取全部的数据，然后保存到 QByteArray 中，但是如果传来的数据很大，这未必是合理的处理方式。对几种常用的方式简单总结：\n\n- **readAll()** 是最简单的方式，但可能在数据较大时消耗较多内存。\n- **read()** 和 **readLine()** 提供了逐步读取的控制，适合处理流式或分块数据。\n- **bytesAvailable()** 让你可以根据数据量动态决定读取策略，适合需要优化性能的场景。\n\n（一）read：逐步读取接收的数据，参数是要读取的字节数。你可以调用它多次来读取一部分数据\n\n```c++\nQByteArray chunk = reply->read(1024);  // 读取1024字节\n```\n\n**适用场景**：当数据量较大或者需要按块处理时，`read()` 允许你控制读取的数据大小。例如处理大型文件或流式数据时，可以避免一次性占用过多内存。\n\n（二）readAll：一次性读取所有可用的数据\n\n```c++\nQByteArray allData = reply->readAll();  // 读取所有数据\n```\n\n**适用场景**：当你知道数据量较小，或者你不关心数据的大小时，`readAll()` 是最简单的方式。它会把所有接收到的数据存储在一个字节数组中。\n\n（三）readLine：读取一行数据，行以换行符（`\\n`）或回车换行符（`\\r\\n`）作为结尾。它会读取直到遇到这些字符或达到给定字节数\n\n```c++\nQByteArray line = reply->readLine();\n```\n\n**适用场景**：适合处理以行结构组织的文本数据（例如 HTTP 响应头、CSV 文件）\n\n（四）bytesAvailable：返回当前可以从缓冲区中读取的字节数。你可以使用它来查看是否有足够的数据可供读取\n\n```c++\nqint64 availableBytes = reply->bytesAvailable();\n```\n\n用于判断是否有足够数据来决定使用 `read()` 或 `readLine()`","tags":["Qt"],"categories":["technology"]},{"title":"Json 的处理","url":"/2024/09/22/Json-的处理/","content":"\n<!-- toc -->\n\n在 Qt 中处理 JSON 数据时，通常会使用以下头文件：\n\n1. **`QJsonDocument`**：用于封装 JSON 文档（可以是 JSON 对象或 JSON 数组）\n2. **`QJsonObject`**：用于表示 JSON 对象（key-value 形式的 JSON 数据）\n3. **`QJsonArray`**：用于表示 JSON 数组\n4. **`QJsonValue`**：用于表示 JSON 对象或数组中的值（可以是字符串、数字、布尔值等）\n5. **`QJsonParseError`**：用于捕捉 JSON 解析中的错误\n\n序列化和反序列化 JSON 用 QJsonDocument，创建 JSON 用 QJsonObject。\n\n想要在网络中进行传输，需要把 QJsonObject 转换为 QByteArray。\n\n![Json.png](/images/2024/09/22/3aee0120-7883-11ef-9d1d-2119386dba73.png)\n\n## 创建JSON\n\n```c++\n#include <QJsonDocument>\n#include <QJsonObject>\n#include <QJsonArray>\n#include <QJsonValue>\n#include <QDebug>\n\nvoid createJson() {\n    // 创建 JSON 对象\n    QJsonObject jsonObj;\n    jsonObj.insert(\"name\", \"John Doe\");\t// 添加 JSON 数据\n    jsonObj.insert(\"age\", 30);\n    jsonObj.insert(\"isStudent\", false);\n\n    QJsonArray jsonArray;\n    jsonArray.append(\"Reading\");\n    jsonArray.append(\"Traveling\");\n    jsonArray.append(\"Swimming\");\n\n    jsonObj.insert(\"hobbies\", jsonArray);\n\n    // 把 JSON 转换为可在网络传输的 QByteArray\n    QJsonDocument jsonDoc(jsonObj);\n    QByteArray jsonData = jsonDoc.toJson();\t\n    \n    qDebug() << \"Created JSON:\" << jsonData;\n}\n```\n\n## 解析JSON\n\n```c++\n#include <QJsonDocument>\n#include <QJsonObject>\n#include <QJsonArray>\n#include <QJsonValue>\n#include <QDebug>\n\nvoid parseJson(const QByteArray &jsonData) {\n    QJsonParseError jsonError;\n    QJsonDocument jsonDoc = QJsonDocument::fromJson(jsonData, &jsonError);\t // 将 JSON 解析为 UTF-8 编码的 JSON 文档，并从中创建 QJsonDocument\n\n    if (jsonError.error != QJsonParseError::NoError) {\t// 如果 解析有误，退出\n        qDebug() << \"JSON parse error:\" << jsonError.errorString();\n        return;\n    }\n\n    if (jsonDoc.isObject()) {\t// 确保是一个对象\n        QJsonObject jsonObj = jsonDoc.object();\t// 得到 JSON 对象\n        qDebug() << \"Parsed JSON object:\" << jsonObj;\n\n        if (jsonObj.contains(\"name\")) {\t// 确保 key 是合法的\n            qDebug() << \"Name:\" << jsonObj.value(\"name\").toString();\t//获取 key 对应的  v\n        }\n        if (jsonObj.contains(\"age\")) {\n            qDebug() << \"Age:\" << jsonObj.value(\"age\").toInt();\n        }\n    }\n}\n```","tags":["Qt"],"categories":["technology"]},{"title":"第八章：协程","url":"/2024/09/21/第八章：协程/","content":"\n<!-- toc -->\n\n## 协程是什么？\n\n普通函数返回点：返回\n\n协程返回点：**暂停** + 返回\n\n```C++\nint func(){\n    printf(\"A\");\n    return 0;\n    printf(\"B\");\n    return 0;\n    printf(\"C\");\n}\n```\n\n如果是普通函数，待输入字符 A，执行 return 返回，该函数执行完成。往后的代码永远不会有执行的机会。\n\n如果是协程，待输出字符 A，执行 return 返回，该函数执行完成。但下一次该函数可以继续被执行，并且从上次结束的地方继续往下执行，你可以说它有暂停功能，但也许记忆功能会更容易理解。往下执行，输出字符 A，执行 return 返回。\n\n至于 C++20 中如何支持协程，可见此文：[C++20协程入门教程](https://zplutor.github.io/2022/03/25/cpp-coroutine-beginner/)。\n\n![协程.png](/images/2024/09/21/ca34b010-781d-11ef-b897-6fd30f248963.png)\n\n## Asio 提供的协程接口\n\nBoost.Asio 从 C++20 开始支持协程。通过协程，可以编写异步代码，避免了嵌套的回调函数或复杂的状态机。这使得代码结构更加直观和易于维护。Boost.Asio 利用 C++ 的协程语法，使得异步操作看起来像同步操作。\n\n常用库组件：\n\n- **`boost::asio::awaitable`**: 表示一个可以使用协程等待的类型\n- **`boost::asio::use_awaitable`**: 用作异步操作的最后一个参数，告诉 Asio 操作返回一个 `awaitable` 对象，可以与协程配合使用\n- **`co_spawn`**: 启动一个协程，参数分别为调度器，执行的函数，以及启动方式。比方说启动方式是 deatched，表示将协程对象分离出来，这种启动方式可以启动多个协程，他们都是独立的，如何调度取决于调度器，在用户的感知上更像是线程调度的模式，类似于并发运行，其实底层都是串行的\n- **`co_await`**: 等待异步操作完成\n\n### boost::asio::awaitable\n\n```c++\ntemplate<\n    typename T,\n    typename Executor = any_io_executor>\nclass awaitable\n```\n\n作为协程或异步操作的**返回类型**。从定义来看，必填模板参数是返回类型 T，也就是说协程或异步操作的返回类型是什么， T 就填什么。\n\n```c++\nboost::asio::awaitable<void> my_async_function();\nboost::asio::awaitable<int> my_async_function_with_result();\n```\n\n第一个代表 my_async_function 返回值类型是 void ，第二个代表 my_async_function_with_result 返回值类型是 int。\n\n### boost::asio::use_awaitable\n\n```c++\nconstexpr use_awaitable_t use_awaitable;\n\ntemplate<\n    typename Executor = any_io_executor>\nstruct use_awaitable_t\n```\n\n`use_awaitable` 是一个标记（无参数，仅作为标记使用），告诉 Boost.Asio 返回一个 `awaitable` 对象，支持协程等待。\n\n常用操作：在进行异步操作时，它作为参数传递给函数，表示希望异步结果能够与协程配合使用。\n\n```c++\nco_await async_read(socket, boost::asio::buffer(data), boost::asio::use_awaitable);\n```\n\n### boost::asio::co_spawn\n\n用于启动协程的函数，它允许协程在 `io_context` 中运行，管理异步任务的生命周期。\n\n```c++\ntemplate<\n    typename Executor, \n    typename Awaitable, \n    typename Token>\nvoid co_spawn(Executor&& ex, Awaitable&& awaitable, Token&& token);\n```\n\n`Executor`：执行异步任务的执行器（通常是 `io_context`）。\n\n`Awaitable`：一个协程，通常是返回 `awaitable<T>` 类型的函数。\n\n`Token`：协程结束后如何处理返回值，通常使用 `detached` 选项表示不关心返回值；或者使用 `use_future` 来获取返回值。\n\n举例说明：\n\n```c++\nboost::asio::co_spawn(io_context, my_async_function(), boost::asio::detached);\n```\n\n`detached`：表示协程完成后不需要返回值或等待结果。它用于简单的异步操作，不关心任务的结果。\n\n`use_future`：协程完成后，返回一个 `std::future` 对象，可以等待协程的结果。\n\n### co_await\n\n等待一个异步操作完成，通常配合 `awaitable` 一起使用。\n\n比方说：\n\n```c++\nco_await async_read(socket, boost::asio::buffer(buffer), boost::asio::use_awaitable);\n```\n\n### use_future\n\n`use_future` 是 `co_spawn` 的另一个选项，表示协程运行完成后，将返回一个 `std::future` 对象，可以等待并获取协程的结果。\n\n```c++\nauto future = boost::asio::co_spawn(io_context, my_async_function(), boost::asio::use_future);\nauto result = future.get(); // 等待协程结果\n```\n\n### boost::asio::steady_timer\n\n`steady_timer` 是 Boost.Asio 的定时器类，常与协程一起使用，用于执行定时任务或延迟任务。\n\n```c++\nboost::asio::steady_timer timer(io_context);\ntimer.expires_after(std::chrono::seconds(5));\nco_await timer.async_wait(boost::asio::use_awaitable);\n```\n\n`io_context`：执行器，用于管理异步操作。\n\n`expires_after`：设置定时器的超时时间。\n\n`async_wait`：等待定时器超时，与协程配合使用。\n\n### 异步操作函数\n\nBoost.Asio 提供了各种异步操作函数（如 `async_read`, `async_write`, `async_connect`, `async_resolve`），这些函数都可以使用协程来等待结果。\n\n```c++\nco_await boost::asio::async_connect(socket, endpoints, boost::asio::use_awaitable);\nco_await boost::asio::async_read(socket, boost::asio::buffer(buffer), boost::asio::use_awaitable);\nco_await boost::asio::async_write(socket, boost::asio::buffer(data), boost::asio::use_awaitable);\n```\n\n常见参数：\n\n- `socket`：用于通信的 `tcp::socket` 对象。\n- `buffer`：用于传输数据的缓冲区，通常是 `boost::asio::buffer`。\n- `endpoints`：用于连接的地址列表。\n- `use_awaitable`：表示使用协程等待异步操作的结果。\n\n## 解读官方代码\n\n我觉得结合前面接口的介绍，读懂下面的代码就不难了：\n\n```c++\n#include <boost/asio/co_spawn.hpp>\n#include <boost/asio/detached.hpp>\n#include <boost/asio/io_context.hpp>\n#include <boost/asio/ip/tcp.hpp>\n#include <boost/asio/signal_set.hpp>\n#include <boost/asio/write.hpp>\n#include <cstdio>\nusing boost::asio::ip::tcp;\nusing boost::asio::awaitable;\nusing boost::asio::co_spawn;\nusing boost::asio::detached;\nusing boost::asio::use_awaitable;\nnamespace this_coro = boost::asio::this_coro;\n#if defined(BOOST_ASIO_ENABLE_HANDLER_TRACKING)\n# define use_awaitable \\\n  boost::asio::use_awaitable_t(__FILE__, __LINE__, __PRETTY_FUNCTION__)\n#endif\nawaitable<void> echo(tcp::socket socket)\n{\n    try\n    {\n        char data[1024];\n        for (;;)\n        {\n            std::size_t n = co_await socket.async_read_some(boost::asio::buffer(data), use_awaitable);\n            co_await async_write(socket, boost::asio::buffer(data, n), use_awaitable);\n        }\n    }\n    catch (std::exception& e)\n    {\n        std::printf(\"echo Exception: %s\\n\", e.what());\n    }\n}\nawaitable<void> listener()\n{\n    auto executor = co_await this_coro::executor;\n    tcp::acceptor acceptor(executor, { tcp::v4(), 10086 });\n    for (;;)\n    {\n        tcp::socket socket = co_await acceptor.async_accept(use_awaitable);\n        co_spawn(executor, echo(std::move(socket)), detached);\n    }\n}\nint main()\n{\n    try\n    {\n        boost::asio::io_context io_context(1);\n        boost::asio::signal_set signals(io_context, SIGINT, SIGTERM);\n        signals.async_wait([&](auto, auto) { io_context.stop(); });\n        co_spawn(io_context, listener(), detached);\n        io_context.run();\n    }\n    catch (std::exception& e)\n    {\n        std::printf(\"Exception: %s\\n\", e.what());\n    }\n}\n```\n\n`co_spawn(io_context, listener(), detached)` 。co_spawn 意味着 启动一个协程，那么需要传递三个参数，第一个参数是异步任务的执行器，网络编程中通常就是 io_context 无疑了。第二个参数就是协程，即一个函数，只不过这个函数如何才可以被视为协程，后续再聊。第三个参数有两种选择，一种选择是不关心返回值，一种是关心返回值。你可以看到我们传递的协程是没有返回值的，那就可以用 detached，表示协程完成后不需要返回值或等待结果。否则你传递 use_future ，代表协程完成后，返回一个 `std::future` 对象，可以等待协程的结果。\n\n`listener()` 。它究竟如何是被视为一个 协程的？请看下面：\n\n1. 返回类型为 `boost::asio::awaitable<T>`。（必须）\n2. 使用 `co_await` 操作符等待异步操作。（必须）\n3. 使用 `co_return` 返回结果（如果有的话，我们这里是没有的）。（非必须）\n4. 是被 `boost::asio::co_spawn` 启动的。（必须）\n\n`listener` 内部做了什么 ？\n\n先通过`this_coro::executor` 获取当前协程的执行器（即 io_context 中的执行上下文），然后监听 TCP 连接。每当有客户端连接到服务器，`async_accept` 接收连接，并启动 `echo` 协程来处理该连接。这个过程是异步等待的，因为我们使用 co_await ，即`co_await acceptor.async_accept(use_awaitable)`。`co_spawn` 用于启动 `echo` 协程，并且使用 `detached` 方式运行，表示不需要等待其结束。\n\necho 函数就不提了，和 listener 并无二致。我主要还是提一提`this_coro::executor` ：\n\n**获取执行器 (executor)**: `this_coro::executor` 是一个特殊的对象，它代表当前协程正在使用的执行器（即协程是在哪个 `io_context` 或 `executor` 上运行的）。\n\n**确保异步操作正确调度**: 当你通过 `co_await this_coro::executor` 获取执行器时，实际上是在告诉编译器，当前协程的所有异步操作都需要通过这个执行器调度。这使得协程中的 `co_await` 异步操作能够正确使用 `executor` 来调度执行。\n\n那为什么我们主函数中没有使用呢？\n\n在主函数中，执行器并没有直接在协程中运行，因此不需要使用 `this_coro::executor`。`io_context` 是在主函数中直接创建的，并且作为参数传递给 `co_spawn`。当 `co_spawn` 启动协程时，它会自动将 `io_context` 作为执行器传递给协程内部使用的 `this_coro::executor`。\n\n---\n\n⭐️内容取自 B 站 UP 恋恋风辰和 mmoaay 的《Boost.Asio C++ 网络编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议看原视频或者读原书。","tags":["网络编程","Asio"],"categories":["technology"]},{"title":"47.全排列II","url":"/2024/09/21/47-全排列II/","content":"\n```c++\nclass Solution {\nprivate:\n    set<int> recordFirst;\n    vector<vector<int>> result;\n    vector<int> path;\npublic:\n    void backtrace(vector<int>& nums){\n        if(path.size() == nums.size()){\n            result.push_back(path);\n            return;\n        }\n        set<int> recordSecond;\n        for(int i = 0; i < nums.size(); i++){\n            \n            // 去重同一个元素（由下标判断）\n            if(recordFirst.find(i) != recordFirst.end()){ \n                continue;\n            }\n\n            // 去重同一个 path\n            if(recordSecond.find(nums[i]) != recordSecond.end()){ \n                continue;\n            }\n            \n            path.push_back(nums[i]);\n            recordFirst.insert(i);\n            recordSecond.insert(nums[i]);\n            backtrace(nums);\n            recordFirst.erase(i);\n            path.pop_back();\n        }\n    }\n    vector<vector<int>> permuteUnique(vector<int>& nums) {\n        backtrace(nums);\n        return result;\n    }\n};\n```\n\n这道题很好体现 树层和树枝的去重，树层去重需要创建一个局部记录项，树枝去重需要创建一个全局记录项。因为树枝在不同的栈中，树层在同一个栈中。\n\n![47.全排列II.png](/images/2024/09/21/0ffb1b50-77b7-11ef-9780-8f1229f68407.png)\n\n由于数组中有相同的元素，树枝去重记录项 recordFirst 记录下标，因为下标是唯一的；树层去重记录项 recordSecond 记录元素，因为相同的元素意味着重复行为，是移除的对象。","tags":["回溯"],"categories":["leetcode"]},{"title":"46.全排列","url":"/2024/09/20/46-全排列/","content":"\n```c++\nclass Solution {\nprivate:\n    set<int> recordFirst;\n    vector<vector<int>> result;\n    vector<int> path;\npublic:\n    void backtrace(vector<int>& nums){\n        if(path.size() == nums.size()){\n            result.push_back(path);\n            return;\n        }\n\n        for(int i = 0; i < nums.size(); i++){\n            if(recordFirst.find(nums[i]) != recordFirst.end()){\n                continue;\n            }\n\n            path.push_back(nums[i]);\n            recordFirst.insert(nums[i]);\n            backtrace(nums);\n            recordFirst.erase(nums[i]);\n            path.pop_back();\n        }\n    }\n\n    vector<vector<int>> permute(vector<int>& nums) {\n        backtrace(nums);\n        return result;\n    }\n};\n```\n\n我们简单捋一下思路，这道题相当简单。\n\n从此题的题意可以看出，我们每次必须从数组的开头遍历，那我们就不需要像前面的组合题那样需要一个参数来记录当前位置，以方便下一个栈能够找到从哪里继续开始。\n\n也正因为这个缘故，我们必须判断已加入到路径中的元素不可再重复。用一个全局的记录项 recordFirst，借此来去重。我们不是同一栈的去重，而是和前面所有被加入路径的元素进行去重，那就得有之前的信息，全局记录项就是恰当的。\n\n","tags":["回溯"],"categories":["leetcode"]},{"title":"491. 非递减子序列","url":"/2024/09/20/491-非递减子序列/","content":"\n```c++\nclass Solution {\nprivate:\n    vector<vector<int>> result;\n    vector<int> path;\npublic:\n      void backtrace(vector<int>& nums, int cur){\n        if(path.size() >= 2){\n            result.push_back(path);\n        }\n        set<int> removeSame;\n        for(int i = cur; i < nums.size(); i++){\n            if(!path.empty() && path.back() > nums[i]){     // 非递增\n                continue;\n            }\n            if(removeSame.find(nums[i]) != removeSame.end()){   // 有重复\n                continue;\n            }\n\n            // 到达这里的，皆是合法的\n            removeSame.insert(nums[i]);\n            path.push_back(nums[i]);\n            backtrace(nums,i + 1);\n            path.pop_back();\n        }\n      }\n    vector<vector<int>> findSubsequences(vector<int>& nums) {\n        backtrace(nums,0);\n        return result;\n    }\n};\n```\n\n这道题真的困扰好久，我觉得就是没有去画图，导致在脑子里来回绕，特画如下简图：\n\n![491.非递增子序列.png](/images/2024/09/20/656a9320-775a-11ef-8444-c35b50d6b191.png)\n\n我们先解决非递增问题。前一个栈的元素 A 和当前栈的所有元素逐一比较，如果谁比 A 大，那么这个数就是不合法的，将被跳过。合法的就会继续往下判断。\n\n接着处理重复元素的问题，从图中明显看得出是同一栈中的元素重复了，那就只需要维护一个当前栈的一个记录项（这里用的 set）即可，当它进入下一个栈时就会被清空。因此，只需要让检查当前栈的元素是否存在与 set 集合中，存在就意味着是不合法的。因此`removeSame.insert(nums[i])`，即加入当前栈且合法的元素进去，以便后续去重。\n\n还要`path.push_back(nums[i])`，因为合法的元素是要加入到 path 中记录的，这也是我们的最终目标的组成部分。\n\n来到末尾，从题意中可以看到的是，我们是要在合法元素的下一个位置开始，因此 backtrace 的第二个参数是 i + 1。可不要误写成为 cur + 1。","tags":["回溯"],"categories":["leetcode"]},{"title":"第九章：CMake 交叉编译","url":"/2024/09/20/第九章：CMake-交叉编译/","content":"\n之前学习过交叉编译，但一直缺乏实践，因为我也不接触嵌入式开发。就在昨天和网络上一个朋友解决CMake相关的问题，恰好就有机会实践交叉编译。\n\n如果你在 Linux 系统上，你希望编译出的可执行程序在 Arm 系统上执行，这就需要交叉编译。\n\n整个可执行程序链接的库也必须是在 Arm 系统上的，不要编译出 Linux 系统上的库，这是不要弄混的，因为你最终要在 Arm 系统执行你的程序（通过 file 命令能够查看相关信息）。\n\n首先，需要安装适用于 ARM 的交叉编译工具链，可以根据自己的情况选择，下面简单举例：\n\n```bash\nsudo apt-get install gcc-arm-none-eabi\n```\n\n然后在你的根CMakeLists.txt文件中添加如下参数的配置，记得更换相关程序的路径。\n\n```cmake\n# 指定目标系统名称和处理器类型\nset(CMAKE_SYSTEM_NAME Linux) # 设置目标系统名称为 Linux\nset(CMAKE_SYSTEM_PROCESSOR arm) # 设置目标处理器类型为 ARM\n\n# 设置交叉编译器路径（填绝对路径）\nset(CMAKE_C_COMPILER /usr/bin/arm-none-eabi-gcc) # 设置 C 编译器为 ARM 交叉编译器\nset(CMAKE_CXX_COMPILER /usr/bin/arm-none-eabi-g++) # 设置 C++ 编译器为 ARM 交叉编译器\n\n# 设置交叉编译器的 sysroot 路径（填绝对路径）\n# 假设 sysroot 位于 /path/to/arm/sysroot\nset(CMAKE_SYSROOT /path/to/arm/sysroot) # 指定交叉编译器使用的 sysroot 路径，通常包含目标系统的库和头文件\n\n# 配置查找路径模式\nset(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER) # 指定 CMake 查找程序时不使用 sysroot 路径\nset(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY) # 指定 CMake 查找库时仅使用 sysroot 路径\nset(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY) # 指定 CMake 查找头文件时仅使用 sysroot 路径\nset(CMAKE_FIND_ROOT_PATH_MODE_PACKAGE ONLY) # 指定 CMake 查找包时仅使用 sysroot 路径\n```\n\n当然你可以选择把这些参数单独放在一个cmake文件中（例如 `arm-toolchain.cmake`），这样你需要交叉编译的时候再指定这个文件进行交叉编译也不迟。\n\n```bash\ncmake -S . -B build -DCMAKE_TOOLCHAIN_FILE=../arm-toolchain.cmake\n```\n\n最后再次强调，如果你的目标是Arm系统，那么在你本机Linux系统上编译的库必须是针对Arm架构编译得到的。\n\n这个库文件的编译也是用的交叉编译工具，你只需要在编译库文件时指定前面创建的`arm-toolchain.cmake`文件即可（在你所编译的库文件的源码下创建即可），步骤都差不多的。\n\n```bash\ncmake -S . -B build -DCMAKE_TOOLCHAIN_FILE=../arm-toolchain.cmake\n```\n\n","tags":["CMake"],"categories":["technology"]},{"title":"第八章：CMake 切换生成器","url":"/2024/09/20/第八章：CMake-切换生成器/","content":"\n如果你在 Windows 系统上，默认采用 Visual Studio 中的某个版本作为生成器。\n\n如果你希望指定 其它生成器，我们先来看看CMake支持哪些编译器？\n\n你输入 `cmake --help`命令，会有如下内容：\n\n```bash\nGenerators\n\nThe following generators are available on this platform (* marks default):\n* Visual Studio 17 2022        = Generates Visual Studio 2022 project files.\n                                 Use -A option to specify architecture.\n  Visual Studio 16 2019        = Generates Visual Studio 2019 project files.\n                                 Use -A option to specify architecture.\n  Visual Studio 15 2017 [arch] = Generates Visual Studio 2017 project files.\n                                 Optional [arch] can be \"Win64\" or \"ARM\".\n  Visual Studio 14 2015 [arch] = Generates Visual Studio 2015 project files.\n                                 Optional [arch] can be \"Win64\" or \"ARM\".\n  Visual Studio 12 2013 [arch] = Deprecated.  Generates Visual Studio 2013\n                                 project files.  Optional [arch] can be\n                                 \"Win64\" or \"ARM\".\n  Visual Studio 9 2008 [arch]  = Deprecated.  Generates Visual Studio 2008\n                                 project files.  Optional [arch] can be\n                                 \"Win64\" or \"IA64\".\n  Borland Makefiles            = Generates Borland makefiles.\n  NMake Makefiles              = Generates NMake makefiles.\n  NMake Makefiles JOM          = Generates JOM makefiles.\n  MSYS Makefiles               = Generates MSYS makefiles.\n  MinGW Makefiles              = Generates a make file for use with\n                                 mingw32-make.\n  Green Hills MULTI            = Generates Green Hills MULTI files\n                                 (experimental, work-in-progress).\n  Unix Makefiles               = Generates standard UNIX makefiles.\n  Ninja                        = Generates build.ninja files.\n  Ninja Multi-Config           = Generates build-<Config>.ninja files.\n  Watcom WMake                 = Generates Watcom WMake makefiles.\n  CodeBlocks - MinGW Makefiles = Generates CodeBlocks project files\n                                 (deprecated).\n  CodeBlocks - NMake Makefiles = Generates CodeBlocks project files\n                                 (deprecated).\n  CodeBlocks - NMake Makefiles JOM\n                               = Generates CodeBlocks project files\n                                 (deprecated).\n  CodeBlocks - Ninja           = Generates CodeBlocks project files\n                                 (deprecated).\n  CodeBlocks - Unix Makefiles  = Generates CodeBlocks project files\n                                 (deprecated).\n  CodeLite - MinGW Makefiles   = Generates CodeLite project files\n                                 (deprecated).\n  CodeLite - NMake Makefiles   = Generates CodeLite project files\n                                 (deprecated).\n  CodeLite - Ninja             = Generates CodeLite project files\n                                 (deprecated).\n  CodeLite - Unix Makefiles    = Generates CodeLite project files\n                                 (deprecated).\n  Eclipse CDT4 - NMake Makefiles\n                               = Generates Eclipse CDT 4.0 project files\n                                 (deprecated).\n  Eclipse CDT4 - MinGW Makefiles\n                               = Generates Eclipse CDT 4.0 project files\n                                 (deprecated).\n  Eclipse CDT4 - Ninja         = Generates Eclipse CDT 4.0 project files\n                                 (deprecated).\n  Eclipse CDT4 - Unix Makefiles= Generates Eclipse CDT 4.0 project files\n                                 (deprecated).\n  Kate - MinGW Makefiles       = Generates Kate project files (deprecated).\n  Kate - NMake Makefiles       = Generates Kate project files (deprecated).\n  Kate - Ninja                 = Generates Kate project files (deprecated).\n  Kate - Ninja Multi-Config    = Generates Kate project files (deprecated).\n  Kate - Unix Makefiles        = Generates Kate project files (deprecated).\n  Sublime Text 2 - MinGW Makefiles\n                               = Generates Sublime Text 2 project files\n                                 (deprecated).\n  Sublime Text 2 - NMake Makefiles\n                               = Generates Sublime Text 2 project files\n                                 (deprecated).\n  Sublime Text 2 - Ninja       = Generates Sublime Text 2 project files\n                                 (deprecated).\n  Sublime Text 2 - Unix Makefiles\n                               = Generates Sublime Text 2 project files\n                                 (deprecated).\n```\n\n然后通过 -G 参数来指定你需要用到的编译器即可。\n\n```bash\ncmake -S . -B build -G Ninja\n```\n\n但我个人建议使用 cmake-gui 来做这个工作，当你第一次点击Configure的时候，会让你选择生成器。","tags":["CMake"],"categories":["technology"]},{"title":"终章：结局只是一种虚构","url":"/2024/09/20/终章：结局只是一种虚构/","content":"\n按照之前的承诺，已经把准备手写 CMake 教程前罗列的目录对应的内容完成了。如我一开始所讲，CMake 的内容其实相当之多，没有必要为了求全而在这个方向上费心费力。就国内当前的 CMake 书籍实在难以让人满意，如《CMake构建实战：项目开发卷》，由于国内当前只有这一本可以选择，依旧有人购买，依旧迎来失望，因为作者花费太多笔墨在语法上，而忘了 CMake 是个实践的工具。\n\n想必细心的朋友看到 CMake 很多的语法我都没有介绍，这些语法往往在跨平台编译等场景中才会大量出现，而个人当前的开发还没有要考虑那么多情况，这块的实践较少。我的这份 CMake 教程是实践的教程，按理已是终章。如标题所言，所谓结局只是一种虚构，保不齐后面这个 CMake 教程还会继续更新，但更新的内容是什么就完全不能罗列出目录来。看来这份教程已经进入一种混沌状态，你可以说它已经完成，你也可以说它正在完成的路上。但不管怎样，此文就是划分一个界限，即之前的内容是本教程的目标，之后的内容是本教程的扩展。\n","tags":["CMake"],"categories":["technology"]},{"title":"第七章：CMake 构建 Qt 项目","url":"/2024/09/20/第七章：CMake-构建-Qt-项目/","content":"\n网上就我的搜索经验来看，没有一篇文章实打实的把这个讲清楚，尽管我实践成功也来源于网上公布的文章，因此绝非要嘲讽谁。发此文就是希望那些想要通过 CMake 来管理 Qt 项目的人能够成功，网上的文章针对这块比较零散，把这些零散的内容和自身的实际情况结合，此文得以形成。\n\n![qt.png](/images/2024/09/20/fb0cb650-772e-11ef-bb33-ad22fef3cf2e.png)\n\nQt中要管理头文件、源文件、ui文件、qrc资源文件，针对上面这种文件结构对应的CMakeLists.tx文件内容如下：\n\n```cmake\ncmake_minimum_required(VERSION 3.26)\nproject(WarehouseManageSys)\n\nset(CMAKE_CXX_STANDARD 17)\n\n# 务必指定 ，即Qt库的路径\nset(CMAKE_PREFIX_PATH \"C:/Qt/6.5.3/mingw_64\")\n\n# 在当前目录中查找包含文件\nset(CMAKE_INCLUDE_CURRENT_DIR ON)\n\n# 查找所需的Qt6组件\nfind_package(Qt6 COMPONENTS\n        Core\n        Gui\n        Widgets\n        Sql\n        REQUIRED)\n\n\n#搜索头文件\ninclude_directories(include/)\nfile(GLOB HEADER_FILES \"include/*.h\")\n\n#搜索源文件\nfile(GLOB SRC_LIST \"src/*.cpp\")\n\n# 搜索ui文件\nfile(GLOB UI_FILES \"ui/*.ui\")\n\n# 搜索资源文件（图片、图标、音乐等）\nfile(GLOB_RECURSE RESOURCES \"sources/*.qrc\")\n\nadd_subdirectory(src)\nadd_subdirectory(thirdpart/OpenXLSX)\n\n# 生成头文件的 MOC 文件\nQT6_WRAP_CPP(HEADERS_MOC ${HEADER_FILES})\n# 生成 UI 文件对应的头文件\nQT6_WRAP_UI(FORMS_HEADERS ${UI_FILES})\n# 添加资源文件\nQT6_ADD_RESOURCES(RCC ${RESOURCES})\n\nadd_executable(WarehouseManageSys main.cpp ${HEADERS_MOC} ${SRC_LIST} ${FORMS_HEADERS} ${RCC})\n\ntarget_link_libraries(WarehouseManageSys\n        Qt6::Core\n        Qt6::Gui\n        Qt6::Widgets\n        Qt6::Sql\n        OpenXLSX::OpenXLSX\n)\n```\n\n也许 CMake 管理 Qt 项目还有其它语法，但个人实践成功并一直使用的就是如上方式，在今后的项目中只需要参考这份文件应该不会有大碍。如果无法满足需求的话，CMake 官方也有有关 Qt 项目语法介绍，尽管我从来没去看过。\n\n最后补充一个点，即由于在 CLion 上进行 Qt 开发，因此 ui_xx.h文件都在 cmake-build-debug 中，但是我又没有配置如何找到这些头文件的语法，写程序的时候是如何找到的呢？ \n\n在 `CMakeLists.txt` 中，已经使用了 `QT6_WRAP_UI` 来处理 `.ui` 文件。这些宏会生成相应的 `ui_xx.h` 文件，并将其路径添加到编译器的搜索路径中。这个过程是自动处理的，因此你不需要显式地指定这些生成文件的路径。","tags":["CMake"],"categories":["technology"]},{"title":"第六章：CMake 找库文件的两种方式","url":"/2024/09/20/第六章：CMake-找库文件的两种方式/","content":"\n<!-- toc -->\n\n在上一小节当中，查找第三方库用到一个新语法 find_package，这个语法往往被人误解，以为只要是找第三方库就可以用，但如果你看我第三章的那种方式构建库文件，你就无法用 find_package。\n\n我们是官方的第三方库，我们可以用 find_package，因为人家已经整理好相关的文件到一个变量中，我们才可以非常方便简单设置几个参数值快速找到库文件。但如果说我们自己的或不规范的第三方库，即没提过规范的语法设置快速寻找，就只能先添加库文件的寻找路径，再一个一个寻找，这就是 find_library 命令。\n\n总之，find_package 和 find_library 都可以用于在 CMake 中查找和链接库，但 find_package 更适用于具有CMake 配置文件的库，而 find_library 则适用于没有 CMake 配置文件的库。\n\n## find_package\n\n### 典型用法\n\n```cmake\nfind_package(<PackageName> [<version>] [REQUIRED] [COMPONENTS <components>...])\n```\n\n\\<PackageName\\> 是唯一的必选参数。\n\n\\<version\\> 通常会被省略，如果没有软件包就无法成功配置项目，则应给出 REQUIRED。\n\n一些更复杂的软件包支持组件，可以使用 COMPONENTS 关键字来选择组件，但大多数软件包都没有这种复杂程度。\n\n```cmake\n#查找名为 OpenCV 的包，找不到不报错，事后可以通过 ${OpenCV_FOUND} 查询是否找到\nfind_package(OpenCV)\t\n\n#查找名为 OpenCV 的包，找不到不报错，也不打印任何信息\nfind_package(OpenCV QUIET)\t\n\n#查找名为 OpenCV 的包，找不到就报错（并终止 cmake 进程，不再继续往下执行）\nfind_package(OpenCV REQUIRED) # 最常见用法\n\n#查找名为 OpenCV 的包，找不到就报错，且必须具有 OpenCV::core 和 OpenCV::videoio 这两个组件，如果没有这两个组件也会报错\nfind_package(OpenCV REQUIRED COMPONENTS core videoio)\n\n#查找名为 OpenCV 的包，找不到就报错，可具有 OpenCV::core 和 OpenCV::videoio 这两个组件，没有这两组件不会报错，通过 ${OpenCV_core_FOUND} 查询是否找到 core 组件\nfind_package(OpenCV REQUIRED OPTIONAL_COMPONENTS core videoio)\n```\n\n### 搜索包的模式\n\n**Module 模式**：在这种模式下，CMake 会搜索名为 `Find<PackageName>.cmake` 的文件，首先在 `CMAKE_MODULE_PATH` 指定的路径中查找，则在CMake安装目录（即**CMAKE_ROOT**变量）下的**Modules**目录下查找。找到文件后，CMake 会读取并处理它，负责查找包、检查版本，并生成任何必要的消息。\n\n```cmake\n#查找顺序\nCMAKE_MODULE_PATH\nCMAKE_ROOT\n```\n\n**Config 模式**：在这种模式下，CMake 会搜索名为 `<lowercasePackageName>-config.cmake` 或 `<PackageName>Config.cmake` 的文件。如果指定了版本信息，还会查找 `<lowercasePackageName>-config-version.cmake` 或 `<PackageName>ConfigVersion.cmake`。Config 模式下，可以指定一个包名列表来搜索。CMake 搜索配置和版本文件的位置比 Module 模式复杂得多。\n\n```cmake\n#查找文件\n<lowercasePackageName>-config.cmake 或 <PackageName>Config.cmake\n#如果指定版本\n<lowercasePackageName>-config-version.cmake` 或 `<PackageName>ConfigVersion.cmake\n```\n\n默认情况下是先 Module 模式，如果查找失败就采用 Config 模式。\n\nOpenCV 是 Config 模式，见下：\n\n![findpackage.png](/images/2024/09/20/d47086c0-772e-11ef-bb33-ad22fef3cf2e.png)\n\n如果想让CMake找到\\<PackageName\\>Config.cmake文件，需要在CMakeLists.txt中设置参数\\<PackageName\\>_DIR来设置路径。\n\n比方说OpenCV的设置情况：\n\n```c++\nset(OpenCV_DIR \"${CMAKE_CURRENT_SOURCE_DIR}/thirdpart/opencv_x64\")\n```\n\n然后你接着去设置头文件路径、库文件路径，最后把库文件链接到可执行程序中\n\n```cmake\nfind_package(OpenCV REQUIRED)\ninclude_directories(${OpenCV_INCLUDE_DIRS})\n \nadd_executable(YourProjectName main.cpp)\ntarget_link_libraries(YourProjectName ${OpenCV_LIBS})\n```\n\n因此 `find_package` 并**不是直接去找具体的动态库文件和头文件**。而是去找**包配置文件**，这个**配置文件里包含了包的具体信息**，包括**动态库文件的位置**，**头文件的目录**，**链接时需要开启的编译选项**等等。\n\n再者，不同的操作系统平台，CMake 都会有默认的搜索路径，再结合官方提供的CMake信息，以及你的 CMakeLists.txt 文件就能找到库文件。那如果你没有把这些库文件安装到 CMake 默认搜索路径呢？\n\n### 默认的搜索路径\n\nWindows 和 Linux 都有自己的标准路径，这里就以 Linux 作为探讨对象。\n\n```tex\n<prefix>/(lib/<arch>|lib*|share)/cmake/<name>*/\n<prefix>/(lib/<arch>|lib*|share)/<name>*/\n<prefix>/(lib/<arch>|lib*|share)/<name>*/cmake/\n<prefix>/<name>*/(lib/<arch>|lib*|share)/cmake/<name>*/\n<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/\n<prefix>/<name>*/(lib/<arch>|lib*|share)/<name>*/cmake/\n```\n\n- `<prefix>` 是变量 `${CMAKE_PREFIX_PATH}`，Unix 平台默认为 `/usr`。\n- `<name>` 是你在 `find_package(<name> REQUIRED)` 命令中指定的包名。\n- `<arch>` 是系统的架构，例如 `x86_64-linux-gnu` 或 `i386-linux-gnu`。\n  - （ Ubuntu 喜欢把库文件套娃在 `/usr/lib/x86_64-linux-gnu` 目录下）\n\n例如你是 64 位的 Linux 系统，`find_package(Qt5 REQUIRED)` 会依次搜索：\n\n```tex\n/usr/lib/cmake/Qt5/Qt5Config.cmake\n/usr/lib/x86_64-linux-gnu/cmake/Qt5/Qt5Config.cmake\n/usr/share/cmake/Qt5/Qt5Config.cmake\n/usr/lib/Qt5/Qt5Config.cmake\n/usr/lib/x86_64-linux-gnu/Qt5/Qt5Config.cmake\n/usr/share/Qt5/Qt5Config.cmake\n/usr/Qt5/lib/cmake/Qt5/Qt5Config.cmake\n/usr/Qt5/lib/x86_64-linux-gnu/cmake/Qt5/Qt5Config.cmake\n/usr/Qt5/share/cmake/Qt5/Qt5Config.cmake\n/usr/Qt5/lib/Qt5/Qt5Config.cmake\n/usr/Qt5/lib/x86_64-linux-gnu/Qt5/Qt5Config.cmake\n/usr/Qt5/share/Qt5/Qt5Config.cmake\n```\n\n### 非标准路径下的搜索\n\n如果你没有在前面介绍的标准路径下，你在其他地方下载并编译安装了，也没有把库文件和头文件移动到标准路径中，那该怎么办？这时你**需要手动指定一个变量**告诉它在哪儿。我们依旧还是以 Linux 举例。\n\n例如Qt5 安装到了`/opt/Qt5.12.1`。 首先找到它里面的 `Qt5Config.cmake` 文件所在位置。假如你找到该文件的位置是 `/opt/Qt5.12.1/lib/cmake/Qt5/Qt5Config.cmake`，那么请你设置变量 Qt5_DIR 为 `/opt/Qt5.12.1/lib/cmake/Qt5`。有三种设置方法：\n\n1. 单次有效：在 configure 阶段，可以从命令行设置： `cmake -B build -DQt5_DIR=\"/opt/Qt5.12.1/lib/cmake/Qt5\"`\n2. 全局启用：修改你的 `~/.bashrc` 文件添加环境变量： `export Qt5_DIR=\"/opt/Qt5.12.1/lib/cmake/Qt5\"`，然后重启终端。这样以后你每次构建任何项目，find_package 都能自动找到这个路径的 Qt5 包了。\n3. 单项目有效：直接在你自己项目的 CMakeLists.txt 最开头写一行： `set(Qt5_DIR \"\"/opt/Qt5.12.1/lib/cmake/Qt5\")`。但是一定要写在最前面。\n\n![利弊.png](/images/2024/09/20/c712be30-772e-11ef-bb33-ad22fef3cf2e.png)\n\n只要不删除 build ,单次有效的方式就会一直存在，因为 CMake 会有缓存，但如果你删除 build 了，下次你还得再设置一次。\n\n## find_library\n\n在 CMake 中，`find_library` 用于查找特定的库文件（如 `.lib`、`.a`、`.so` 等），并将该库的路径存储到变量中。它的功能类似于手动指定库文件路径，但通过 `find_library` 可以让 CMake 自动在系统的标准库路径或用户指定的路径中查找库。\n\n```cmake\nfind_library(<VAR> name [PATHS paths...])\n```\n\n**`<VAR>`**: 将找到的库的完整路径存储到这个变量中。\n\n**`name`**: 要查找的库的名称，不需要后缀（如 `.a` 或 `.so`）。\n\n**`PATHS`**: 可选，指定额外的搜索路径，CMake 会在这些路径中查找库。\n\n如果库文件已经在标准路径中，无需指定。否则，需要通过 PATH 参数指定。\n\n```c++\nfind_library(MYLIB_LIB NAMES mylib PATHS /usr/local/lib /opt/libs)\n\nif(MYLIB_LIB)\n    message(STATUS \"Found mylib: ${MYLIB_LIB}\")\n    target_link_libraries(MyExecutable ${MYLIB_LIB})\nelse()\n    message(FATAL_ERROR \"Could not find mylib!\")\nendif()\n```\n\n**`find_library(MYLIB_LIB NAMES mylib)`**: 这是查找名为 `mylib` 的库文件，查找到的路径会存储在 `MYLIB_LIB` 变量中。\n\n**`PATHS /usr/local/lib /opt/libs`**: 在这些路径下查找库文件。如果没有指定 `PATHS`，CMake 会默认查找系统标准的库路径，例如 `/usr/lib`、`/lib` 等。\n\n**`target_link_libraries(MyExecutable ${MYLIB_LIB})`**: 如果找到了库文件，将其链接到目标 `MyExecutable`。","tags":["CMake"],"categories":["technology"]},{"title":"第五章：CMake 添加第三方依赖库","url":"/2024/09/20/第五章：CMake-添加第三方依赖库/","content":"\n为什么要单独讲这个？我在导入第三方依赖库时遇到很多曲折，且不说那些没有被 CMake 管理的第三方库。综合考虑选择编译安装 OpenCV，因为它本身还依赖其它第三方库，特别适合做为本节内容演示。\n\n现在你已经下载并解压 OpenCV 的源码，进入文件夹之后你会看到根 CMakeLists.txt 文件。\n\n打开你的 cmake-gui 程序：\n\n1. 点击右侧 Browse Source 指定源文件路径，即根CMakeLists.txt文件存在的路径\n2. 点击右侧 Browse Build 指定 build 输出路径，可以自行创建或者 cmake-gui 帮我们自动创建\n3. 点击左下角 Configure，会让你选择编译的环境\n\n![cmakegui.png](/images/2024/09/20/cfc0f780-7725-11ef-bb33-ad22fef3cf2e.png)\n\n接下来就关注图中的红色区域的内容，这些都是参数，通常我们需要配置的参数是安装路径 CMAKE_INSTALL_PREFIX。\n\n![安装路径.png](/images/2024/09/20/d35a23d0-7725-11ef-bb33-ad22fef3cf2e.png)\n\n设置好对应的参数之后，再次点击 Configure 对设置的参数进行更新，没有出错之后（会出错，这个后面单独拎出来谈）点击 Generate 即可。\n\n退出 cmake-gui 程序，我们来到终端（ OpenCV 源码的 build 目录下，这个 build 文件夹前面我们就创建的，即 Browse Build 指定 build 输出路径），通过命令继续编译。\n\n```c++\nmingw32-make -j6\n    \nmingw32-make install\n```\n\n然后把我们编译成功之后 OpenCV 的 bin 文件目录加入到环境变量中，重启电脑即可。\n\n```c++\nD:\\opencv-4.10.0\\opencv_x64\\x64\\mingw\\bin\n```\n\n---\n\n前面有个地方说明，即点击 Configure 对设置的参数进行更新会出错，这是因为 OpenCV 需要去远端下载文件，往往下载失败。\n\n当然，这不是我要讲的主题，我要说的是 OpenCV 依赖 ffmpeg，不在编译 OpenCV 指定 ffmpeg 第三方库，OpenCV 将无法处理视频。\n\n现在我假定你已经编译安装 ffmpeg 了，你如何为 OpenCV  指定 ffmpeg 的安装路径 ？点击 Configure 对设置的参数进行更新会出错，这里面的出错信息就包含让你如何通过设置参数指定 ffmpeg 的安装路径。\n\n在系统环境变量中配置之后，记得重启电脑才能生效。\n\n![ffmpeg.png](/images/2024/09/20/d8548dd0-7725-11ef-bb33-ad22fef3cf2e.png)\n\n往后，如果你想要在你的项目中使用 OpenCV ，只需要把之前配置的安装路径下的文件拷贝过去即可。\n\n但这通常还不够，因为需要配置我们项目的 CMakeLists.txt 文件来找到第三方库。\n\n关于如何找到第三方库，学习上节内容之后，各位不会陌生，但是我们上节的文件结构相当简单，如果面对那种文件结构层级很多的怎么办？尽管用上节的内容也可以解决，但非常的麻烦。\n\n我想一个好的库文件（用 CMake 管理）应该只需要几个语法就能找到并导入，这通常也是存在的。\n\n![findpackage.png](/images/2024/09/20/dc8ae480-7725-11ef-bb33-ad22fef3cf2e.png)\n\n在我们的安装路径中找到 .cmake 配置文件（通常命名为**库名称+Config.cmake**），里面就会有如何帮我们导入第三方库的方式，打开看看里面前面注释的部分的核心内容。\n\n```cmake\nFIND_PACKAGE(OpenCV REQUIRED)\t#找到库文件\nTARGET_LINK_LIBRARIES(MY_TARGET_NAME ${OpenCV_LIBS})\t#链接到库文件\n```\n\n还有一个参数 OpenCV_INCLUDE_DIRS 提供给我们，这里包含所有头文件，我们只需要通过 include_directories 将其导入即可，这样就找到所有头文件了。\n\n```cmake\ninclude_directories(${OpenCV_INCLUDE_DIRS})\n```\n\n为了让如上内容都生效，我们就需要设置这个 .cmake 文件的路径。\n\n而且你会发现OpenCV_DIR这个参数好像在 .cmake 文件中没有说明，我猜想它的构成应该是FIND_PACKAGE中的库名称，然后加上下划线和DIR构成，即**库名称_DIR**（官网有说明，也就不是猜想了）。\n\n```c++\nset(OpenCV_DIR \"${CMAKE_CURRENT_SOURCE_DIR}/thirdpart/opencv_x64\")\n```\n\n下面，就看看完整版的 CMakeLists.txt 文件：\n\n```cmake\ncmake_minimum_required(VERSION 3.17)\nproject(YourProjectName)\n\nset(CMAKE_CXX_STANDARD 14)\n\n# 设置 OpenCV 的路径\nset(OpenCV_DIR \"${CMAKE_CURRENT_SOURCE_DIR}/thirdpart/opencv_x64\")\n\nfind_package(OpenCV REQUIRED)\ninclude_directories(${OpenCV_INCLUDE_DIRS})\n\nadd_executable(YourProjectName main.cpp)\ntarget_link_libraries(YourProjectName ${OpenCV_LIBS})\n```\n\n这里面有个新语法 FIND_PACKAGE，会在下节介绍，如何把我们的库文件也能像这样让用户轻松找到呢？下节就要见分晓。\n\n注：**库名称+Config.cmake**文件在build目录下也存在，而且也更详细，建议参考。","tags":["CMake"],"categories":["technology"]},{"title":"第四章：CMake 构建和链接静态库与动态库","url":"/2024/09/20/第四章：CMake-构建和链接静态库与动态库/","content":"\n<!-- toc -->\n\n我最近在尝试手写线程池，尽管还有很多改进的地方，但用来学习本节内容足够了。\n\n![线程池.png](/images/2024/09/20/ddcf40d0-7724-11ef-bb33-ad22fef3cf2e.png)\n\n## 构建静态库和动态库\n\n光是构建静态库和动态库还不够， 还需要指定生成路径，这样别人使用你的库文件将相当方便（后面你就知道了）。\n\n先看看如何构建静态库和动态库。\n\n```cmake\nadd_library(静态库名称 STATIC 源文件) \nadd_library(动态库名称 SHARED 源文件) \n```\n\n对于安装路径、头文件安装路径、静态库安装路径、动态库安装路径已在上节介绍。\n\n这里重点讲 install 的配置，即用户在终端使用 install 命令就能生成提前配置好的安装路径。\n\n```cmake\ninstall(TARGETS <target>... [...])              # 安装指定的目标（可执行文件、库等）\ninstall(DIRECTORY <dir>... [...])                # 安装指定的目录及其内容\n\n#本节尚未应用\ninstall(IMPORTED_RUNTIME_ARTIFACTS <target>... [...])  # 安装导入的运行时文件（通常由外部构建导入）\ninstall({FILES | PROGRAMS} <file>... [...])      # 安装指定的文件或程序\ninstall(SCRIPT <file> [...])                     # 执行指定的安装脚本\ninstall(CODE <code> [...])                       # 执行指定的 CMake 代码段\ninstall(EXPORT <export-name> [...])              # 导出指定的目标到一个 CMake 导出文件\ninstall(RUNTIME_DEPENDENCY_SET <set-name> [...]) # 安装运行时依赖项集合\n```\n\n因此，我们的重点关注静态库和动态库以及头文件的安装路径，那我们先设置路径和配置生成库文件的命令。\n\n```cmake\ncmake_minimum_required(VERSION 3.26)\nproject(YThreadPool)\nset(CMAKE_CXX_STANDARD 17)\n\ninclude_directories((${PROJECT_SOURCE_DIR}/include))\n\naux_source_directory(src SRC_LIST)\n\nset(CMAKE_INSTALL_PREFIX YThreadPool_x86)   # 指定安装路径的前缀\n\nset(CMAKE_INSTALL_INCLUDEDIR include)       # 设置基于安装路径的前缀的头文件生成路径\n\nset(CMAKE_INSTALL_LIBDIR lib)       # 设置基于安装路径的前缀的静态库生成路径 lib\nadd_library(YThreadPoolLIB STATIC ${SRC_LIST})     # 生成静态库\n\nset(CMAKE_INSTALL_BINDIR bin)       # 设置基于安装路径的前缀的动态库生成路径 bin\nadd_library(YThreadPoolBIN SHARED ${SRC_LIST})     # 生成动态库\n```\n\n但如果我们希望用户应用 install 命令来把这些文件全部放在安装路径下，就还需要继续往下配置。\n\n下面的配置中有些新参数在前面没有介绍，比如：DESTINATION、ARCHIVE、RUNTIME、LIBRARY。\n\n```cmake\n#安装 include 目录中的文件到指定安装的头文件目录\ninstall(DIRECTORY  ${PROJECT_SOURCE_DIR}/include/   \n        DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})\n\n #安装静态库 YThreadPoolLIB 到指定安装的库文件目录\ninstall(TARGETS YThreadPoolLIB                 \t\n        ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR})\n        \n # 安装动态库 YThreadPoolBIN 到指定安装的可执行文件和库文件目录\ninstall(TARGETS YThreadPoolBIN                     \n        RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n        LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR})\n```\n\n对出现的新参数，下面用列表来展示：\n\n| 目标文件 | 内容             | 安装目录变量             | 默认安装文件夹 |\n| -------- | ---------------- | ------------------------ | -------------- |\n| ARCHIVE  | 静态库           | ${CMAKE_INSTALL_LIBDIR}) | lib            |\n| LIBRARY  | 动态库           | ${CMAKE_INSTALL_LIBDIR}) | lib            |\n| RUNTIME  | 可执行二进制文件 | ${CMAKE_INSTALL_BINDIR}  | bin            |\n\n还有非常关键的指令：DESTINATION \\<dir\\>\n\n即指定磁盘上要安装文件的目录。`<dir>` 应为相对路径。 绝对路径是允许的，但不建议使用。\n\n下面开始整个静态库和动态库的构建和安装过程，最后再看看安装情况。\n\n```cmake\ncmake -S . -B build\ncmake --build build\ncmake --install build --config Debug \t#指定生成 Debug版\n```\n\n效果：\n\n![install.png](/images/2024/09/20/e4d0ec80-7724-11ef-bb33-ad22fef3cf2e.png)\n\n以后用户想要使用这个库，就只需要把 YThreadPool_x86 拷贝到自己的项目文件中。\n\n然后在 CMakeLists.txt 中找到所需库文件和头文件即可，这也是下面要演示的内容，即如何使用链接静态库和动态库。\n\n## 链接静态库和动态库\n\nlink_directories 用来指定库的路径，那么后续使用 link_libraries 或 target_link_libraries 搜索库文件的时候，也就只需要传入库文件名称即可。\n\nlink_directories 不会进行层级搜索。它只会将指定的目录添加到链接器的搜索路径中，而不会自动搜索该目录下的子目录。也就是说，如果你使用 `link_directories(${CMAKE_SOURCE_DIR}/lib)`，链接器只会查找 `${CMAKE_SOURCE_DIR}/lib` 目录中的库文件，不会查找 `lib` 目录中的子目录。\n\n如果你需要链接某个子目录中的库，必须显式地使用 `link_directories` 指定那个子目录，或者使用 `target_link_libraries` 直接指定库的完整路径。\n\n（一）链接静态库\n\n```c++\nlink_libraries(<static lib> [<static lib>...])\n\n参数1：指定出要链接的静态库的名字\n\n\t\t1.可以是全名 libxxx.a\n  \n\t\t2.也可以是掐头（lib）去尾（.a）之后的名字 xxx\n  \n参数2-N：要链接的其它静态库的名字，用空格隔开即可\n```\n\n如果是系统提供的静态库，填写静态库名称即可。\n\n如果是第三方静态库，需要给出具体路径才行（但我们一般选择 link_directories 方法找到库文件的位置）。\n\n**注意**：因为静态库是在编译可执行程序之前要存在的一个文件，因此我们的`link_libraries`语法 务必 在 `add_executable` 语法之前。\n\n（二）链接动态库\n\n```cmake\ntarget_link_libraries(\n    <target> \n    <PRIVATE|PUBLIC|INTERFACE> <item>... \n    [<PRIVATE|PUBLIC|INTERFACE> <item>...]...)\n```\n\n我们需要指定链接的目标，因为我们是要动态加载的，因此必须指定加载到哪个应用程序中，因此target参数是可执行程序的名称。\n\n**注意**：因为动态库是在编译可执行程序之后要存在的一个文件，因此我们的`target_link_libraries`语法 务必 在 `add_executable` 语法之后。\n\n| 关键字    | 说明                                                         | 传递方式                                             |\n| --------- | ------------------------------------------------------------ | ---------------------------------------------------- |\n| PRIVATE   | 目标链接到库，但不会传递给依赖此目标的其他目标               | 链接库仅对当前目标可见                               |\n| PUBLIC    | 目标链接到库，并且依赖此目标的其他目标也会链接到该库         | 链接库对当前目标和依赖此目标的所有目标都可见         |\n| INTERFACE | 目标本身不会链接到库，但任何依赖此目标的目标会链接到该库。适用于仅在接口需要的库 | 链接库对依赖此目标的所有目标可见，但对当前目标不可见 |\n\n如上这种讲法还是不太好理解，下面用实例说明：\n\n```cmake\n# target A depends on libA\ntarget_link_libraries(A PRIVATE libA)\n\n# target B depends on target A\ntarget_link_libraries(B PUBLIC A)\n\n# target C depends on target B\ntarget_link_libraries(C INTERFACE B)\n```\n\n`A` 链接到 `libA`，但只有 `A` 自己能看到 `libA`，所以 `libA` 不会传递给 `B` 或 `C`。\n\n`B` 链接到 `A`，并且这个链接关系是 `PUBLIC`，所以 `B` 和 `C` 都能看到 `A`。\n\n`C` 链接到 `B`，但这种链接关系是 `INTERFACE`，所以 `C` 能看到 `B` 的接口，但 `B` 实际上没有链接到其他库。\n\n---\n\n下面我就具体演示，把静态库和动态库一并引入，实际情景中你可能只需要静态库或动态库即可。\n\n```cmake\ncmake_minimum_required(VERSION 3.16)\nproject(YThreadPool)\nset(CMAKE_CXX_STANDARD 17)\n\n# 设置库文件的头文件路径\ninclude_directories(${PROJECT_SOURCE_DIR}/YThreadPool_x86/include)\n\n# 设置静态库和动态库的搜索路径\nlink_directories(${PROJECT_SOURCE_DIR}/YThreadPool_x86/lib)\nlink_directories(${PROJECT_SOURCE_DIR}/YThreadPool_x86/bin)\n\nlink_libraries(YThreadPoolLIB)  # 添加静态库\n\nadd_executable(Demo main.cpp)\n\n# 添加动态库 和 添加 pthread 库链接（因为我们用到线程了）\ntarget_link_libraries(Demo PUBLIC YThreadPoolBIN pthread)\n```","tags":["CMake"],"categories":["technology"]},{"title":"第三章：CMake 常用内置变量","url":"/2024/09/20/第三章：CMake-常用内置变量/","content":"\n<!-- toc -->\n\nCMake变量有很多，下面列举一些常用且可能会用到的变量。再者，CMake变量通过 set 来设置参数。\n\n## 基本变量\n\n| 变量名                   | 功能描述                               |\n| ------------------------ | -------------------------------------- |\n| CMAKE_SOURCE_DIR         | 顶层CMakeLists.txt所在的目录           |\n| CMAKE_CURRENT_SOURCE_DIR | 当前处理的CMakeLists.txt文件所在的目录 |\n| PROJECT_SOURCE_DIR       | 项目顶层目录                           |\n| CMAKE_BINARY_DIR         | 运行cmake命令的目录，即构建目录        |\n| CMAKE_CURRENT_BINARY_DIR | 当前处理的CMakeLists.txt文件的构建目录 |\n| PROJECT_BINARY_DIR       | 项目的构建目录                         |\n| CMAKE_INSTALL_PREFIX     | 指定安装路径                           |\n\n在编译第三方库并导入到一个文件夹中，以后需要用到所需库文件，只需要拷贝这个文件夹到特定项目中即可，CMAKE_INSTALL_PREFIX 就指定此输出文件夹的。\n\n## 编译器相关变量\n\n控制和定制编译器的行为。\n\n| 变量名                  | 功能描述                          |\n| ----------------------- | --------------------------------- |\n| CMAKE_C_COMPILER        | C编译器的路径                     |\n| CMAKE_C_FLAGS           | 添加到C编译器的标志               |\n| CMAKE_C_FLAGS_DEBUG     | 为调试构建配置添加的C编译器标志   |\n| CMAKE_C_FLAGS_RELEASE   | 为发布构建配置添加的C编译器标志   |\n| CMAKE_CXX_COMPILER      | C++编译器的路径                   |\n| CMAKE_CXX_FLAGS         | 添加到C++编译器的标志             |\n| CMAKE_CXX_FLAGS_DEBUG   | 为调试构建配置添加的C++编译器标志 |\n| CMAKE_CXX_FLAGS_RELEASE | 为发布构建配置添加的C++编译器标志 |\n\n## 构建选项\n\n| 变量名                 | 功能描述                                                 |\n| ---------------------- | -------------------------------------------------------- |\n| CMAKE_BUILD_TYPE       | 构建类型（如Debug、Release、RelWithDebInfo、MinSizeRel） |\n| CMAKE_VERBOSE_MAKEFILE | 设置为ON时，生成详细的Makefile                           |\n\n## 链接器相关变量\n\n| 变量名                    | 功能描述                           |\n| ------------------------- | ---------------------------------- |\n| CMAKE_EXE_LINKER_FLAGS    | 为生成可执行文件传递的额外链接标志 |\n| CMAKE_SHARED_LINKER_FLAGS | 为生成共享库传递的额外链接标志     |\n| CMAKE_MODULE_LINKER_FLAGS | 为生成模块库传递的额外链接标志     |\n\n## 安装相关变量\n\n| 变量名                   | 功能描述               |\n| ------------------------ | ---------------------- |\n| CMAKE_INSTALL_PREFIX     | 安装路径的前缀         |\n| CMAKE_INSTALL_BINDIR     | 安装可执行文件的子目录 |\n| CMAKE_INSTALL_LIBDIR     | 安装库文件的子目录     |\n| CMAKE_INSTALL_INCLUDEDIR | 安装头文件的子目录     |\n\n如果我们的项目是设计可打包的库文件（动态库或静态库），在CMake中配置好这些参数，非常有利于使用者导入我们的库文件。\n\n通常情况下 bin 目录存放动态库和可执行文件，lib 目录存放静态库。\n\n## 查找库和包\n\n| 变量名             | 功能描述                     |\n| ------------------ | ---------------------------- |\n| CMAKE_PREFIX_PATH  | 用于指定查找包和库的前缀路径 |\n| CMAKE_MODULE_PATH  | 用于指定查找CMake模块的路径  |\n| CMAKE_LIBRARY_PATH | 用于指定查找库的路径         |\n| CMAKE_INCLUDE_PATH | 用于指定查找头文件的路径     |\n\n这些变量名往往要结合其它方法才能实际找到第三方库。","tags":["CMake"],"categories":["technology"]},{"title":"第二章：CMake 管理多个目录和多个文件","url":"/2024/09/20/第二章：CMake-管理多个目录和多个文件/","content":"\n<!-- toc -->\n\n## 演示常见项目的管理方式\n\n很多人讲 CMake 特别喜欢讲单个文件夹和单个文件的处理情况，可这是没有必要的。这种文件结构并不常见，不如上来直接讲如何管理多个目录和多个文件，这样更具实际价值。\n\n就当前个人的项目编写情况来看，常用的结构如下：\n\n```markdown\ninclude\nsrc\nthirdparty\nCMakeLists.txt\n```\n\ninclude 用来存放头文件，src 用来存储源文件，thirdparty 用来存储第三方库。\n\n*这里的第三方库还只是个简单的头文件，后续有章节会演示结构复杂的第三方库的引入（用 CMake 管理的第三方库和没用 CMake 管理的第三方库的两种情况的引入）。*\n\nCMakeLists.txt 文件是 CMake 的核心文件，用于描述整个项目的构建过程。使用该文件可以方便地管理项目的构建和编译过程。只有源文件存在的文件夹才有可能用到 CMakeLists.txt 文件，而且子 CMakeLists.txt 文件将继承父 CMakeLists.txt 文件的变量，也就是说这里有传递关系。\n\n为了方便看清楚每个 CMakeLists.txt 文件的内容，对下面的结构中的 CMakeLists.txt 文件进行序号标识：\n\n```markdown\n├── CMakeLists.txt ①\n├── include\n│   ├── public.h\n│   └── server\n│       ├── ChatServer.h\n│       ├── ChatService.h\n│       ├── db\n│       │   └── db.h\n│       ├── model\n│       │   ├── FriendModel.h\n│       │   ├── Group.h\n│       │   ├── GroupModel.h\n│       │   ├── GroupUser.h\n│       │   ├── OfflineMsgModel.h\n│       │   ├── User.h\n│       │   └── UserModel.h\n│       └── redis\n├── src\n│   ├── client\n│   │   ├── Client.cpp\n│   │   └── CMakeLists.txt ③\n│   ├── CMakeLists.txt ②\n│   └── server\n│       ├── ChatServer.cpp\n│       ├── ChatService.cpp\n│       ├── CMakeLists.txt ④\n│       ├── db\n│       │   └── db.cpp\n│       ├── model\n│       │   ├── FriendModel.cpp\n│       │   ├── Group.cpp\n│       │   ├── GroupModel.cpp\n│       │   ├── OfflineMsgModel.cpp\n│       │   ├── User.cpp\n│       │   └── UserModel.cpp\n│       ├── redis\n│       └── Server.cpp\n└── thirdparty\n    └── json.hpp\n```\n\n① CMakeLists.txt 文件（根，也是管理项目的起点，这里设置的变量将会传递给其后代）：\n\n```cmake\n# 设置CMake的最低版本要求为3.16\ncmake_minimum_required(VERSION 3.16)\n\n# 定义项目名称为“chat”，语言为C++\nproject(chat CXX)\n\n# 设置C++编译标志，添加-g选项以生成调试信息\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g\")\n\n# 设置可执行文件的输出目录为项目根目录下的bin目录\nset(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/bin)\n\n# 包含项目的头文件目录\ninclude_directories(${PROJECT_SOURCE_DIR}/include)\ninclude_directories(${PROJECT_SOURCE_DIR}/include/server)\ninclude_directories(${PROJECT_SOURCE_DIR}/include/server/db)\ninclude_directories(${PROJECT_SOURCE_DIR}/include/server/model)\ninclude_directories(${PROJECT_SOURCE_DIR}/include/server/redis)\ninclude_directories(${PROJECT_SOURCE_DIR}/thirdparty)\n\n# 添加src子目录，其中包含项目的源文件和进一步的CMakeLists.txt文件\nadd_subdirectory(src)\n```\n\ninclude_directories 用于指定在编译期间搜索头文件的目录。通过指定这些目录，编译器在处理`#include`指令时会优先搜索这些目录。但是，你切记这个是无法层级搜索头文件的，只能搜索到指定目录下的头文件。如果你指定的文件夹A下面还有文件夹B，那么文件夹B下面的头文件是无法被搜索到的，你需要再添加一个关于文件夹B的头文件搜索路径。这些头文件搜索的结果会传递给当前文件夹的子文件夹，前提是被 add_subdirectory 包含了\n\nadd_subdirectory 命令用于将指定的子目录添加到构建过程中，并处理该子目录中的 CMakeLists.txt 文件。\n\n② CMakeLists.txt 文件：\n\n```cmake\nadd_subdirectory(client)\nadd_subdirectory(server)\n```\n\nsrc文件夹下面没有要处理的源文件，但是src文件下的client和server文件夹却有，所以继续利用 add_subdirectory 命令往下递进\n\n ③和 ④是同层级的目录，优先看 ③ CMakeLists.txt 文件：\n\n```cmake\n# 将当前目录中的所有源文件添加到 CLIENT_LIST 变量中\naux_source_directory(. CLIENT_LIST)\n\n# 将 ../server/model 目录中的所有源文件添加到 MODEL_LIST 变量中\naux_source_directory(../server/model MODEL_LIST)\n\n# 将 ../server/db 目录中的所有源文件添加到 DB_LIST 变量中\naux_source_directory(../server/db DB_LIST)\n\n# 创建一个名为 ChatClient 的可执行文件，并将 CLIENT_LIST、MODEL_LIST 和 DB_LIST 中的源文件添加到目标文件中\nadd_executable(ChatClient ${CLIENT_LIST} ${MODEL_LIST} ${DB_LIST})\n\n# 链接 ChatClient 可执行文件所需的库\ntarget_link_libraries(ChatClient muduo_net muduo_base mysqlclient hiredis pthread)\n```\n\naux_source_directory 用于将指定目录中的所有源文件添加到一个变量中，且不会递归地搜索指定目录及其子目录中的源文件。它只会在指定的目录中查找源文件，而不会自动搜索子目录中的文件。\n\nadd_executable 用于定义一个可执行目标，第一个参数是可执行文件的名称，其后跟的就是源文件（aux_source_directory会把需要的源文件存储到一个变量中，这些变量就需要加入到这里面来）。至于所需的头文件，其父已经帮我们寻找了，就无需再找，因为前面说过父寻找到头文件记录会传递给其后代。\n\n头文件实际上并不会被编译，编译器只会编译源文件。只是在编译之前，会将源文件中#include包含的文件在源文件中展开。所以头文件无需加入到 add_executable 中，只要编译器能找到头文件即可。include_directories 显然就是干这个工作的。\n\n如果我们的可执行文件还需要链接库文件，那就需要用 target_link_libraries 。第一个参数指定需要链接库的可执行程序的名称，后买你的参数就是所需库的名称（到后面讲静态库动态库再细究）。\n\n再看④ CMakeLists.txt 文件：\n\n```cmake\n# 将当前目录中的所有源文件添加到 SRC_LIST 变量中\naux_source_directory(. SRC_LIST)\n\n# 将 ./db 目录中的所有源文件添加到 DB_LIST 变量中\naux_source_directory(./db DB_LIST)\n\n# 将 ./model 目录中的所有源文件添加到 MODEL_LIST 变量中\naux_source_directory(./model MODEL_LIST)\n\n# 将 ./redis 目录中的所有源文件添加到 REDIS_LIST 变量中\naux_source_directory(./redis REDIS_LIST)\n\n# 创建一个名为 ChatServer 的可执行文件，并将 SRC_LIST、DB_LIST、REDIS_LIST 和 MODEL_LIST 中的源文件添加到目标文件中\nadd_executable(ChatServer ${SRC_LIST} ${DB_LIST} ${REDIS_LIST} ${MODEL_LIST})\n\n# 链接 ChatServer 可执行文件所需的库\ntarget_link_libraries(ChatServer muduo_net muduo_base mysqlclient hiredis pthread)\n```\n\n## 总结\n\ninclude_directories：搜索头文件。指定文件夹下的头文件编译器就能找到，且最好在根CMakeLists.txt 文件完成这个工作，那么所有子CMakeLists.txt 文件都无需再用该语法了。\n\naux_source_directory ：搜索源文件。用于将指定目录中的所有源文件添加到一个变量中。\n\nadd_executable：生成可执行程序。第一个参数填写可执行程序名称，后面就跟上需要的源文件（通常用aux_source_directory 搜索到源文件且保存到一个变量中，然后再把这个变量引入进来）。\n\ntarget_link_libraries：链接所需库。第一个参数填写可执行程序名称，后面就跟库文件名称。\n\n*include_directories 和 aux_source_directory都不会递归地搜索指定目录及其子目录中的文件。它只会在指定的目录中查找文件，而不会自动搜索子目录中的文件*。\n\n## 不得不介绍的FILE命令\n\n这个命令非常重要，可以替代 include_directories 和 aux_source_directory 命令（**能层级搜索**指定目录下的文件）。\n\n后面讲 Qt 项目配置的时候，就需要这个命令，因为 ui 文件、qss 文件、qrc 文件等资源没有专门的命令来查找，但是借助 file 这个命令就能解决。简单来讲，file 可以把任何文件保存到一个变量中，然后给别人引用。\n\n这里只演示匹配指定模式的文件，并将结果存储在变量中：\n\n```cmake\nfile(GLOB TEST_RESULT /public/home *.cpp)\t\t\t#只会查找指定目录下的文件，不会递归子目录，即不会层级搜索.cpp文件\n\nfile(GLOB_RECURSE TEST_RESULT /public/home *.cpp)\t #会递归查找指定目录及其所有子目录中的文件，即会层级搜索.cpp文件\n```\n\n但不建议替代 include_directories，因为编译器不会知道去哪里寻找头文件。那么导入头文件会有很长的路径，极其不美观。如果你真这么做了，那记得把头文件搜索结果存储的变量加入到 add_executable 中，因为编译器找不到头文件。\n\n个人觉得，优先选择 include_directories 和 aux_source_directory 命令，再考虑 file 命令辅助。特别是如果只是用来查找头文件而不是要用头文件再去编译（Qt就需要把头文件编译为 ui_xxx.h 文件，所以不得不用 file 命令，但尽管如此，我们也还是会用到 include_directories 来帮我们搜索头文件）。\n\n即 file 即使存在，include_directories 也无可替代，aux_source_directory 可以被替代。\n\n使用 `file(GLOB ...)` 和 `file(GLOB_RECURSE ...)` 的时候要注意，CMake 在配置期间会获取文件列表，但如果之后文件列表发生变化（如新增或删除文件），你可能需要重新运行 CMake 来更新构建系统配置。\n\n通常推荐显式列出源文件，以避免这种潜在的问题。我看很多第三方库都采用这种方式，我觉得确实可以采纳过来，就像下面这样：\n\n```cmake\n# 添加头文件目录\ninclude_directories(${CMAKE_SOURCE_DIR}/include)\n\n# 显式列出源文件\nset(SOURCES\n    src/main.cpp\n    src/foo.cpp\n    src/bar.cpp\n)\n```","tags":["CMake"],"categories":["technology"]},{"title":"第一章：与 CMake 剪不断理还乱","url":"/2024/09/20/第一章：与-CMake-剪不断理还乱/","content":"\n如果你经常使用CMake管理项目，一路艰辛，自不必多言。我从来没写过Makefile，在预备学习它之前就知道CMake管理工具的存在了，那是第一次和CMake相识。等到真正需要用CMake管理项目的时候，在网上找教程对其简单学习，可是没过多久就在需求增多的情况下深感不足。下定决心对CMake深入学习，可因为语法的理解不够透彻，以及Clion本身的缓存问题影响到我的判断，这让我一度觉得CMake是个恶心工具（网上骂的人确实不少）。但是，越来越多的人使用CMake，如果能够熟练掌握它对后续项目的管理和第三方库的引入会相当方便。我企图通过手写CMake教程来再次梳理CMake本身，这对我而言是个挑战。\n\n要把CMake弄明白？如果不这样的话，真的很难和CMake好好的交往。但是CMake内容很多，这个教程也应该是个持续更新的状态，所记录的是当前我所用到的内容，而非以求全而梳理的教程。\n\n暂定目录：\n\n1. CMake管理多个目录和多个源文件\n2. CMake 构建和链接静态库和动态库\n3. CMake 添加第三方依赖库\n4. CMake install 部署项目\n5. Cmake 构建 Qt 项目\n\n完成本教程可能会用到的网址：\n\nhttps://cmake-doc.readthedocs.io/zh-cn/latest/guide/tutorial/index.html\n\nhttps://github.com/xiaoweiChen/Modern-CMake-for-Cpp/tree/main","tags":["CMake"],"categories":["technology"]},{"title":"命令行参数","url":"/2024/09/20/命令行参数/","content":"\n```c\nint main(int argc,char* argv[]);\n```\n\nargc 代表参数的个数。\n\nargv 是个字符串数组，用以存储用户的输入的参数（默认第一个参数是程序本身的名称）。\n\n我重点要讲的是如何把获取的参数转换为实际的类型，哪怕你写的是整数参数，也会是字符串类型。\n\n```c\nint sscanf(const char *str, const char *format, ...);\n```\n\n从字符串中读取数据，并将其转换为指定的格式。常见转换格式：\n\n- `%d`：将字符串转换为整数（`int`）。\n- `%f`：将字符串转换为浮点数（`float`）。\n- `%lf`：将字符串转换为双精度浮点数（`double`）。\n- `%c`：将字符串的第一个字符转换为 `char`。\n\n```c++\nint num;\n// 将命令行参数 argv[1] 转换为整数\nif (sscanf(argv[1], \"%d\", &num) == 1) {\n    printf(\"You entered the number: %d\\n\", num);\n}\n```","tags":["C"],"categories":["technology"]},{"title":"文件操作","url":"/2024/09/20/文件操作/","content":"\n<!-- toc -->\n\n## 打开文件\n\n```c++\nFILE *freopen(const char *pathname, const char *mode, FILE *stream);\n```\n\npathname：可以填写相对路径或绝对路径\n\nstream：文件流\n\nmode：模式（重点）\n\n| mode | 含义     | 文件不存在       | 文件存在                       |\n| ---- | -------- | ---------------- | ------------------------------ |\n| r    | 只读     | 防护NULL（错误） | 从文件头开始读取               |\n| w    | 清空写入 | 创建新文件       | 清空文件内容，从头开始写入     |\n| a    | 追加写入 | 创建新文件       | 在文件末尾追加内容             |\n| r+   | 读写     | 防护NULL（错误） | 从文件头开始读写               |\n| w+   | 读写清空 | 创建新文件       | 清空文件内容，从头开始读写     |\n| a+   | 读写追加 | 创建新文件       | 在文件末尾追加内容，但允许读写 |\n\n上面是以文本形式进行操作，如果你想以二进制形式操作文件，只需要在 mode 后面添加 b 即可。\n\n![二进制操作.png](/images/2024/09/20/08476880-7719-11ef-b0af-63b8ef3b8d38.png)\n\n## 关闭文件\n\n```c++\nint fclose(FILE *stream);\n```\n\n文件流不再需要使用，记得用 fclose 关闭。\n\n## 读写文件\n\n### 文本\n\n（一）读写单个字符\n\n```c\nint fgetc(FILE *stream);\t// 从文件流 stream 中读取单个字符\n\nint fputc(int c, FILE *stream);\t// 把单个字符写入文件流 stream\n```\n\n示例程序：\n\n```c++\nvoid readFile(const char* path) {\n\tFILE* src = fopen(path, \"r\");\n\tif (!src) {\n\t\tfprintf(stderr, \"src fopen failed!!!\");\n\t\texit(-1);\n\t}\n\n\tFILE* dst = fopen(\"b.txt\", \"w\");\n\tif (!dst) {\n\t\tfprintf(stderr, \"dst fopen failed!!!\");\n\t\texit(-1);\n\t}\n\n\tchar c;\n\twhile ((c = fgetc(src)) != EOF)\t// 按单个字符读取和写入 fget，fput\n\t{\n\t\tif ((c >= 'a' && c <= 'm') || (c >= 'A' && c <= 'M')) {\n\t\t\tfputc(c + 13, dst);\n\t\t}\n\t\telse if ((c >= 'n' && c <= 'z') || (c >= 'N' && c <= 'Z')) {\n\t\t\tfputc(c - 13, dst);\n\t\t}\n\t\telse {\n\t\t\tfputc(c, dst);\n\t\t}\n\t}\n\n\tfclose(src);\n\tfclose(dst);\n}\n```\n\n（二）读写一行\n\n```c\nchar *fgets(char *s, int size, FILE *stream);\t// 从文件流 stream 读取指定长度的字符串\n\nint fputs(const char *s, FILE *stream);\t\t// 读取指定长度的字符串 写入文件流 stream \n```\n\n示例程序：\n\n```c\n#define MAX_LEN 128\nvoid readFile(const char* path) {\n\tFILE* src = fopen(path, \"r\");\n\tif (!src) {\n\t\tfprintf(stderr, \"src fopen failed!!!\");\n\t\texit(-1);\n\t}\n\n\tFILE* dst = fopen(\"b.txt\", \"w\");\n\tif (!dst) {\n\t\tfprintf(stderr, \"dst fopen failed!!!\");\n\t\texit(-1);\n\t}\n\n\tchar* line[MAX_LEN];\n\tchar* message[MAX_LEN];\n\tint index = 1;\n\twhile ((fgets(line, MAX_LEN, src) != NULL))\t// 按行读取和写入 fgets，fputs\n\t{\n\t\tsprintf(message, \"%d. %s\", index, line);\n\t\tfputs(message, dst);\n\t\tindex++;\n\t}\n\n\tfclose(src);\n\tfclose(dst);\n}\n```\n\n（三）格式化地读写\n\n```c++\nint fscanf(FILE *stream, const char *format, ...);\n\nint fprintf(FILE *stream, const char *format, ...);\n```\n\n示例程序：\n\n```c\n#define MAX_LEN 128\n#define NAME_LEN 20\n\ntypedef struct student\n{\n\tint id;\n\tchar name[NAME_LEN];\n\tchar sex;\n\tint chinese;\n\tint math;\n\tint english;\n} Student;\n\nvoid readFile(const char* path) {\n\tFILE* src = fopen(path, \"r\");\n\tif (!src) {\n\t\tfprintf(stderr, \"src fopen failed!!!\");\n\t\texit(-1);\n\t}\n\n\tFILE* dst = fopen(\"b.txt\", \"w\");\n\tif (!dst) {\n\t\tfprintf(stderr, \"dst fopen failed!!!\");\n\t\texit(-1);\n\t}\n\t\n\t// 按格式读取和写入 fscanf，fprintf\n\tfor (;;) {\n\t\tStudent s;\n\t\tint n = fscanf(src, \"%d%s %c%d%d%d\", &s.id, s.name, &s.sex, &s.chinese, &s.math, &s.english);\n\t\tif (n != 6) break;\n\n\t\ts.chinese = s.chinese * 0.85;\n\t\ts.math = s.math * 0.9;\n\t\ts.english = s.english * 0.8;\n\n\t\tfprintf(dst, \"%d %s %c %d %d %d\\n\", s.id, s.name, s.sex, s.chinese, s.math, s.english);\n\t}\n\n\tfclose(src);\n\tfclose(dst);\n}\n```\n\n### 二进制\n\n```c++\nsize_t fread(void *ptr, size_t size, size_t nmemb, FILE *stream);\n\nsize_t fwrite(const void *ptr, size_t size, size_t nmemb,FILE *stream);\n```\n\nfread 的返回值是读取的大小，这个返回值将作为 fwrite size 参数。不然读取超出已读的长度会出现错误。\n\n示例程序：\n\n```c++\n#define MAX_LEN 128\nvoid readFile(const char* path) {\n\tFILE* src = fopen(path, \"r\");\n\tif (!src) {\n\t\tfprintf(stderr, \"src fopen failed!!!\");\n\t\texit(-1);\n\t}\n\n\tFILE* dst = fopen(\"b.txt\", \"w\");\n\tif (!dst) {\n\t\tfprintf(stderr, \"dst fopen failed!!!\");\n\t\texit(-1);\n\t}\n\n\tchar* data[MAX_LEN];\n\tint n = 0;\n\twhile ((n = fread(data, 1, MAX_LEN, src)) > 0) {\n\t\tfwrite(data, 1, n, dst);\t// 容易犯错的地方,误填为MAX_LEN，应该填写读的字节数 n\n\t}\n\n\tfclose(src);\n\tfclose(dst);\n}\n```\n\n## 移动文件位置\n\n```c\nint fseek(FILE *stream, long offset, int whence);\t// 移动文件位置\n\nlong ftell(FILE *stream);\t // 获取当前文件位置\n\nvoid rewind(FILE *stream);\t// 回到文件起始位置\n```\n\n其中 whence 参数有三个取值：\n\n**`SEEK_SET`**: 文件开头，表示从文件的起始位置移动文件指针。\n\n**`SEEK_CUR`**: 当前文件指针位置，表示从当前指针位置移动。\n\n**`SEEK_END`**: 文件末尾，表示从文件末尾开始移动。\n\n示例程序：\n\n```c++\nchar* readFile(const char* path) {\n\tFILE* fp = fopen(path, \"r\");\n\tif (!fp) {\n\t\texit(-1);\n\t}\n\n\tfseek(fp, 0, SEEK_END);\n\tlong int len = ftell(fp);\n\trewind(fp);\n\n\tif (len == -1) {\n\t\texit(-1);\n\t}\n\n\tchar* data = malloc(sizeof(char) * (len + 1));\n\tif (!data) {\n\t\texit(-1);\n\t}\n\n\tsize_t reNum = fread(data, 1, len, fp);\n\tif (reNum != len) {\n\t\tfree(data);\n\t\tfclose(fp);\n\t\texit(-1);\n\t}\n\tdata[reNum] = '\\0';\t\t// 根据实际读取的长度，并在其后添加 空字符\n\n\tfclose(fp);\n\treturn data;\n}\n```\n\n由于我们要把某个文件内容全部读取到数组中，但是我们又不知道要申请多大的空间，利用 刚刚介绍的方法就能轻松解决这个问题：\n\n```c\nfseek(fp, 0, SEEK_END);\t// 指向 文件末尾\nlong int len = ftell(fp); // 获取当前位置下标\nrewind(fp);\t// 移动回文件开头，这是容易被忽的\n```","tags":["C"],"categories":["technology"]},{"title":"第七章：Beast网络库实现WebSocket服务器","url":"/2024/09/19/第七章：Beast网络库实现WebSocket服务器/","content":"\n<!-- toc -->\n\n## 接口\n\n### Connecting（连接）\n\n处理 WebSocket 流的连接和接收。\n\n（一）连接到 WebSocket 服务器\n\n要与 WebSocket 服务器建立连接，首先需要连接到服务器，然后执行 WebSocket 握手。Boost.Beast 提供了一个 `stream` 类来管理 WebSocket 连接。你可以使用 `tcp_stream` 作为底层流来实现这一点。\n\n```c++\n#include <boost/asio.hpp>\n#include <boost/beast.hpp>\n#include <iostream>\n\nnamespace net = boost::asio;\nnamespace beast = boost::beast;\nusing tcp = net::ip::tcp;\n\n// 创建 WebSocket 客户端并连接到服务器\nint main() {\n    try {\n        net::io_context ioc;\n\n        // 创建 WebSocket 流\n        beast::websocket::stream<tcp::socket> ws(ioc);\n        tcp::resolver resolver(ioc);\n\n        // 解析主机名和端口\n        auto const results = resolver.resolve(\"example.com\", \"ws\");\n\n        // 连接到服务器\n        beast::get_lowest_layer(ws).connect(results);\n\n        // 执行 WebSocket 握手\n        ws.handshake(\"example.com\", \"/\");\n\n        std::cout << \"Connected and handshake completed\" << std::endl;\n\n        // 在这里你可以发送和接收消息\n\n    } catch (std::exception const& e) {\n        std::cerr << \"Exception: \" << e.what() << std::endl;\n    }\n}\n```\n\n（二）接收来自客户端的连接\n\n要接受传入的 WebSocket 连接，你需要创建一个 `acceptor` 对象来监听连接请求。接受到连接后，你可以创建一个 `stream` 对象来处理 WebSocket 连接。\n\n```c++\n#include <boost/asio.hpp>\n#include <boost/beast.hpp>\n#include <iostream>\n\nnamespace net = boost::asio;\nnamespace beast = boost::beast;\nusing tcp = net::ip::tcp;\n\n// 创建 WebSocket 服务器并接受连接\nint main() {\n    try {\n        net::io_context ioc;\n\n        // 创建接受器\n        tcp::acceptor acceptor(ioc, tcp::endpoint(tcp::v4(), 0));\n        acceptor.listen();\n\n        std::cout << \"Listening for connections on port \" << acceptor.local_endpoint().port() << std::endl;\n\n        // 等待并接受连接\n        tcp::socket socket(ioc);\n        acceptor.accept(socket);\n\n        // 创建 WebSocket 流对象\n        beast::websocket::stream<tcp::socket> ws(std::move(socket));\n\n        // 执行 WebSocket 握手\n        ws.accept();\n\n        std::cout << \"Connection accepted and handshake completed\" << std::endl;\n\n        // 在这里你可以发送和接收消息\n\n    } catch (std::exception const& e) {\n        std::cerr << \"Exception: \" << e.what() << std::endl;\n    }\n}\n```\n\n（三）使用 `acceptor` 直接接收连接到 WebSocket 流\n\n如果你希望 WebSocket 流在接受连接时直接使用 `acceptor`，可以这样做：\n\n```c++\n#include <boost/asio.hpp>\n#include <boost/beast.hpp>\n#include <iostream>\n\nnamespace net = boost::asio;\nnamespace beast = boost::beast;\nusing tcp = net::ip::tcp;\n\n// 创建 WebSocket 服务器并接受连接\nint main() {\n    try {\n        net::io_context ioc;\n\n        // 创建接受器\n        tcp::acceptor acceptor(ioc, tcp::endpoint(tcp::v4(), 0));\n        acceptor.listen();\n\n        // 创建 WebSocket 流，并使用 strand 保证线程安全\n        beast::websocket::stream<tcp::socket> ws(net::make_strand(ioc));\n\n        // 直接将套接字传递给 WebSocket 流\n        acceptor.accept(beast::get_lowest_layer(ws).socket());\n\n        // 执行 WebSocket 握手\n        ws.accept();\n\n        std::cout << \"Connection accepted and handshake completed\" << std::endl;\n\n        // 在这里你可以发送和接收消息\n\n    } catch (std::exception const& e) {\n        std::cerr << \"Exception: \" << e.what() << std::endl;\n    }\n}\n```\n\n### Handshaking（握手）\n\n（一）客户端\n\nWebSocket 会话开始于客户端发送一个 HTTP/1.1 升级请求，通过建立的连接请求 WebSocket 协议。服务器收到请求后，发送一个表示接受请求并将连接升级的响应。这个升级请求必须包含 `Host` 字段和请求的目标资源。下面是一个典型的 HTTP 升级请求的示例：\n\n```c++\nGET / HTTP/1.1\nHost: www.example.com\nUpgrade: websocket\nConnection: upgrade\nSec-WebSocket-Key: 2pGeTR0DsE4dfZs2pH+8MA==\nSec-WebSocket-Version: 13\nUser-Agent: Boost.Beast/216\n```\n\n使用 `websocket::stream` 类的 `handshake` 和 `async_handshake` 成员函数可以发送带有所需 `Host` 和目标字符串的请求。下面的代码展示了如何在客户端角色中连接到服务器，并执行 WebSocket 握手：\n\n```c++\n#include <boost/asio.hpp>\n#include <boost/beast.hpp>\n#include <iostream>\n\nnamespace net = boost::asio;\nnamespace beast = boost::beast;\nusing tcp = net::ip::tcp;\n\nint main() {\n    try {\n        net::io_context ioc;\n\n        // 创建 WebSocket 流\n        beast::websocket::stream<tcp::socket> ws(ioc);\n        tcp::resolver resolver(ioc);\n\n        // 连接到服务器\n        beast::get_lowest_layer(ws).connect(resolver.resolve(\"www.example.com\", \"ws\"));\n\n        // 在客户端角色中执行 WebSocket 握手\n        ws.handshake(\"www.example.com\", \"/\");\n\n        std::cout << \"Connected and handshake completed\" << std::endl;\n\n        // 这里可以发送和接收消息\n\n    } catch (std::exception const& e) {\n        std::cerr << \"Exception: \" << e.what() << std::endl;\n    }\n}\n```\n\n在客户端收到 HTTP 升级响应后，可能希望对收到的 HTTP 响应消息执行额外的验证。例如，检查基本认证挑战的响应是否有效。可以通过重载的 `handshake` 成员函数，将收到的 HTTP 消息存储到 `response_type` 类型的输出引用参数中：\n\n```c++\n#include <boost/asio.hpp>\n#include <boost/beast.hpp>\n#include <iostream>\n\nnamespace net = boost::asio;\nnamespace beast = boost::beast;\nusing tcp = net::ip::tcp;\n\nint main() {\n    try {\n        net::io_context ioc;\n\n        // 创建 WebSocket 流\n        beast::websocket::stream<tcp::socket> ws(ioc);\n        tcp::resolver resolver(ioc);\n\n        // 连接到服务器\n        beast::get_lowest_layer(ws).connect(resolver.resolve(\"www.example.com\", \"ws\"));\n\n        // 用于接收 HTTP 响应的变量\n        beast::http::response<beast::http::string_body> res;\n\n        // 执行 WebSocket 握手\n        ws.handshake(res, \"www.example.com\", \"/\");\n\n        std::cout << \"Connected and handshake completed with response\" << std::endl;\n\n        // 这里可以发送和接收消息\n\n    } catch (std::exception const& e) {\n        std::cerr << \"Exception: \" << e.what() << std::endl;\n    }\n}\n```\n\n（二）服务端\n\n使用 `accept` 和 `async_accept` 成员函数可以读取 WebSocket HTTP 升级请求握手，并发送 WebSocket HTTP 升级响应：\n\n```c++\n#include <boost/asio.hpp>\n#include <boost/beast.hpp>\n#include <iostream>\n\nnamespace net = boost::asio;\nnamespace beast = boost::beast;\nusing tcp = net::ip::tcp;\n\nint main() {\n    try {\n        net::io_context ioc;\n\n        // 创建接受器\n        tcp::acceptor acceptor(ioc, tcp::endpoint(tcp::v4(), 0));\n        acceptor.listen();\n\n        // 等待并接受连接\n        tcp::socket socket(ioc);\n        acceptor.accept(socket);\n\n        // 创建 WebSocket 流对象\n        beast::websocket::stream<tcp::socket> ws(std::move(socket));\n\n        // 执行 WebSocket 握手\n        ws.accept();\n\n        std::cout << \"Connection accepted and handshake completed\" << std::endl;\n\n        // 这里可以发送和接收消息\n\n    } catch (std::exception const& e) {\n        std::cerr << \"Exception: \" << e.what() << std::endl;\n    }\n}\n```\n\n（三）握手缓冲\n\n服务器可以从流中读取数据，并在后续决定这些缓冲的字节是否应该解释为 WebSocket 升级请求。为此，提供了接受额外缓冲序列参数的 `accept` 和 `async_accept` 重载函数。\n\n```c++\n#include <boost/asio.hpp>\n#include <boost/beast.hpp>\n#include <string>\n\nnamespace net = boost::asio;\nnamespace beast = boost::beast;\nusing tcp = net::ip::tcp;\n\nint main() {\n    try {\n        net::io_context ioc;\n\n        // 创建接受器\n        tcp::acceptor acceptor(ioc, tcp::endpoint(tcp::v4(), 0));\n        acceptor.listen();\n\n        // 等待并接受连接\n        tcp::socket socket(ioc);\n        acceptor.accept(socket);\n\n        // 创建 WebSocket 流对象\n        beast::websocket::stream<tcp::socket> ws(std::move(socket));\n\n        // 用于存储 HTTP 请求的缓冲区\n        std::string s;\n\n        // 读取缓冲区中的 HTTP 请求，直到遇到请求结束标志\n        net::read_until(ws, net::dynamic_buffer(s), \"\\r\\n\\r\\n\");\n\n        // 使用缓冲的数据接受连接\n        ws.accept(net::buffer(s));\n\n        std::cout << \"Connection accepted and handshake completed with buffered data\" << std::endl;\n\n    } catch (std::exception const& e) {\n        std::cerr << \"Exception: \" << e.what() << std::endl;\n    }\n}\n```\n\n（四）检查 HTTP 请求\n\n当实现一个支持 WebSocket 的 HTTP 服务器时，服务器通常会读取来自客户端的 HTTP 请求。可以使用 `websocket::is_upgrade` 函数来检测传入的 HTTP 请求是否为 WebSocket 升级请求。\n\n如果 HTTP 请求是 WebSocket 升级请求，可以使用重载的 `accept` 和 `async_accept` 函数，这些函数接受整个 HTTP 请求头作为对象，以执行握手。通过手动读取请求，可以处理普通的 HTTP 请求以及升级请求。示例如下：\n\n```c++\n#include <boost/asio.hpp>\n#include <boost/beast.hpp>\n#include <iostream>\n\nnamespace net = boost::asio;\nnamespace beast = boost::beast;\nusing tcp = net::ip::tcp;\n\nint main() {\n    try {\n        net::io_context ioc;\n\n        // 创建接受器\n        tcp::acceptor acceptor(ioc, tcp::endpoint(tcp::v4(), 0));\n        acceptor.listen();\n\n        // 等待并接受连接\n        tcp::socket socket(ioc);\n        acceptor.accept(socket);\n\n        // 用于读取 HTTP 消息的缓冲区\n        beast::flat_buffer buffer;\n\n        // 读取 HTTP 请求\n        beast::http::request<beast::http::string_body> req;\n        beast::http::read(socket, buffer, req);\n\n        // 检查是否为 WebSocket 升级请求\n        if (beast::websocket::is_upgrade(req)) {\n            // 创建 WebSocket 流对象\n            beast::websocket::stream<tcp::socket> ws(std::move(socket));\n\n            // 确保缓冲区为空\n            BOOST_ASSERT(buffer.size() == 0);\n\n            // 接受升级请求\n            ws.accept(req);\n\n            std::cout << \"WebSocket upgrade request accepted\" << std::endl;\n        } else {\n            // 不是 WebSocket 升级请求，处理为普通 HTTP 请求\n            std::cout << \"Normal HTTP request received\" << std::endl;\n        }\n\n    } catch (std::exception const& e) {\n        std::cerr << \"Exception: \" << e.what() << std::endl;\n    }\n}\n```\n\n（五）子协议\n\n如果客户端请求一组子协议中的一个，客户端将在初始 WebSocket 升级 HTTP 请求中设置 `Sec-WebSocket-Protocol` 头。服务器需要解析该头并选择一个接受的协议。服务器通过在接受头中设置 `Sec-WebSocket-Protocol` 头来指示选定的协议。\n\n```c++\n#include <boost/asio.hpp>\n#include <boost/beast.hpp>\n#include <array>\n#include <algorithm>\n#include <string>\n\nnamespace net = boost::asio;\nnamespace beast = boost::beast;\nusing tcp = net::ip::tcp;\n\n// 选择最优协议的函数\nauto select_protocol = [](beast::string_view offered_tokens) -> std::string {\n    beast::http::token_list offered(offered_tokens);\n\n    // 支持的协议数组，按优先级顺序排列\n    static const std::array<beast::string_view, 3> supported = {{\n        \"v3.my.chat\",\n        \"v2.my.chat\",\n        \"v1.my.chat\"\n    }};\n\n    std::string result;\n\n    for (auto proto : supported) {\n        auto iter = std::find(offered.begin(), offered.end(), proto);\n        if (iter != offered.end()) {\n            // 找到客户端提供的支持的协议\n            result.assign(proto.begin(), proto.end());\n            break;\n        }\n    }\n\n    return result;\n};\n\nint main() {\n    try {\n        net::io_context ioc;\n\n        // 创建接受器\n        tcp::acceptor acceptor(ioc, tcp::endpoint(tcp::v4(), 0));\n        acceptor.listen();\n\n        // 等待并接受连接\n        tcp::socket socket(ioc);\n        acceptor.accept(socket);\n\n        // 用于读取 HTTP 消息的缓冲区\n        beast::flat_buffer buffer;\n\n        // 读取 HTTP 请求\n        beast::http::request<beast::http::string_body> req;\n        beast::http::read(socket, buffer, req);\n\n        // 检查是否为 WebSocket 升级请求\n        if (beast::websocket::is_upgrade(req)) {\n            std::string protocol = select_protocol(req[beast::http::field::sec_websocket_protocol]);\n\n            if (protocol.empty()) {\n                // 没有提供有效的协议\n                beast::http::response<beast::http::string_body> res;\n                res.result(beast::http::status::bad_request);\n                res.body() = \"No valid sub-protocol was offered. This server implements v3.my.chat, v2.my.chat, and v1.my.chat\";\n                beast::http::write(socket, res);\n            } else {\n                // 创建 WebSocket 流对象\n                beast::websocket::stream<tcp::socket> ws(std::move(socket));\n\n                ws.set_option(beast::websocket::stream_base::decorator(\n                    [protocol](beast::http::response_header<>& hdr) {\n                        hdr.set(beast::http::field::sec_websocket_protocol, protocol);\n                    }\n                ));\n\n                // 接受升级请求\n                ws.accept(req);\n\n                std::cout << \"WebSocket upgrade request accepted with selected protocol: \" << protocol << std::endl;\n            }\n        } else {\n            // 不是 WebSocket 升级请求，处理为普通 HTTP 请求\n            std::cout << \"Normal HTTP request received\" << std::endl;\n        }\n\n    } catch (std::exception const& e) {\n        std::cerr << \"Exception: \" << e.what() << std::endl;\n    }\n}\n```\n\n### Decorator（装饰器）\n\n使用 Boost.Beast 提供的装饰器（decorator）功能来修改 WebSocket 的 HTTP 升级请求和响应。装饰器允许程序在发送 HTTP 消息之前修改这些消息，从而实现自定义的 HTTP 头字段或其他行为。\n\n**装饰器**：可以是函数指针或可调用对象，在 WebSocket 实现发送 HTTP 消息之前被调用。\n\n**装饰对象类型**：\n\n- `request_type`：代表 HTTP 升级请求的类型。\n- `response_type`：代表 HTTP 升级响应的类型。\n- `stream_base::decorator`：用于持有装饰器对象，通过 `set_option` 方法应用到流上。\n\n可以通过 `set_option` 将装饰器设置到 `stream` 对象上。装饰器必须在握手（handshake）或接受连接（accept）之前设置。以下是几个典型的使用方式：\n\n（一）普通函数\n\n```c++\nvoid set_user_agent(request_type& req)\n{\n    req.set(http::field::user_agent, \"My User Agent\");\n}\n\nstream<tcp_stream> ws(ioc);\nws.set_option(stream_base::decorator(&set_user_agent));\n```\n\n（二）函数对象\n\n```c++\nstruct set_server\n{\n    void operator()(response_type& res)\n    {\n        res.set(http::field::user_agent, \"My Server\");\n    }\n};\n\nws.set_option(stream_base::decorator(set_server{}));\n```\n\n（三）Lambda 表达式\n\n```c++\nws.set_option(stream_base::decorator(\n    [](response_type& res)\n    {\n        res.set(http::field::user_agent, \"My Server\");\n    }));\n```\n\n（四）同时处理请求和响应\n\n```c++\nstruct set_message_fields\n{\n    void operator()(request_type& req)\n    {\n        req.set(http::field::user_agent, \"My User Agent\");\n    }\n\n    void operator()(response_type& res)\n    {\n        res.set(http::field::user_agent, \"My Server\");\n    }\n};\n\nws.set_option(stream_base::decorator(set_message_fields{}));\n```\n\n装饰器对象通过 **衰退复制（decay-copy）** 转移到 `stream`，因此支持移动类型。可以使用 `std::unique_ptr` 等资源管理对象：\n\n```c++\nstruct set_auth\n{\n    std::unique_ptr<std::string> key;\n\n    void operator()(request_type& req)\n    {\n        req.set(http::field::authorization, *key);\n    }\n};\n\nws.set_option(stream_base::decorator(\n    set_auth{boost::make_unique<std::string>(\"Basic QWxhZGRpbjpPcGVuU2VzYW1l\")}));\n```\n\n注意：装饰器**不应**修改 WebSocket 升级特定的字段（如 `Upgrade` 或 `Connection` 字段），否则会导致未定义行为。\n\n### Message\n\n消息可以是文本（UTF-8 编码）或二进制。文本消息必须是有效的 UTF-8 字符串，这在接收时会进行验证，但在发送时不会检查。\n\n（一）发送消息\n\n**发送完整消息**：可以使用 `write` 或 `async_write` 函数一次性发送完整的消息。\n\n**发送部分消息**：可以通过 `write_some` 或 `async_write_some` 函数分段发送消息，适用于将消息分割为多个帧的情况。\n\n```c++\nnet::const_buffer b(\"Hello, world!\", 13);\nws.text(true);  // 设置消息为文本模式\nws.write(b);    // 发送消息\n```\n\n（二）接收消息\n\n**读取完整消息**：可以使用 `read` 或 `async_read` 函数将完整消息读取到动态缓冲区中。\n\n**读取部分消息**：如果消息较大或者需要逐步处理，可以使用 `read_some` 或 `async_read_some` 函数分段读取。这适用于流媒体或处理无法一次加载到内存中的大型数据。\n\n```c++\nflat_buffer buffer;\nws.read(buffer);\nws.text(ws.got_text());\nws.write(buffer.data());\nbuffer.consume(buffer.size());\n```\n\n注：`websocket::stream` 类是 **非线程安全的**，因此其成员函数的调用必须在同一 strand（线程或任务序列）中进行，以避免竞争条件。\n\n### Timeouts\n\n与基础的 `tcp_stream` 或 `basic_stream` 的通用超时机制不同，WebSocket 流提供了一套更复杂的超时配置，专门用于 WebSocket 通信。\n\n**stream_base::timeout**：表示 WebSocket 流的超时设置。\n\n![timeout.png](/images/2024/09/19/5b440a30-767d-11ef-ad8a-396c11c32935.png)\n\n**stream_base::timeout::suggested**：根据角色（客户端或服务端）返回建议的超时设置。\n\n**stream::set_option**：用于将超时和其他设置应用到 WebSocket 流上。\n\n（一）设置建议的超时\n\n```c++\n// 为服务端角色应用建议的超时选项\nws.set_option(stream_base::timeout::suggested(role_type::server));\n```\n\n（二）手动设置超时\n\n```c++\nstream_base::timeout opt{\n    std::chrono::seconds(30),   // 握手超时\n    stream_base::none(),        // 禁用空闲超时\n    false                       // 不启用 keep_alive_pings\n};\n\n// 将自定义的超时设置应用到 WebSocket 流\nws.set_option(opt);\n```\n\n（三）超时通知\n\n当超时发生时，系统会关闭套接字或流，并通过 `async_read` 的完成处理器传递超时错误（`error::timeout`）。\n\n不需要手动关闭连接，系统会自动关闭。\n\n```c++\nws.async_read(b,\n    [](error_code ec, std::size_t)\n    {\n        if(ec == beast::error::timeout)\n            std::cerr << \"timeout, connection closed!\";\n    });\n```\n\n### 重要注意事项\n\n- WebSocket 的超时功能仅在**异步 I/O**操作时可用。\n- WebSocket 流的超时机制与 `tcp_stream` 的超时机制**不兼容**。如果从一个启用了超时的 `tcp_stream` 构造 WebSocket 流，应首先禁用 `tcp_stream` 的超时\n\n```c++\n// 禁用 tcp_stream 上的任何超时\nsock.expires_never();\n\n// 构造 WebSocket 流并接管现有的 tcp_stream\nstream<tcp_stream> ws(std::move(sock));\n```\n\n## 代码实现和测试\n\n在输入框中输入 ws:://127.0.0.1:8080，点击连接，网站会提示连接成功。然后到输入框中输入你要发送的数据，服务器接收到之后会回复相同的信息。\n\n![websocket.png](/images/2024/09/19/54075150-767d-11ef-ad8a-396c11c32935.png)\n\n测试网址：http://websocket-test.com/\n\n代码地址：[实现WebSocketServer](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/13-WebSocketServer)\n\n---\n\n⭐️内容取自 B 站 UP 恋恋风辰和 mmoaay 的《Boost.Asio C++ 网络编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议看原视频或者读原书。","tags":["网络编程","Asio"],"categories":["technology"]},{"title":"第六章：Beast网络库实现HTTP服务器","url":"/2024/09/19/第六章：Beast网络库实现HTTP服务器/","content":"\n<!-- toc -->\n\n经过前面几章节的训练，[基于 Asio 实现HTTP服务器](https://llfc.club/category?catid=225RaiVNI8pFDD5L4m807g7ZwmF#!aid/2RbaWyENb1b1trG4KoWHtScUHri)也不难，但是这种造轮子行为还是不推荐的，下面就介绍如何基于 Beast 库实现 HTTP 和 WebSocket 服务器。\n\nBoost.Beast 是基于 Boost.Asio 的 C++ 网络库，用于处理 HTTP 和 WebSocket 协议。它简化了处理 HTTP 和 WebSocket 请求与响应的过程，同时提供高效的异步操作，广泛用于开发高性能网络应用。\n\n文档地址：[Beast官方文档](https://www.boost.org/doc/libs/master/libs/beast/doc/html/index.html)\n\n## 接口\n\n### [Message Containers](https://www.boost.org/doc/libs/master/libs/beast/doc/html/beast/using_http/message_containers.html)\n\n完整的 HTTP 消息使用 message class 建模，用户可进行自定义。\n\n```c++\n// An HTTP message\ntemplate<\n    bool isRequest,             // `true` 代表 requests, `false` 代表 responses\n    class Body,                 // Controls the container and algorithms used for the body\n    class Fields = fields>      // The type of container to store the fields\nclass message;\n\n// A typical HTTP request\ntemplate<class Body, class Fields = fields>\nusing request = message<true, Body, Fields>;\n\n// A typical HTTP response\ntemplate<class Body, class Fields = fields>\nusing response = message<false, Body, Fields>;\n```\n\n从上面的模板可以看出，message 通过 第一个参数来区分 request 和 response，然后第三个参数 有默认参数。所以，对于 创建  request 和 response 的时候必须填写的参数是 Body，Fields 是可选的。\n\n![Body.png](/images/2024/09/19/c6b59930-7661-11ef-a8f8-f3952e97d7ff.png)\n\n这里面值得一提的是 [DynamicBuffer](https://www.boost.org/doc/libs/master/libs/beast/doc/html/beast/concepts/DynamicBuffer.html) 动态缓冲区。\n\n动态缓冲区封装了内存存储，该存储可以根据需要自动调整大小，其中内存分为输入序列和输出序列。这些内存区域是动态缓冲区的内部，但提供了对元素的直接访问，以允许它们有效地用于 I/O 操作，例如套接字的发送或接收操作。 写入动态缓冲区对象输出序列的数据将追加到同一对象的输入序列中。\n\n如果你要存储 request 和 response ，可以如下定义：\n\n```c++\nnamespace beast = boost::beast;         // from <boost/beast.hpp>\nnamespace http = beast::http;           // from <boost/beast/http.hpp>\n\nhttp::request<http::dynamic_body> request_;\nhttp::response<http::dynamic_body> response_;\n```\n\n等后面我们学习消息的发送和接受，就能用到了。\n\n这里记录一下官方的使用案例：\n\n**我们构建了一个带有空消息正文的 HTTP GET 请求。**\n\n![createReq.png](/images/2024/09/19/c1dce800-7661-11ef-a8f8-f3952e97d7ff.png)\n\n**我们创建了一个 HTTP 响应，状态代码表示成功。**\n\n![createRes.png](/images/2024/09/19/be018290-7661-11ef-a8f8-f3952e97d7ff.png)\n\n---\n\n我们前面处理的消息是包含 body + header，如果你只需要处理 header，beast 也支持。\n\n```c++\n// An HTTP header\ntemplate<\n    bool isRequest,             // `true` for requests, `false` for responses\n    class Fields = fields>      // The type of container to store the fields\nclass header;\n\n// A typical HTTP request header\ntemplate<class Fields>\nusing request_header = header<true, Fields>;\n\n\t\n// A typical HTTP response header\ntemplate<class Fields>\nusing response_header = header<false, Fields>;\n```\n\n### [Message Stream Operations](https://www.boost.org/doc/libs/master/libs/beast/doc/html/beast/using_http/message_stream_operations.html)\n\n提供 `read`、`async_read` 等函数用于从流中读取 HTTP 消息数据。\n\n提供 `write`、`async_write` 等函数用于将 HTTP 消息写入流中。\n\n![messageStream.png](/images/2024/09/19/b2f28c00-7661-11ef-a8f8-f3952e97d7ff.png)\n\n我们直接看官方案例就好，这些函数的含义在前面的章节已经学习过，尽管参数的类型可能会有所不同。\n\n这个参数类型就是 [flat_buffer](https://www.boost.org/doc/libs/master/libs/beast/doc/html/beast/ref/boost__beast__flat_buffer.html)，通常用于处理网络 I/O 操作中的可变大小的字节序列。而且，它非常适合和前面讲的 动态缓冲区 结合使用。\n\n（一）Reading\n\n同步读：\n\n```c++\nflat_buffer buffer;\nrequest<string_body> req;\nread(sock, buffer, req);\n```\n\n异步读：\n\n```c++\nflat_buffer buffer;\nresponse<string_body> res;\nasync_read(sock, buffer, res,\n    [&](error_code ec, std::size_t bytes_transferred)\n    {\n        boost::ignore_unused(bytes_transferred);\n        std::cerr << ec.message() << std::endl;\n    });\n```\n\n用于限制 HTTP 消息标头的最大大小的技术，以防止缓冲区溢出攻击：\n\n```c++\nflat_buffer buffer{10};\n// Try to read a request\nerror_code ec;\nrequest<string_body> req;\nread(sock, buffer, req, ec);\nif(ec == http::error::buffer_overflow)\n    std::cerr << \"Buffer limit exceeded!\" << std::endl;\n```\n\n（二）Writing\n\n同步写：\n\n```c++\nresponse<string_body> res;\nres.version(11);\nres.result(status::ok);\nres.set(field::server, \"Beast\");\nres.body() = \"Hello, world!\";\nres.prepare_payload();\n\nerror_code ec;\nwrite(sock, res, ec);\n```\n\n异步写：\n\n```c++\nasync_write(sock, res,\n    [&](error_code ec, std::size_t bytes_transferred)\n    {\n        boost::ignore_unused(bytes_transferred);\n        if(ec)\n            std::cerr << ec.message() << std::endl;\n    });\n```\n\n### Serialization\n\n 将 HTTP 消息转化为字节缓冲区。\n\n```c++\n// 将 HTTP message 序列化为字节流\ntemplate<\n    bool isRequest,\n    class Body,\n    class Fields = fields\n>\nclass serializer;\n\n\t\n// 将 HTTP request 序列化为字节流\ntemplate<\n    class Body,\n    class Fields = fields\n>\nusing request_serializer = serializer<true, Body, Fields>;\n\n//将 HTTP response 序列化为字节流\ntemplate<\n    class Body,\n    class Fields = fields\n>\nusing response_serializer = serializer<false, Body, Fields>;\n```\n\n其实这不难理解，就是我们构建 HTTP 数据包，将其序列化后就可以发送出去了。\n\n```c++\n// 构建HTTP响应\n        http::response<http::string_body> res{http::status::ok, 11};\n        res.set(http::field::server, \"Beast\");\n        res.set(http::field::content_type, \"text/plain\");\n        res.body() = \"Hello, World!\";\n        res.prepare_payload(); // 准备消息体的负载\n\n// 创建序列化器\n        http::response_serializer<http::string_body> sr{res};\n\n// 循环写入流，直到所有数据都被发送\n        while(! sr.is_done()) {\n            beast::error_code ec;\n            http::write_some(socket, sr, ec);  // 逐步发送\n            if(ec) {\n                std::cerr << \"Error: \" << ec.message() << std::endl;\n                break;\n            }\n        }\n```\n\n按照常见的通信模式来看，服务器需要进行序列化（Serialization），而客户端需要进行反序列化（Parsing）。下面看看可用的传输序列化数据的操作：\n\n![Serializer_Stream.png](/images/2024/09/19/a283b2e0-7661-11ef-a8f8-f3952e97d7ff.png)\n\n### Parsing\n\n将字节缓冲区解析为 HTTP 消息。\n\n```c++\n// 生成 message 的解析器\ntemplate<\n    bool isRequest,                       \n    class Body,                             \n    class Allocator = std::allocator<char>> \nclass parser\n    : public basic_parser<...>;\n\n// 生成 request message 的解析器\ntemplate<class Body, class Allocator = std::allocator<char>>\nusing request_parser = parser<true, Body, Allocator>;\n\n//生成 response message 的解析器\ntemplate<class Body, class Allocator = std::allocator<char>>\nusing response_parser = parser<false, Body, Allocator>;\n```\n\n比方说我们构造 HTTP 请求发给 百度，然后将百度的 response 进行解析，通过 get 方法获取解析结果。下面仅记录核心代码：\n\n```c++\n// 构建HTTP请求\n        http::request<http::string_body> req{ http::verb::get, \"/\", 11 };\n        req.set(http::field::host, \"www.baidu.com\");\n        req.set(http::field::user_agent, BOOST_BEAST_VERSION_STRING);\n\n// 将请求发送到服务器\n        http::write(socket, req);\n\n// 定义一个缓冲区来存储从服务器接收到的数据\n        beast::flat_buffer buffer;\n\n// 定义一个HTTP响应解析器\n        http::response_parser<http::string_body> parser;\n\n// 读取响应头和消息体，存入缓冲区并由解析器处理\n        http::read(socket, buffer, parser);\n\n// 获取解析后的响应对象\n        auto const& response = parser.get();\n\n// 提取HTTP状态码\n        std::cout << \"Status: \" << response.result_int() << std::endl;\n\n// 提取Content-Length头部字段\n        if (response.find(http::field::content_length) != response.end()) {\n            std::cout << \"Content-Length: \" << response[http::field::content_length] << std::endl;\n        }\n\n// 提取Content-Type头部字段\n        if (response.find(http::field::content_type) != response.end()) {\n            std::cout << \"Content-Type: \" << response[http::field::content_type] << std::endl;\n        }\n```\n\n解析结果：\n\n![HTTPdemo.png](/images/2024/09/19/9a680bb0-7661-11ef-a8f8-f3952e97d7ff.png)\n\n通过 get 获取整个 HTTP 消息的 header + body，我们常常需要获取 header 中的字段信息，部分字段可直接调用接口，其余字段需要通过 find 方法查找。我们讲完 response_parse ，也就 自然领会 request_parse，它们的操作也都是一致的。\n\n![Parser_Stream.png](/images/2024/09/19/e071bbb0-7661-11ef-a8f8-f3952e97d7ff.png)\n\n## 代码实现和测试\n\n**get 请求测试**\n\n![get请求.png](/images/2024/09/19/947278d0-7661-11ef-a8f8-f3952e97d7ff.png)\n\n**post 请求测试**\n\n![post请求.png](/images/2024/09/19/8ed677a0-7661-11ef-a8f8-f3952e97d7ff.png)\n\n测试工具：Postman\n\n代码地址：[实现HttpServer](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/12-HttpServer/)\n\n---\n\n⭐️内容取自 B 站 UP 恋恋风辰和 mmoaay 的《Boost.Asio C++ 网络编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议看原视频或者读原书。","tags":["网络编程","Asio"],"categories":["technology"]},{"title":"第五章：多线程的两种方案","url":"/2024/09/18/第五章：多线程的两种方案/","content":"\n<!-- toc -->\n\n## 多线程\n\n我们将介绍两种模式：\n\n- IOServicePool --> 启动多个线程，每个线程管理一个 io_context\n- IOThreadPool --> 只启动一个 io_context，被多个线程共享\n\n### IOServicePool\n\n早前的单线程模式中，我们的主线程不仅要监听客户端的连接，同时还要继续监听该客户端后续的读写事件。尽管我们已经把客户端需要的服务交互给工作线程，达到网络和计算工作的解耦，但是在接下来的多线程中，还可以继续解耦。即让主线程继续监听客户端的连接，但是后续这些连接的读写事件讲交给其他的线程处理。\n\n![IOServicePool.png](/images/2024/09/18/274f5ec0-75b8-11ef-9cea-e757e7343ac6.png)\n\n1. 每一个 io_context 跑在不同的线程里，所以同一个 socket 会被注册在同一个 io_context 里，它的回调函数也会被单独的一个线程回调，那么对于同一个 socket，他的回调函数每次触发都是在同一个线程里，就不会有线程安全问题，网络 IO 层面上的并发是线程安全的\n2. 对于不同的 socket，回调函数的触发可能是同一个线程（两个 socket 被分配到同一个 io_context），也可能不是同一个线程（两个socket被分配到不同的io_context里）。所以如果两个 socket 对应的上层逻辑处理，如果有交互或者访问共享区，会存在线程安全问题。比如 socket1 代表玩家 1，socket2 代表玩家 2，玩家 1 和玩家 2 在逻辑层存在交互，比如两个玩家都在做工会任务，他们属于同一个工会，工会积分的增加就是共享区的数据，需要保证线程安全。可以通过加锁或者逻辑队列的方式解决安全问题，我们目前采取了后者\n\n这里面有个内容值得一提，即 `boost::asio::io_context::work` 。我们调用 `boost::asio::io_context` 的 run 方法之后进入 事件循环。根据官方文档, 在已经启动 `io_context::run()` 的情况下, 如果此时没有了 IO 操作, 那么 `io_context` 会自动取消事件循环, 那么此时如果再有异步 IO 回调, 也不会发生作用了。\n\n```c++\nboost::asio::io_context::work(boost::asio::io_context & io_context);\n```\n\n但是有些情况下, 我们希望 `run()` 函数的事件循环在没有 IO 事件的情况下, 也不会退出事件循环, 而是一直等待, 当有了新的异步 IO 调用的时候, 还可以继续使用该循环。`io_context::work` 就可以办到，就是防止 `io_context` 在没有 IO 的情况下依旧能够运行。直到你调用 它的 reset 方法销毁 work 对象才会停止发挥作用。\n\n用法也相当简单，只需要把对应 io_context 传递给 work 作为参数，就代表让 该 work 管理了。\n\n比方说我们的核心代码如下：\n\n```c++\n\tfor (std::size_t i = 0; i < size; i++) {\n\t\tworkVec_[i] = std::unique_ptr<Work>(new Work(ioServiceVec_[i]));\n\t}\n```\n\n有新连接到来就会轮询分配 IOService。\n\n![IOSerTest.png](/images/2024/09/18/1ed80300-75b8-11ef-9cea-e757e7343ac6.png)\n\n代码地址：[增加IOServicePool](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/10-%E5%A2%9E%E5%8A%A0IOServicePool)\n\n### IOThreadPool\n\n```c++\nAsioIOServicePool::AsioIOServicePool(std::size_t size)\n\t:threadVec_(size),nextIOService_(0),size_(size)\n\t,work_(new Work(ioService_))\n{\n\t// 一个 线程上 启动同一个 ioService\n\tfor (std::size_t i = 0; i < size; i++) {\n\t\tthreadVec_.emplace_back([this]() {\n\t\t\tioService_.run();\n\t\t\t});\n\t}\n}\n```\n\n我们的代码不是基于前一个多线程代码来修改的，而是基于上一章的 LogicalDesign。\n\n我首先疑惑的是为什么多个线程可以多次启动 io_context，这当然是不了解 Asio 底层原理所致，也打算在第七章或者终章记录任何有关 Asio 库的相关问题。\n\n`boost::asio::io_context` 是设计为线程安全的，并支持多个线程并发调用其 `run()` 方法。这是通过内部同步机制实现的，确保同一时刻只有一个线程处理某个具体任务，但多个线程可以同时调度任务。\n\n如下图所示，每个线程内部已经调用 run 方法，它是一个阻塞调用，直到所有挂起的异步操作都完成或被显式地停止。在处理完所有操作后，它会返回。但是我没已经用 work 帮我们让它始终不会停止，除非我们手动 reset。run 之后会开始处理所有已注册的异步操作，那么多线程都等待者异步事件到来，即等待被分配任务队列，然后去执行回调函数。\n\n![IOThreadPool1.png](/images/2024/09/18/10f700b0-75b8-11ef-9cea-e757e7343ac6.png)\n\n即便如此，还是存在一个隐患，即同一个 Socket 的多个事件被分配到多个线程中（每个线程只得到一个事件，即回调函数），那么同一个 Socket 是共享数据区域的，那么多个线程同时对这块区域进行操作就会有问题了。比如第一次是在线程 A，第二次是在线程 C，如果这两次触发间隔时间不大，那么很可能出现不同线程并发访问数据的情况，比如在处理读事件时，第一次回调触发后我们从 Socket 的接收缓冲区读数据出来，第二次回调触发,还是从 Socket 的接收缓冲区读数据，就会造成两个线程同时从 Socket 中读数据的情况，会造成数据混乱。\n\n![IOThreadPool2.png](/images/2024/09/18/0d855990-75b8-11ef-9cea-e757e7343ac6.png)\n\n如果需要多个线程访问共享资源，你可以使用 `boost::asio::strand` 来串行化这些任务，确保某些任务只能由一个线程排他性地处理。`strand` 的目的是保证一系列操作是按照顺序执行的，即使它们分布在不同的线程中。\n\n![IOThreadPool3.png](/images/2024/09/18/09a5d570-75b8-11ef-9cea-e757e7343ac6.png)\n\n**创建 strand 对象**\n\n```c++\nboost::asio::io_context io_context;\nboost::asio::strand<boost::asio::io_context::executor_type> strand(io_context.get_executor());\n\n//这里 strand 是一个串行化的执行器，它绑定到 io_context 的执行器上\n```\n\n**boost::asio::bind_executor：将执行器与回调函数完全绑定在一起**\n\n```c++\n// 没有绑定 strand 之前\n\tauto& msgnode = sendQue_.front();\n\tsocket_.async_write_some(boost::asio::buffer(msgnode->data_, msgnode->total_len_),\n\t\tstd::bind(&Session::handle_write, shared_from_this(), std::placeholders::_1));\n\n// 绑定 strand 之后\n\tauto& msgnode = sendQue_.front();\n\tsocket_.async_write_some(boost::asio::buffer(msgnode->data_, msgnode->total_len_),\n\t\tboost::asio::bind_executor(strand_,std::bind(&Session::handle_write, shared_from_this(), std::placeholders::_1)));\n```\n\n绑定 strand 之后，绑定的函数就会有 strand 来调用，就不会有前面讲的并发安全问题。我们需要在所有收发的地方，都将调度器绑定为`strand_`，这边是集中在 Session类 中。Server类 中尽管也有，但是它是工作在单线程的，不存在并发问题。\n\n代码地址：[增加IOThreadPool](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/11-%E5%A2%9E%E5%8A%A0IOThreadPool)\n\n### 性能比较\n\n把两端的输入全部移除，压力测试不要有任何输出。我这边 10万并发量 需要 15s （IOThreadPool 和 IOSerivcePool都是一样），这当然取决于你的机器。\n\n---\n\n⭐️内容取自 B 站 UP 恋恋风辰和 mmoaay 的《Boost.Asio C++ 网络编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议看原视频或者读原书。","tags":["网络编程","Asio"],"categories":["technology"]},{"title":"Vim基础教程","url":"/2024/09/14/Vim基础教程/","content":"\n<!-- toc -->\n\n## 换行\n\n如果在 Vim 中打开文件时没有自动换行（换行显示），有可能是因为文件内容中没有换行符，或者 Vim 的自动换行设置没有开启。\n\nVim 有两种常见的换行方式：**硬换行**和**软换行**。\n\n- **硬换行**：文件中真正存在换行符\n- **软换行**：Vim 自动将一行文本在窗口宽度内进行折叠显示（不改变文件内容）\n\n```bash\n// 启用软换行（自动换行显示）\n:set wrap\t\n\n// 禁用软换行（保持长行不折行）\n:set nowrap\n\n// 软换行的视觉优化（如果你希望在折行时更清楚地看到行的起始和结束）\n:set linebreak\n```\n\n如果希望 Vim 每次启动都开启自动换行，可以在 Vim 配置文件 (`~/.vimrc`) 中添加以下设置：\n\n```bash\nset wrap\nset linebreak\n```\n\n## 普通模式\n\n### 查找\n\n![查找.png](/images/2024/09/14/f59f2c70-727e-11ef-82d8-fd739d506881.png)\n\n### 粘贴，撤销和恢复以及保存退出\n\n![粘贴撤销恢复.png](/images/2024/09/14/efd78760-727e-11ef-82d8-fd739d506881.png)\n\n如果你以为 Ctrl + s 是保存，那你就大错特错，并且会进入僵死状态，输入 Ctrl + q 可以解除。\n\n下面这个才是保存命令和退出命令。 \n\n![保存.png](/images/2024/09/14/eb0b0b30-727e-11ef-82d8-fd739d506881.png)\n\n### 移动光标\n\n![移动光标.png](/images/2024/09/14/e5ef84a0-727e-11ef-82d8-fd739d506881.png)\n\n### 删除（delete）文本\n\n`dw` --> delete word，删除一个单词，但是要把光标放到单词的首字母上。\n\n`dt\"` 删除到`\"`，但不包含`\"`\n\n`dt)` 删除到`)`，但不包含`)`\n\n![删除.png](/images/2024/09/14/e0c8b370-727e-11ef-82d8-fd739d506881.png)\n\n### 复制（yank）文本\n\n![复制.png](/images/2024/09/14/db93ff90-727e-11ef-82d8-fd739d506881.png)\n\n### 修改（change）文本\n\n删除文本并进入编辑模式，只要你学会删除文本，这个也就等价于会了。\n\n![修改.png](/images/2024/09/14/d5e95860-727e-11ef-82d8-fd739d506881.png)\n\n### 替换（substitute）文本\n\n![替换.png](/images/2024/09/14/cffa7c40-727e-11ef-82d8-fd739d506881.png)\n\n## 视图模式\n\n视图模式是用来选择内容的。选择内容之后，我们就可以对其进行复制或者删除。\n\n```bash\nv：行选模式\n[ctrl] + v：竖选模式\n```\n\n常见用法：批量注释\n\n```tex\n1) [ctrl]+v 进入竖选模式\n2) 选择范围\n3) 输入 I（大写的字母i）\n4) 输入 //\n5) 输入 [ESC]\n```","tags":["Linux"],"categories":["technology"]},{"title":"第四章：逻辑层设计","url":"/2024/09/14/第四章：逻辑层设计/","content":"\n<!-- toc -->\n\n## 消息头完善\n\n早前我们的数据包设计为 头部+数据，但是要进行逻辑处理，就需要传递一个 id 字段表示要处理的消息 id，当然可以不在包头传 id 字段，将 id 序列化到消息体也是可以的，但是我们为了便于处理也便于回调逻辑层对应的函数，最好是将 id 写入包头。\n\n![新的消息体.png](/images/2024/09/14/19a4b5c0-7236-11ef-95c5-9b77976d41aa.png)\n\n基于之前的 MsgNode 再设计两个节点类，即 RecvNode 和 SendNode，前者表示接收消息的节点，后者表示发送消息的节点。就不新建类来定义，直接再 MsgNode 类文件中一起实现了。随之，我们的 Session 类也要有所改动。\n\n上一章的末尾讲到把传递的实体数据序列化，那就在这节把传递数据序列化的代码完成。同时，本次代码还进行一收一发的过程，如果你要测试是否存在粘包，只需要把客户端代码中的收数据过程注释掉进行测试即可，如果你想测试客户端和服务端通信的收发过程没有问题，再将注释关闭即可。\n\n![加入序列化和完善MsgNode.png](/images/2024/09/14/16324b50-7236-11ef-95c5-9b77976d41aa.png)\n\n代码地址：[加入序列化和完善MsgNode](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/8-%E5%8A%A0%E5%85%A5%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%AE%8C%E5%96%84MsgNode)\n\n## 优雅退出\n\n让服务器优化退出可以采用信号的方式，如果你是在 Linux 系统中，你可以在主线程设置监听某个信号，如果有对应的信号产生，就执行事先设置好的回调函数。\n\nasio 也提供有这样的方式，在主函数中添加如下代码即可：\n\n```c++\nint main()\n{\n    try {\n        boost::asio::io_context  io_context;\n        boost::asio::signal_set signals(io_context, SIGINT, SIGTERM);\n        signals.async_wait([&io_context](auto, auto) {\n            io_context.stop();\n            });\n        CServer s(io_context, 10086);\n        io_context.run();\n    }\n    catch (std::exception& e) {\n        std::cerr << \"Exception: \" << e.what() << endl;\n    }\n}\n```\n\n从代码中可以看出， boost::asio::signal_set 定义一个变量，第一个参数是 io_context，表示由它监听接下来要设置的信号。后面的参数就是要监听的信号，然后 async_wait 异步等待信号的发送，如果有等待的信号产生，就执行 回调函数。这里的回调函数是匿名函数，这样方便传递外部的变量，至于这里为什么是(auto, auto)，是因为这里的 async_wait 里面的回调函数本身是要两个参数的。这两个参数见下：\n\n```c++\nsignals.async_wait([&io_context](auto error, auto signal_number) {\n    io_context.stop();\n});\n```\n\n但由于我们暂时不用这两个变量，也就没有写明（反正《恋恋风尘》是这么写的，我只是说清楚）。\n\n下面是一些其他的 API，可以了解看看。\n\n```c++\nsignal_set(io_context): 构造函数，接受一个 io_context 对象来处理异步操作\n    \nadd(int signal_number): 向信号集添加要监听的信号\n    \nremove(int signal_number): 从信号集中移除指定信号\n    \nclear(): 清除所有已注册的信号\n    \nasync_wait(handler): 异步等待信号的触发，当信号被捕获时调用指定的处理程序\n```\n\n## LogicSystem单例类\n\n单例类的实现可见此文：[单例模式](https://xiaoyangst.github.io/2024/09/11/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/)\n\n我们的消息格式已经重新设计，这个新增的 ID 字段究竟代表着什么？客户端通过 ID 来表明自己需要的服务。简单举例，服务器现在是一个聊天服务器，客户端就谈过 ID 来表达自己的功能需求。传递 ID = 1 表明需要注册用户，其账号和密码就包含在消息体中，服务器通过解析 JSON 数据就可以拿出并把数据存储注册信息的数据库中，同时返回 ID = 10，表示注册成功。客户端接收到这个信息之后，也就知道自己已经注册成功了。\n\nLgicSystem 类就是和网络库进行分离的，即网络和计算工作进行分离。在网络阶段解析到 用户数据包中的 ID字段之后，就加入到 LgicSystem 提供的队列中，LgicSystem 这边会自动唤醒工作线程来执行任务函数（ID 和 回调函数以 key-value 存在 map 容器中，查找方便）。也就是说，之前我们是让网络库来执行和用户交互的工作，但是现在网络库就是来处理客户端的连接和客户端发来的消息，至于后续执行客户端需求和回复客户端状态的事情将交给工作线程来做（LgicSystem 中的 dealMsg成员函数），实现网络和计算工作的解耦合。\n\n![逻辑层设计完成.png](/images/2024/09/14/062c6d30-7236-11ef-95c5-9b77976d41aa.png)\n\n代码地址：[逻辑层设计完成](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/9-%E9%80%BB%E8%BE%91%E5%B1%82%E8%AE%BE%E8%AE%A1%E5%AE%8C%E6%88%90)\n\n---\n⭐️内容取自 B 站 UP 恋恋风辰和 mmoaay 的《Boost.Asio C++ 网络编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议看原视频或者读原书。","tags":["网络编程","Asio"],"categories":["technology"]},{"title":"C++中的友元类","url":"/2024/09/13/C-中的友元类/","content":"\n<!-- toc -->\n\n早之前很少用友元类，直到最近跟某个博主写 Asio 网络库，跟着用到友元类，但是今天却遇到一个问题，通过查询得到解决，特记录于此。不过，在此之前，还是把友元类的基础知识做个记录。\n\n## 基础知识\n\n友元可以是一个函数，该函数被称为友元函数。\n\n类的友元函数是定义在类外部，但有权访问类的所有私有（private）成员和保护（protected）成员。尽管友元函数的原型有在类的定义中出现过，但是友元函数并不是成员函数。\n\n```c++\nclass Box\n{\n   double width;\npublic:\n   double length;\n   friend void printWidth( Box box );\t// 友元函数\n   void setWidth( double wid );\n};\n```\n\n友元也可以是一个类，该类被称为友元类，在这种情况下，整个类及其所有成员都是友元。\n\n下面声明 Session 类 是 MsgNode 类的友元类，意味着 Session 类可以访问 MsgNode 类 中所有的成员变量和成员函数（public、protected、private）\n\n```c++\nclass MsgNode\n{\n\tfriend class Session;\npublic:\n\tMsgNode(short max_len);\t\n\t~MsgNode();\nprotected:\n\tchar* data_;\n};\n```\n\n## 注意点\n\n友元并不属于这个类本身，无论是友元函数还是友元类。都不能使用类内的this指针，同时也不可以被继承，如同父亲的朋友不一定是儿子的朋友这个道理。\n\n- 友元关系不能被继承\n- 友元关系是单向的，不具有交换性。若类B是类A的友元，类A不一定是类B的友元，要看在类中是否有相应的声明\n- 友元关系不具有传递性。若类B是类A的友元，类C是B的友元，类C不一定是类A的友元，同样要看类中是否有相应的申明\n\n## 遇到的问题：不可访问友元类的继承的私有成员\n\n我要先把类的继承关系罗列出来，才能讲这里的问题：\n\n```c++\nclass MsgNode\n{\n\tfriend class LogicNode;\n\tfriend class LogicSystem;\n\tfriend class RecvNode;\npublic:\n\tMsgNode(short max_len);\t\n\t~MsgNode();\n\tvoid clear();\t// 清空数据，避免多次构造节点带来的开销\nprivate:\n\tchar* data_;\n};\n\nclass RecvNode : public MsgNode {\t// 接收节点\n\tfriend class LogicNode;\n\tfriend class LogicSystem;\npublic:\n\tRecvNode(short max_len, short msgID);\nprivate:\n\tshort msgID_;\n};\n```\n\nRecvNode 类 基础自 MsgNode 类，即有部分成员变量来源于它。我在 LogicSystem 类中要去访问 RecvNode 类 中的成员函数，就在 RecvNode 类中把 LogicSystem 声明为 友元，成功访问到 msgID_ 成员函数，但是却不能访问 data_ 成员。\n\n截止，我们提出这个问题：子类从父类继承的成员变量，是属于子类呢还是属于父类呢？\n\n因此可以看出，**父类中的所有变量都被子类给继承了下来，都属于子类的一部分。**虽然父类中 `private` 访问权限的成员不能被子类访问，但是仍然属于子类的一部分。同理，在子类继承父类时，除了继承父类中所有的成员变量，也同时继承了除了父类构造函数外的所有成员函数，这样便可以有效节省代码量，提高代码复用效率。\n\n哦，我们知道了！！！父类中 private 访问权限下的成员不能被子类访问，哪怕它属于子类的一部分。那么子类 RecvNode  都不能访问到父类 MsgNode，凭什么你 友元类 LogicSystem 就可以呢？显然 LogicSystem 类也不可以访问。\n\n该怎么做 ？让子类 RecvNode  能访问到父类 MsgNode即可，所以修改父类 MsgNode 的 private 下的成员变量为 protected 即可。你当然也可以修改为 public，那我设置友元类干什么？","tags":["CPP"],"categories":["technology"]},{"title":"为什么子类需要调用父类的构造函数 ？","url":"/2024/09/11/为什么子类需要调用父类的构造函数-？/","content":"\n因为长时间没有写过继承相关的代码，竟然忘记子类需要给父类初始化成员，即调用父类的构造函数初始化继承过来的成员变量。\n\n```c++\n// 基类\nMsgNode::MsgNode(char* msg, int max_len)\n\t: cur_len_(0)\n\t, total_len_(max_len + HEAD_LENGTH)\n{\n\tdata_ = new char[total_len_ + 1]();\n\t// 暂时封装为 头部+数据\n\tmemcpy(data_, &max_len, HEAD_LENGTH);\n\tmemcpy(data_ + HEAD_LENGTH, msg, max_len);\n\tdata_[total_len_] = '\\0';\n}\n\nMsgNode::MsgNode(int max_len)\n\t: cur_len_(0)\n\t, total_len_(max_len)\n{\n\tdata_ = new char[total_len_ + 1]();\n}\n\n// 派生类\nRecvNode::RecvNode(int max_len, int msgID)\n\t: MsgNode(max_len)\n\t, msgID_(msgID)\n{\n\n}\n\n// 派生类\nSendNode::SendNode(const char* msg, short max_len, short msgID)\n\t: MsgNode(max_len + HEAD_LENGTH)\n\t, msgID_(msgID)\n{\n\n}\n```\n\n子类对象包含父类部分，必须确保父类部分被正确初始化。否则，父类的数据成员可能会处于未定义状态，从而导致程序错误或不稳定。通过调用父类构造函数，可以重用父类中已有的初始化逻辑，避免在每个子类中重复编写相同的初始化代码。如果父类的构造函数有某些重要的初始化操作，这些操作需要在任何子类对象创建时都执行，以确保一致的行为。\n\n- **父类构造函数无参**：如果父类提供了一个无参构造函数，子类构造函数可以不显式调用它。编译器会自动调用它\n- **父类构造函数有参数**：如果父类构造函数需要参数，子类必须在其构造函数的初始化列表中显式调用父类的构造函数，并传递适当的参数","tags":["技术杂文"],"categories":["technology"]},{"title":"单例模式","url":"/2024/09/11/单例模式/","content":"\n单例模式能够保证一个类只有一个实例， 并提供一个访问该实例的全局节点，所以任何用户在该实例创建之后将不再允许再次创建。\n\n[单例模式有多种实现方式](https://www.yuque.com/xiaoyang-wyxle/his01x/cvyavebud851hnoh)，当我们要实现的单例模式必须是线程安全，且派生类通过继承就可以得到轻松创建该派生类的单例模式，后续就不必在每个类中都去实现一份单例了。\n\n- once_flag 和 call_once 保证创建单例的方法在多线程环境下只会被调用一次\n- static 关键字 保证 实例只能拥有一份（但需要设计才能保证多线程环境下独一份）\n- 用智能指针管理单例的实例对象\n- 禁用拷贝构造函数和拷贝赋值运算符函数，保证对象不可被拷贝构造和拷贝赋值，但是由于我们这里要设计的这个单例类用以被继承，所以得是 protected。派生类以 public 继承之后，自然会让其成为 private\n- 单例类的构造函数必须是 private，这样才能将类的创建权控制在类的内部，但是由于我们这里要设计的这个单例类用以被继承，所以得是 protected。派生类以 public 继承之后，自然会让其成为 private\n- 单例类的析构函数必须是 private，保证对象不可以在外部随意删除，但是由于我们这里要设计的这个单例类用以被继承，所以得是 protected。派生类以 public 继承之后，自然会让其成为 private\n- 既然希望创建任意类的单例，需要用到模板类\n\n```c++\ntemplate <typename T>\nclass Singleton {\nprotected:\n\tSingleton() = default;\n\t~Singleton() = default;\n\n\tSingleton(const Singleton<T>&) = delete;\n\tSingleton& operator=(const Singleton<T>&) = delete;\n\n\tstatic std::shared_ptr<T> instance_;\n\tstatic std::once_flag once_;\npublic:\n\tstatic std::shared_ptr<T> getInstance() {\n\t\tstd::call_once(once_, []() {\t\t\n\t\t\tinstance_ = std::make_shared<T>();\n\t\t\t});\n\t\treturn instance_;\n\t}\n};\n\ntemplate <typename T>\nstd::shared_ptr<T> Singleton<T>::instance_ = nullptr;\n\ntemplate <typename T>\nstd::once_flag Singleton<T>::once_;\n```\n\n客户端测试代码：\n\n```c++\nclass Student : public Singleton<Student> {\n    friend class Singleton<Student>;\t// 将 Singleton<Student> 声明为友元类，其私有的构造函数和析构函数都可以被 Singleton 调用了\npublic:\n\tvoid doSomething() {\n\t\tstd::cout << \" Student do\" << std::endl;\n\t}\n};\n\nvoid testSingleton() {\n\tstd::shared_ptr<Student> instance1 = Student::getInstance();\n\tstd::shared_ptr<Student> instance2 = Student::getInstance();\n\n\tif (instance1 == instance2) {\n\t\tstd::cout << \"Singleton test passed: Both instances are the same.\" << std::endl;\n\t}\n\telse {\n\t\tstd::cout << \"Singleton test failed: Instances are different.\" << std::endl;\n\t}\n\n\tinstance1->doSomething();\n}\n\nint main() {\n\n\tstd::thread t1(testSingleton);\n\tstd::thread t2(testSingleton);\n\n\tt1.join();\n\tt2.join();\n\n\treturn 0;\n}\n/*\n\tSingleton test passed: Both instances are the same.\n \t Student do\n\tSingleton test passed: Both instances are the same.\n       Student do\n*/\n```","tags":["设计模式"],"categories":["technology"]},{"title":"call_once 和 once_flag","url":"/2024/09/11/call-once-和-once-flag/","content":"\nstd::call_once 和 std::once_flag 是 C++11 中引入的**线程安全**的函数和类型，用于**确保某个函数只被调用一次**\n\n```c++\ntemplate <class Fn, class... Args>\nvoid call_once (once_flag& flag, Fn&& fn, Args&&... args);\n```\n\n**flag**：`std::once_flag` 对象，用来确保某个函数只被调用一次\n\n**fn**：要调用的函数\n\n**args**：传递给函数 `fn` 的参数\n\n官网概述：\n\n- 如果另一个线程已经主动执行了带有相同标记的 call_once 调用，则会导致被动执行： 被动执行不会调用 fn\n- 如果对 call_once 的主动调用因抛出异常而结束（异常会传播给调用线程），并且存在被动执行，则会从这些被动执行中选择一个，并调用它作为新的主动调用\n- 如果一旦主动执行返回，所有当前的被动执行和未来对 call_once 的调用（使用相同的标志）也会返回，而不会成为主动执行\n\n如果一个线程 A 正在执行带有 call_once 标记的函数 fn，其它线程企图调用 fn 是无法成功的（标记为被动执行）。如果前面的线程A执行成功，那么标记为被动执行的其它线程将没有调用 fn 的机会。如果前面的线程A执行失败，哪些标记为被动执行的线程中会有一个被选择化为主动执行，即可以调用 fn，其它没被选中的依旧保持被动执行的标记\n\n```c++\n#include <iostream>       \n#include <thread>         \n#include <chrono>        \n#include <mutex>          // std::call_once, std::once_flag\n\nint winner;\nvoid set_winner (int x) { winner = x; }\nstd::once_flag winner_flag;\n\nvoid wait_1000ms (int id) {\n  for (int i=0; i<1000; ++i)\n    std::this_thread::sleep_for(std::chrono::milliseconds(1));\n  std::call_once (winner_flag,set_winner,id);\n}\n\nint main ()\n{\n  std::thread threads[10];\n  for (int i=0; i<10; ++i)\n    threads[i] = std::thread(wait_1000ms,i+1);\n\n  std::cout << \"waiting for the first among 10 threads to count 1000 ms...\\n\";\n\n  for (auto& th : threads) th.join();\n  std::cout << \"winner thread: \" << winner << '\\n';\n\n  return 0;\n}\n```\n\n输出结果：\n\n![call_once验证.png](/images/2024/09/11/e9f8b0a0-6fe8-11ef-bdaf-31a8545cb19b.png)","tags":["技术杂文"],"categories":["technology"]},{"title":"模板模式","url":"/2024/09/11/模板模式/","content":"\n在父类中定义了算法的骨架，其骨架中包含（部分包含）可供子类重写的算法，即允许子类在不改变算法结构的前提下重定义算法的某些特定步骤。\n\n```c++\nclass Game {\npublic:\n\t// 如下方法由 继承者 重写\n\tvirtual void Start() = 0;\n\tvirtual void Process() = 0;\n\tvirtual void End() = 0;\n\n\tvoid Play() {\t// 算法骨架\n\t\tStart();\n\t\tProcess();\n\t\tEnd();\n\t}\n};\n\nclass FootBall : public Game{\npublic:\n\tvoid Start() {\n\t\tcout << \" FootBall Start \" << endl;\n\t}\n\tvoid Process() {\n\t\tcout << \" FootBall Process \" << endl;\n\t}\n\tvoid End() {\n\t\tcout << \" FootBall End \" << endl;\n\t}\n};\n\nclass BasketBall : public Game {\npublic:\n\tvoid Start() {\n\t\tcout << \" BasketBall Start \" << endl;\n\t}\n\tvoid Process() {\n\t\tcout << \" BasketBall Process \" << endl;\n\t}\n\tvoid End() {\n\t\tcout << \" BasketBall End \" << endl;\n\t}\n};\n```\n\n客户端测试代码：\n\n```c++\nint main(int argc,char* argv[]) {\n\n\tshared_ptr<Game> g = make_shared<BasketBall>();\n\tg->Play();\n\n\treturn 0;\n}\n/*\n\t BasketBall Start\n \t  BasketBall Process\n\t BasketBall End\n*/\n```\n\n模板模式和策略模式确实很容易混淆，但如果细细对比还是可以发现两者的区别。模板模式是已经搭建好行为框架，然后子类重定义框架中的行为（部分行为），其执行逻辑是被限制在框架内的。但是策略模式的整个算法行为没有框架，而是完全让子类自己实现的，所以框架的整个逻辑由自己掌控的。\n\n当然，下面的区别总结来源于其他网站：\n\n- [模板方法](https://refactoringguru.cn/design-patterns/template-method)基于继承机制： 它允许你通过扩展子类中的部分内容来改变部分算法。 [策略模式](https://refactoringguru.cn/design-patterns/strategy)基于组合机制： 你可以通过对相应行为提供不同的策略来改变对象的部分行为。\n- 模板方法在类层次上运作， 因此它是静态的。 策略在对象层次上运作， 因此允许在运行时切换行为。","tags":["设计模式"],"categories":["technology"]},{"title":"第六章：惰性求值","url":"/2024/09/10/第六章：惰性求值/","content":"\n<!-- toc -->\n\n假定现在需要对 A 和 B 进行求值，但问题是后面可能未必需要用到，这就白白浪费 CPU 时间去计算它了。也许可以用 Lambda 表达式，等需要的时候调用函数 P 来获取乘积结果。\n\n```c++\nauto P = [A,B] {\n  return A * B;  \n};\n```\n\n对于一个可能不需要结果的复杂的计算，这样做就是对代码的优化。但也带来了新的问题：如果这个值不止一次被使用怎么办？使用这种方法，每次调用都要计算这个值。更好的做法是在第一次计算该值时，将它保存起来。\n\n这就是“惰性”的全部意义：对于工作不是提前而是尽可能推后。因为有惰性，也不可能多次重复做一件事，所以当得到结果后，就应记住这个结果。\n\n## 惰性作为一种优化技术\n\n### 集合惰性排序\n\n假设有几百个员工信息存储在一个向量中，一个窗口一次可以显示其中的 10 名员工。用户可根据姓名、年龄和工龄等多种标准对员工进行排序。当用户选择按年龄对员工进行排序时，程序应显示 10 个年龄最大的员工，并且允许用户向下滚动，查看剩余的部分。\n\n用快速排序算法，找到合适的基准元素，对基准前面的元素进行递归排序，对基准后面的元素暂时不进行递归排序。\n\n![快速排序.png](/images/2024/09/10/3ac43190-6f39-11ef-b15c-053f95c5eeaa.png)\n\n### 通过缓存函数结果修剪递归树\n\nC++ 虽然不直接支持惰性求值，但可以根据自己的意愿进行实现。对于不同的情况决定如何实现惰性求职。看一个常见的例子：\n\n![斐波拉契数列.png](/images/2024/09/10/312322e0-6f39-11ef-b15c-053f95c5eeaa.png)\n\n这种实现是低效的，因为有很多重复的计算，见下图：\n\n![重复计算.png](/images/2024/09/10/2c4f53b0-6f39-11ef-b15c-053f95c5eeaa.png)\n\n该函数是纯函数，对于给定的输入总返回相同的结果。在计算 fib(n) 之后，可以保存起来，在需要的时候使用这个值。如果把前面的计算结果都缓存起来，就可以删除所有重复的子树。\n\n```c++\nstd::vector<unsigned int> cache {0, 1};\n\nunsigned int fib(unsigned int n)\n{\n    if (cache.size() > n) {\n        return(cache[n]);\n    } else {\n        const auto result = fib(n - 1) + fib(n - 2);\n        cache.push_back(result);\n        return result;\n    }\n}\n```\n\n效果如下图：\n\n![缓存.png](/images/2024/09/10/2162b230-6f39-11ef-b15c-053f95c5eeaa.png)\n\n实际上这里还可以继续优化，因为本质上计算当前值，只需要利用前面两个值的结果就行，意味着不需要每次计算都存储一个计算结果，这会导致空间越来越大，实际上只需要存储两个元素的空间大小即可。\n\n```c++\nunsigned int fib(unsigned int n) {\n    if (n == 0) return 0;\n    if (n == 1) return 1;\n\n    unsigned int prev1 = 0;\n    unsigned int prev2 = 1;\n\n    for (unsigned int i = 2; i <= n; ++i) {\n        unsigned int current = prev1 + prev2;\n        prev1 = prev2;\n        prev2 = current;\n    }\n\n    return prev2;\n}\n```\n\n### 动态规划作为惰性形式\n\n如果你了解动态规划，就明白之前的案例已经就是动态规划的思想，尽管那不是动态规划的写法。\n\n```c++\nclass Solution {\npublic:\n    int fib(int n) {\n        if(n <= 1) return n;\n        vector<int> result(n+1);\n        result[0] = 0;\n        result[1] = 1;\n        for(int i = 2; i <= n; i++){\n            result[i] = result[i - 1] + result[i-2];\n        }\n        return result[n];\n    }\n};\n```\n\n## 通用记忆化\n\n对于不同的问题单独编写自定义缓存是比较好的，这样就可以控制特特定值在缓存中的存放时间，并且可以确定最好的缓存结构，但有时把一个函数进行包装，而得到该函数的记忆化版本会比较好。\n\n如果不知道函数的调用参数，那么通用的缓存就是 map。任何纯函数都是从参数到值得映射，因此这种缓存可毫无问题地适应任何纯函数。\n\n![函数指针记忆化.png](/images/2024/09/10/1c10d960-6f39-11ef-b15c-053f95c5eeaa.png)\n\n如果要对递归函数记忆化，最好缓存它的最后结果，而不是递归结果，因为递归调用是调用的原函数，而不是记忆化的包装函数。\n\n## 表达式模板与惰性字符串拼接\n\n考虑多个字符串拼接，见下图：\n\n![字符串拼接1.png](/images/2024/09/10/17d133e0-6f39-11ef-b15c-053f95c5eeaa.png)\n\n虽然能够实现字符串拼接，但是这样效率低效。因为没有提前分配内存大小，导致没拼接一次就要进行扩容拷贝操作。\n\n![字符串拼接2.png](/images/2024/09/10/13997da0-6f39-11ef-b15c-053f95c5eeaa.png)\n\n这正是**表达式模板**起作用的地方：它们允许产生表达式的定义，而不是求解表达式的值。不是实现操作符 + 拼接字符串，而是返回表达式表示的定义，后面再对它进行计算。在这个例子中，问题的根源在于操作符 + 是一个二元操作符，却要实现多次字符串拼接。因此，需要创建一个表示拼接多个字符串的结构。因为需要存储任意数目的字符串，所以创建一个递归结构模板比较合适：一个节点保存单个字符串（data成员），另一节点保存剩下的所有字符串（tail成员）。\n\n![字符串拼接3.png](/images/2024/09/10/0e9a0a90-6f39-11ef-b15c-053f95c5eeaa.png)\n\n表达式模板是一种迟延计算的强大工具。它们经常用在操作矩阵的库中，或在提交编译器之前对表达式进行优化的场合。\n\n---\n\n⭐️内容取自译者程继洪、孙玉梅、娄山佑《函数式编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["函数式编程"],"categories":["technology"]},{"title":"字符串数组","url":"/2024/09/09/字符串数组/","content":"\n字符串数组即存储字符串的数组，我们可能会想到用二维数组来存储字符串。就像下面这样：\n\n```c\nchar planets[][8] = {\"Mercury\", \"Venus\", \"Earth\", \n                     \t\"Mars\", \"Jupiter\", \"Saturn\", \n                     \t\"Uranus\", \"Neptune\", \"Pluto\"};\n```\n\n那么对于没有占用字符的位置会填充为0，但这本就属于多余申请的空间。\n\n![字符串数组二维.png](/images/2024/09/09/87506c40-6eb7-11ef-8b20-af503e99b33d.png)\n\n如果我们该用一维数组来存储字符串指针，不但可以存储字符串，还可以节约空间。\n\n```\nchar* planets[] = {\"Mercury\", \"Venus\", \"Earth\", \n                     \t\"Mars\", \"Jupiter\", \"Saturn\", \n                     \t\"Uranus\", \"Neptune\", \"Pluto\"};\n```\n\n就像下面这样：\n\n![字符串数组一维.png](/images/2024/09/09/7e4b4f70-6eb7-11ef-8b20-af503e99b33d.png)\n\n因此，我们存储字符串用一维数组，即指向字符串的指针的数组。","tags":["C"],"categories":["technology"]},{"title":"指针基础","url":"/2024/09/09/指针基础/","content":"\n<!-- toc -->\n\n## 指针和指针变量\n\n指针是地址，指针变量是存储地址的变量。\n\n如下图为，指针变量 p 指向 变量 i 的地址。\n\n![指针1.png](/images/2024/09/09/9c5b2df0-6eb2-11ef-9a3d-f9a0fb494c06.png)\n\n## 取地址运算符和间接寻址运算符\n\n```c++\nint main(void) {\n\n\tint num = 10;\n\n\tint* p;\t// 声明一个指针变量\n\n\tp = &num;\t// 指向变量 num 的地址\n\n\tprintf(\"p = %d\", *p);\t// 对指针变量 p 解引用，即获取 指针变量 p 指向地址的数据\n\n\treturn 0;\n}\n```\n\n& 获取变量的地址，\\* 对指针变量解引用。\n\n你可以看到 & 和 \\* 是互相抵消的关系，如上述代码中`*p = *&num = num`。\n\n只要 p 指向 num，p 就是 num 的别名。p 不仅拥有和 num 相同的值，而且对 p 的改变也会改变 num 的值。（p 是左值，所以对它赋值是合法的。）\n\n## 指针赋值\n\n```c++\nint main(void) {\n\n\tint num1 = 10;\n\tint num2 = 20;\n\n\tint* p = &num1;\n\tint* m = &num2;\n\n\tp = m;\n\n\tprintf(\"p = %d, m = %d\\n\", *p, *m);\t\n\n\t*p = *m;\n\n\tprintf(\"p = %d, m = %d\\n\", *p, *m);\n\n\treturn 0;\n}\n```\n\n两个指针，对于不同的赋值方式含义也是不同的。\n\n`p = m` 是指针赋值，即 指针变量p 原来指向变量 num1的地址，现在和 指针变量m 一起指向 变量 num2。\n\n![指针2.png](/images/2024/09/09/94b21eb0-6eb2-11ef-9a3d-f9a0fb494c06.png)\n\n`*p = *m` 是把 m 指向的值（num2 的值）复制到 p 指向的对象（变量num1）中。\n\n![指针3.png](/images/2024/09/09/90731570-6eb2-11ef-9a3d-f9a0fb494c06.png)\n\n至此，我们可以说改变 变量的值有两种方式，一个是修改所指向的对象，一个是修改所指向的对象存储的值。切记弄清楚两种赋值方式的区别。","tags":["C"],"categories":["technology"]},{"title":"二级指针和函数指针","url":"/2024/09/09/二级指针和函数指针/","content":"\n<!-- toc -->\n\n\\* 可以作为定义指针时的形式说明符和取出指针变量保存的地址所指向的内存单元的值。我们可以通过 \\* 结合地址的方式来访问内存单元中的数据并存入数据；而＆是取地址运算符，通过它得到变量的地址。\n\n## 二级指针\n\n```c\nint num = 10;\n\nint* p = &num;\t// 一级指针\n\nint** m = &p;\t// 二级指针\n```\n\n指向关系如下：\n\n![二级指针3.png](/images/2024/09/09/050aedc0-6eab-11ef-a00b-73f543e7dc50.png)\n\n图中 m 是指针变量，类型为 int\\*\\*，用以指向一级指针，即存储一级指针的地址。p 是指针变量，类型为 int\\*，用以指向变量，即存储变量的地址。num 是变量，类型为 int，用以存储实际数据，即实际数据的地址。\n\n指针变量 m 存储的是 指针变量 p 的地址，指针变量 p 存储的是 变量 num 的地址，变量 num 存储的数据 10。\n\n![二级指针2.png](/images/2024/09/09/0a80c950-6eab-11ef-a00b-73f543e7dc50.png)\n\n那么二级指针作为参数传递的时候，究竟应该传一级指针，还是传二级指针呢？\n\n在回答这个问题之前，可以回顾之前的一级指针，即如何让 swap 函数的两个形参实际交换数据。\n\n```c\nvoid Swap1(int a, int b) {\t// 交换失败\n\tint tmp = a;\n\ta = b;\n\tb = tmp;\n}\n\nvoid Swap2(int *a, int *b) {\t// 交换成功\n\tint tmp = *a;\n\t*a = *b;\n\t*b = tmp;\n}\n\nint main(void) {\n\n\tint a = 10;\n\tint b = 20;\n\tSwap1(a, b);\n\tprintf(\"a = %d , b = %d\\n\", a, b);\n\n\tint* p = &a;\n\tint* m = &b;\n\tSwap2(p, m);\n\tprintf(\"a = %d , b = %d\\n\", a, b);\n\n\treturn 0;\n}\n```\n\n如果你传递变量的值或 const 指针，那么你不会交换成功。如果你传递变量的地址，那么你会交换成功。\n\n那我们就以链表的头插法来举例，先看看错误示范：\n\n```c\nNode* add_before(Node* head, Node* tail, int val)\n{\n\tNode* new_node = malloc(sizeof(Node));\n\tif (!new_node) {\n\t\tperror(\"malloc failed\\n\");\n\t\texit(-1);\n\t}\n\tnew_node->data = val;\n\tnew_node->next = head;\n\n\thead = new_node;  // 这只会修改函数内部的局部副本，而不会影响外部的 head\n\n\tif (tail == NULL) {\n\t\ttail = new_node;  // 这也只会修改函数内部的局部副本\n\t}\n\n\treturn new_node;\n}\n```\n\n我们在函数外部传递 链表 head 进来，函数形参这边也是以一级指针接收这个链表，那么我们传递的是这个链表的副本。所以，如果我们需要成功更改这个链表的话，那就需要传递这个链表的地址，即在传递参数到函数中时，需要对该链表进行取地址，即 &head。那么我们函数的形参如果要接受这个参数，就得是 **head 才能接收这个链表的内存地址。\n\n```c\nvoid add_before_head(Node** phead, Node** ptail, int val)\n{\n\t// 创建一个 Node 节点\n\tNode* new_node = malloc(sizeof(Node));\n\tif (!new_node) {\n\t\tperror(\"malloc failed\\n\");\n\t\texit(-1);\n\t}\n\tnew_node->data = val;\n\tnew_node->next = *phead;\n\t*phead = new_node;\n\n\tif (*ptail == NULL) {\n\t\t*ptail = new_node;\n\t}\n}\n```\n\n千言万语，不抵一张图：\n\n![二级指针4.png](/images/2024/09/09/15e3fa60-6eab-11ef-a00b-73f543e7dc50.png)\n\n为了更清楚地解释：\n\n- 当你传递 `Node* head`，你实际上传递的是指向链表第一个节点的指针的副本。这意味着在函数内部修改 `head`，只是修改了这份副本的值，而不会修改调用函数时传入的 `head` 的值。\n- 你确实可以遍历链表，因为传入的 `head` 指针指向的是链表的第一个节点，它仍然指向链表结构。但是，**当你试图修改 `head` 本身时**，例如将它指向新的节点时，这些修改只会作用在副本上，无法反映到原来的链表头指针。\n\n你传递进去的是链表头结点的指针，也就是 `head` 和 `tail`，它们确实是指向链表头部和尾部的指针。但是，C 语言中的函数参数是**按值传递**的，也就是说你传递的是 `head` 和 `tail` 的**副本**。在函数内部修改这些副本，并不会影响到原来的指针。\n\n```c\nvoid test(Node* head) {\n    head = malloc(sizeof(Node)); // 这里的 head 是一个局部变量的副本\n    head->data = 42;\n}\n\nint main() {\n    Node* head = NULL;\n    test(head); // 调用函数后，head 仍然是 NULL\n    // head 仍然没有指向新的节点\n}\n```\n\n在上面的例子中，`head` 被传递给 `test` 函数，但是 `test` 内部的修改不会影响 `main` 函数中的 `head`，因为传递的只是一个副本。\n\n那我们继续回到之前的话题。head 指针变量 指向 Node1节点内存区域，现在新节点 new_node 已经头插成功，就需要让 head 能够再次成为头结点（之前是，现在已经不是的缘故）。\n\nhead 指向的是 Node1，可以对这个节点进行数据修改，指向其他节点，但唯独不可以更改自己的内存地址。就以下面这个例子说明。num1 和 num2 是相同类型，可以进行赋值，但这个修改的是 num1 的值，但不是 num1 的内存地址。也就是说 num1 代表的内存地址存储的数据已经被修改，但是 num1 这个变量的地址本身是没有被改变的。\n\n```c\nint num1 = 10;\nint num2 = 20;\n\nnum1 = num2;\n```\n\n我们知道改变 变量的值有两种方式，一个是修改对应内存地址的数据，一个是修改所指向的对象。当前这个变量的地址需要通过 & 来获取，而存储这个结果的只能是一级指针。那我们的链表本身就是多个节点连接的，通过一个头结点就能找到所有连接的节点。头节点本身就是一个指针，即一级指针。如果我们想要修改这个指针的数据，传递一级指针即可，就是它变量本身。如果我们想要修改这个指针指向的地址，就得获取它本身的内存地址，即对其进行取地址运算，然后把新对象的地址赋值给它，实现更改所指对象了。\n\n```c\nvoid test(Node* head) {\t// 修改节点的数据，传递一级指针就够了\n\twhile (head != NULL) {\n\t\thead->data = 2 * head->data;\n\t\thead = head->next;\n\t}\n}\n```\n\n如何修改？那就是修改 head 指针变量指向的地址，即让 head 原本指向 Node1（0x001） 现在指向 new_node（0x000）。也就是要拿到 head 指针变量本身的地址，phead 就是记录着 head 指针变量本身的地址，通过 *phead = new_node 就修改成功了。\n\n![二级指针5.png](/images/2024/09/09/22c0ac10-6eab-11ef-a00b-73f543e7dc50.png)\n\n## 函数指针\n\n函数指针常见的应用是回调函数，它只支持两个操作：\n\n- 解引用`*`\n- 函数调用`()`\n\n```c++\nreturn_type (*pointer_name)(parameter_list);\n```\n\n- return_type：函数返回类型\n- pointer_name：函数指针的名字\n- parameter_list：函数的参数列表\n\n比方说：`int (*func) (int, int)`，函数指针的名称为 func，返回值类型为 int，形参为两个 int 类型变量。\n\n```c++\n#include <stdio.h> \n\n// 定义一个函数指针 'func'，该指针指向一个接受两个 int 参数并返回 int 的函数\nint (*func) (int, int);\n\n// 定义一个函数 'add'，接受两个 int 参数，返回它们的和\nint add(int n1, int n2) {\n    return n1 + n2;\n}\n\nint main(void) {\n    // 将函数指针 'func' 指向函数 'add'\n    func = add;  \n\n    // 使用函数指针 'func' 调用函数 'add'，传入参数 1 和 2\n    int num = func(1, 2);\n\n    printf(\"num = %d\\n\", num);\n\n    return 0;  \n}\n```\n\n函数指针必须和接受的函数有相同的形参个数和对应的类型，以及相同的返回值类型。\n\n我们也可以不用声明函数指针再去指向函数，可以直接定义，见下：\n\n```c++\nint (*func) (int, int) = add;\n\nint num = func(1, 2);\n```","tags":["C"],"categories":["technology"]},{"title":"98.验证二叉搜索树","url":"/2024/09/09/98-验证二叉搜索树/","content":"\n```c++\nclass Solution {\nprivate:\n    vector<int> data;\npublic:\n    // 中序遍历保证有序\n    void collect_num(TreeNode* root){\n        if(!root) return;\n        collect_num(root->left);\n        data.push_back(root->val);\n        collect_num(root->right);\n    }\n    bool isValidBST(TreeNode* root) {\n        collect_num(root);\n        for(int i = 1; i < data.size(); i++){\n            if(data[i] <= data[i - 1]){\n                return false;\n            }\n        }\n        return true;\n    }\n};\n```\n\n中序遍历二叉搜索树得到递增的有序数据，将得到的数据前后对比，若前后两个数据有不符和递增的就代表不是二叉搜索树，否则就是二叉搜索树。","tags":["树"],"categories":["leetcode"]},{"title":"第三章：粘包和反序列化","url":"/2024/09/08/第三章：粘包和反序列化/","content":"\n<!-- toc -->\n\n在上一章中，但我们编写基于官方代码的 全双工通信，发现由于 Session 管理不当，导致多次析构。我们要解决 Session 的生命周期问题，以及网络传输必然存在的粘包问题。\n\n## 伪闭包延长连接生命周期\n\n### Server类\n\n我们可以通过 [shared_ptr 智能指针](https://xiaoyangst.github.io/2024/08/16/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/)对这些 Session 进行管理，shared_ptr 智能指针管理的对象会在引用技术为 0 的时候自动析构。\n\n那用什么来存储这些 Session 呢？unordered_map容器，key 为 Session 的 uuid，value 为该 Session 的智能指针。由于存储到 unordered_map 容器中的对象是拷贝一份进来的，那么引用计数会 加 1，至少可以保证说如果我们不在容器中移除 这些存储的 Session，就能保证它必然不会被析构。\n\n```c++\nunordered_map<std::string, std::shared_ptr<Session>> sessionMap_;\n```\n\n管理 Session 的是 Server 类，因此 sessionMap_ 定义在  Server 类中。所以只涉及让 Session 在适当的地方增加和删除操作。\n\n```c++\nvoid Server::ClearSession(const std::string& uuid)\n{\n\tsessionMap_.erase(uuid);\n}\n\nvoid Server::start_accept()\n{\n\tstd::shared_ptr<Session> new_session = std::make_shared<Session>(ioc_,this);\n\tacceptor_.async_accept(new_session->Socket(),\n\t\tstd::bind(&Server::handle_accept, this, new_session, std::placeholders::_1));\n}\n\nvoid Server::handle_accept(std::shared_ptr<Session> new_session, const boost::system::error_code& error)\n{\n\tif (!error) {\n\tnew_session->Start();\t\t\n\tsessionMap_.insert(std::make_pair(new_session->getUUID(), new_session));\t// 代表有新连接建立，所以触发此回调了\n\tstart_accept();\n\t}\n}\n```\n\n这里我们重点分析 new_session 对象的引用计数情况。start_accept 函数 中第一次创建 共享智能指针对象 new_session，引用计数加 1，即从 0 变为 1。调用 acceptor_ 对象的 async_accept 方法需要 bind 一个回调函数，该回调函数需要用到 new_session 对象，但我们知道 bind 是通过拷贝值来满足函数调用的参数需求的，这个时候 共享智能指针对象 new_session，引用计数加 1，即从 1 变为 2。\n\n触发回调之后，进入 handle_accept 函数，这也意味着 start_accept 函数 执行完毕，那么一开始创建的 new_session 脱离作用域，引用计数减 1，即从 2 变为 1。由于 bind 绑定的 handle_accept 函数还没有执行完毕，所以不会修改引用计数。那么开始 执行 handle_accept 函数，把 共享智能指针对象 new_session 加入到 map 容器中，也是把 对象拷贝到容器中，引用计数加 1，即从 1 变为 2。等到 handle_accept 函数执行完成，那么 bind 绑定所需的 new_session 也就 离开其作用域了，引用计数减 1，即从 2 变为 1。所以 最后的 这个为 1 的引用计数是 map 容器中还保留着 new_session 对象。\n\n### Session类\n\n如果我们从 map 容器中移除 new_session 对象，这就是 new_session 对象的消亡时刻。那我们的 读写回调函数在如果继续前一章的测试条件还是会出错，因为读事件回调如果从 map 容器中移除 new_session 对象，写事件回调在有错误的情况下同样会 再次从 map 容器中移除 new_session 对象，这也是不正确的做法。因为 从 map 中移除对象，会调用对应的回调函数，还是会双重析构。\n\n其实，我们需要保证的是，读写事件在执行的时候能够保证 new_session 对象 是可用的，这样就不出现重复删除同一个对象了。在类中使用 shared_ptr 智能指针要注意一个问题，避免通过 this 指针 创建 shared_ptr 对象，因为并不会返回 shared_ptr 对象，而是返回到裸指针。如果真要能够返回 当前类的 shared_ptr 对象，需要让当前类继承 enable_shared_from_this，然后调用 shared_from_this 函数即可。\n\n我们给 handle_read 和 handle_write 函数就会得到 new_session 对象，并让 引用计数 加 1，就保证 读写事件在执行的时候能够保证 new_session 对象 是可用的。\n\n《恋恋风尘》博主是如下第一种写法，我是采用的第二种写法：\n\n```c++\nsocket_.async_read_some(boost::asio::buffer(data_, BUFFSIZE),\t// 接收客户端发生来的数据\n\t\tstd::bind(&Session::handle_read, this, std::placeholders::_1, std::placeholders::_2, shared_from_this()));\n\nsocket_.async_read_some(boost::asio::buffer(data_, BUFFSIZE),\n        std::bind(&Session::handle_read, shared_from_this(), std::placeholders::_1, std::placeholders::_2));\n```\n\n询问ChatGpt结果：\n\n- **第一种方式**：`this` 是裸指针，可能会导致生命周期问题，虽然 `shared_from_this()` 提供了一定的保护，但 `this` 依然存在风险。\n- **第二种方式**：完全使用 `shared_ptr<Session>` 来管理生命周期，更加安全。\n\n通常，**第二种方式**更推荐使用，因为它可以确保在异步操作完成之前，`Session` 对象的生命周期得到完全管理，避免使用裸指针的潜在风险。\n\n### 代码实现和结果验证\n\n代码地址：[保证读写事件连接的可用性](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/4-%E4%BF%9D%E8%AF%81%E8%AF%BB%E5%86%99%E4%BA%8B%E4%BB%B6%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%AF%E7%94%A8%E6%80%A7)\n\n![实现连接存活.png](/images/2024/09/08/674145c0-6dd4-11ef-85cc-4768e704f183.png)\n\n采用之前同样的断点进行测试，图中只进行一次析构，说明连接保活成功。\n\n## 增加发送队列实现全双工通信\n\n解决多次析构的问题，就要进入到消息发送的问题上来了。实际的网络服务器那都是全双工，即读写事件同时监听。我们需要实现一个 Buffer 结构（这里实现的MsgNode类），用于读和写事件数据的存储，把未发送完的数据保存到队列中，保证消息的有序性。同时还要重写之前的读写回调函数。\n\n### 实现全双工的读写回调流程\n\n```c++\nvoid Session::handle_write(const boost::system::error_code& error)\n{\n\tstd::cout << \"触发 write event\" << std::endl;\n\n\tif (error) {\n\t\tstd::cout << \"handle_write error = \" << error << std::endl;\n\t\tserver_->ClearSession(uuid_);\n\t\treturn;\n\t}\n\tstd::lock_guard<std::mutex> send_lock(mtx_);\n\tif (!sendQue_.empty()) {\n\t\tauto& msgNode = sendQue_.front();\n\t\tboost::asio::async_write(socket_, boost::asio::buffer(msgNode->data_, msgNode->max_len_),\n\t\t\tstd::bind(&Session::handle_write, shared_from_this(), std::placeholders::_1));\n\t\tsendQue_.pop();\n\t}\n}\n\nvoid Session::Send(char* msg, int max_len)\n{\n\tbool pending = false;\n\t// 加锁\n\tstd::lock_guard<std::mutex> send_lock(mtx_);\n\tif (!sendQue_.empty()) {\t\n\t\tpending = true;\n\t}\n\tsendQue_.push(std::make_shared<MsgNode>(msg, max_len));\n\tif (pending) {\t\n\t\treturn;\n\t}\n\n\tsocket_.async_write_some(boost::asio::buffer(msg,max_len),\t\n\t\tstd::bind(&Session::handle_write, shared_from_this(), std::placeholders::_1));\n}\n```\n\n增加的这个队列是发送队列。当客户端第一次发送数据，触发这边的读回调，该回调内部就会调用 Send 函数。在 Send 函数中，对数据进行操作需要加锁，异步编程中，你不知道会被哪个线程再次调用 Send 接口。如果 发送队列 sendQue_ 不为空，代表 handle_write 内部已经再次监听写事件，这边就只需要把数据加入到发生队列中即可。如果发送队列 sendQue_ 为空，代表当前 socket 没有再监听写事件，那么我们需要再次 监听写事件。通过这样的方式，就可以一直保证监听写事件，不管队列中有没有数据。\n\n我们的 handle_read 函数 接受客户端数据之后，就继续监听读事件了。\n\n至此，该服务器虽然实现了全双工通信，但是仍存在缺陷，比如粘包问题未处理。\n\n### 代码实现和粘包现象\n\n代码地址：[添加发生消息队列保证消息处理的有序性](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/5-%E6%B7%BB%E5%8A%A0%E5%8F%91%E7%94%9F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E5%A4%84%E7%90%86%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7)\n\n我们只需要把客户端修改为 循环发送 数据就可以见证粘包现象。记得不要写成客户端发一个消息，然后接一个消息，这会让服务器很快就处理数据，看不到粘包现象了。\n\n![粘包.png](/images/2024/09/08/6d16a670-6dd4-11ef-85cc-4768e704f183.png)\n\n## 处理网络粘包问题\n\n网络粘包问题可见我的另一篇文章[记住：TCP 是一种流协议](https://xiaoyangst.github.io/2024/08/10/%E8%AE%B0%E4%BD%8F%EF%BC%9ATCP%E6%98%AF%E4%B8%80%E7%A7%8D%E6%B5%81%E5%8D%8F%E8%AE%AE/)。\n\n### Session类\n\n说明：红色数据代表已发送，灰色数据代表未发送\n\n![粘包情况分析.png](/images/2024/09/08/72528640-6dd4-11ef-85cc-4768e704f183.png)\n\n- 如果头部记录的长度大于数据长度，意味着本次接受的消息不完整，还有一部分数据在下一个数据包中\n- 如果头部记录的长度小于数据长度，意味着本次接受的消息包含上一个数据包未完整接受到的数据和其他数据\n- 如果头部记录的长度等于数据长度，意味着解析完成或者刚好没有粘包，直接接受即可\n- 头部记录的长度非法，头部记录的长度远远超出我们规定的可接受数据包的最大长度，这种视为非法的带有攻击性的数据包，直接丢弃即可\n\n由于我们调用的异步函数 async_read_some，对方只要有发送数据就会触发回调函数，那我们就得写复杂的拆包逻辑。消息不完整的，需要等待下次数据包到来切割出剩余的数据，拼凑出完整的数据。消息超出头部记录的长度，需要把多余的部分切割出来给到上一次的数据包，然后继续处理余下的数据包。其余两种情况就不难处理了。不管怎么样，我们要记录很多的信息，消息处理到哪个位置了？上次的消息有没有处理完？诸如此类的考量，以至于《恋恋风辰》写出[如此复杂的代码](https://llfc.club/category?catid=225RaiVNI8pFDD5L4m807g7ZwmF#!aid/2PSqYnkrogKeDPjv3gdBUAcbN5P)，实在看不下去了。其实，就算我们按照这种情况去处理，也可以写出比这个还看起来轻松的代码，但我们还是直接利用 async_receive 异步回调函数 满足指定长度才触发回到的机制来实现吧。\n\n### 代码实现和解决粘包\n\n代码地址：[处理网络粘包问题](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/6-%E5%A4%84%E7%90%86%E7%BD%91%E7%BB%9C%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98)\n\n![服务器解决粘包问题.png](/images/2024/09/08/7968cb60-6dd4-11ef-85cc-4768e704f183.png)\n\n客户端的代码要修改，即发生消息按照 数据头+数据 的格式发送过来。我这边只是测试服务器的是否解决粘包，所以依旧是客户端大量发送消息。\n\n## 字节序处理和消息队列的控制\n\n字节序问题可以看我此文的介绍：[主机字节序和网络字节序](https://xiaoyangst.github.io/2024/08/10/%E4%B8%BB%E6%9C%BA%E5%AD%97%E8%8A%82%E5%BA%8F%E5%92%8C%E7%BD%91%E7%BB%9C%E5%AD%97%E8%8A%82%E5%BA%8F/)\n\n网络字节序是大端字节序，而主机字节序可能是大端（如某些RISC处理器）或小端（如x86/x86_64处理器）。为了保证不同系统间的数据兼容性，需要在网络数据交换时进行字节序转换。\n\n当你发送或接收的数据中包含整数（如IP地址、端口号等），需要进行字节序转换。例如，TCP/IP协议中有很多字段需要进行字节序转换：\n\n- **端口号**（如`htons`和`ntohs`）：网络中使用的端口号在发送之前需要转换为网络字节序，接收后需要转换为主机字节序。\n- **IP地址**（如`htonl`和`ntohl`）：IP地址通常以32位的整数形式传输，发送前转换为网络字节序，接收后转换为主机字节序。\n\n我们知道网络传输数据务必保证字节序相同，即采用网络字节序，因此看看 asio 提供什么接口给我们使用了。\n\n```c++\n// 将一个 32 位无符号整数从主机字节序转换为网络字节序，返回转换后的结果\nboost::asio::detail::socket_ops::host_to_network_long()\n\n // 将一个 16 位无符号整数从主机字节序转换为网络字节序，返回转换后的结果\nboost::asio::detail::socket_ops::host_to_network_short()\n```\n\n需要注意的是，在使用这些函数时，应该确保输入参数和返回结果都是无符号整数类型，否则可能会出现错误。同样的道理，我们只需要在服务器发送数据时，将数据长度转化为网络字节序，在接收数据时，将长度转为本机字节序即可。客户端也要遵循相同的规则。\n\n```c++\nboost::asio::detail::socket_ops::network_to_host_short()\n\nboost::asio::detail::socket_ops::network_to_host_long()\n```\n\n**发生数据时，把本地字节序转换为网络字节序。接受数据时，把网络字节序转换为本地字节序。**客户端和服务端都要遵守。下面只截取一部分代码作为演示：\n\n```c++\n// 服务器端代码\nvoid Session::handle_read(const boost::system::error_code& error, size_t bytes_transfered)\n{\n\tif (error) {\n\t\tstd::cout << \"handle_read error = \" << error.message() << std::endl;\n\t\tClose();\n\t\tserver_->ClearSession(uuid_);\n\t\treturn;\n\t}\n\n\tint data_len = 0;\n\tmemcpy(&data_len, recv_head_node_->data_, HEAD_LENGTH);\n\tstd::cout << \" data length = \" << data_len << std::endl;\n\n\tif (data_len > MAX_LENGTH) {\t// 非法\n\t\tstd::cout << \"invalid data length is \" << data_len << std::endl;\n\t\tserver_->ClearSession(uuid_);\n\t\treturn;\n\t}\n\t\n       //网络字节序转化为本地字节序\n\tdata_len = boost::asio::detail::socket_ops::network_to_host_short(data_len);\n\n\trecv_msg_node_ = std::make_shared<MsgNode>(data_len);\n\tsocket_.async_receive(boost::asio::buffer(recv_msg_node_->data_, data_len),\t// 读完 HEAD_LENGTH 字节才触发读回调\n\t\tstd::bind(&Session::HandleReadMsg, shared_from_this(), std::placeholders::_1, std::placeholders::_2));\n\n}\n\n// 客户端代码\nvoid send_thread(tcp::socket& sock) {\n    for (;;) {\n        this_thread::sleep_for(std::chrono::milliseconds(2));\n        const char* request = \"hello world!\";\n        // 本地字节序转换为网络字节序\n        short request_length = boost::asio::detail::socket_ops::host_to_network_short(strlen(request));\n        \n        char send_data[MAX_LENGTH] = { 0 };\n        memcpy(send_data, &request_length, HEAD_LENGTH);\n        memcpy(send_data + HEAD_LENGTH, request, request_length);\n\n        std::lock_guard<std::mutex> lock(mtx);\n        boost::asio::write(sock, boost::asio::buffer(send_data, request_length + HEAD_LENGTH));\n    }\n}\n```\n\n我在实际测试的时候，发现 asio 这几个库函数出现问题，导致我的客户端发送数据失败。建议还是用 我博客介绍的 htons 和 ntohs 来进行转换吧。\n\n还有就是我们的发送队列要有限制，不然无限添加也不合理。\n\n```c++\nvoid Session::Send(char* msg, int max_len)\n{\n\tbool pending = false;\n\tstd::lock_guard<std::mutex> send_lock(mtx_);\n\tif (!sendQue_.empty()) {\t\n\t\tpending = true;\n\t}\n\tif (sendQue_.size() > MAX_SENDQUE) {\t// 超过队列限制大小，直接丢弃\n\t\tstd::cout << \"uuid = \"<< uuid_ << \"Exceeding the maximum capacity of the SendQue\" << std::endl;\n\t\treturn;\n\t}\n\tsendQue_.push(std::make_shared<MsgNode>(msg, max_len));\n\tif (pending) {\t\n\t\treturn;\n\t}\n\n\tsocket_.async_write_some(boost::asio::buffer(msg,max_len),\t\n\t\tstd::bind(&Session::handle_write, shared_from_this(), std::placeholders::_1));\n}\n```\n\n代码地址：[字节序处理和消息队列控制](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/7-%E5%AD%97%E8%8A%82%E5%BA%8F%E5%A4%84%E7%90%86%E5%92%8C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%8E%A7%E5%88%B6)\n\n## 序列化\n\n常见的序列化方式是通过 Json 或 Protobuf 来完成，这里就以 json这种格式简单看看 在网络库中的应用。你可以理解为就是把传递的消息进行打包，那么对方在接收到这份数据之后，能够根据一定的规则得到数据中存储的有效值（毕竟 key 是用来查找 value，实际我们关心的就是 value）。\n\n![序列化和反序列化.png](/images/2024/09/08/84628c40-6dd4-11ef-85cc-4768e704f183.png)\n\n如果你要发送的数据是有联系的，你不进行反序列化话就要多次发生数据。如果进行反序列化就可以打包在一起发过去，只需要发生一次数据，然后对端序列化之后通过 key 来读取实际要获取的数据就可以了。序列化只是把数据打包，因此依旧要通过 数据头部+数据长度解决粘包问题。序列化和反序列化可以规范数据的传输格式，但并不能解决**粘包**或**拆包**问题。**粘包问题**主要是由于TCP流式传输的特性引起的，而不是数据的编码方式。\n\n序列化可以规范和压缩数据结构，但为了避免粘包，常结合**消息头+消息体**的方式进行序列化。比如，你可以先序列化数据，将其打包成字节流，再在字节流前加上长度信息，接收方根据长度信息判断数据是否完整，然后再反序列化还原数据。\n\n客户端把要发生的数据序列化：\n\n```c++\n    Json::Value root;\n    root[\"id\"] = 1001;\n    root[\"data\"] = \"hello world\";\n    std::string request = root.toStyledString();\n    size_t request_length = request.length();\n    char send_data[MAX_LENGTH] = { 0 };\n    int request_host_length = htons(request_length);\n    memcpy(send_data, &request_host_length, 2);\n    memcpy(send_data + 2, request.c_str(), request_length);\n    boost::asio::write(sock, boost::asio::buffer(send_data, request_length + 2));\n```\n\n客户端收到数据之后，进行反序列化：\n\n```c++\n    Json::Reader reader;\n    Json::Value root;\n    reader.parse(std::string(_recv_msg_node->_data, _recv_msg_node->_total_len), root);\n    std::cout << \"recevie msg id  is \" << root[\"id\"].asInt() << \" msg data is \"\n    << root[\"data\"].asString() << endl;\n```\n---\n\n⭐️内容取自 B 站 UP 恋恋风辰和 mmoaay 的《Boost.Asio C++ 网络编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议看原视频或者读原书。","tags":["网络编程","Asio"],"categories":["technology"]},{"title":"第二章：同步和异步","url":"/2024/09/07/第二章：同步和异步/","content":"\n<!-- toc -->\n\n## 同步\n\n### 同步写\n\nwrite_some 可以每次向指定的空间写入固定的字节数，如果写缓冲区满了，就只写一部分，返回写入的字节数。但是使用起来比较麻烦，需要多次调用，就不多介绍了。重点讲一讲 send 和 write。\n\n（一）send\n\nsend函数会一次性将buffer中的内容发送给对端，如果有部分字节因为发送缓冲区满无法发送，则阻塞等待，直到发送缓冲区可用，则继续发送完成。\n\n```c++\n // 连接到服务器，后续就可以通过 socket 进行通信\n\n// 通过 send 发送数据，传递数据和数据的长度即可\n\ntry {\n    std::string buf = \"My name is ClientA\";\n    int send_length = sock.send(buffer(buf.c_str(), buf.length()));\n    if (send_length != buf.length())\n    {\n        cout << \"Warning: Not all data sent, only \" << send_length << \" bytes sent.\" << endl;\n    }\n} catch (const boost::system::system_error& e) {\n    cout << \"Exception during send: \" << e.what() << endl;\n}\n```\n\n（二）write\n\nasio 还提供了一个 write 函数，可以一次性将所有数据发送给对端，如果发送缓冲区满了则阻塞，直到发送缓冲区可用，将数据发送完成。这个和 send 非常类似，只是调用方式有所不同。\n\n```c++\nint send_length = write(sock,buffer(buf.c_str(), buf.length()));\n```\n\n### 同步读\n\nread_some 就和 前面不介绍的 write_some 一样，需要循环去读取，同样不做介绍。重点讲一讲receive 和 read。\n\n（一）receive\n\n可以一次性同步接收对方发送的数据。\n\n```c++\n// 连接到服务器，后续就可以通信了\n\n// 通过 receive 发送数据，记得把 char 数组 转换成 asio 自己的 buffer 类型\n\nconst size_t BUFF_SIZE = 7;\nchar buffer_receive[BUFF_SIZE + 1]; // +1 用于字符串终止符\n\ntry {\n    int recv_length = sock.receive(asio::buffer(buffer_receive, BUFF_SIZE));\n    if (recv_length > 0) {\n        buffer_receive[recv_length] = '\\0'; // 确保字符串终止\n        cout << \"Received: \" << buffer_receive << endl;\n    } else {\n        cout << \"recv failed!!!\" << endl;\n    }\n} catch (const boost::system::system_error& e) {\n    cout << \"Exception during receive: \" << e.what() << endl;\n}\n```\n\n（二）read\n\n```c++\n int recv_length = read(sock,asio::buffer(buffer_receive,BUFF_SIZE));\n```\n\n### 读取直到指定字符\n\n我们可以一直读取，直到读取指定字符结束\n\n```c++\nstd::string  read_data_by_until(asio::ip::tcp::socket& sock) {\n    asio::streambuf buf;\n    asio::read_until(sock, buf, '\\n');\n    std::string message;\n    std::istream input_stream(&buf);\n    std::getline(input_stream, message);\n    return message;\n }\n```\n\n## 基于同步读写 API 实现 CS 互相通信\n\n代码地址：[Asio同步CS通信](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/1-Asio%E5%90%8C%E6%AD%A5CS%E9%80%9A%E4%BF%A1)\n\n![同步通信.png](/images/2024/09/07/72b475e0-6ce3-11ef-a06d-3139b1d9613b.png)\n\n## 异步\n\n### 异步写\n\n```c++\nasync_write_some(buffer, handler);\n\nasync_send(buffer, handler);\n```\n\nasync_write_some 函数不能保证每次回调函数触发时发送的长度为总长度，这样我们每次都要在回调函数判断发送数据是否完成。asio 提供了一个更简单的发送函数 async_send，这个函数在发送的长度未达到我们要求的长度时就不会触发回调，所以触发回调函数时要么时发送出错了要么是发送完成了,其内部的实现原理就像不断的调用 async_write_some 直到完成发送，所以 async_send 不能和 async_write_some 混合使用。\n\n### 异步读\n\n```c++\nasync_read_some(buffer,handler);\n\nasync_receive(buffer, handler);\n```\n\n接下来介绍异步读操作，异步读操作和异步的写操作类似同样有 async_read_some 和 async_receive函数，前者触发的回调函数获取的读数据的长度可能会小于要求读取的总长度，后者触发的回调函数读取的数据长度等于读取的总长度。同样 async_read_some 和 async_receive 不能混合使用，否则会出现逻辑问题。\n\n## 基于异步读写 API 实现 CS 互相通信\n\n同步的网络通信方式是在不可能用于高性能服务器的开发，因此前面只是简单的实现客户端和服务器端通信，用以对前面网络通信基本API以及同步发生消息和接收消息API的应用。只不过，接下来要讲的异步通信就相当重要了，后续所有的讨论都是建立在异步通信的基础上，也将伴随着整个教程的终结，可见意义非凡。\n\n下面要实现的是官方的案例，即Echo服务器。尽管它存在隐患，这个问题也会提及的。\n\n代码地址：[Asio异步CS通信](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/2-Asio%E5%BC%82%E6%AD%A5CS%E9%80%9A%E4%BF%A1)\n\n![异步通信.png](/images/2024/09/07/6944fe80-6ce3-11ef-a06d-3139b1d9613b.png)\n\n客户端发送消息和接受消息之后就会断开连接，因此服务器那边会触发读事件并且提示客户端已经关闭连接。\n\n代码地址：[证实官方代码存在安全隐患](https://github.com/xiaoyangst/Code/tree/master/Asio%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/3-%E8%AF%81%E5%AE%9E%E5%AE%98%E6%96%B9%E4%BB%A3%E7%A0%81%E5%AD%98%E5%9C%A8%E5%AE%89%E5%85%A8%E9%9A%90%E6%82%A3)\n\n![两次析构.png](/images/2024/09/07/660b0930-6ce3-11ef-a06d-3139b1d9613b.png)\n\n特意修改客户端代码，即发生一个消息给服务器，接收服务器的一个消息，再次发生一个消息给服务器。再次发生消息是复现问题的关键，它会触发服务器的读事件，从而保证触发服务器的写事件。这个时候我们需要下断点保证先触发服务器的读事件异常去 delete  Seesion 对象，即断开连接。既然 Seesion 对象已经被 delete 一次了，那么由于客户端发来的消息服务器准备要去回复，但是发现出现异常，导致再次 delete  Seesion 对象。\n\n![断点复现.png](/images/2024/09/07/60fa3100-6ce3-11ef-a06d-3139b1d9613b.png)\n\n### 存在隐患的代码解读\n\n（一）Session类\n\n 一个会话 Session 对应一个 Socket，而一个 Socket 无外乎处理两个关键的事件，即读写事件。在代码中分别对应两个回调函数 handle_read 和 handle_write。\n\n我们的目的暂时还很简单，只是实现客户端和服务端的文本通信。如果客户端发来消息，触发异步读函数 async_read_some 绑定的 handle_read ，读取数据之后，就给异步发生消息函数 async_write_some 绑定回调函数 handle_write，即回复客户端发送的消息回复给客户端。回复消息之后，就会给 async_read_some 绑定回调函数 handle_read，从而返回接收和读取客户端消息了。\n\n![异步通信流程.png](/images/2024/09/07/5cd2ce70-6ce3-11ef-a06d-3139b1d9613b.png)\n\n当你调用 Start 接口之后，当前 Session 就开始异步等待 读事件的到来，然后层层 函数的调用形成一个 环，即图中的 2-3-4 步骤。这个环的功能就是先监听客户端的读事件，即先读取客户端发来的消息。然后调用异步发送函数，把同样的消息回复给客户端。回复消息给客户端之后，继续监听客户端的读事件。\n\n至此，我们就完成 Echo 服务器，但是我们这个服务器不是全双工的，即读和写没有分离（这就是为什么说官方案例是隐患，如果你设计成全双工就有问题，但如果不是就没有影响）。按理实际开发中应该是全双工通信，即可以同时收发消息，但是我们的这个官方案例，如果采用全双工通信就会出现多次析构问题（两次），具体原因分析可看[官方案例的隐患](https://llfc.club/category?catid=225RaiVNI8pFDD5L4m807g7ZwmF#!aid/2ODYV1A2xbhTjWr0FJ1ZS22ijZO)。\n\n（二）Server类\n\nServer 类就是用来监听客户端连接，并为其创建一个 Session 的。\n\n所以当你创建 Server 对象之后，构造函数中会调用 start_accept 函数，该函数内部就会创建一个 Session ，并调用 异步函数 async_accept，该函数绑定的回调函数是 handle_accept。如果有客户端连接，那么就会 调用 Session 的 Start 函数（前面已经介绍过），同时继续调用 start_accept 函数。处理完一个连接，继续监听新的连接到来。\n\n### 证实隐患的代码解读\n\n将原先的 Session 代码进行简单的修改，让 一个 socket 同时监听读写事件，不像之前监听读事件和监听写事件不是同时存在的。让一个 socket 同时监听读写事件存在的隐患就是，对方关闭连接触发读事件回调，进而删除 Session 对象，那么写事件早之前被客户端触发（但还没有实际把数据发过去），就会出现异常，进而再次删除 Session 对象，出现多次析构，这个问题是很严重的。\n\n表明上看这已经不是官方的代码，已经做了修改，但是官方提供的代码如果结合实际开发就会出现问题，即读写分离的通信方式。这也是为什么说为隐患的原因，即便是现在证实隐患存在的那份代码，直接运行也不一定会出现问题，但如果大量客户端连接和大量收发消息，必然会在某一刻出现问题，因为这是异步编程，读事件和写事件的触发不是有顺序的。\n\n至此，我们引出如何对 Session 对象的正确管理了。","tags":["网络编程","Asio"],"categories":["technology"]},{"title":"90.子集II","url":"/2024/09/07/90-子集II/","content":"\n```c++\nclass Solution {\nprivate:\n    vector<vector<int>> result;\n    vector<int> path;\npublic:\n\n    void backtrace(vector<int>& nums, int cur,bool used){\n        result.push_back(path);\n        for(int i = cur; i < nums.size(); i++){\n            if(i > 0 && nums[i] == nums[i - 1] && used == false){ \t// 判断是否同一层\n                continue;\n            }            \n            path.push_back(nums[i]);\n            used = true;\n            backtrace(nums,i + 1,used);\n            used = false;\n            path.pop_back();\n        }\n    }\n\n    vector<vector<int>> subsetsWithDup(vector<int>& nums) {\n        sort(nums.begin(),nums.end());\t// 记得排序\n        vector<bool> used(nums.size(),false);\n        backtrace(nums,0,used);\n        return result;\n    }\n};\n```\n\n这道题确实再刷没能做出来，但我清楚要去重的是同一层的节点。结合前面已经做的几道题，按理这道就是一个组合题，但可能长时间思考导致思路混乱。这道题卡住我的是 去重，但去重已经在 [40.组合总和 II](https://xiaoyangst.github.io/2024/08/09/40-组合总和-II/) 完成，应该是隔离刷题时间有点久。\n\n有一点你要注意，记得排序，不然我们的去重判断会失败。\n\n![90.子集.png](/images/2024/09/07/cbcabfb0-6cb4-11ef-aab5-778ee711175d.png)\n\n","tags":["回溯"],"categories":["leetcode"]},{"title":"78.子集","url":"/2024/09/06/78-子集/","content":"\n```c++\n从图中红线部分，可以看出遍历这个树的时候，把所有节点都记录下来，就是要求的子集集合。class Solution {\nprivate:\n    vector<vector<int>> result;\n    vector<int> path;\npublic:\n    void backtrace(vector<int>& nums, int cur){\n\n        result.push_back(path);\n\n        for(int i = cur; i < nums.size(); i++){\n            path.push_back(nums[i]);\n            backtrace(nums,i + 1);\n            path.pop_back();\n        }\n    }\n\n    vector<vector<int>> subsets(vector<int>& nums) {\n        backtrace(nums,0);\n        return result;\n    }\n};\n```\n\n子集问题是把树所有的节点收集起来，见下图：\n\n![78.子集.png](/images/2024/09/06/6feda540-6c55-11ef-a49b-a5cc0f1e27e0.png)\n\n从图中红线部分，可以看出**遍历这个树的时候，把所有节点都记录下来，就是要求的子集集合**。","tags":["回溯"],"categories":["leetcode"]},{"title":"结构体","url":"/2024/09/05/结构体/","content":"\n<!-- toc -->\n\n## 声明方式\n\n结构体常见的两种声明方式，其余稀奇古怪的皆不谈。\n\n```c\nstruct Node {\n\tint data;\n\tstruct Node* next;\n};\n```\n\n上面这种方式最为常见，在创建结构体的时候，必须是 struct Node 才能创建。如果你觉得每次创建都要加上 struct 关键字很麻烦，那可以起别名，就像下面这样。\n\n```c\ntypedef struct node {\n\tint data;\n\tstruct node* next;\n} Node;\n```\n\n这其中的原理是什么呢 ？\n\ntypedef 是给类型起别名的，因此我们的下面这部分其实代表的是一个自定义类型，因此为这个自定义类型取名为 Node，方便以后使用。\n\n```c\nstruct node {\n\tint data;\n\tstruct node* next;\n}\n```\n\n## 字节对齐\n\n这个已在其他文章中讲过，不必多言，这里重点说一说结构体字节对齐的特点：\n\n1. 一片连续的内存空间\n2. 成员是按声明的顺序依次存放\n3. 在结构体的中间或者后面可能会存在填充\n4. 填充的目的是为了对齐，对齐的目的是为了更快的访问数据项\n\n## 操作\n\n如果想把 一个结构体所有的数据全部 复制给另一个数据，只需要通过 = 赋值即可，而数组就做不到了。\n\n```c\nNode node1 = { 12,NULL };\nNode node2 = { 13,NULL };\n\nnode2 = node1;\n```\n\n那我们如何访问结构体的数据呢？\n\n- 如果值访问，那就是 `.`\n- 如果是指针访问，那就是 `->`\n\n```c\nNode node1 = { 12,NULL };\nnode1.data = 14;\t// 值访问\n\nNode* node2 = malloc(sizeof(Node));\nnode2->data = 17;\t// 指针访问\n```","tags":["C"],"categories":["technology"]},{"title":"命令模式","url":"/2024/09/04/命令模式/","content":"\n命令模式在 C++ 代码中很常见，大部分情况下， 它被用于代替包含行为的参数化 UI 元素的回调函数。我不知道你是否阅读过任意网络库，这边就以 Muduo 网络库举例说明：\n\n![命令模式1.png](/images/2024/09/04/1ffad470-6abd-11ef-8177-61a1f0d93f6c.png)\n\n用户传递的 某个回调函数（往往是读操作和写操作）通过层层传递，最终会被 Channel 这个调用者执行，但是用户不必关心谁来执行这个回调函数（即用户发出的命令），只需要发出命令即可。可以看出，用户发出的命令会被存储起来，实际的执行也不是由 TcpServer 执行。\n\n因此，我们讲命令模式可以对发送者和接收者（执行者）完全解耦，发送者与接收者之间没有直接引用关系，发送请求的对象只需要知道如何发送请求，而不必知道如何完成请求。本质是对命令进行封装，将发出命令的责任和执行命令的责任分割开。\n\n```c++\n#include <iostream>\n#include <map>\n#include <list>\nusing namespace std;\n\n// 由于 存在不同的命令，因此需要将 命令类 设置为 抽象基类\n\nclass Command {\npublic:\n\tvirtual string name() = 0;\n\tvirtual void Excute() = 0;\t\t\n\tvirtual ~Command(){}\n};\n\n// 命令执行者\nclass Invoker {\npublic:\n\tvoid makeGBJD() {\n\t\tcout << \"制作 宫保鸡丁\" << endl;\n\t}\n\n\tvoid makeCQXM() {\n\t\tcout << \"制作 重庆小面\" << endl;\n\t}\n\n\tvoid makeMCKR() {\n\t\tcout << \"制作 梅菜扣肉\" << endl;\n\t}\n};\n\n// 每个命令会被封装为一个对象\nclass GBJDCommand : public Command {\npublic:\n\tGBJDCommand(Invoker* inv) :invoker_(inv){}\n\tvoid Excute() override {\n\t\tinvoker_->makeGBJD();\n\t}\n\tstring name() override {\n\t\treturn \"GBJD\";\n\t}\n\tvirtual ~GBJDCommand() {};\nprotected:\n\tInvoker* invoker_;\n};\n\nclass CQXMCommand : public Command {\npublic:\n\tCQXMCommand(Invoker* inv) :invoker_(inv) {}\n\tvoid Excute() override {\n\t\tinvoker_->makeCQXM();\n\t}\n\tstring name() override {\n\t\treturn \"CQXM\";\n\t}\n\tvirtual ~CQXMCommand() {};\nprotected:\n\tInvoker* invoker_;\n};\n\nclass MCKRCommand : public Command {\npublic:\n\tMCKRCommand(Invoker* inv) :invoker_(inv) {}\n\tvoid Excute() override {\n\t\tinvoker_->makeMCKR();\n\t}\n\tstring name() override {\n\t\treturn \"MCKR\";\n\t}\n\tvirtual ~MCKRCommand() {};\nprotected:\n\tInvoker* invoker_;\n};\n\n\n// 命令传递者（接收者）\nclass Transmitter {\npublic:\n\t// 下达命令\n\tvoid give_order(int uuid,Command* command) {\n\t\tcout << \"uuid = \" << uuid << \"| 下达命令 = \" << command->name() <<endl;\n\n\t\tauto its = orders_.find(uuid);\n\t\tif (its != orders_.end()) {\t\n\t\t\torders_[uuid].push_back(command);\n\t\t}\n\t\telse {\n\t\t\tlist<Command*> data = { command };\n\t\t\torders_[uuid] = data;\n\t\t}\n\n\t}\n\t// 撤销命令\n\tvoid cancel_order(int uuid, Command* command) {\n\t\tauto its = orders_.find(uuid);\n\t\tif (its != orders_.end()) {\n\t\t\tcout << \"uuid = \" << uuid << \"| 取消命令 = \" << command->name() << endl;\n\t\t\torders_[uuid].remove(command);\n\t\t}\n\t}\n\n\t// 提交命令\n\tvoid submit_order() {\n\t\tfor (auto order : orders_) {\n\t\t\tfor (auto conmand : order.second) {\n\t\t\t\tconmand->Excute();\n\t\t\t}\n\t\t}\n\t\torders_.clear();\n\t}\n\nprivate:\n\tmap<int, list<Command*>> orders_;\t\t// key 是用户id，value 是用户下达的命令\n};\n```\n\n客户端测试代码：\n\n```c++\nint main(int argc,char* argv[]) {\n\n\tInvoker* invoker = new Invoker();\n\tTransmitter* trans = new Transmitter();\n\n\t// 创建一个命令列表\n\tGBJDCommand* gbjd = new GBJDCommand(invoker);\n\tCQXMCommand* cqxm = new CQXMCommand(invoker);\n\tMCKRCommand* mkqr = new MCKRCommand(invoker);\n\n\t// 用户可以下达命令了，通过传递命令的人\n\n\ttrans->give_order(1, gbjd);\n\ttrans->give_order(1, mkqr);\n\ttrans->cancel_order(1, mkqr);\n\ttrans->submit_order();\n\n\ttrans->give_order(2, cqxm);\n\ttrans->give_order(2, gbjd);\n\ttrans->give_order(2, mkqr);\n\ttrans->cancel_order(2, gbjd);\n\ttrans->submit_order();\n\n\treturn 0;\n}\n\n/*\nuuid = 1| 下达命令 = GBJD\nuuid = 1| 下达命令 = MCKR\nuuid = 1| 取消命令 = MCKR\n制作 宫保鸡丁\nuuid = 2| 下达命令 = CQXM\nuuid = 2| 下达命令 = GBJD\nuuid = 2| 下达命令 = MCKR\nuuid = 2| 取消命令 = GBJD\n制作 重庆小面\n制作 梅菜扣肉\n*/\n```\n\n想必各位也看出来了，如果我们需要更多的命令，那就需要添加更多的命令类，同时还要在 Invoker 类中添加实际的执行代码。","tags":["设计模式"],"categories":["technology"]},{"title":"字符串操作的相关函数","url":"/2024/09/03/字符串操作的相关函数/","content":"\n<!-- toc -->\n\n| 函数名    | 功能说明                                                     |\n| --------- | ------------------------------------------------------------ |\n| `strlen`  | 计算字符串的长度（不包括终止符 `\\0`）。                      |\n| `strcpy`  | 将源字符串复制到目标字符串（包括终止符 `\\0`）。              |\n| `strncpy` | 将指定长度的字符串复制到目标字符串，未复制部分用 `\\0` 填充（适合固定长度的字符串复制）。 |\n| `strcat`  | 将源字符串追加到目标字符串的末尾（包括终止符 `\\0`）。        |\n| `strncat` | 将指定长度的源字符串追加到目标字符串的末尾。                 |\n| `strcmp`  | 比较两个字符串的大小（按字典顺序），返回值小于0表示第一个字符串小于第二个，大于0则相反。 |\n| `strncmp` | 比较指定长度的两个字符串的大小。                             |\n\n具体要用的时候再去查，这些函数都存在或多或少的问题，这是 C 语言本身的问题，操作字符串及其麻烦，你务必每次主要空字符`\\0` 的记录。\n\n## 惯用法\n\n### 遍历字符串\n\n```c\nsize_t xy_strlen(const char* s) {\n\tconst char* start = s;\t// 字符串 s 的首地址\n\twhile (*s) {\n\t\ts++;\n\t}\n\treturn s - start;\n}\n```\n\n当然，如果你还想省略，那也是可以的，见下：\n\n```c\nsize_t xy_strlen(const char* s) {\n\tconst char* start = s;\t// 字符串 s 的首地址\n\twhile (*s++) { ; }\n\treturn s - start;\n}\n```\n\n### 复制字符串\n\n```c\nchar* xy_strcat(char* p, const char* s) {\n\tconst char* start = p;\n\twhile (*p)\n\t{\n\t\tp++;\n\t}\n\twhile (*p++ = *s++) { ; }\n\treturn start;\n}\n```\n\n前面的遍历字符串其实就是遍历到字符串的末尾，因此这里利用它到达末尾，就可以开始考虑字符串的复制了。","tags":["C"],"categories":["technology"]},{"title":"字符串字面量和字符串变量","url":"/2024/09/03/字符串字面量和字符串变量/","content":"\n<!-- toc -->\n\n字符串字面量（又名字符串常量）是不能被修改的，但可以被读取。字符串变量是可以被修改的，还可以被访问。\n\n```c\nint main(void) {\n\n\t// 字符串变量\n\tchar str1[] = \"hello\";\n\tstr1[0] = 'A';\t\n\n\t// 字符串字面量\n\tchar* str2 = \"hello\";\n\tstr2[0] = 'A';\t// 报错\n\n\treturn 0;\n}\n```\n\n## 字符串字面量\n\n字符串字面量是用一对双引号括起来的字符序列。通常存储在只读数据区（只读内存区域），它的内容是不可修改的。尝试修改字符串字面量会导致未定义行为。编译器自动计算并在编译时确定其长度，通常包括末尾的 `\\0` 终止符。\n\n从本质而言，C语言把字符串字面量作为字符数组来处理。当C语言编译器在程序中遇到长度为的字符串字面量时，它会为字符串字面量分配长度为的内存空间。这块内存空间将用来存储字符串字面量中的字符，以及一个用来标志字符串末尾的额外字符（空字符）。空字符是一个所有位都为0的字节，因此用转义序列`\\0`来表示\n\n![字符串字面值.png](/images/2024/09/03/fdf62a40-69ff-11ef-b30d-bbd8f07aedd3.png)\n\n## 字符串变量\n\n存储在栈（或堆）内存中，可以被修改。字符串变量通常是一个字符数组或指向字符数组的指针。可以存储不同长度的字符串，长度由你在定义数组时指定，或者在运行时动态确定。\n\n一些编程语言为声明字符串变量提供了专门的 string 类型。C 语言采取了不同的方式：只要保证字符串是以空字符结尾的，任何一维的字符数组都可以用来存储字符串。\n\n```c\nchar str1[] = \"hello\";\n```\n\n看起来好像是 字符串字面量，但其实不然。C编译器会把它看成是数组初始化式的缩写形式。实际上，我们可以写成：\n\n```c\nchar str[] = {'h','e','l','l','o','\\0'};\n```\n\n如果指定数组大小没有被填充满，会自动补0。如果指定数组大小务必要能有一个位置给其添加`\\0`，否则这不是一个合法的字符变量。\n\n## 字符数组和字符指针\n\n```c\nchar date[] = \"June 14\";\nchar *date = \"June 14\";\n```\n\n前者声明 date 是一个数组，后者声明 date 是一个指针。正因为有了数组和指针之间的紧密关系，才使上面这两个声明中的 date 都可以用作字符串。尤其是，任何期望传递字符数组或字符指针的函数都能够接收这两种声明的 date 作为参数。\n\n然而，需要注意，不能错误地认为上面这两种date可以互换。两者之间有很大的差异：\n\n- 在声明为数组时，就像任意数组元素一样，可以修改存储在date中的字符。在声明为指针时，date指向字符串字面量，前面我们已经看到字符串字面量是不可以修改的。\n- 在声明为数组时，date是数组名。在声明为指针时，date是变量，这个变量可以在程序执行期间指向其他字符串。\n\n如果希望可以修改字符串，那么就要建立字符数组来存储字符串，声明指针变量就不够的。因为指针变量没有指向一个有效的地址，对其修改会产生未定义的行为。下面的声明使编译器**为指针变量分配了足够的内存空间**：\n\n```c\nchar* p\n```\n\n可惜的是，它不能为字符串分配空间。（怎么会这样呢？因为我们没有指明字符串的长度。）在使用p作为字符串之前，必须把 p 指向字符数组。可以把p指向已经存在的字符串变量：\n\n```c\nchar str[STR_LEN+1], *p;\np = str;\n```\n\n现在 p 指向了 str 的第一个字符，所以可以把 p 作为字符串使用了。\n\n```c\nchar *p;\np[0] = 'a';   // 报错\np[1] = 'b';  // 报错\n```\n\n因为 p 没有被初始化，所以我们不知道它指向哪里。用指针 p 把字符 a、b 写入内存会导致未定义的行为。","tags":["C"],"categories":["technology"]},{"title":"传入参数和传出参数","url":"/2024/09/03/传入参数和传出参数/","content":"\n```c++\nvoid min_max(const int* arr, int n, int* pmin, int* pmax) {\n    *pmin = arr[0];\n    *pmax = arr[0];\n\n    for (int i = 1; i < n; i++) {\n        if (arr[i] < *pmin) {\n            *pmin = arr[i];\n        } else if (arr[i] > *pmax) {\n            *pmax = arr[i];\n        }\n    }\n}\n```\n\n传入参数，即传入的参数不会被修改，如代码中的 arr 对象。\n\n传出参数，即传出的参数意味着可以被修改，如代码中的 pmin 和 pmax 对象。","tags":["C"],"categories":["technology"]},{"title":"常量指针和指针常量","url":"/2024/09/03/常量指针和指针常量/","content":"\n<!-- toc -->\n\n```c\nint i = 10;\nint* p = &i;\n```\n\n指针是用来存储地址的，我们用指针 p 指向一个变量 i ，即存储该变量的地址。其中 & 意味着取地址符，* 意味着解引用。所以，当我们想要获取变量 i 存储的实际数据，可以选择直接输出 变量 i ，或者选择 *p 解引用来获取变量 i 存储的实际数据。两个的区别就是，变量 i 直接访问到内存，而 *p 需要先读取到 指针 p 指向的内存，然后再访问内存。因此，我们讲 变量 i 是直接访问，指针 p 是间接访问。\n\n你要知道 p 等价于 变量 i 的内存地址，*p 就等于于 i。\n\n![指针.png](/images/2024/09/03/3e5038c0-69fa-11ef-b30d-bbd8f07aedd3.png)\n\n此刻的指针 p 对指向的内存有读和写的权限，即读取指向内存的数据和修改指向内存的数据。\n\n```c\n#define _CRT_SECURE_NO_WARNINGS\n#include <stdio.h>\n\nint main(void) {\n\n\tint i = 10;\n\tint* p = &i;\n\tprintf(\"p = %d\\n\", *p);\n\t*p = 20;\n\tprintf(\"p = %d\\n\", *p);\n\n\treturn 0;\n}\n```\n\n输出结果：\n\n```c\np = 10\np = 20\n```\n\n## 常量指针\n\n```c\nint main(void) {\n\n\tint i = 10;\n\tint j = 20;\n\tconst int* p = &i;\n\n\tprintf(\"p = %d\\n\", p);\n\n\tp = &j;\n\n\t*p = 10;\t// 报错\n\n\tprintf(\"p = %d\\n\", *p);\n\n\treturn 0;\n}\n```\n\n从左往右看，常量（const）+ 指针（*）。\n\n从报错情况来看，*p 对于指向内存的数据有读的权限，但是没有写的权限。p对于指向内存的数据有读的权限，也有写的权限。即常量指针能改变所指的对象，但是不可以改变所指对象的数据。\n\n![常量指针.png](/images/2024/09/03/38bbffc0-69fa-11ef-b30d-bbd8f07aedd3.png)\n\n## 指针常量\n\n```c\nint main(void) {\n\n\tint i = 10;\n\tint j = 20;\n\tint* const p = &i;\n\n\tprintf(\"p = %d\\n\", p);\n\n\tp = &j;\t\t// 报错\n\n\t*p = 10;\t\n\n\tprintf(\"p = %d\\n\", *p);\n\n\treturn 0;\n}\n```\n\n从左往右看，指针（*）+ 常量（const）。\n\n从报错情况来看，*p 对于指向内存的数据有读的权限，也有写的权限。p对于指向内存的数据有读的权限，但是没有写的权限。即常量指针不能改变所指的对象，但是可以改变所指对象的数据。\n\n![指针常量.png](/images/2024/09/03/33771f40-69fa-11ef-b30d-bbd8f07aedd3.png)\n\n## 常量指针常量\n\nconst int* const 变量名。不必多说，既不能修改所指的对象，还不可以修改所指对象的数据。","tags":["C"],"categories":["technology"]},{"title":"Base64 和 MD5 的使用","url":"/2024/09/01/Base64-和-MD5-的使用/","content":"\n<!-- toc -->\n\n## 为什么要使用 Base64 ?\n\nBase64 虽然可以用于简单的加密，但通常用于传输数据。\n\n在网络上交换数据时，比如说从 A 地传到 B 地，往往要经过多个路由设备，由于不同的设备对字符的处理方式有一些不同，这样那些不可见字符就有可能被处理错误，这是不利于传输的。把数据先做一个 Base64 编码，统统变成可见字符，这样出错的可能性就大降低了。很多场景下的数据传输要求数据只能由简单通用的字符组成，比如 HTTP 协议要求请求的首行和请求头都必须是 ASCII 编码。\n\n## 为什么要使用 MD5 ?\n\nMD5 就是用来加密数据（**MD5 并不是一种加密算法，而是一种摘要算法**，我们也可以叫它哈希函数），且不可逆，即只用暴力碰撞来解密，当时它已经不是一个安全的加密算法了。\n\n使用 MD5 加密数据的目的通常是为了验证数据的完整性。因为哈希算法具有一致性，所以如果数据没有被篡改，我们可以把它的哈希值与原来的哈希值进行比较，如果完全一致，则说明数据没有被篡改。但是，由于哈希算法是单向的，所以我们无法通过哈希值推出原来的数据。如果你需要获取原来的数据，你必须要拥有原来的数据本身。\n\n## Qt 中使用 Base64 \n\n```c++\n// 编码\n    QByteArray base = \"你好, 世界\";\n    base = base.toBase64();\n    qDebug() << base;\n\n// 解码\n    base= QByteArray::fromBase64(base);\n    qDebug() << base.data();\n```\n\n## Qt 中使用 MD5\n\n```c++\n    QString input = \"Hello, World!\";\n    QByteArray byteArray = input.toUtf8();\n    \n// 生成 MD5 哈希\n    QByteArray md5Hash = QCryptographicHash::hash(byteArray, QCryptographicHash::Md5);\n    qDebug() << \"MD5 Hash:\" << md5Hash.toHex();\n```\n\n[MD5 既然不安全](https://draveness.me/whys-the-design-password-with-md5/)，那么 Qt 中可以使用的加密算法还有很多，主要通过 `QCryptographicHash` 和 `QCA`（Qt Cryptographic Architecture）库来实现。在任何场景下，我们都应该避免 MD5 的使用，可以选择更好的摘要算法替代 MD5，例如 SHA256、SHA512。\n\n尽管摘要算法无论如何都不安全，因为会被碰撞出来。哈希加盐的方式确实能够增加攻击者的成本，但这远远不够，随着计算机算力的增强已经难以抵挡。使用 `bcrypt` 相比于直接使用哈希加盐是一种更加安全的方式，也是我们目前推荐使用的方法，为了增加攻击者的成本，`bcrypt` 引入了计算成本这一可以调节的参数，能够调节执行 `bcrypt` 函数的成本。\n\n---\n参考链接：\nhttps://xiaoyangst.github.io/2024/09/01/Base64-%E5%92%8C-MD5-%E7%9A%84%E4%BD%BF%E7%94%A8/\nhttps://blog.csdn.net/weixin_35749545/article/details/129072384\nhttps://blog.51cto.com/yang/2894100","tags":["Qt"],"categories":["technology"]},{"title":"位运算","url":"/2024/09/01/位运算/","content":"\n<!-- toc -->\n\n## 位运算符\n\n![位运算.png](/images/2024/09/01/f915d080-6855-11ef-bc89-e5593d4b1f18.png)\n\n`a >> 1` 如果没有超出类型范围，代表 a = a / 2\n\n`a << 1` 如果没有超出类型范围，代表 a = a * 2\n\n## 异或运算常用特性\n\n![异或运算的性质.png](/images/2024/09/01/ffdda780-6855-11ef-bc89-e5593d4b1f18.png)\n\n## 常见面试算法题\n\n（一）如何获取一个数字最右侧的 1 ？\n\n```c\nint xor = a & (-a)\n```\n\nxor 就代表了整数 `a` 的二进制表示中最右边的 `1` 所在的位置（以二进制形式表示），其中对应的二进制中 1 所处的位置表示整数 a 最右侧的 1 的 位置，剩下的全部为 0。\n\n![最右侧的1.png](/images/2024/09/01/067ff520-6856-11ef-bc89-e5593d4b1f18.png)\n\n注：补码即原码取反再加1，C语言中的负数就是用补码表示\n\n（二）分离奇偶数\n\n奇数和偶数的二进制特点就是，奇数必然在第一位为 1，而偶数必然在第一位为 0。\n\n```c\nbool is_odd(int num) {\n\treturn (num & (-num)) == 1;\n}\n```\n\n上述函数就可以判断是否为奇数。取最右侧的数字 1 的位置，如果结果等于 1，代表这个数的二进制第一位就是标记为 1，代表必然为奇数。\n\n（三）如何将数组中不同的两个数找到（其余元素两两出现）？\n\n```c\nvoid get_diff_nums(int *data,int length) {\n\tint result = 0;\n\t// 得到两个数\n\tfor (int i = 0; i < length; i++) {\n\t\tresult ^= data[i];\n\t}\n\t// 将两个数分离出来\n\tint num1 = 0;\n\tint num2 = 0;\n\tint xor = result & (-result);\n\tfor (int i = 0; i < length; i++) {\n\t\tif (data[i] & xor) {\n\t\t\tnum1 ^= data[i];\n\t\t}\n\t\telse {\n\t\t\tnum2 ^= data[i];\n\t\t}\n\t}\n\n\tprintf(\"num1 = %d , num2 = %d\\n\", num1, num2);\n}\n```\n\n1. 异或会把相同的两个数抵消，所以全部元素异或之后，result = 3 ^ 5\n2. 那我们需要想办法把两个数分离出来，两个不同的数，必然至少会有一位不同。即在这一位上，如果你是 0，那么我就是 1（不是南通，别误会）。这样的两个数异或，这个位置会被 1 标识（0 和 1 异或为 1），那就利用 `result & (-result)` 找到这个位置，这是区分两个数的关键所在。\n3. xor 的二进制中，除了用以区分两个数的位置被标记为 1 ，其余全部为 0。所以我们遍历数组，和 xor 进行 & 操作。相同的两个数必然会被分到一组，且会因为异或而抵消。不同的两个数，会因为 & 计算分离出来。\n\n也许“不同的两个数，会因为 & 计算分离出来”会让人不解。我们知道现在的 xor = 0010，而 3 = 0011，5 = 0101。xor 与之 & 得到的结果为某个数为大于 0，某个数等于0，这就将两个数分离出来了。","tags":["C"],"categories":["technology"]},{"title":"if 和 switch","url":"/2024/09/01/if-和-switch/","content":"\n<!-- toc -->\n\n## 悬空 ‘else’ 的问题\n\n```c\nif (y != 0)  \n\tif (x != 0)    \n\t\tresult = x / y;\nelse  \n\tprintf(\"Error: y is equal to 0\\n\");\n```\n\n上面的 else 子句究竟属于哪一个 if 语句呢？\n\n缩进格式暗示它属于最外层的if语句。然而，C语言遵循的规则是 else子句 应该属于离它最近的且还未和其他 else 匹配的 if 语句。\n\n在此例中，else子句实际上属于最内层的if语句，所以正确的缩进格式应该如下所示：\n\n```c\nif (y != 0)  \n\tif (x != 0)    \n\t\tresult = x / y;\n\telse  \n\t\tprintf(\"Error: y is equal to 0\\n\");\n```\n\n如果你希望 else 属于最外层 if ，那就可以把内存的 if 语句用花括号括起来，如下所示：\n\n```c\nif (y != 0)  {\n\tif (x != 0)    \n\t\tresult = x / y;\n} else  \n\tprintf(\"Error: y is equal to 0\\n\");\n```\n\n所以，为了避免含义表达错误，我们建议用花括号，尽管这看起来可能不美观，但至少保证代码不会出现不必要的bug。况且，C 语言不是通过缩进判断 else 属于哪个 if语句，这不是 Python 语法，而是根据 “else子句 应该属于离它最近的且还未和其他 else 匹配的 if 语句” 来判断的。\n\n## switch 语句\n\n```c\nswitch(表达式) /*首先计算表达式的值*/ \n{ \n    case 常量表达式1:语句1; \n    case 常量表达式2:语句2; \n    case 常量表达式3:语句3; \n    // …… \n    case 常量表达式n:语句n; \n    default:语句n+1;\n}\n```\n\nC语言不允许有重复的分支标号（即常量表达式），但对分支的顺序没有要求，特别是 default 分支不一定要放置在最后。switch 语句不要求一定有 default 分支。如果 default 不存在，而且控制表达式的值和任何一个分支标号都不匹配的话，控制会直接传给 switch 语句后面的语句。\n\ncase后边只可以跟随一个常量表达式。但是，多个分支标号可以放置在同一组语句的前面，代表着这几个常量表达式是等价的，即满足这几个常量表达式任意一个就会执行后面的语句。比方说下面的例子，如果你的 case 是 4，3，2，1，那么都会去执行打印文本内容Passing。\n\n```c\nswitch  (grade)  {\n    case 4:  \n    case 3:  \n    case 2:  \n    case 1:  \n        printf(\"Passing\");\n        break;\n    case 0:  \n        printf(\"Failing\");\n        break;\n    default:  \n        printf(\"Illegal grade\");\n        break;\n}\n```\n\n为了节省空间，程序员有时还会把几个分支标号放置在同一行中。\n\n```c\nswitch  (grade)  {\n    case 4:  case 3:  case 2:  case 1:  \n        printf(\"Passing\");\n        break;\n    case 0:  \n        printf(\"Failing\");\n        break;\n    default:  \n        printf(\"Illegal grade\");\n        break;\n}\n```\n\n还有要注意 switch 中的 break语句，如果不恰当使用，就会出现穿透问题。比方说下面这个例子，如果你 case 为0，那么会打印文本内容Failing，但由于后面没有 break语句，就会穿透下去，还会打印文本内容Illegal grade。\n\n```c\nswitch  (grade)  {\n    case 4:  case 3:  case 2:  case 1:  \n        printf(\"Passing\");\n        break;\n    case 0:  \n        printf(\"Failing\");\n    default:  \n        printf(\"Illegal grade\");\n        break;\n}\n```\n\n忘记使用break语句是编程时常犯的错误。虽然有时会故意忽略 break 以便多个分支共享代码，但通常情况下省略 break 是因为疏忽。\n\n## if 和 switch 性能问题\n\n用 if 和 switch 实现如下代码，即根据输入的成绩打印对应的等级：\n\n**A** 等级: 90-100分\n\n**B** 等级: 80-89分\n\n**C** 等级: 70-79分\n\n**D** 等级: 60-69分\n\n**F** 等级: 0-59分\n\n先查看 switch 对应的核心汇编代码：\n\n```c\n\tswitch (score / 10) 对应的汇编代码\n        \n007D45AC  mov         eax,dword ptr [score]      ; 将score的值加载到eax寄存器中\n007D45AF  cdq                                   ; 将EAX的符号位扩展到EDX:EAX\n007D45B0  mov         ecx,0Ah                    ; 将10 (0xA)加载到ecx寄存器\n007D45B5  idiv        ecx                        ; 用ecx的值除eax的值，商存入eax，余数存入edx\n007D45B7  mov         dword ptr [ebp-0DCh],eax   ; 将商（即 score / 10 的结果）存入 [ebp-0DCh]\n007D45BD  cmp         dword ptr [ebp-0DCh],0Ah   ; 比较score / 10的结果和10（即判断是否是满分）\n007D45C4  ja          $LN14+6h (07D45F1h)        ; 如果结果大于10，跳到非法成绩的处理部分\n007D45C6  mov         edx,dword ptr [ebp-0DCh]   ; 将商的值存入edx寄存器\n007D45CC  jmp         dword ptr [edx*4+7D4628h]  ; 使用乘法计算地址并跳转到跳转表中的对应位置\n```\n\nswitch 会提前把要符合常量表达式地址计算出来，然后直接跳转过去，所以效率会比 if 语句高。if 语句是从上到下按照顺序往下进行判断，直到遇到符合条件的，并非直接调整到指定地址进行代码执行。\n\n```c\n    if (score >= 90 && score <= 100) {\n007D186C  cmp         dword ptr [score],5Ah  \n007D1870  jl          __$EncStackInitStart+32h (07D187Eh)  \n007D1872  cmp         dword ptr [score],64h  \n007D1876  jg          __$EncStackInitStart+32h (07D187Eh)  \n        grade = 'A';\n007D1878  mov         byte ptr [grade],41h  \n    }\n007D187C  jmp         __$EncStackInitStart+89h (07D18D5h)  \n    else if (score >= 80 && score < 90) {\n007D187E  cmp         dword ptr [score],50h  \n007D1882  jl          __$EncStackInitStart+44h (07D1890h)  \n007D1884  cmp         dword ptr [score],5Ah  \n007D1888  jge         __$EncStackInitStart+44h (07D1890h)  \n        grade = 'B';\n007D188A  mov         byte ptr [grade],42h  \n    }\n007D188E  jmp         __$EncStackInitStart+89h (07D18D5h)  \n    else if (score >= 70 && score < 80) {\n007D1890  cmp         dword ptr [score],46h  \n007D1894  jl          __$EncStackInitStart+56h (07D18A2h)  \n007D1896  cmp         dword ptr [score],50h  \n007D189A  jge         __$EncStackInitStart+56h (07D18A2h)  \n        grade = 'C';\n007D189C  mov         byte ptr [grade],43h  \n    }\n007D18A0  jmp         __$EncStackInitStart+89h (07D18D5h)  \n    else if (score >= 60 && score < 70) {\n007D18A2  cmp         dword ptr [score],3Ch  \n007D18A6  jl          __$EncStackInitStart+68h (07D18B4h)  \n007D18A8  cmp         dword ptr [score],46h  \n007D18AC  jge         __$EncStackInitStart+68h (07D18B4h)  \n        grade = 'D';\n007D18AE  mov         byte ptr [grade],44h  \n    }\n007D18B2  jmp         __$EncStackInitStart+89h (07D18D5h)  \n    else if (score >= 0 && score < 60) {\n007D18B4  cmp         dword ptr [score],0  \n007D18B8  jl          __$EncStackInitStart+7Ah (07D18C6h)  \n007D18BA  cmp         dword ptr [score],3Ch  \n007D18BE  jge         __$EncStackInitStart+7Ah (07D18C6h)  \n        grade = 'F';\n007D18C0  mov         byte ptr [grade],46h  \n    }\n007D18C4  jmp         __$EncStackInitStart+89h (07D18D5h)  \n    else {\n        printf(\"Invalid score\\n\");\n007D18C6  push        offset string \"Invalid score\\n\" (07D7B30h)  \n007D18CB  call        _printf (07D10CDh)  \n007D18D0  add         esp,4  \n        return;\n007D18D3  jmp         __$EncStackInitStart+9Bh (07D18E7h)  \n    }\n```\n最后，如果 if 和 switch 的分支语句太短，那么性能就没有区别了。","tags":["C"],"categories":["technology"]},{"title":"关于数组","url":"/2024/08/31/关于数组/","content":"\n<!-- toc -->\n\n数组就是一片连续的内存空间，并且被划分成大小相等的小空间。\n\n## 为什么数组下标从0开始？\n\n寻址公式：i_address = base_addr + i * sizeof(element)\n\n- 如果下标从 0 开始，第一个元素 `arr[0]` 的地址为 `A + 0 * S = A`，这与数组的基地址相同，无需额外的计算。\n- 如果下标从 1 开始，第一个元素 `arr[1]` 的地址会是 `A + (1-1) * S = A`，虽然结果相同，但在逻辑上需要多一层计算处理，即计算 (1-1) 的结果。\n\n## 从来只有一维数组\n\n```c++\nint data[2][2] = { 1,1,1,1 };\n\n// 等价于\n\nint data[2][2] = { {1,1},{1,1} };\t// 可读性强\n```\n\n数组名称是 data ，数据类型是 int\\[2\\]\\[2\\]。 data\\[0\\] 或 data\\[1\\] 的数据类型是 int[2]。 data\\[0\\]\\[0\\] 或 data\\[0\\]\\[1\\] 的数据类型是 int。\n\n![数组数据类型.png](/images/2024/08/31/4ecd2730-677f-11ef-98d3-c7da4f8e7a55.png)\n\n因此，这就能很好理解数组计算长度的公式了。\n\n```c++\nsizeof(data) / sizeof(data[0][0])\n```\n\n我们说数据类型指示数据的范围，data 的数据类型代表的范围是 4 个 int 类型，而 data\\[0\\]\\[0\\] 的数据类型代表的范围是 1 个 int 类型。\n\n## 小心数组退化为指针\n\n因为数组作为实参传递给函数的时候，回退化为指针，而我们遍历数组需要长度，这个时候你再用前面的方式计算数组长度就会出现错误，所以我们希望你在传递数组作为实参的时候，记得提前计算长度并也作为实参传递进去。\n\n于此同时，我们应该在传递数组作为实参的时候，类型应该写成 指针，这样读者就会认为这是传递进来的一个数组，且已退化为指针。如果你不是这样做，而是像这样 int\\[\\] data 或  int\\[2\\] data ，那么读者虽然能看出这是一个数组，但是容易忘记它已经退化为指针。\n\n```c++\nint func(int *data, int len) {\n\tfor (int i = 0; i < len; i++) {\n\t\tprintf(\"%d \", data[i]);\n\t}\n}\n\nint main(void) {\n\n\tint data[4] = { 1,2,3,4 };\n\n\tint len = sizeof(data) / sizeof(data[0]);\n\n\tfunc(data, len);\n\n\treturn 0;\n}\n```\n\n如果你非要这么做，即以数组的视角去定义形参，那么访问数组元素需要用如下方式。\n\n```c\nint func(int data[], int len) {\n\tfor (int i = 0; i < len; i++) {\n\t\tprintf(\"%d \", data[i]);\n\t}\n}\n\nint main(void) {\n\n\tint data[4] = { 1,2,3,4 };\n\n\tint len = sizeof(data) / sizeof(data[0]);\n\n\tfunc(data, len);\n\n\treturn 0;\n}\n```\n\n你可能想问，如果是多维数组，我们该如何传递长度呢？只需要传递可以被省略的那个数即可，比方说 data\\[2\\]\\[2\\] 可以省略为 data\\[\\]\\[2\\]，也就是说第一个可以被省略。或者，你直接把行和列的长度都传进去，因为我们通常不会超过二维数组，所以这不是什么难考虑的事情。","tags":["C"],"categories":["technology"]},{"title":"标准输入输出","url":"/2024/08/31/标准输入输出/","content":"\n<!-- toc -->\n\n![标准输入输出.png](/images/2024/08/31/ace538c0-6776-11ef-a499-ddf8d91f56f9.png)\n\n敲击键盘输入的数据会缓存到 stdin 缓冲区中，scanf函数就从缓冲区中取出数据。printf函数会把要显示的数据放到 stdout 缓冲区中，由显示器从中取出并显示。缓冲区中的数据都是一次性的，读取之后就会消失，你完全可以理解为管道。\n\n由于不同系统，不的硬件底层实现输入输出的具体方法可能不一样，C语言要求系统为每个程序提供两个指针,这两个指针分别指向两个结构体，这两个结构体分别表示了键盘和屏幕在内存中的抽象表示（缓冲区的地址值被记录在这个结构体中）,并将指向这两个结构体的指针命名为stdin和 stdout.这两个指针就是所谓的标准输入和标准输出。\n\n## 标准输出\n\n格式：printf(格式串,表达式1,表达式2,...)\n\n原理：打印格式串的内容，并用后面的表达式替换格式串中的转换说明\n\n![printf.png](/images/2024/08/31/a747d800-6776-11ef-a499-ddf8d91f56f9.png)\n\n格式串里面包含两个内容：普通字符和转换说明。\n\n普通字符原样输出即可，因为内容已经写死。所以这里最值得讲的就是转换说明，也是很多人没有弄明白的地方。\n\n转换说明的作用就是起到占位符的作用，它的格式：%\\[符号\\]\\[宽度\\]\\[.精度\\]类型\n\n```c\n%m.pX\t\t//右对齐，当显示字符不足 m 时，左补空格\n%-m.pX\t\t// 左对齐，当显示字符不足 m 时，右补空格\n%0m.pX\t\t// 右对齐，当显示字符不足 m 时，左补0\n```\n\nm 用来控制最小字段宽度。如果输出字段大于等于指定宽度就正常输出，否则 `-` 右补空格 或 `0` 左边 0 来满足欠缺的长度；如果你没有指定符号的话，就会左补空格。\n\n```c\n\tint age = 1000;\n\n\tprintf(\"age = %d | \", age);\n\tprintf(\"age = %3d | \", age);\n\tprintf(\"age = %5d | \", age);\n\tprintf(\"age = %-5d | \", age);\n\tprintf(\"age = %07d | \", age);\n\n// 输出\n\nage = 1000 | age = 1000 | age =  1000 | age = 1000  | age = 0001000 |\n```\n\np 用来控制精度。如果指定的精度大于要输出的精度就会补0，否则显示指定长度的精度。\n\n```c\n\tdouble dnum = 192.167;\n\n\tprintf(\"dnum = %.1f | \", dnum);\n\tprintf(\"dnum = %.2lf | \", dnum);\n\tprintf(\"dnum = %.3lf | \", dnum);\n\tprintf(\"dnum = %.5lf | \", dnum);\n\n// 输出\ndnum = 192.2 | dnum = 192.17 | dnum = 192.167 | dnum = 192.16700 |\n```\n\nX代表发生的类型转换。\n\n```tex\n（1）%d:用于显示十进制有符号数，char,short,int,long long\n\n（2）%u:用于显示十进制无符号数，unsinged short,unsigned int,unsigned long long\n\n（3）%x: 用于显示十六进制整数，所有有符号及无符号整型\n\n（4）%f:用于显示十进制浮点数，float,double\n\n（5）%c:显示字符\n\n（6）%s:显示字符串\n```\n\n## 标准输入\n\n格式：scanf(格式串,表达式1,表达式2,...)\n\n原理：本质是模式匹配\n\n从左到右，根据格式串匹配 stdin 中的字符。如果匹配成功，继续匹配下一项；如果匹配失败，立即返回。最后，返回匹配成功的转换说明的个数。\n\n我们的格式串包含三块内容：普通字符，空白字符，转换说明。\n\n（一）普通字符需要精确匹配，如果匹配失败就会立即退出\n\n```c\n\tint num;\n\n\t// 普通字符需要精确匹配，如果匹配失败就会立即退出\n\tscanf(\"/%d/\", &num);\n\tprintf(\"num = %d\", num);\n```\n\n如果你在输入字符的时候没有正常输入前面的 / 或 后面的 / ，那么就会匹配失败，并且立即退出。如果你没有成功匹配前面的 / ，那么立即匹配失败并退出，导致 num 为随机值，因为你不会有输入 num 值的机会。如果你没有匹配后面的 /，那么立即匹配失败并退出，但是 num 会正常输出，因为在此之前你已经成功输入 num 值并匹配到占位符中，只是后面的 / 没有匹配成功。如果 / 后面还有其他字符，也不会得到输出的，因为后面的 / 匹配失败导致后续的格式串也得不到匹配了，即没有被加入到 stdin 缓冲区中。\n\n（二）在寻找数的起始位置时，会忽略任意零个或多个空白字符（如空格、制表符、换行符）\n\n```c++\n\tint num1;\n\tint num2;\n\n//任意多个（包括0个）空白字符（如空格、制表符、换行符）\n\tscanf(\"%d%d\", &num1, &num2);\n\tprintf(\"num1 = %d , num2 = %d\", num1, num2);\n```\n\n![scanf输出.png](/images/2024/08/31/9dfa8ea0-6776-11ef-a499-ddf8d91f56f9.png)\n\n你可以看到数字 10 前面的空白字符会被忽略，数字 20 前面的空白字符会被忽略。因为 scanf 函数在寻找每个数的起始位置时会跳过空白字符，所以它可以成功读取这些数。  \n\n\n\n下面强调几个使用 scanf 容易忽视的地方：\n\n- 在 `scanf` 的格式字符串中，任何空白字符（空格、制表符、换行符）都会使得 `scanf` 忽略输入中的空白字符，直到遇到下一个非空白字符。\n- scanf 有返回值，返回匹配成功的个数。不要将 scanf 放到 while 循环中使用。\n- 使用 `%c` 时需要注意，`scanf` 不会跳过空白字符，可能会读取到空格或换行符。因此要在 占位符前面加上一个空格，比方说 ' %c'。\n- 使用 `%s` 读取字符串时，`scanf` 会跳过前导空白字符，并在遇到第一个空白字符时停止读取。\n\n## getchar 和 putchar\n\n前面我们将 scanf 获取单个字符存在问题，你必须占位符前面添加一个空格才可以，但是这很容易让人忘记。`getchar` 函数用于从标准输入读取一个字符。\n\ngetchar 从标准输入（通常是键盘）读取一个字符。如果输入的字符是 EOF 或在按下回车键之前没有输入字符，它将返回 EOF。\n\n```c\nint getchar(void);\n```\n\n而 putchar 就用于输出一个字符了。\n\n```c\nint putchar(int char);\n```\n\n---\n\n参考阅读：[C语言的标准输入输出](https://www.cnblogs.com/nullzx/p/5598574.html)","tags":["C"],"categories":["technology"]},{"title":"随机数生成","url":"/2024/08/31/随机数生成/","content":"\n<!-- toc -->\n\nC语言提供两个随机数相关的函数，即 rand 和 srand。主要弄清楚它的伪随机，以及如何产生真正意义上的随机数。\n\n```c++\nint rand (void);\t\t// 返回值是一个伪随机数\n```\n\n此数字由一种算法生成，该算法在每次调用时都会返回一系列明显不相关的数字。此算法使用种子生成序列，应使用下面的 srand 函数 将其初始化为某个独特的值。\n\n```c++\nvoid srand (unsigned int seed);\t// 传递一个种子数\n```\n\n## 为什么说它是伪随机？\n\n```c++\nprintf(\"first random number = %d\\n\", rand());\nprintf(\"second random number = %d\\n\", rand());\n```\n\n运行上面的函数你会得到两个随机数，但你再次运行你会发现还是之前得到的两个随机数，这就是说 rand() 得到的是伪随机的原因。当你确定种子的那一刻起，你后面生成的数字也就都被确定下来，这就是为什么伪随机的缘故。\n\n下面通过 srand() 创建种子，看看现象：\n\n```c++\nsrand(10);\nprintf(\"first random number = %d\\n\", rand());\nsrand(10);\nprintf(\"second random number = %d\\n\", rand());\n\n/*\nfirst random number = 71\nsecond random number = 71\n*/\n```\n\n没错，当你种子确定的那一刻，那么底层算法就已经帮你规定好后面顺序的所有数字该多少了。当你第一次规定种子为 10，那么获取随机数为 71，如果这个时候你重新规定种子为 10，那么再次获取随机数也还是71。\n\n## 如何得到真正意义上的随机数？\n\n既然，种子不同就会得到不同的随机数，那么时间是不断变化的，只要我们传入 每一刻的时间即可。\n\n```c++\nsrand(time(NULL));\n```\n\n往后，你调用 rand 得到的必然就是随机数了。\n\n注意：srand() 函数只需要在程序中调用一次即可，而 rand() 函数可以多吃调用生成随机数。\n\n## 为什么srand()建议只调用一次？\n\n**频繁重置种子**：如果你在短时间内多次调用 `srand(time(NULL))`，种子值可能不会发生变化（因为 `time(NULL)` 返回的是当前时间，单位是秒）。因此，随机数生成器会被重新初始化为相同的种子值，这会导致生成的随机数序列重复，从而降低随机性。\n\n**随机性降低**：理想情况下，随机数序列应当尽可能不可预测。如果你不断地调用 srand 并使用几乎相同的种子，生成的随机数序列将会是相同的或高度相关的，这就违背了使用随机数的目的。\n\n因此，避免多次调用 `srand(time(NULL))`，这样可以保持随机数序列的随机性和不可预测性。","tags":["C"],"categories":["technology"]},{"title":"进程的虚拟内存空间","url":"/2024/08/31/进程的虚拟内存空间/","content":"\n![进程的虚拟内存地址空间.png](/images/2024/08/31/b3adae00-6760-11ef-a26a-13be39d63a86.png)\n\n操作系统给每个进程营造一种假象，即独占整个内存。在 x86 系统中，为每个进程虚拟出 4G 的内存空间，其中 3G 为用户空间，这块空间各进程相互独立；1G 为内核空间，这块空间进程间共享。\n\n进程在用户态时，只能访问用户空间内存；只有进入内核态后，才可以访问内核空间内存。虽然每个进程的地址空间都包含了内核空间，但这些内核空间，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。\n\n![进程的虚拟地址空间2.png](/images/2024/08/31/b84118d0-6760-11ef-a26a-13be39d63a86.png)\n\n代码段：用来存放程序执行代码，也可能包含一些只读的常量。这块区域的大小在程序运行时就已经确定，并且为了防止代码和常量遭到修改，代码段被设置为只读\n\n数据段：用来存放程序中已初始化全局变量与静态变量\n\nBSS段：用来存放程序中未初始化全局变量与静态变量\n\n堆区：动态内存分配区域，用来存放动态分配的内存，堆内存由用户申请分配和释放，从低地址向高地址增长\n\n文件映射段：也叫共享区，主要包括共享内存、动态链接库等共享资源，从低地址向高地址增长\n\n栈区：存放程序中临时创建的局部变量，如函数的参数、内部变量等\n\n---\n\n参考文章地址：[进程的虚拟内存布局是怎样的？](https://www.51cto.com/article/770253.html)\n\n","tags":["C"],"categories":["technology"]},{"title":"第一章：Asio 建立网络连接基本 API","url":"/2024/08/30/第一章：Asio-建立网络连接基本-API/","content":"\n<!-- toc -->\n\n- *boost::asio*：这是核心类和函数所在的地方。重要的类有 *io_service* 和 *streambuf*。类似*read, read_at, read_until*方法，它们的异步方法，它们的写方法和异步写方法等自由函数也在这里\n- *boost::asio::ip*：这是网络通信部分所在的地方。重要的类有 *address, endpoint, tcp, udp和 icmp*，重要的自由函数有 *connect* 和 *async_connect*。要注意的是在 *boost::asio::ip::tcp::socket*中间，*socket*只是 *boost::asio::ip::tcp* 类中间的一个*typedef*关键字\n- *boost::asio::error*：这个命名空间包含了调用 I/O 例程时返回的错误码\n- *boost::asio::ssl*：包含了 SSL 处理类的命名空间\n- *boost::asio::local*：这个命名空间包含了 POSIX 特性的类\n- *boost::asio::windows*：这个命名空间包含了 Windows 特性的类\n\n## IP地址的处理\n\n由于下面介绍终端端点需要用到关于 IP 地址作为参数传递，先提前讲，因为不是单纯的传递 string 类型的 IP 参数就可以的。\n\n- ip::address(v4_or_v6_address)：这个函数把一个v4或者v6的地址转换成 ip::address\n- ip::address:from_string(str)：这个函数根据一个IPv4地址或者一个IPv6地址创建一个地址\n- ip::address::to_string() ：这个函数返回这个地址的字符串\n- ip::address_v4::broadcast([addr, mask])：这个函数创建了一个广播地址 \n- ip::address_v4::any()：这个函数返回一个能表示任意地址的地址\n- ip::address_v4::loopback(), ip_address_v6::loopback()：这个函数返回环路地址（为v4/v6协议）\n- ip::host_name()：这个函数用 string 数据类型返回当前的主机名\n\n注：不支持传递域名\n\n## 终端端点\n\n所谓终端节点就是**用来通信的端对端的节点**，可以通过ip地址和端口构造，其它的节点可以连接这个终端节点进行通信。不同类型的 socket 有它自己的 endpoint 类，比如 ip::tcp::endpoint、 ip::udp::endpoint 和 ip::icmp::endpoint。\n\n- endpoint()：这是默认构造函数，某些时候可以用来创建UDP/ICMP socket\n- endpoint(protocol, port)：这个方法通常用来创建可以接受新连接的服务器端socket\n- endpoint(addr, port)：这个方法创建了一个连接到某个地址和端口的端点\n\n```c++\nusing namespace std;\nusing namespace boost::asio::ip;\n\n// 客户端可以通过对端地址和端口构造一个endpoint，用这个endpoint和其通信\n    string ip = \"192.168.1.12\";\t\n    int port = 8080;\t\n    tcp::endpoint c_ep(address::from_string(ip),port);  \n\n// 服务端只需根据本地地址绑定就可以生成endpoint\n    int server_port = 8080;\t\n    tcp::endpoint s_ep(address_v4::any(), server_port);\n```\n\n给定一个端点，可以获得他的地址，端口和IP协议（v4或者v6）：\n\n```c++\ncout << c_ep.address().to_string() << \":\" << c_ep.port() << \"/\" << c_ep.protocol() << endl;\n```\n\n注：输出协议部分报错，因为 `c_ep.protocol()` 返回的 `tcp::protocol` 类型没有与 `std::cout` 流兼容的 `<<` 运算符重载，所以实际上你只能打印出地址和端口信息\n\n## 创建socket\n\nasio 有三种类型的套接字类：ip::tcp, ip::udp 和 ip::icmp。当然它也是可扩展的，你可以创建自己的socket类，尽管这相当复杂。我们知道在网络通信中有两种 socket 类型，即监听客户端连接的socket，以及用于后续和客户端通信的socket。\n\n下面介绍 socket 相关的函数，这些函数用来连接或绑定socket、断开socket字连接以及查询连接是活动还是非活动的：\n\n- assign(protocol,socket)：这个函数分配了一个原生的 socket 给这个 socket 实例。当处理老（旧）程序时会使用它（也就是说，原生socket已经被建立了）\n- open(protocol)：这个函数用给定的 IP 协议（v4 或者 v6）打开一个 socket。你主要在 UDP/ICMP socket，或者服务端 socket 上使用\n- bind(endpoint)：这个函数绑定到一个地址\n- connect(endpoint)：这个函数用同步的方式连接到一个地址\n- async_connect(endpoint)：这个函数用异步的方式连接到一个地址\n- is_open()：如果套接字已经打开，这个函数返回 true\n- close()：这个函数用来关闭套接字。调用时这个套接字上任何的异步操作都会被立即关闭，同时返回 error::operation_aborted 错误码\n- shutdown(type_of_shutdown)：这个函数立即使 send 或者 receive 操作失效，或者两者都失效\n- cancel()：这个函数取消套接字上所有的异步操作。这个套接字上任何的异步操作都会立即结束，然后返回 error::operation_aborted 错误码\n\n创建用于接收客户端连接的 socket\n\n```c++\nio_context ic;\ntcp protocol = tcp::v4();\ntcp::acceptor acceptor(ic);\nacceptor.open(protocol);\n```\n\n创建用于通信的 socket\n\n```c++\nio_context ic;\ntcp protocol = tcp::v4();\ntcp::socket sock(ic);\nsock.open(protocol);\n```\n\n## 绑定acceptor\n\n```c++\n// 服务端需要创建的端点\n    int server_port = 8080;\n    tcp::endpoint s_ep(address_v4::any(), server_port);\n\n// 创建用于接收客户端连接的 socket 类型，即 acceptor\n    io_context ic;\n    tcp protocol = tcp::v4();\n    tcp::acceptor acceptor(ic);\n    acceptor.open(protocol);\n\n// 绑定 端点和acceptor\n    acceptor.bind(s_ep);\n```\n\n将 acceptor 绑定到 端点，意味着在这个端点上进行客户端连接的接收，即所有连接这个端点的连接都可以被接收到。\n\n## 连接指定的端点\n\n```c++\n//  创建端点，记录服务器的信息   \n    string ip = \"192.168.1.12\";\n    int port = 8080;\n    tcp::endpoint ep(address::from_string(ip), port);\n\n//  连接到服务器\n    io_context ic;\n    tcp::socket sock(ic, ep.protocol());\n    sock.connect(ep);\n\n// 后续就可以通信了\n```\n\n作为客户端可以连接服务器指定的端点进行连接，用于后续通信。\n\n## 服务器接收连接\n\n```c++\n    const int BACKLOG_SIZE = 30;\n    int server_port = 8080;\n    tcp::endpoint s_ep(address_v4::any(), server_port);\n\n// 创建用于接收客户端连接的 socket 类型，即 acceptor\n    io_context ic;\n    tcp protocol = tcp::v4();\n    tcp::acceptor acceptor(ic);\n    acceptor.open(protocol);\n\n// 绑定、监听、接收客户端连接\n    acceptor.bind(s_ep);\n    acceptor.listen(BACKLOG_SIZE);\n\n    tcp::socket c_socket(ic);\n    acceptor.accept(c_socket);\n\n// 后续就可以和客户端通信了\n```\n\n当有客户端连接时，服务器需要接收连接，如何就可以完成这个工作。\n\n---\n\n⭐️内容取自 B 站 UP 恋恋风辰和 mmoaay 的《Boost.Asio C++ 网络编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议看原视频或者读原书。","tags":["网络编程","Asio"],"categories":["technology"]},{"title":"生成可执行文件的过程","url":"/2024/08/28/生成可执行文件的过程/","content":"\n![编译流程.png](/images/2024/08/28/9e339a00-6547-11ef-822d-8d911ea6426b.png)\n1. 预处理：执行预处理指令\n2. 编译：将预处理后的文件翻译成汇编代码\n3. 汇编：将汇编代码翻译成机器指令，生成目标文件\n4. 链接：将目标文件和库文件链接起来，得到可执行文件\n\n目标文件一般分为三种：\n- 可重定位的目标文件：汇编器生成的目标文件是可重定位的目标文件，是不可执行的，需要链接器经过链接、重定位之后才能运行\n- 可执行的目标文件：即可直接执行的文件，由程序转换为进程\n- 可被共享的目标文件：可被共享的目标文件一般以共享库的形式存在，在程序运行时需要动态加载到内存，跟应用程序一起运行","tags":["C"],"categories":["technology"]},{"title":"i++ 和 ++i 的区别","url":"/2024/08/28/i-和-i-的区别/","content":"\n```c++\n#define _CRT_SECURE_NO_WARNINGS\n\n#include <stdio.h>\n\nint main(void) {\n\t\n\tint i;\n\n\ti = 0;\n\tprintf(\"i++ = %d\\n\", i++);\n\tprintf(\"i = %d\\n\", i);\n\n\ti = 0;\n\tprintf(\"++i = %d\\n\", ++i);\n\tprintf(\"i = %d\\n\", i);\n\n\treturn 0;\n}\n```\n\n输出结果：\n\n```tex\ni++ = 0\ni = 1\n++i = 1\ni = 1\n```\n\n不管是 i++ 还是 ++i 最终都会让 i 产生副作用，即都会使得 i 在原来的基础上 加 1。二者的区别在于 `++i` 的值 代表 i+1，而 `i++` 的值 代表 i。即 ++i 会立即产生自增的效果，而 i++ 不会立即产生自增的效果。\n\n```c\ni++ 对应的汇编代码\n\n0042186C  mov         eax,dword ptr [i]        \t\t; 将变量 i 的值加载到 eax 寄存器中\n0042186F  mov         dword ptr [ebp-0D0h],eax    ; 将 eax 中的值（即 i 的当前值）存储到内存（临时变量）\n00421875  mov         ecx,dword ptr [i]        \t\t; 再次加载 i 的值到 ecx 寄存器\n00421878  add          ecx,1                    \t       ; 对 ecx 中的 i 进行递增操作\n0042187B  mov         dword ptr [i],ecx        \t\t; 将递增后的值存储回 i\n0042187E  mov         edx,dword ptr [ebp-0D0h]   ; 将最初保存的 i 的值加载到 edx\n00421884  push        edx                      \t\t     ; 将最初的 i 值压入堆栈，用于 printf 输出\n00421885  push        offset string \"%lld\\n\"   \t     ; 压入字符串格式化参数\n0042188A  call          _printf                  \t\t; 调用 printf 函数\n0042188F  add          esp,8                   \t            ; 调整堆栈指针\n\n\n++i 对应的汇编代码\n\n004218AA  mov         eax,dword ptr [i]        \t\t\t; 将变量 i 的值加载到 eax 寄存器中\n004218AD  add         eax,1                    \t\t\t      ; 对 eax 中的 i 进行递增操作\n004218B0  mov         dword ptr [i],eax       \t\t       ; 将递增后的值存储回 i\n004218B3  mov         ecx,dword ptr [i]        \t\t\t; 再次加载递增后的 i 到 ecx 寄存器\n004218B6  push        ecx                     \t\t\t     ; 将递增后的 i 值压入堆栈，用于 printf 输出\n004218B7  push        offset string \"++i = %d\\n\" \t   ; 压入字符串格式化参数\n004218BC  call         _printf                  \t\t\t; 调用 printf 函数\n004218C1  add         esp,8                    \t\t\t     ; 调整堆栈指针\n```\n\n解读：\n\n从 ++i 的汇编代码可以看出是 先让 i 执行自增操作之后才打印 i 的值，所以打印结果为 1。\n\ni++ 的汇编代码是把 i 最初的值转存到其他临时地址，并读取原始 i 的值进行自加后放到其他寄存器，然后再把之前存储到临时地址的 i 的数据用于输出，所以打印结果为 0。\n\n总结：\n\n`i++` 先使用 `i` 的原值，再递增。这就需要在递增之前保存 `i` 的原值，以便在后续操作中使用。\n\n`++i` 先递增 `i`，然后使用递增后的值。这个过程更简单，不需要保存原值，因为递增操作已经完成。\n","tags":["C"],"categories":["technology"]},{"title":"类型转换","url":"/2024/08/28/类型转换/","content":"\n<!-- toc -->\n\n## 隐式转换\n\n即不需要程序员手动添加转换规则，而是由编译器自动转换，为了避免隐式转换可能带来的安全隐患（不被程序员控制，可能导致数据溢出），需要列举出会发生隐式转换的情况。总的来说，当给定的类型与需要的类型不同时，就可能发生隐式转换。\n\n1. 如果操作数中有任何低于 int 和 unsigned int 的类型，会首先将该操作数转换为 int 类型或者 unsigned int 类型，这个过程我们称之为整数提升\n2. int --> long --> long long --> float --> double --> long double（等级由低到高，低等级向高等级隐式转换）\n3. **同一转换等级**的有符号整数和无符号整数一起参与运算时：有符号整数会转换成对应的无符号整数\n\n最好尽量避免使用无符号整数，特别是不要把它和有符号整数混合使用。（无符号整数一般用于底层开发中，在应用层面很少会使用）。\n\n```c++\nint i = -10;\nunsigned int u = 10;\nif(i < u)\n\tprintf(\"i is less than u\\n\");\n```\n\n由于 int 会向 unsigned int 转换（因为你在 if 判断语句中 用 int 类型数据和 unsigned int 数据进行比较），导致 i 会变成一个非常大的数，所以出现不符合题意的判断了。\n\n## 显式转换\n\n需要程序员手动给出需要强转的类型。比方说将 int 类型强制转换为 float 类型。\n\n```c++\nint x = 10;\n\nprintf(\" x = %f\\n\", (float)x);\n```\n\n那为什么需要显示转换呢？\n\n1. 使用强制类型转换显示表明肯定会发生的转换\n2. 使用强制类型转换进行我们需要的类型转换\n3. 可以用强制类型转换计算浮点数的小数部分\n4. 可以使用强制类型转换来避免溢出\n\n示例：可以用强制类型转换计算浮点数的小数部分\n\n```c++\nvoid fun() {\n\tfloat num2 = 3.176;\n\tfloat num1 = num2 - (int)num2;\n\n\tprintf(\"%f\", num1);\t\t// 0.176000\n}\n```\n\n示例：可以使用强制类型转换来避免溢出\n\n```c++\nvoid fun() {\n\tlong long millisPerDay = 24 * 60 * 60 * 1000;\n\tlong long nanosPerDay = 24 * 60 * 60 * 1000 * 1000 * 1000;\n       printf(\"%lld\\n\", nanosPerDay / millisPerDay);\t\t// 1000000\n}\n```\n\nmillisPerDay 和 nanosPerDay 变量没有溢出，但不代表 等号 右边的数据没有溢出。即哪怕是常量也是有数据类型的，那就意味着有一定的存储范围，` 24 * 60 * 60 * 1000 * 1000 * 1000` 这是 6 个 int 类型的数据相乘，完全超出 int 数据类型表示的范围了。\n\n```c++\nvoid fun() {\n\tlong long millisPerDay = 24 * 60 * 60 * 1000;\n\tlong long nanosPerDay = (double)24 * 60 * 60 * 1000 * 1000 * 1000;\n\tprintf(\"%lld\\n\", nanosPerDay / millisPerDay);\n}\n```\n\n注意：强制转换中，如果宽度长的转换到宽度低的会丢失精度。","tags":["C"],"categories":["technology"]},{"title":"变量和常量","url":"/2024/08/28/变量和常量/","content":"\n<!-- toc -->\n\n## 变量的本质\n\n在C语言中，不同类型的数据有不同的存储方式，在内存中所占的大小不同，地址对齐方式也不相同。我们可以使用不同的数据类型来定义变量，不同类型的变量在内存中的存储方式和大小也不相同。\n\n```c++\n#define _CRT_SECURE_NO_WARNINGS\n#include <stdio.h>\n\nint main(void) {\n\tint x = 10;\n\tchar c = 'A';\n\n\tprintf(\" x 字节大小 = %d\\n\", sizeof(x));\n\tprintf(\" c 字节大小 = %d\\n\", sizeof(c));\n\n\treturn 0;\n}\n```\n\n输出结果：\n\n```\nx 字节大小 = 4\nc 字节大小 = 1\n```\n\n数据类型定义字节大小，变量名是内存地址的别名，存储实际数据。这个内存地址是存储实际数据的起始地址，而数据类型的字节大小就表明从这个起始地址开始读取的字节大小，这样就能够找到对应存储的实际数据，不会多读，也不会少读。\n\n变量名的本质，其实就是一段内存空间的别名。编译器在编译程序时会将变量名看成一个符号，符号值即变量的地址，各种不同的符号保存在符号表中。我们可以通过变量名对和它绑定的内存单元进行读写，而不是直接使用内存地址。通过变量名访问内存，既方便了程序的编写，也大大增强了程序的可读性。\n\n![变量本质.png](/images/2024/08/28/7a75c780-6521-11ef-b96b-3728f540b1e8.png)\n\n不同类型的变量有不同的存储方式、作用域和生命周期。在定义一个变量时，我们可以使用char、int、float、double等关键字来指定变量的类型，再加上short和long这两个整型限定符，基本上就确定了这个变量在内存中的存储空间的大小。有时候我们还可以使用一些变量修饰限定符来改变变量的存储方式，常用的修饰符有auto、register、static、extern、const、volatile、restrict、typedef等。这些修饰限定符往往会决定变量的存储位置、作用域或生命周期，所以一般也被称为存储类关键字。\n\n![不同类型的变量存储.png](/images/2024/08/28/769b4c70-6521-11ef-b96b-3728f540b1e8.png)\n\n## 常量折叠\n\n```c++\nint val = 3 * 4 + 5 * 2;\n```\n\n查看变量地址存储数据：\n\n![常量.png](/images/2024/08/28/71ec1c40-6521-11ef-b96b-3728f540b1e8.png)\n\n十六进制 00000016 转换成 十进制为 22，所以当一个C语言程序中存在常量表达式时，编译器在编译时会把常量表达式优化成一个固定的常量值，以节省存储空间。我们把这种编译优化称为常量折叠。\n---\n⭐️内容取自王利涛《嵌入式自我修养》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["C"],"categories":["technology"]},{"title":"宏定义和宏函数","url":"/2024/08/28/宏定义和宏函数/","content":"\n<!-- toc -->\n\n## 宏定义\n\n```c++\n#define N 5\n```\n\n切记，宏定义的后面没有`;`\n\n实际上任何以 # 开头的预定义后面都不能有分号，毕竟文本替换会把这个分号一并带过去，那么必然照成错误。\n\n```c++\n#define _CRT_SECURE_NO_WARNINGS\n\n#include <stdio.h>\n\n#define N 5;\t\t// 测试如果添加 分号 会造成什么错误\n\nint main(void) {\n\n\tint num = N * N;\n\n\treturn 0;\n}\n```\n\n测试结果：\n\n![宏定义.png](/images/2024/08/28/6c504320-6516-11ef-b96b-3728f540b1e8.png)\n\n## 宏函数\n\n宏函数要注意的地方就是，一定要学会添加括号`()`\n\n1. 参数要加括号\n2. 整个表达式要加括号\n3. 左括号要紧靠宏函数名称\n\n```c++\n#define _CRT_SECURE_NO_WARNINGS\n\n#include <stdio.h>\n\n#define FUN(x) x * x\n\nint main(void) {\n\tint x = 10;\n\tint y = 20;\n\tprintf(\"x * x = %d\", FUN(x + y));\n\n\treturn 0;\n}\n```\n\n查看预编译情况：\n\n![宏函数1.png](/images/2024/08/28/67877070-6516-11ef-b96b-3728f540b1e8.png)\n\n预处理语句就是单纯的文本替换，所有对于宏函数务必严格添加合适的括号来保证语句逻辑的合理性。\n\n```c++\n#define FUN(x) ((x) * (x))\n```\n\n再次查看预编译情况：\n\n![宏函数2.png](/images/2024/08/28/632cc8e0-6516-11ef-b96b-3728f540b1e8.png)\n\n如果左括号没有紧靠宏函数，会如何？这其实很容易被人忽视，还是先看看现象：\n\n![宏函数3.png](/images/2024/08/28/5ee7f340-6516-11ef-b96b-3728f540b1e8.png)\n\n没错，如果你左括号没有紧靠宏函数，那么这将是宏定义，而非一个宏函数了。\n\n当然，前面写的宏函数都是一行代码，如果是多行的那种代码，注意分行。\n\n```c\n#define MAX(a, b) \\\n    ({ \\\n        typeof(a) _a = (a); \\\n        typeof(b) _b = (b); \\\n        _a > _b ? _a : _b; \\\n    })\n```\n\n除了最后一行不用添加 `\\`，其余行都要添加。宏的每一行都以反斜杠（`\\`）结尾，以指示宏定义的行继续到下一行。在宏定义的最后一行，反斜杠并不需要，因为没有更多的行继续定义宏。如果在最后一行添加反斜杠，它实际上是多余的，因为宏定义已经结束。","tags":["C"],"categories":["technology"]},{"title":"131.分割回文串","url":"/2024/08/27/131-分割回文串/","content":"\n```c++\nclass Solution {\nprivate:\n    vector<vector<string>> result;\n    vector<string> path;\npublic:\n    // 判断是否为回文串\n    bool isReStr(const string& str){\n        int left = 0;\n        int right = str.size() - 1;\n        while(left <= right){\n            if(str[left] != str[right]){\n                return false;\n            }\n            left++;\n            right--;\n        }\n        return true;\n    }\n\n    void backtrace(string s,int start){\n        if(start == s.size()){\n            result.push_back(path);\n            return;\n        }\n        for(int i = start; i < s.size(); i++){\n            string data = s.substr(start,i - start + 1);\t\t// 核心\n            if(isReStr(data)){  \n                path.push_back(data);\n                backtrace(s,i + 1);\t\t\t\t\t\t    // 核心\n                path.pop_back();\n            }\n        }\n    }\n\n    vector<vector<string>> partition(string s) {\n        backtrace(s,0);\n        return result;\n    }\n};\n```\n\n这道题没有能够做出来，尽管对于切割有些思路了，但是对于 substr 方法有些误解（后面详细谈一谈它的用法），导致实际返回的容器中有很多重复项。\n\n再有就是对 ` s.substr(start,i - start + 1) ` 语句没有理解透彻，这是用来切割可能要加入到路径中的字符。首先 start 指明要切割字符串的起始地址，而 substr 的第二个参数要填写切割的长度，由于 i 代表的是指向当前字符串的终止位置（不一定就是字符串的最后位置），且最初 i = start，那么至少要切割一个字符，因此是 i - start + 1。由于切割的字符串得是回文字符串才会再次进入循环， 否则一直不断增加切割长度，直到出现回文字符串，否则退出当前循环，这也是为什么要 i - start + 1，假定这次不满足，下一次循环中 i 会自增，而 start 保持不变，也就实现继续切割。\n\n![切割字符串.png](/images/2024/08/27/71955150-647f-11ef-9ca4-574185f1c035.png)\n\n再一个重点就是 `backtrace(s,i + 1)` ，我们注意看传递进去的第二个参数的含义，即 切割字符串的起始位置，你可能会误写成 start + 1，但实际上是 i + 1，因为 i 指向被切割字符的最后的位置，所以下一个被切割字符串的位置是 i + 1。因为 [start,i] 区间内的字符串已经被处理了，所以下一次切割的地址是 i + 1，而不是 start + 1。\n\n---\n\n```c++\nstring substr (size_t pos = 0, size_t len = npos) const;\n```\n\npos 代表切割字符串的起始地址\n\nlen 代表从指定起始地址开始切割的长度\n\n```c++\nstring name = \"aahswl\";\n\ncout << name.substr(0, 2) <<endl;\n\ncout << name.substr(4, 3) << endl;\n\n/*\n\taa\n\twl\n*/\n```\n\n主要强调第二个切割，明明指定长度加上起始位置已经超出 name 字符串的长度，但还是切割成功，所以即便只能切割到最后两个字符串了（因为按理我们要切割长度为三的字符串），这也是切割成功，返回字符串 wl。\n\n如果 len 等于字符串长度，返回空字符串；如果 len 大于 字符串长度，抛出异常。","tags":["回溯"],"categories":["leetcode"]},{"title":"策略模式","url":"/2024/08/22/策略模式/","content":"\n假如你需要前往机场。 你可以选择乘坐公共汽车、 预约出租车或骑自行车。 这些就是你的出行策略。 你可以根据预算或时间等因素来选择其中一种策略。\n\n![策略模式.png](/images/2024/08/22/570136c0-608c-11ef-8a04-1b1053f71f15.png)\n\n在策略模式定义了一系列算法或策略，并将每个算法封装在独立的类中，使得它们可以互相替换。通过使用策略模式，可以在运行时根据需要选择不同的算法，而不需要修改客户端代码。\n\n```c++\n#include <iostream>\n#include <memory>\nusing namespace std;\n\nclass Strategy {\n public:\n  virtual void toAirport() = 0;     // 统一策略接口\n  virtual ~Strategy() = default;\n};\n\n// 分别实现每个策略，以后有新策略添加，只需要新建一个类\n// 即 一个 class 代表 一个 策略\n\nclass Bike : public Strategy {\n public:\n  void toAirport() override {\n    std::cout << \"Biking to the airport costs $0\" << std::endl;\n  }\n};\n\nclass Shuttle : public Strategy {\n public:\n  void toAirport() override {\n    std::cout << \"Shuttle to the airport costs $2\" << std::endl;\n  }\n};\n\nclass Cab : public Strategy {\n public:\n  void toAirport() override {\n    std::cout << \"Cab to the airport costs $3\" << std::endl;\n  }\n};\n\nclass Context {\n public:\n  Context(std::unique_ptr<Strategy> strategy) : strategy_(std::move(strategy)) { }\n\n  void toAirport() {\n    strategy_->toAirport();\n  }\n\n  void setStrategy(std::unique_ptr<Strategy> strategy) {\n    strategy_ = std::move(strategy);\n  }\n\n private:\n  std::unique_ptr<Strategy> strategy_;\n};\n```\n\n客户端测试代码：\n\n```c++\nint main() {\n    \n  auto bike = std::make_unique<Bike>();\n  Context context(std::move(bike));\n  context.toAirport();\n\n  auto cab = std::make_unique<Cab>();\n  context.setStrategy(std::move(cab));\n  context.toAirport();\n\n  return 0;\n}\n\n/*\nBiking to the airport costs $0\nCab to the airport costs $3\n*/\n```\n\n由于这是开篇的第一个设计模式的讲解，需要特别说明几点：\n\n- 如果你的系统没有任何可变，那你不需要设计模式，因为设计模式是应对变，即后来的扩展而发展出来的。那么在 C++ 中能有变化的就是抽象基类，所以在后续学习设计模式，只要搞清楚这个设计模式去应对哪个地方的变化，然后联想到抽象基类就会很容易写出代码了。就拿此处的策略模式举例，对于去机场有三种策略，这里需要变化的就是各种不同的策略，意味着要有一个抽象基类，这里面提高一个去机场的接口，然后各种策略继承这个接口并实现即可。\n- 抽象基类不能被实例化，但是说可以被声明用来接收各种类型的派生类。\n\n```c++\n// 声明（可以）\nstd::unique_ptr<Strategy> strategy_;\n\n//自身实例化（不可以）\nstd::unique_ptr<Strategy> strategy_ = make_unique<Strategy>();\n\n//定义并接收各种派生类实例化（可以）\nstd::unique_ptr<Strategy> strategy_ = make_unique<Bike>();\n```\n最后，我们还是要说一下策略模式的缺点：\n\n- 客户端必须知道所有的策略类，并自行决定使用哪一个策略类。\n- 策略模式将造成产生很多策略类。","tags":["设计模式"],"categories":["technology"]},{"title":"第五章：文件系统","url":"/2024/08/22/第五章：文件系统/","content":"\n<!-- toc -->\n\n## I/O设备\n\n下面你会对操作系统如何与设备交互有基本的理解。本章将介绍了两种技术，中断和 DMA，用于提高设备效率。我们还会介绍访问设备寄存器的两种方式， I/O 指令和内存映射 I/O。最后，我们还介绍了设备驱动程序的概念，展示了操作系统本身如何封装底层细节，从而更容易以设备无关的方式构建操作系统的其余部分。\n\n### 系统架构\n\n我们先看一个典型系统的架构。其中， CPU 通过某种内存总线或互连电缆连接到系统内存。图像或者其他高性能 I/O 设备通过常规的I/O 总线连接到系统，在许多现代系统中会是 PCI 或它的衍生形式。最后，更下面是外围总线，它们将最慢的设备连接到系统，包括磁盘、鼠标及其他类似设备。  \n\n![原型系统架构.png](/images/2024/08/22/3bfa3900-6071-11ef-b5d8-395e250ad2a7.png)\n\n系统的设计采用了这种分层的方式，这样可以让要求高性能的设备（比如显卡）离 CPU 更近一些，低性能的设备离 CPU 远一些。将磁盘和其他低速设备连到外围总线的好处很多，其中较为突出的好处就是你可以在外围总线上连接大量的设备。\n\n### 标准设备\n\n现在来看一个标准设备（不是真实存在的），通过它来帮助我们更好地理解设备交互的机制。\n\n![标准设备.png](/images/2024/08/22/32d64990-6071-11ef-b5d8-395e250ad2a7.png)\n\n可以看到一个包含两部分重要组件的设备：\n\n1. 向系统其他部分展现的硬件接口。同软件一样，硬件也需要一些接口，让系统软件来控制它的操作。因此，所有设备都有自己的特定接口以及典型交互的协议。\n2. 内部结构部分包含设备相关的特定实现，负责具体实现设备展示给系统的抽象接口。非常简单的设备通常用一个或几个芯片来实现它们的功能。更复杂的设备会包含简单的 CPU、一些通用内存、设备相关的特定芯片，来完成它们的工作。  \n\n### 标准协议\n\n如上图所示，一个（简化的）设备接口包含 3 个寄存器：一个状态（status）寄存器，可以读取并查看设备的当前状态；一个命令（command）寄存器，用于通知设备执行某个具体任务；一个数据（data）寄存器，将数据传给设备或从设备接收数据。通过读写这些寄存器，操作系统可以控制设备的行为。  \n\n![协议.png](/images/2024/08/22/294abeb0-6071-11ef-b5d8-395e250ad2a7.png)\n\n1. 通过轮训的方式持续读取 STATUS\n2. 操作系统下发数据到数据寄存器\n3. 写入命令到寄存器中，这样设备就知道数据已经准备好了，它应该开始执行命令\n4. 操作系统再次通过不断轮询设备，等待并判断设备是否执行完成命令（有可能得到一个指示成功或失败的错误码）\n\n这个简单的协议好处是足够简单并且有效。但是难免会有一些低效和不方便。我们注意到这个协议存在的第一个问题就是轮询过程比较低效，在**等待设备执行完成命令时浪费大量 CPU 时间，如果此时操作系统可以切换执行下一个就绪进程，就可以大大提高 CPU 的利用率**。    \n\n### 利用中断减少 CPU 开销\n\n有了中断后， CPU 不再需要不断轮询设备，而是向设备发出一个请求，然后就可以让对应进程睡眠，切换执行其他任务。当设备完成了自身操作，会抛出一个硬件中断，引发 CPU 跳转执行操作系统预先定义好的中断服务例程，或更为简单的中断处理程序。中断处理程序是一小段操作系统代码，它会结束之前的请求（比如从设备读取到了数据或者错误码）并且唤醒等待 I/O 的进程继续执行。  \n\n如果我们不用中断，而是轮训，那么进程 CPU 会一直等待 I/O 操作完成，如下图所示：\n\n![轮询.png](/images/2024/08/22/212a3580-6071-11ef-b5d8-395e250ad2a7.png)\n\n但是，在 CPU 等待的这段时间完全可以把 CPU 资源让给其他进程，如果这边 I/O 完成再把 CPU 资源拿过来继续往下执行任务。在下面这个例子中，在磁盘处理进程 1 的请求时，操作系统在 CPU 上运行进程 2。磁盘处理完成后，触发一个中断，然后操作系统唤醒进程 1 继续运行。这样，在这段时间，无论CPU 还是磁盘都可以有效地利用。  \n\n![中断.png](/images/2024/08/22/1b6db400-6071-11ef-b5d8-395e250ad2a7.png)\n\n### 利用 DMA 进行更高效的数据传送  \n\n进程 1 在运行过程中需要向磁盘写一些数据，所以它开始进行 I/O 操作，将数据从内存拷贝到磁盘（其中标示 c 的过程）。拷贝结束后，磁盘上的 I/O 操作开始执行，此时 CPU 才可以处理其他请求。  \n\n![内存拷贝到磁盘.png](/images/2024/08/22/131cf310-6071-11ef-b5d8-395e250ad2a7.png)\n\n也就是说将内存数据拷贝到磁盘，是 CPU 来完成。为了让 CPU 得到更好的利用，我们应该把这个工作，即将内存数据拷贝到磁盘交给其他人来完成，也就是我们要介绍的 DMA。DMA 引擎是系统中的一个特殊设备，它可以协调完成内存和设备间的数据传递，不需要 CPU 介入。  \n\nDMA 工作过程如下。为了能够将数据传送给设备，操作系统会通过编程告诉 DMA 引擎数据在内存的位置，要拷贝的大小以及要拷贝到哪个设备。在此之后，操作系统就可以处理其他请求了。当 DMA 的任务完成后， DMA 控制器会抛出一个中断来告诉操作系统自己已经完成数据传输。\n\n![DMA.png](/images/2024/08/22/0add9740-6071-11ef-b5d8-395e250ad2a7.png)\n\n从时间线中可以看到，数据的拷贝工作都是由 DMA 控制器来完成的。因为 CPU 在此时是空闲的，所以操作系统可以让它做一些其他事情，比如此处调度进程 2 到 CPU 来运行。因此进程 2 在进程 1 再次运行之前可以使用更多的 CPU。  \n\n### 设备交互的方法\n\n你可能已经注意到了一个问题：我们还没有真正讨论过操作系统究竟如何与设备进行通信！\n\n1. 用明确的 I/O 指令。这些指令规定了操作系统将数据发送到特定设备寄存器的方法，从而允许构造上文提到的协议。例如在 x86 上， in 和 out 指令可以用来与设备进行交互。当需要发送数据给设备时，调用者指定一个存入数据的特定寄存器及一个代表设备的特定端口。执行这个指令就可以实现期望的行为。\n2. 内存映射 I/O（memory- mapped I/O）。通过这种方式，硬件将设备寄存器作为内存地址提供。当需要访问设备寄存器时，操作系统装载（读取）或者存入（写入）到该内存地址；然后硬件会将装载/存入转移到设备上，而不是物理内存。  \n\n### 纳入操作系统：设备驱动程序  \n\n在最底层，操作系统的一部分软件清楚地知道设备如何工作，我们将这部分软件称为设备驱动程序，所有设备交互的细节都封装在其中。\n\n我们来看看 Linux 文件系统栈，理解抽象技术如何应用于操作系统的设计和实现。下图粗略地展示了 Linux 软件的组织方式。可以看出，文件系统（当然也包括在其之上的应用程序）完全不清楚它使用的是什么类型的磁盘。它只需要简单地向通用块设备层发送读写请求即可，块设备层会将这些请求路由给对应的设备驱动，然后设备驱动来完成真正的底层操作。尽管比较简单，但下图展示了这些细节如何对操作系统的大部分进行隐藏。  \n\n![Linux文件系统.png](/images/2024/08/22/05099620-6071-11ef-b5d8-395e250ad2a7.png)\n\n### 中断和轮询各有应用场景\n\n中断并不是适用于所有的场景，假如有一个非常高性能的设备，它处理请求很快：通常在 CPU 第一次轮询时就可以返回结果。此时如果使用中断，反而会使系统变慢：切换到其他进程，处理中断，再切换回之前的进程代价不小。因此，如果设备非常快，那么最好的办法反而是轮询。如果设备比较慢，那么采用允许发生重叠的中断更好。如果设备的速度未知，或者时快时慢，可以考虑使用混合策略，先尝试轮询一小段时间，如果设备没有完成操作，此时再使用中断。这种两阶段的办法可以实现两种方法的好处。  \n\n另一个最好不要使用中断的场景是网络。网络端收到大量数据包，如果每一个包都发生一次中断，那么有可能导致操作系统发生活锁，即不断处理中断而无法处理用户层的请求。例如，假设一个 Web 服务器因为“点杠效应”而突然承受很重的负载。这种情况下，偶尔使用轮询的方式可以更好地控制系统的行为，并允许 Web 服务器先服务一些用户请求，再回去检查网卡设备是否有更多数据包到达。  \n\n另一个基于中断的优化就是合并。设备在抛出中断之前往往会等待一小段时间，在此期间，其他请求可能很快完成，因此多次中断可以合并为一次中断抛出，从而降低处理中断的代价。当然，等待太长会增加请求的延迟，这是系统中常见的折中。  \n\n## 磁盘驱动器\n\n### 基本几何形状\n\n![磁道.png](/images/2024/08/22/fd2d41e0-6070-11ef-b5d8-395e250ad2a7.png)\n\n盘片：是一个圆形坚硬的表面，通过引入磁性变化来永久存储数据。磁盘可能有一个或多个盘片。每个盘片有两面，每面都称为表面。这些盘片通常由一些硬质材料（如铝）制成，然后涂上薄薄的磁性层，即使驱动器断电，驱动器也能持久存储数据位。  \n\n主轴（转轴）：所有盘片都围绕主轴连接在一起，主轴连接到一个电机，以一个恒定（固定）的速度旋转盘片（当驱动器接通电源时）。  \n\n磁道：数据在扇区的同心圆中的每个表面上被编码。 我们称这样的同心圆为一个磁道（track）。一个表面包含数以千计的磁道，紧密地排在一起，数百个磁道只有头发的宽度。  \n\n读写磁头：要从表面进行读写操作，我们需要一种机制， 使我们能够感应（即读取）磁盘上的磁性图案，或者让它们发生变化（即写入）。读写过程由磁头完成；驱动器的每个表面有一个这样的磁头。  \n\n磁臂：磁头连接到单个磁盘臂上，磁盘臂在表面上移动，将磁头定位在期望的磁道上。  \n\n---\n\n图中的磁道和扇区容易看不清楚，这边单独拿出来，见下图：\n\n![扇区和磁道.png](/images/2024/08/22/f101ded0-6070-11ef-b5d8-395e250ad2a7.png)\n\n盘面中一圈圈灰色同心圆为一条条磁道，从圆心向外画直线，可以将磁道划分为若干个弧段，每个磁道上一个弧段被称之为一个扇区（图践绿色部分）。扇区是磁盘的最小组成单元，通常是512字节。（由于不断提高磁盘的大小，部分厂商设定每个扇区的大小是4096字节）\n\n### 简单的磁盘驱动器\n\n该磁道只有 12 个扇区，每个扇区的大小为 512 字节（典型的扇区大小，回忆一下），因此用 0 到 11 的数字表示。这里的单个盘片围绕主轴旋转，电机连接到主轴。当然，磁道本身并不太有趣，我们希望能够读取或写入这些扇区，因此需要一个连接到磁盘臂上的磁头。\n\n![磁道.png](/images/2024/08/22/e85b35b0-6070-11ef-b5d8-395e250ad2a7.png)\n\n**（一）单磁道延迟：旋转延迟**\n\n在我们的简单磁盘中，磁盘不必做太多工作。 具体来说，它必须等待期望的扇区旋转到磁头下。这种等待在现代驱动器中经常发生，并且是 I/O 服务时间的重要组成部分，它有一个特殊的名称：旋转延迟。\n\n在这个例子中，如果完整的旋转延迟是 R，那么磁盘必然产生大约为 R/2 的旋转延迟，以等待 0 来到读/写磁头下面（如果我们从 6 开始）。对这个单一磁道，最坏情况的请求是第 5 扇区，这导致接近完整的旋转延迟，才能服务这种请求。  \n\n**（二）多磁道：寻道时间**\n\n到目前为止，我们的磁盘只有一条磁道，这是不太现实的。现代磁盘当然有数以百万计的磁道。因此，我们来看看更具现实感的磁盘表面，这个表面有 3 条磁道。在该图中，磁头当前位于最内圈的磁道上（它包含扇区 24～35）。下一个磁道包含下一组扇区（12～23），最外面的磁道包含最前面的扇区（0～11）。  \n\n![多磁道.png](/images/2024/08/22/e2c09410-6070-11ef-b5d8-395e250ad2a7.png)\n\n为了理解驱动器如何访问给定的扇区，我们现在追踪请求发生在远处扇区的情况，例如，读取扇区 11。\n\n为了服务这个读取请求，驱动器必须首先将磁盘臂移动到正确的磁道（在这种情况下，是最外面的磁道），通过一个所谓的**寻道**过程。寻道之后，磁盘臂将磁头定位在正确的磁道上。如你所见，在寻道过程中，磁盘臂已经移动到所需的磁道上，并且盘片当然已经开始旋转，在这个例子中，大约旋转了 3 个扇区。因此，扇区 9 即将通过磁头下方，我们只能承受短暂的转动延迟，以便完成传输。当扇区 11 经过磁盘磁头时， I/O 的最后阶段将发生，称为**传输**，数据从表面读取或写入表面。\n\n因此，我们得到了完整的 I/O 时间图：**首先寻道，然后等待转动延迟，最后传输**。  \n\n### 磁盘调度\n\n与任务调度不同，每个任务的长度通常是不知道的，对于磁盘调度，我们可以很好地猜测“任务”（即磁盘请求）需要多长时间。通过估计请求的查找和可能的旋转延迟，磁盘调度程序可以知道每个请求将花费多长时间， 因此（贪婪地）选择先服务花费最少时间的请求。\n\n**（一）SSTF：最短寻道时间优先**\n\nSSTF 按磁道对 I/O 请求队列排序，选择在最近磁道上的请求先完成。例如，假设磁头当前位置在内圈磁道上，并且我们请求扇区 21（中间磁道）和 2（外圈磁道），那么我们会首先发出对 21 的请求，等待它完成，然后发出对 2 的请求。\n\n![SSTF.png](/images/2024/08/22/dbb76e50-6070-11ef-b5d8-395e250ad2a7.png)\n\n**（二）电梯（又称 SCAN 或 C-SCAN）**\n\n因为它的行为像电梯，电梯要么向上要么向下，而不只根据哪层楼更近来服务请求。所以一开始选择最近的磁道之后就一直往下走，直到满足选定方向的所有请求。\n\n![SCAN.png](/images/2024/08/22/d70c5cd0-6070-11ef-b5d8-395e250ad2a7.png)\n\n上图是SCAN，SCAN 不一定要走到尽头才回头，而是满足选定方向的所有请求之后就回头了，当时下面的C-SCAN一定要走到尽头才回头，哪怕尽头没有要满足磁头需求。\n\n![CSCAN.png](/images/2024/08/22/d18f0730-6070-11ef-b5d8-395e250ad2a7.png)\n\n**（三）SPTF：最短定位时间优先**\n\n在这个例子中，磁头当前定位在内圈磁道上的扇区 30上方。因此，调度程序必须决定：下一个请求应该为安排扇区 16（在中间磁道上）还是扇区 8（在外圈磁道上）。接下来应该服务哪个请求？答案当然是“视情况而定”。\n\n在现代驱动器中，正如上面所看到的，查找和旋转大致相当（当然，视具体的请求而定），因此 SPTF 是有用的，它提高了性能。然而，它在操作系统中实现起来更加困难，操作系统通常不太清楚磁道边界在哪， 也不知道磁头当前的位置（旋转到了哪里）。 因此， SPTF通常在驱动器内部执行。\n\n![SPTF.png](/images/2024/08/22/cb44ebb0-6070-11ef-b5d8-395e250ad2a7.png)\n\n## 廉价冗余磁盘阵列（ RAID）\n\nRAID 这种技术使用多个磁盘一起构建更快、更大、更可靠的磁盘系统。从外部看， RAID 看起来像一个磁盘：一组可以读取或写入的块。在内部， RAID 是一个复杂的庞然大物，由多个磁盘、内存（包括易失性和非易失性）以及一个或多个处理器来管理系统。硬件 RAID 非常像一个计算机系统，专门用于管理一组磁盘。\n\n与单个磁盘相比，RAID 具有许多优点。一个好处就是性能。并行使用多个磁盘可以大大加快 I/O 时间。另一个好处是容量。大型数据集需要大型磁盘。最后，RAID 可以提高可靠性。在多个磁盘上传输数据（无 RAID 技术）会使数据容易受到单个磁盘丢失的影响。通过某种形式的冗余，RAID 可以容许损失一个磁盘并保持运行，就像没有错误一样。  \n\n### 接口和 RAID 内部\n\n对于上面的文件系统， RAID 看起来像是一个很大的、（我们希望是）快速的、并且（希望是）可靠的磁盘。就像使用单个磁盘一样， 它将自己展现为线性的块数组，每个块都可以由文件系统（或其他客户端）读取或写入。\n\n当文件系统向 RAID 发出逻辑 I/O 请求时， RAID 内部必须计算要访问的磁盘（或多个磁盘）以完成请求，然后发出一个或多个物理 I/O 来执行此操作。这些物理 I/O 的确切性质取决于 RAID 级别，我们将在下面详细讨论。\n\n### 故障模型\n\n要理解 RAID 并比较不同的方法，我们必须考虑故障模型。 RAID 旨在检测并从某些类型的磁盘故障中恢复。我们假设的第一个故障模型非常简单，并且被称为故障—停止故障模型。在这种模式下，磁盘可以处于两种状态之一：工作状态或故障状态。使用工作状态的磁盘时，所有块都可以读取或写入。相反，当磁盘出现故障时，我们认为它永久丢失。\n\n我们暂时不必担心更复杂的“无声”故障，如磁盘损坏。我们也不必担心在其他工作磁盘上无法访问单个块（有时称为潜在扇区错误）。 稍后我们会考虑这些更复杂的（遗憾的是，更现实的）磁盘错误。\n\n### 如何评估 RAID\n\n容量：在给定一组 N 个磁盘的情况下， RAID 的客户端可用的容量有多少？没有冗余， 答案显然是 N。不同的是，如果有一个系统保存每个块的两个副本，我们将获得 N/2 的有用容量。\n\n可靠性：给定设计允许有多少磁盘故障？根据我们的故障模型，我们只假设整个磁盘可能会故障。\n\n性能：性能有点难以评估，因为它在很大程度上取决于磁盘阵列提供的工作负载。因此，在评估性能之前，我们将首先提出一组应该考虑的典型工作负载。  \n\n### RAID 0 级：条带化\n\n第一个 RAID 级别实际上不是 RAID 级别，因为没有冗余。但是，RAID 0 级因其更为人所知，可作为性能和容量的优秀上限，所以值得了解。\n\n![R0.png](/images/2024/08/22/c39aa3f0-6070-11ef-b5d8-395e250ad2a7.png)\n\n以轮转方式将磁盘阵列的块分布在磁盘上。这种方法的目的是在对数组的连续块进行请求时，从阵列中获取最大的并行性（例如，在一个大的顺序读取中）。我们将同一行中的块称为条带，因此，上面的块 0、 1、 2 和 3 在相同的条带中。\n\n在这个例子中， 我们做了一个简化的假设， 在每个磁盘上只有 1 个块（每个大小为 4KB）放在下一个磁盘上。但是，这种安排不是必然的。在下面这个例子中，我们在每个磁盘上放置两个 4KB 块，然后移动到下一个磁盘。因此，此 RAID 阵列的大块大小为 8KB，因此条带由 4 个大块（或 32KB）数据组成。  \n\n![大块大小.png](/images/2024/08/22/beae1ca0-6070-11ef-b5d8-395e250ad2a7.png)\n\n一方面，大块大小主要影响阵列的性能。另一方面，较大的大块大小减少了这种文件内的并行性，因此依靠多个并发请求来实现高吞吐量。但是，较大的大块大小减少了定位时间。因此，确定“最佳”的大块大小是很难做到的，因为它需要大量关于提供给磁盘系统的工作负载的知识。\n\n### RAID 1 级：镜像\n\n对于镜像系统，我们只需生成系统中每个块的多个副本。当然，每个副本应该放在一个单独的磁盘上。通过这样做，我们可以容许磁盘故障。在下面这个例子中，磁盘 0 和磁盘 1 具有相同的内容，而磁盘 2 和磁盘 3 也具有相同的内容。数据在这些镜像对之间条带化。\n\n![R1.png](/images/2024/08/22/b6975770-6070-11ef-b5d8-395e250ad2a7.png)\n\n从镜像阵列读取块时， RAID 有一个选择：它可以读取任一副本。例如，如果对 RAID发出对逻辑块 5 的读取，则可以自由地从磁盘 2 或磁盘 3 读取它。但是，在写入块时，不存在这样的选择： RAID 必须更新两个副本的数据，以保持可靠性。但请注意，这些写入可以并行进行。例如，对逻辑块 5 的写入可以同时在磁盘 2 和 3 上进行。\n\n### RAID 4 级：通过奇偶校验节省空间\n\n基于奇偶校验的方法试图使用较少的容量，从而克服由镜像系统付出的巨大空间损失。\n\n下面这是 5 个磁盘的 RAID-4 系统的例子。对于每一条数据，我们都添加了一个奇偶校验块，用于存储该条块的冗余信息。例如，奇偶校验块 P1 具有从块 4、5、 6 和 7 计算出的冗余信息。比方说磁盘 0 的 0 块如果损坏，可以利用磁盘 4 中 P0 通过计算推导出 磁盘 0 的 0 块的数据。\n\n![R4.png](/images/2024/08/22/b0f1e060-6070-11ef-b5d8-395e250ad2a7.png)\n\n### RAID 5 级：旋转奇偶校验\n\nRAID-5的工作原理与 RAID-4 几乎完全相同，只是它将奇偶校验块跨驱动器旋转。如你所见，每个条带的奇偶校验块现在都在磁盘上旋转，以消除 RAID-4 的奇偶校验磁盘瓶颈。\n\n![R5.png](/images/2024/08/22/abd82e90-6070-11ef-b5d8-395e250ad2a7.png)\n\n## 文件系统实现\n\n### 思考方式\n\n第一个方面是文件系统的数据结构。换言之，文件系统在磁盘上使用哪些类型的结构来组织其数据和元数据？我们即将看到的第一个文件系统（包括下面的VSFS）使用简单的结构，如块或其他对象的数组，而更复杂的文件系统使用更复杂的基于树的结构。\n\n文件系统的第二个方面是访问方法。如何将进程发出的调用，如 open()、read()、 write()等，映射到它的结构上？在执行特定系统调用期间读取哪些结构？改写哪些结构？所有这些步骤的执行效率如何？\n\n如果理解了这两个方面，可能就理解了文件系统基本工作原理。\n\n### 整体组织\n\n我们现在来开发 VSFS 文件系统在**磁盘上的数据结构**的整体组织。 \n\n我们需要做的第一件事是将磁盘分成块（ block）。简单的文件系统只使用一种块大小，这里正是这样做的。我们选择常用的 4KB。\n\n![分块.png](/images/2024/08/22/a39ffeb0-6070-11ef-b5d8-395e250ad2a7.png)\n\n现在让我们考虑一下，为了构建文件系统，需要在这些块中存储什么。当然，首先想到的是用户数据。实际上，任何文件系统中的大多数空间都是（并且应该是）用户数据。我们将用于存放用户数据的磁盘区域称为数据区域，简单起见，将磁盘的固定部分留给这些块，例如磁盘上 64 个块的最后 56 个：\n\n![存储数据.png](/images/2024/08/22/9cf23f60-6070-11ef-b5d8-395e250ad2a7.png)\n\n文件系统必须记录每个文件的信息。该信息是元数据的关键部分，并且记录诸如文件包含哪些数据块（在数据区域中）、文件的大小，其所有者和访问权限、访问和修改时间以及其他类似信息的事情。为了存储这些信息，文件系统通常有一个名为 **inode** 的结构。\n\n为了存放 inode，我们还需要在磁盘上留出一些空间。我们将这部分磁盘称为 inode 表，它只是保存了一个磁盘上 inode 的数组。因此，假设我们将 64 个块中的 5 块用于 inode，磁盘映像现在看起来如下：\n\n![inode表.png](/images/2024/08/22/95d6a310-6070-11ef-b5d8-395e250ad2a7.png)\n\n到目前为止，我们的文件系统有了数据块（ D）和 inode（ I），但还缺一些东西。你可能已经猜到，还需要某种方法来记录 inode 或数据块是空闲还是已分配。因此，这种分配结构是所有文件系统中必需的部分。\n\n我们可以用一个空闲列表，指向第一个空闲块，然后它又指向下一个空闲块，依此类推。我们选择一种简单而流行的结构，称为位图， 一种用于数据区域（数据位图， data bitmap）， 另一种用于 inode 表（ inode位图， inode bitmap）。位图是一种简单的结构：每个位用于指示相应的对象/块是空闲（0）还是正在使用（1）。 \n\n![位图.png](/images/2024/08/22/8e9444e0-6070-11ef-b5d8-395e250ad2a7.png)\n\n细心的读者可能已经注意到，在极简文件系统的磁盘结构设计中，还有一块。我们将它保留给超级块，在下图中用 S 表示。超级块包含关于该特定文件系统的信息，包括例如文件系统中有多少个 inode 和数据块等等。它可能还包括一些幻数，来标识文件系统类型（在本例中为 VSFS）。 \n\n![系统数据结构.png](/images/2024/08/22/88b87b90-6070-11ef-b5d8-395e250ad2a7.png)\n\n### 文件组织：inode\n\n每个 inode 都由一个数字（称为 inumber）隐式引用，我们之前称之为文件的低级名称。在 VSFS（和其他简单的文件系统）中，给定一个 inumber，你应该能够直接计算磁盘上相应节点的位置。\n\n在每个 inode 中，实际上是所有关于文件的信息：文件类型（例如，常规文件、目录等）、大小、分配给它的块数、保护信息（如谁拥有该文件以及谁可以访问它）、一些时间信息（包括文件创建、修改或上次访问的时间文件下），以及有关其数据块驻留在磁盘上的位置的信息（如某种类型的指针）。我们将所有关于文件的信息称为元数据。实际上，文件系统中除了纯粹的用户数据外，其他任何信息通常都称为元数据。\n\n设计 inode 时，最重要的决定之一是它如何引用数据块的位置。常见的是**多级索引**。\n\n为了支持更大的文件，文件系统设计者必须在 inode 中引入不同的结构。一个常见的思路是有一个称为间接指针（ indirect pointer）的特殊指针。它不是指向包含用户数据的块，而是指向包含更多指针的块，每个指针指向用户数据。因此， inode 可以有一些固定数量（例如 12 个）的直接指针和一个间接指针。如果文件变得足够大，则会分配一个间接块（来自磁盘的数据块区域），并将 inode 的间接指针设置为指向它。\n\n毫不奇怪，在这种方法中，你可能希望支持更大的文件。为此，只需添加另一个指向inode 的指针：双重间接指针。该指针指的是一个包含间接块指针的块，每个间接块都包含指向数据块的指针。 因此，双重间接块提供了可能性，允许使用额外的 1024× 1024 个 4KB 块来增长文件，换言之，支持超过 4GB 大小的文件。不过，你可能想要更多，我们打赌你知道怎么办：三重间接指针。  \n\n![多级索引.png](/images/2024/08/22/815c05b0-6070-11ef-b5d8-395e250ad2a7.png)\n\n### 目录组织\n\n在 VSFS 中（像许多文件系统一样），目录的组织很简单。一个目录基本上只包含一个二元组（条目名称， inode 号）的列表。对于给定目录中的每个文件或目录，目录的数据块中都有一个字符串和一个数字。 对于每个字符串， 可能还有一个长度（假定采用可变大小的名称）。\n\n例如，假设目录 dir（ inode 号是 5）中有 3 个文件（ foo、 bar 和 foobar），它们的 inode号分别为 12、 13 和 24。 dir 在磁盘上的数据可能如下所示：\n\n![目录组织.png](/images/2024/08/22/7a5047e0-6070-11ef-b5d8-395e250ad2a7.png)\n\n在这个例子中，每个条目都有一个 inode 号，记录长度（名称的总字节数加上所有的剩余空间），字符串长度（名称的实际长度），最后是条目的名称。请注意，每个目录有两个额外的条目： .（点）和 ..（点点）。点目录就是当前目录（在本例中为 dir），而点点是父目录（在本例中是根目录）。\n\n删除一个文件（例如调用 unlink()）会在目录中间留下一段空白空间，因此应该有一些方法来标记它（例如，用一个保留的 inode 号，比如 0）。这种删除是使用记录长度的一个原因：新条目可能会重复使用旧的、更大的条目，从而在其中留有额外的空间。\n\n### 空闲空间管理\n\n文件系统必须记录哪些 inode 和数据块是空闲的，哪些不是，这样在分配新文件或目录时，就可以为它找到空间。因此，空闲空间管理对于所有文件系统都很重要。在 VSFS 中，我们用两个简单的位图来完成这个任务。\n\n例如，当我们创建一个文件时，我们必须为该文件分配一个 inode。文件系统将通过位图搜索一个空闲的内容， 并将其分配给该文件。 文件系统必须将 inode 标记为已使用（用 1），并最终用正确的信息更新磁盘上的位图。分配数据块时会发生类似的一组活动。\n\n### 访问路径：读取和写入\n\n**（一）从磁盘读取文件**\n\n打开一个文件（例如/foo/bar，读取它，然后关闭它）。当你发出一个 `open(\"/foo/bar\", O_RDONLY)` 调用时，文件系统首先需要找到文件 bar 的 inode，从而获取关于该文件的一些基本信息（权限信息、文件大小等等）。为此，文件系统必须能够找到 inode，但它现在只有完整的路径名。文件系统必须遍历路径名，从而找到所需的 inode。\n\n所有遍历都从文件系统的根开始，即根目录，它就记为 /。因此，文件系统的第一次磁盘读取是根目录的 inode。通常， 我们在其父目录中找到文件或目录的 i-number。 根没有父目录（根据定义）。因此，根的 inode 号必须是“众所周知的”。在挂载文件系统时，文件系统必须知道它是什么。在大多数 UNIX 文件系统中，根的 inode 号为 2。因此，要开始该过程，文件系统会读入 inode 号 2 的块（第一个 inode 块）。\n\n一旦 inode 被读入，文件系统可以在其中查找指向数据块的指针，数据块包含根目录的内容。因此，文件系统将使用这些磁盘上的指针来读取目录，在这个例子中，寻找 foo 的条目。通过读入一个或多个目录数据块，它将找到 foo 的条目。一旦找到，文件系统也会找到下一个需要的 foo 的 inode 号（假定是 44）。\n\n下一步是递归遍历路径名，直到找到所需的 inode。在这个例子中，文件系统读取包含 foo 的 inode 及其目录数据的块， 最后找到 bar 的 inode 号。 open()的最后一步是将 bar 的 inode 读入内存。然后文件系统进行最后的权限检查，在每个进程的打开文件表中，为此进程分配一个文件描述符，并将它返回给用户。\n\n打开后，程序可以发出 read() 系统调用，从文件中读取。第一次读取（除非 lseek() 已被调用，则在偏移量 0 处）将在文件的第一个块中读取，查阅 inode 以查找这个块的位置。它也会用新的最后访问时间更新 inode。读取将进一步更新此文件描述符在内存中的打开文件表，更新文件偏移量，以便下一次读取会读取第二个文件块，等等。\n\n另外请注意， open 导致的 I/O 量与路径名的长度成正比。对于路径中的每个增加的目录，我们都必须读取它的 inode 及其数据。更糟糕的是，会出现大型目录。在这里，我们只需要读取一个块来获取目录的内容，而对于大型目录，我们可能需要读取很多数据块才能找到所需的条目。\n\n**（二）写入磁盘**\n\n写入文件是一个类似的过程。首先，文件必须打开（如上所述）。其次，应用程序可以发出 write()调用以用新内容更新文件。最后，关闭该文件。\n\n与读取不同，写入文件也可能会分配一个块（除非块被覆写）。当写入一个新文件时，每次写入操作不仅需要将数据写入磁盘，还必须首先决定将哪个块分配给文件，从而相应地更新磁盘的其他结构（例如数据位图和 inode）。因此，每次写入文件在逻辑上会导致 5 个 I/O：一个读取数据位图（然后更新以标记新分配的块被使用），一个写入位图（将它的新状态存入磁盘），再是两次读取，然后写入 inode（用新块的位置更新），最后一次写入真正的数据块本身。\n\n考虑简单和常见的操作（例如文件创建），写入的工作量更大。要创建一个文件，文件系统不仅要分配一个 inode，还要在包含新文件的目录中分配空间。这样做的 I/O 工作总量非常大：一个读取 inode 位图（查找空闲 inode），一个写入 inode 位图（将其标记为已分配），一个写入新的 inode 本身（初始化它），一个写入目录的数据（将文件的高级名称链接到它的 inode 号），以及一个读写目录 inode 以便更新它。如果目录需要增长以容纳新条目，则还需要额外的 I/O（即数据位图和新目录块）。所有这些只是为了创建一个文件！\n\n### 缓存和缓冲\n\n如上面的例子所示，读取和写入文件可能是昂贵的，会导致（慢速）磁盘的许多 I/O。这显然是一个巨大的性能问题，为了弥补，大多数文件系统积极使用系统内存（ DRAM）来缓存重要的块。\n\n现代系统采用动态划分方法。具体来说，许多现代操作系统将虚拟内存页面和文件系统页面集成到统一页面缓存中。通过这种方式，可以在虚拟内存和文件系统之间更灵活地分配内存，具体取决于在给定时间哪种内存需要更多的内存。  \n\n现在想象一下有缓存的文件打开的例子。第一次打开可能会产生很多 I/O 流量，来读取目录的 inode 和数据，但是随后文件打开的同一文件（或同一目录中的文件），大部分会命中缓存，因此不需要 I/O。\n\n我们也考虑一下缓存对写入的影响。尽管可以通过足够大的缓存完全避免读取 I/O，但写入流量必须进入磁盘，才能实现持久。因此，高速缓存不能减少写入流量，像对读取那样。虽然这么说，写缓冲（ write buffering，人们有时这么说）肯定有许多优点。首先，通过延迟写入，文件系统可以将一些更新编成一批（ batch），放入一组较小的 I/O 中。例如，如果在创建一个文件时， inode 位图被更新，稍后在创建另一个文件时又被更新，则文件系统会在第一次更新后延迟写入，从而节省一次 I/O。其次，通过将一些写入缓冲在内存中，系统可以调度（ schedule）后续的 I/O，从而提高性能。最后，一些写入可以通过拖延来完全避免。例如，如果应用程序创建文件并将其删除，则将文件创建延迟写入磁盘，可以完全避免（ avoid）写入。在这种情况下，懒惰（在将块写入磁盘时）是一种美德。\n\n## 局部性和快速文件系统\n\n![局部性.png](/images/2024/08/22/6d60d180-6070-11ef-b5d8-395e250ad2a7.png)\n\n超级块（S）包含有关整个文件系统的信息：卷的大小、有多少 inode、指向空闲列表块的头部的指针等等。磁盘的 inode 区域包含文件系统的所有 inode。最后，大部分磁盘都被数据块占用。  \n\n### 性能不佳\n\n主要问题是老 UNIX 文件系统将磁盘当成随机存取内存。数据遍布各处，而不考虑保存数据的介质是磁盘的事实，因此具有实实在在的、昂贵的定位成本。\n\n更糟糕的是，文件系统最终会变得非常碎片化（fragmented），因为空闲空间没有得到精心管理。空闲列表最终会指向遍布磁盘的一堆块，并且随着文件的分配，它们只会占用下一个空闲块。结果是在磁盘上来回访问逻辑上连续的文件，从而大大降低了性能。\n\n![性能1.png](/images/2024/08/22/623fb280-6070-11ef-b5d8-395e250ad2a7.png)\n\n如你所见，可用空间被分成两块构成的两大块，而不是很好的连续 4 块。假设我们现在希望分配一个大小为 4 块的文件 E：\n\n![性能2.png](/images/2024/08/22/57e565f0-6070-11ef-b5d8-395e250ad2a7.png)\n\nE 分散在磁盘上，因此，在访问 E 时，无法从磁盘获得峰值（顺序）性能。你首先读取 E1 和 E2，然后寻道，再读取 E3 和 E4。这个碎片问题一直发生在老UNIX 文件系统中，并且会影响性能。\n\n另一个问题：原始块大小太小（512 字节）。因此，从磁盘传输数据本质上是低效的。较小的块是好的，因为它们最大限度地减少了内部碎片，但是由于每个块可能需要一个定位开销来访问它，因此传输不佳。\n\n### 组织结构：柱面组\n\n第一步是更改磁盘上的结构。 FFS 将磁盘划分为一些分组， 称为柱面组。因此，我们可以想象一个具有 10 个柱面组的磁盘：\n\n![柱面组.png](/images/2024/08/22/4ef09cd0-6070-11ef-b5d8-395e250ad2a7.png)\n\n通过在同一组中放置两个文件， FFS 可以确保先后访问两个文件不会导致穿越磁盘的长时间寻道。因此， FFS 需要能够在每个组中分配文件和目录。每个组看起来像这样：\n\n![柱面组2.png](/images/2024/08/22/477665c0-6070-11ef-b5d8-395e250ad2a7.png)\n\n### 策略：如何分配文件和目录\n\n为了遵守规则， FFS 必须决定什么是“相关的”，并将它们置于同一个区块组内。相反，不相关的东西应该放在不同的块组中。\n\n首先是目录的放置。 FFS 采用了一种简单的方法：找到分配数量少的柱面组（因为我们希望跨组平衡目录）和大量的自由 inode（因为我们希望随后能够分配一堆文件），并将目录数据和 inode 放在该分组中。当然，这里可以使用其他推断方法（例如，考虑空闲数据块的数量）。\n\n对于文件， FFS 做两件事。首先，它确保（在一般情况下）将文件的数据块分配到与其 inode 相同的组中，从而防止 inode 和数据之间的长时间寻道（如在老文件系统中）。其次，它将位于同一目录中的所有文件，放在它们所在目录的柱面组中。因此，如果用户创建了 4个文件， /dir1/1.txt、 /dir1/2.txt、 /dir1/3.txt 和/dir99/4.txt， FFS 会尝试将前 3 个放在一起（同一组），与第四个远离（它在另外某个组中）。\n\n### 大文件例外\n\n在 FFS 中，文件放置的一般策略有一个重要的例外，它出现在大文件中。如果没有不同的规则，大文件将填满它首先放入的块组（也可能填满其他组）。以这种方式填充块组是不符合需要的，因为它妨碍了随后的“相关” 文件放置在该块组内，因此可能破坏文件访问的局部性。\n\n因此，对于大文件， FFS 执行以下操作。在将一定数量的块分配到第一个块组（例如， 12 个块，或 inode 中可用的直接指针的数量）之后， FFS 将文件的下一个“大”块（即第一个间接块指向的那些部分）放在另一个块组中（可能因为它的利用率低而选择）。然后，文件的下一个块放在另一个不同的块组中，依此类推。\n\n![大文件.png](/images/2024/08/22/374d2120-6070-11ef-b5d8-395e250ad2a7.png)\n\n### 关于 FFS 的其他几件事\n\nFFS 也引入了一些其他创新。特别是，设计人员非常担心容纳小文件。事实证明，当时许多文件大小为 2KB 左右， 使用 4KB 块虽然有利于传输数据， 但空间效率却不太好。 因此，在典型的文件系统上， 这种内部碎片可能导致大约一半的磁盘浪费。他们决定引入子块（sub-block），这些子块有 512 字节，文件系统可以将它们分配给文件。因此，如果你创建了一个小文件（比如大小为 1KB），它将占用两个子块，因此不会浪费整个 4KB 块。随着文件的增长，文件系统将继续为其分配 512 字节的子块，直到它达到完整的 4KB 数据。此时， FFS 将找到一个 4KB 块，将子块复制到其中，并释放子块以备将来使用。\n\nFFS 引入的第二个巧妙方法，是针对性能进行优化的磁盘布局。那时候（在 SCSI 和其他更现代的设备接口之前），磁盘不太复杂，需要主机 CPU 以更加亲力亲为的方式来控制它们的操作。当文件放在磁盘的连续扇区上时， FFS 遇到了问题。具体来说，在顺序读取期间出现了问题。 FFS 首先发出一个请求，读取块 0。当读取完成时， FFS 向块 1 发出读取，为时已晚：块 1 已在磁头下方旋转，现在对块 1 的读取将导致完全旋转。\n\n![轴1.png](/images/2024/08/22/2feab7d0-6070-11ef-b5d8-395e250ad2a7.png)\n\nFFS 使用不同的布局解决了这个问题，通过每次跳过一块（在这个例子中），在下一块经过磁头之前， FFS 有足够的时间发出请求。实际上， FFS 足够聪明，能够确定特定磁盘在布局时应跳过多少块，以避免额外的旋转。这种技术称为参数化，因为 FFS 会找出磁盘的特定性能参数，并利用它们来确定准确的交错布局方案。\n\n![轴2.png](/images/2024/08/22/2a97f4a0-6070-11ef-b5d8-395e250ad2a7.png)\n\n你可能会想：这个方案毕竟不太好。实际上，使用这种类型的布局只能获得 50%的峰值带宽，因为你必须绕过每个轨道两次才能读取每个块一次。幸运的是，现代磁盘更加智能：它们在内部读取整个磁道并将其缓冲在内部磁盘缓存中（由于这个原因，通常称为磁道缓冲区）。然后，在对轨道的后续读取中，磁盘就从其高速缓存中返回所需数据。因此，文件系统不再需要担心这些令人难以置信的低级细节。如果设计得当，抽象和更高级别的接口可能是一件好事。\n\nFFS 还增加了另一些可用性改进。 FFS 是允许长文件名的第一个文件系统之一，因此在文件系统中实现了更具表现力的名称，而不是传统的固定大小方法（例如， 8 个字符）。此外，引入了一种称为符号链接的新概念。正如前面所讨论的那样，硬链接的局限性在于它们都不能指向目录（因为害怕引入文件系统层次结构中的循环），并且它们只能指向同一卷内的文件（即 inode 号必须仍然有意义）。符号链接允许用户为系统上的任何其他文件或目录创建“别名”，因此更加灵活。 FFS 还引入了一个原子 rename()操作，用于重命名文件。除了基本技术之外，可用性的改进也可能让 FFS 拥有更强大的用户群。  \n\n## 崩溃一致性： FSCK 和日志\n\n想象一下，为了完成特定操作，你必须更新两个磁盘上的结构 A 和 B。由于磁盘一次只为一个请求提供服务，因此其中一个请求将首先到达磁盘（A 或 B）。如果在一次写入完成后系统崩溃或断电，则磁盘上的结构将处于不一致的状态。因此，我们遇到了所有文件系统需要解决的问题。\n\n### 解决方案 1：文件系统检查程序\n\n早期的文件系统采用了一种简单的方法来处理崩溃一致性。基本上，它们决定让不一致的事情发生，然后再修复它们（重启时）。这种偷懒方法的典型例子可以在一个工具中找到：fsck。 它 是一个 UNIX 工具，用于查找这些不一致并修复它们。在不同的系统上，存在检查和修复磁盘分区的类似工具。\n\n### 解决方案 2：日志（或预写日志）\n\n更新磁盘时，在覆写结构之前，首先写下一点小注记（在磁盘上的其他地方，在一个众所周知的位置），描述你将要做的事情。写下这个注记就是“预写”部分，我们把它写入一个结构，并组织成“日志”。因此，就有了预写日志。\n\n通过将注释写入磁盘，可以保证在更新（覆写）正在更新的结构期间发生崩溃时，能够返回并查看你所做的注记，然后重试。因此，你会在崩溃后准确知道要修复的内容（以及如何修复它），而不必扫描整个磁盘。因此，通过设计，日志功能在更新期间增加了一些工作量，从而大大减少了恢复期间所需的工作量。\n\n### 解决方案 3：其他方法\n\nGanger 和 Patt 引入了一种称为软更新的方法。这种方法仔细地对文件系统的所有写入排序，以确保磁盘上的结构永远不会处于不一致的状态。例如，通过先写入指向的数据块，再写入指向它的 inode，可以确保 inode 永远不会指向垃圾。\n\n另一种方法称为写时复制，并且在许多流行的文件系统中使用，包括 Sun 的 ZFS。这种技术永远不会覆写文件或目录。相反，它会对磁盘上以前未使用的位置进行新的更新。在完成许多更新后， COW 文件系统会翻转文件系统的根结构，以包含指向刚更新结构的指针。这样做可以使文件系统保持一致。\n\n另一种方法是我们刚刚在威斯这星大学开发的方法。这种技术名为基于反向指针的一致性，它在写入之间不强制执行排序。为了实现一致性，系统中的每个块都会添加一个额外的反向指针。例如，每个数据块都引用它所属的 inode。访问文件时，文件系统可以检查正向指针（inode 或直接块中的地址）是否指向引用它的块，从而确定文件是否一致。如果是这样，一切都肯定安全地到达磁盘，因此文件是一致的。如果不是，则文件不一致，并返回错误。\n\n## 日志结构文件系统（LFS）\n\n写入磁盘时， LFS 首先将所有更新（包括元数据！）缓冲在内存段中。当段已满时，它会在一次长时间的顺序传输中写入磁盘，并传输到磁盘的未使用部分。LFS 永远不会覆写现有数据，而是始终将段写入空闲位置。由于段很大，因此可以有效地使用磁盘，并且文件系统的性能接近其峰值。\n\n### 按顺序写入磁盘\n\n想象一下，我们正在将数据块 D 写入文件。 将数据块写入磁盘可能会导致以下磁盘布局， 其中 D 写在磁盘地址 A0：\n\n![顺序写入.png](/images/2024/08/22/18fa3870-6070-11ef-b5d8-395e250ad2a7.png)\n\n但是，当用户写入数据块时，不仅是数据被写入磁盘；还有其他需要更新的元数据（metadata）。在这个例子中，让我们将文件的 inode（I）也写入磁盘，并将其指向数据块 D。写入磁盘时，数据块和 inode 看起来如下图所示：\n\n![顺序写入2.png](/images/2024/08/22/11918d90-6070-11ef-b5d8-395e250ad2a7.png)\n\n简单地将所有更新（例如数据块、 inode 等）顺序写入磁盘的这一基本思想是 LFS 的核心。如果你理解这一点，就抓住了基本的想法。但就像所有复杂的系统一样，魔鬼藏在细节中。\n\n### 顺序而高效地写入\n\n遗憾的是， （单单）顺序写入磁盘并不足以保证高效写入。实际上，你必须向驱动器发出大量连续写入（或一次大写入）才能获得良好的写入性能。\n\n为了达到这个目的， LFS 使用了一种称为**写入缓冲**的古老技术。在写入磁盘之前， LFS 会跟踪内存中的更新。收到足够数量的更新时，会立即将它们写入磁盘，从而确保有效使用磁盘。\n\nLFS 一次写入的大块更新被称为段（segment）。虽然这个术语在计算机系统中被过度使用，但这里的意思是 LFS 用来对写入进行分组的大块。因此，在写入磁盘时， LFS 会缓冲内存段中的更新，然后将该段一次性写入磁盘。只要段足够大，这些写入就会很有效。\n\n![写入缓冲.png](/images/2024/08/22/08771400-6070-11ef-b5d8-395e250ad2a7.png)\n\n上面是一个例子，其中 LFS 将两组更新缓冲到一个小段中。实际段更大（几 MB）。第一次更新是对文件 j 的 4 次块写入，第二次是添加到文件 k 的一个块。然后， LFS 立即将整个七个块的段提交到磁盘。\n\n### 通过间接解决方案：inode 映射\n\n我们已经设法将 inode 分散在整个磁盘上！更糟糕的是，我们永远不会覆盖，因此最新版本的 inode（即我们想要的那个）会不断移动。所以该如何寻找 inode 呢？\n\n为了解决这个问题， LFS 的设计者通过名为 inode 映射（inode map， imap）的数据结构，在 inode 号和 inode 之间引入了一个间接层。imap 是一个结构， 它将 inode 号作为输入，并生成最新版本的 inode 的磁盘地址。因此，你可以想象它通常被实现为一个简单的数组，每个条目有 4 个字节（一个磁盘指针）。每次将 inode 写入磁盘时， imap 都会使用其新位置进行更新。\n\n遗憾的是， imap 需要保持持久（写入磁盘）。这样做允许 LFS 在崩溃时仍能记录 inode 位置，从而按设想运行。因此有一个问题： imap 应该驻留在磁盘上的哪个位置？\n\nLFS 将 inode 映射的块放在它写入所有其他新信息的位置旁边。因此，当将数据块追加到文件 k 时， LFS 实际上将新数据块，其 inode 和一段 inode 映射一起写入磁盘，如下所示：\n\n![inode映射.png](/images/2024/08/22/fe6e42d0-606f-11ef-b5d8-395e250ad2a7.png)\n\n在该图中， imap 数组存储在标记为 imap 的块中，它告诉 LFS， inode k 位于磁盘地址A1。接下来，这个 inode 告诉 LFS 它的数据块 D 在地址 A0。\n\n### 检查点区域\n\n我们如何很到 inode 映射，现在它的各个部分现在也分布在整个磁盘上？归根到底：文件系统必须在磁盘上有一些固定且已知的位置，才能开始文件查找。\n\nLFS 在磁盘上只有这样一个固定的位置，称为检查点区域（checkpoint region， CR）。检查点区域包含指向最新的 inode 映射片段的指针（即地址），因此可以通过首先读取 CR 来找到 inode 映射片段。请注意，检查点区域仅定期更新（例如每 30s 左右），因此性能不会受到影响。 因此，磁盘布局的整体结构包含一个检查点区域（指向内部映射的最新部分）， 每个 inode映射块包含 inode 的地址， inode 指向文件（和目录），就像典型的 UNIX 文件系统一样。\n\n![检查点区域.png](/images/2024/08/22/f56862b0-606f-11ef-b5d8-395e250ad2a7.png)\n\n### 从磁盘读取文件：回顾\n\n为了确保理解 LFS 的工作原理，现在让我们来看看从磁盘读取文件时必须发生的事情：\n\n1. 假设从内存中没有任何东西开始。我们必须读取的第一个磁盘数据结构是检查点区域。检查点区域包含指向整个 inode 映射的指针（磁盘地址），因此 LFS 读入整个 inode 映射并将其缓存在内存中\n2. 在此之后，当给定文件的 inode 号时， LFS 只是在 imap 中查很 inode 号到inode 磁盘地址的映射，并读入最新版本的 inode\n3. 要从文件中读取块，此时， LFS 完全按照典型的 UNIX 文件系统进行操作，方法是使用直接指针或间接指针或双重间接指针。在通常情况下，从磁盘读取文件时， LFS 应执行与典型文件系统相同数量的 I/O，整个 imap 被缓存，因此 LFS 在读取过程中所做的额外工作是在 imap 中查很 inode 的地址\n\n### 目录如何\n\n目录结构与传统的 UNIX 文件系统基本相同，因为目录只是（名称， inode号）映射的集合。例如，在磁盘上创建文件时， LFS 必须同时写入新的 inode，一些数据，以及引用此文件的目录数据及其 inode。请记住， LFS 将在磁盘上按顺序写入（在缓冲更新一段时间后）。因此，在目录中创建文件 foo，将导致磁盘上的以下新结构：\n\n![存储目录.png](/images/2024/08/22/eb8fc940-606f-11ef-b5d8-395e250ad2a7.png)\n\ninode 映射的片段包含目录文件 dir 以及新创建的文件 f 的位置信息。因此，访问文件foo（具有 inode 号 f）时，你先要查看 inode 映射（通常缓存在内存中），找到目录 dir（A3）的 inode 的位置。然后读取目录的 inode，它给你目录数据的位置（A2）。读取此数据块为你提供名称到 inode 号的映射（foo， k）。然后再次查阅 inode 映射，很到 inode 号 k（A1）的位置，最后在地址 A0 处读取所需的数据块。\n\ninode 映射还解决了 LFS 中存在的另一个严重问题， 称为递归更新问题。任何永远不会原地更新的文件系统（例如 LFS）都会遇到该问题，它们将更新移动到磁盘上的新位置。具体来说，每当更新 inode 时，它在磁盘上的位置都会发生变化。如果我们不小心，这也会导致对指向该文件的目录的更新，然后必须更改该目录的父目录，依此类推，一路沿文件系统树向上。\n\nLFS 巧妙地避免了 inode 映射的这个问题。即使 inode 的位置可能会发生变化，更改也不会反映在目录本身中。事实上， imap 结构被更新，而目录保持相同的名称到 inumber 的映射。因此，通过间接， LFS 避免了递归更新问题。\n\n### 一个新问题：垃圾收集\n\n你可能已经注意到 LFS 的另一个问题；它会反复将最新版本的文件（包括其 inode 和数据）写入磁盘上的新位置。此过程在保持写入效率的同时，意味着 LFS 会在整个磁盘中分散旧版本的文件结构。我们（毫不客气地）将这些旧版本称为垃圾。\n\n那么，应该如何处理这些旧版本的 inode、数据块等呢？可以保留那些旧版本并允许用户恢复旧文件版本（例如，当他们意外覆盖或删除文件时，这样做可能非常方便）。这样的文件系统称为版本控制文件系统，因为它跟踪文件的不同版本。但是， LFS 只保留文件的最新活版本。因此（在后台）， LFS 必须定期查很文件数据，索引节点和其他结构的旧的死版本，并清理（clean）它们。因此，清理应该使磁盘上的块再次空闲，以便在后续写入中使用。\n\n实际上， LFS 清理程序按段工作，从而为后续写入清理出大块空间。基本清理过程的工作原理如下。 LFS 清理程序定期读入许多旧的（部分使用的）段，确定哪些块在这些段中存在，然后写出一组新的段，只包含其中活着的块，从而释放旧块用于写入。具体来说，我们预期清理程序读取 M 个现有段，将其内容打包（compact）到 N 个新段（其中 N < M），然后将 N 段写入磁盘的新位置。 然后释放旧的 M 段， 文件系统可以使用它们进行后续写入。\n\n但是，我们现在有两个问题：\n\n1. LFS 如何判断段内的哪些块是活的，哪些块已经死了？\n2. 清理程序应该多久运行一次，以及应该选择清理哪些部分？\n\n### 确定块的死活\n\n我们首先关注这个问题。给定磁盘段 S 内的数据块 D， LFS 必须能够确定 D 是不是活的。为此， LFS 会为描述每个块的每个段添加一些额外信息。具体地说，对于每个数据块 D， LFS 包括其 inode 号（它属于哪个文件）及其偏移量（这是该文件的哪一块）。该信息记录在一个数据结构中，位于段头部，称为段摘要块。\n\n根据这些信息，可以直接确定块的死活。对于位于地址 A 的磁盘上的块 D，查看段摘要块并找到其 inode 号 N 和偏移量 T。接下来，查看 imap 以找到 N 所在的位置，并从磁盘读取 N（可能它已经在内存中，这更好）。最后，利用偏移量 T，查看 inode（或某个间接块），看看 inode 认为此文件的第 T 个块在磁盘上的位置。如果它刚好指向磁盘地址 A，则 LFS可以断定块 D 是活的。如果它指向其他地方， LFS 可以断定 D 未被使用（即它已经死了），因此知道不再需要该版本。\n\n![确定块的死活.png](/images/2024/08/22/deef0f20-606f-11ef-b5d8-395e250ad2a7.png)\n\n上面是一个描述机制的图，其中段摘要块（标记为 SS）记录了地址 A0 处的数据块，实际上是文件 k 在偏移 0 处的部分。通过检查 imap 的 k，可以找到 inode，并且看到它确实指向该位置。\n\nLFS 走了一些捷径，可以更有效地确定死活。例如，当文件被截断或删除时， LFS 会增加其版本号，并在 imap 中记录新版本号。通过在磁盘上的段中记录版本号， LFS 可以简单地通过将磁盘版本号与 imap 中的版本号进行比较，跳过上述较长的检查，从而避免额外的读取。\n\n### 策略问题：要清理哪些块，何时清理\n\n作者描述了一种试图分离冷热段的方法。热段是经常覆盖内容的段。因此，对于这样的段，最好的策略是在清理之前等待很长时间，因为越来越多的块被覆盖（在新的段中），从而被释放以供使用。相比之下，冷段可能有一些死块，但其余的内容相对稳定。因此，作者得出结论，应该尽快清理冷段，延迟清理热段，并开发出一种完全符合要求的试探算法。但是，与大多数政策一样，这只是一种方法，当然并非“最佳”方法。\n\n### 崩溃恢复和日志\n\n最后一个问题：如果系统在 LFS 写入磁盘时崩溃会发生什么？你可能还记得上一章讲的日志，在更新期间崩溃对于文件系统来说是棘手的，因此 LFS 也必须考虑这些问题。\n\n在正常操作期间， LFS 将一些写入缓冲在段中，然后（当段已满或经过一段时间后），将段写入磁盘。 LFS 在日志（log）中组织这些写入，即指向头部段和尾部段的检查点区域，并且每个段指向要写入的下一个段。 LFS 还定期更新检查点区域（CR）。在这些操作期间都可能发生崩溃（写入段，写入 CR）。那么 LFS 在写入这些结构时如何处理崩溃？\n\n我们先介绍第二种情况。为了确保 CR 更新以原子方式发生， LFS 实际上保留了两个CR，每个位于磁盘的一端，并交替写入它们。当使用最新的指向 inode 映射和其他信息的指针更新 CR 时， LFS 还实现了一个谨慎的协议。具体来说，它首先写出一个头（带有时间戳），然后写出 CR 的主体，然后最后写出最后一部分（也带有时间戳）。如果系统在 CR 更新期间崩溃， LFS 可以通过查看一对不一致的时间戳来检测到这一点。 LFS 将始终选择使用具有一致时间戳的最新 CR，从而实现 CR 的一致更新。\n\n我们现在关注第一种情况。由于 LFS 每隔 30s 左右写入一次 CR，因此文件系统的最后一致快照可能很旧。因此，在重新启动时， LFS 可以通过简单地读取检查点区域、它指向的imap 片段以及后续文件和目录，从而轻松地恢复。但是，最后许多秒的更新将会丢失。\n\n为了改进这一点， LFS 尝试通过数据库社区中称为前滚的技术，重建其中许多段。基本思想是从最后一个检查点区域开始，很到日志的结尾（包含在 CR 中），然后使用它来读取下一个段，并查看其中是否有任何有效更新。如果有， LFS 会相应地更新文件系统，从而恢复自上一个检查点以来写入的大部分数据和元数据。\n\n## 数据完整性和保护\n\n### 处理潜在的扇区错误\n\n事实证明，潜在的扇区错误很容易处理，因为它们（根据定义）很容易被检测到。当存储系统尝试访问块，并且磁盘返回错误时， 存储系统应该就用它具有的任何**冗余机制**，来返回正确的数据。例如，在镜像 RAID 中，系统应该访问备用副本。在基于奇偶校验的RAID-4 或 RAID-5 系统中，系统应通过奇偶校验组中的其他块重建该块。因此，利用标准冗余机制，可以容易地恢复诸如 LSE 这样的容易检测到的问题。\n\n### 检测讹误：校验和\n\n即数据讹误导致的无声故障。在出现讹误导致磁盘返回错误数据时，如何阻止用户获取错误数据？\n\n与潜在的扇区错误不同，检测讹误是一个关键问题。客户如何判断一个块坏了？一旦知道特定块是坏的，恢复就像以前一样： 你需要有该块的其他副本（希望没有讹误！）。因此，我们将重点放在**检测技术**上。\n\n现代存储系统用于保持数据完整性的主要机制称为校验和（checksum）。校验和就是一个函数的结果，该函数以一块数据（例如 4KB 块）作为输入，并计算这段数据的函数，产生数据内容的小概要（比如 4 字节或 8 字节）。此摘要称为校验和。这种计算的目的在于，让系统将校验和与数据一起存储，然后在访问时确认数据的当前校验和与原始存储值匹配，从而检测数据是否以某种方式被破坏或改变。\n\n发现了讹误，自然的问题是我们应该怎么做呢？如果存储系统有冗余副本，答案很简单：尝试使用它。如果存储系统没有此类副本，则可能的答案是返回错误。在任何一种情况下，都要意识到讹误检测不是神奇的子弹。如果没有其他方法来获取没有讹误的数据，那你就不走运了。\n\n### 一个新问题：错误的写入\n\n上述基本方案对一般情况的讹误块工作良好。但是，现代磁盘有几种不同的故障模式，需要不同的解决方案。\n\n第一种感兴趣的失败模式称为“错误位置的写入”。这出现在磁盘和RAID 控制器中，它们正确地将数据写入磁盘，但位置错误。在单磁盘系统中，这意味着磁盘写入块 Dx 不是在地址 x（像期望那样），而是在地址 y（因此是“讹误的” Dy）。另外，在多磁盘系统中，控制器也可能将 Di， x 不是写入磁盘 i 的 x，而是写入另一磁盘 j。\n\n毫不奇怪，答案很简单：在每个校验和中添加更多信息。在这种情况下，添加物理标识符（Physical Identifier，物理 ID）非常有用。\n\n![物理标识.png](/images/2024/08/22/cfe962f0-606f-11ef-b5d8-395e250ad2a7.png)\n\n可以从磁盘格式看到，磁盘上现在有相当多的冗余：对于每个块，磁盘编号在每个块中重复，并且相关块的偏移量也保留在块本身旁边。但是，冗余信息的存在应该是不奇怪。冗余是错误检测（在这种情况下）和恢复（在其他情况下）的关键。一些额外的信息虽然不是完美磁盘所必需的，但可以帮助检测出现问题的情况。\n\n### 最后一个问题：丢失的写入\n\n遗憾的是，错误位置的写入并不是我们要解决的最后一个问题。具体来说，一些现代存储设备还有一个问题，称为丢失的写入（lost write）。当设备通知上层写入已完成，但事实上它从未持久，就会发生这种问题。因此， 磁盘上留下的是该块的旧内容，而不是更新的新内容。\n\n一种经典方法[BS04]是执行写入验证，或写入后读取。通过在写入后立即读回数据，系统可以确保数据确实到达磁盘表面。然而，这种方法非常慢，使完成写入所需的 I/O 数量翻了一番。\n\n某些系统在系统的其他位置添加校验和，以检测丢失的写入。例如， Sun 的 Zettabyte 文件系统（ZFS）在文件系统的每个 inode 和间接块中，包含文件中每个块的校验和。因此，即使对数据块本身的写入丢失， inode 内的校验和也不会与旧数据匹配。 只有当同时丢失对 inode和数据的写入时，这样的方案才会失败，这是不太可能的情况（但也有可能发生！）。\n\n### 擦净\n\n经过所有这些讨论，你可能想知道：这些校验和何时实际得到检查？当然，在应用程序访问数据时会发生一些检查，但大多数数据很少被访问，因此将保持未检查状态。未经检查的数据对于可靠的存储系统来说是个问题，因为数据位衰减最终可能会影响特定数据的所有副本。\n\n为了解决这个问题，许多系统利用各种形式的磁盘擦净。通过定期读取系统的每个块，并检查校验和是否仍然有效，磁盘系统可以减少某个数据项的所有副本都被破坏的可能性。典型的系统每晚或每周安排扫描。\n\n---\n\n⭐️内容取自译者王海鹏《操作系统导论》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书","tags":["操作系统导论","OS"],"categories":["technology"]},{"title":"第四章：并发","url":"/2024/08/22/第四章：并发/","content":"\n<!-- toc -->\n\n## 并发：介绍\n\n同一进程下的多线程共享内存地址，对同一块内存地址的读不会引发数据竞争，但是修改会引发数据竞争。常用的办法是加锁保护临界区或保证修改的动作是原子的。\n\n原子性是指当指令执行时，它会像期望那样执行更新。它不能在指令中间中断，因为这正是我们从硬件获得的保证：发生中断时，指令根本没有运行，或者运行完成，没有中间状态。\n\n![多线程.png](/images/2024/08/22/d02433f0-606d-11ef-b5d8-395e250ad2a7.png)\n\n## 锁\n\n```c++\n没有加锁\n    balance = balance + 1;\n\n加锁\n    lock_t mutex; \n    ...\n    lock(&mutex); \n    balance = balance + 1; \t\n    unlock(&mutex);\n```\n\n没有加锁前，balance = balance + 1 这个指令可以被多线程同时访问；加锁之后，保证只有一个线程访问到 balance = balance + 1 指令，确保 balance 的值正确 加 1，不会遗漏。\n\n**锁就是一个变量**，因此我们需要声明一个某种类型的锁变量（lock variable，如上面的mutex），才能使用。这个**锁变量（简称锁）保存了锁在某一时刻的状态**。它要么是可用的（available，或 unlocked，或 free），表示没有线程持有锁，要么是被占用的（acquired，或 locked，或 held），表示有一个线程持有锁，正处于临界区。我们也可以保存其他的信息，比如持有锁的线程，或请求获取锁的线程队列，但这些信息会隐藏起来，锁的使用者不会发现。\n\nlock 和 unlock 函数会传入一个变量，因为我们可能用不同的锁来保护不同的变量。这样可以增加并发：不同于任何临界区都使用同一个大锁（粗粒度的锁策略），通常大家会用不同的锁保护不同的数据和结构，从而允许更多的线程进入临界区（细粒度的方案）。\n\n调用 lock()尝试获取锁，如果没有其他线程持有锁（即它是可用的），该线程会获得锁，进入临界区。这个线程有时被称为锁的持有者（owner）。如果另外一个线程对相同的锁变量（本例中的 mutex）调用 lock()，因为锁被另一线程持有，该调用不会返回。这样，当持有锁的线程在临界区时，其他线程就无法进入临界区。\n\n锁的持有者一旦调用 unlock()，锁就变成可用了。如果没有其他等待线程（即没有其他线程调用过 lock()并卡在那里），锁的状态就变成可用了。如果有等待线程（卡在 lock()里），其中一个会（最终）注意到（或收到通知）锁状态的变化，获取该锁，进入临界区。\n\n锁为程序员提供了最小程度的调度控制。我们把线程视为程序员创建的实体，但是被操作系统调度，具体方式由操作系统选择。**锁让程序员获得一些控制权**。通过给临界区加锁，可以保证临界区内只有一个线程活跃。**锁将原本由操作系统调度的混乱状态变得更为可控**。\n\n## 条件变量\n\n线程可以使用条件变量（condition variable），来等待一个条件变成真。条件变量是一个显式队列，当某些执行状态（即条件，condition）不满足时，线程可以把自己加入队列，等待（waiting）该条件。另外某个线程，当它改变了上述状态时，就可以唤醒一个或者多个等待线程（通过在该条件上发信号），让它们继续执行。\n\n条件变量有两种相关操作：wait()和 signal()。线程要睡眠的时候（等待条件被满足，条件满足会被唤醒，即后面的signal指令），调用 wait()。当线程想唤醒等待在某个条件变量上的睡眠线程时，调用 signal()。\n\n```c++\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n\n// 定义全局变量和同步原语\nint done = 0;\npthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t c = PTHREAD_COND_INITIALIZER;\n\nvoid thr_exit() {\n    pthread_mutex_lock(&m);  // 锁住互斥锁\n    done = 1;               \n    pthread_cond_signal(&c); // 发出条件变量信号\n    pthread_mutex_unlock(&m); // 解锁互斥锁\n}\n\nvoid *child(void *arg) {\n    printf(\"child\\n\");\n    thr_exit();\n    return NULL;\n}\n\nvoid thr_join() {\n    pthread_mutex_lock(&m); // 锁住互斥锁\n    while (done == 0) {     // 等待条件满足\n        pthread_cond_wait(&c, &m); // 等待条件变量信号\n    }\n    pthread_mutex_unlock(&m); // 解锁互斥锁\n}\n\nint main(int argc, char *argv[]) {\n    printf(\"parent: begin\\n\");\n    pthread_t p;\n    pthread_create(&p, NULL, child, NULL); // 创建子线程\n    thr_join(); // 等待子线程完成\n    printf(\"parent: end\\n\");\n    return 0;\n}\n```\n\n你可能注意到一点，wait()调用有一个参数，它是互斥量。它假定在 wait()调用时，这个互斥量是已上锁状态。wait()的职责是释放锁，并让调用线程休眠（原子地）。当线程被唤醒时（在另外某个线程发信号给它后），它必须重新获取锁，再返回调用者。这样复杂的步骤也是为了避免在线程陷入休眠时，产生一些竞态条件。\n\n## 信号量\n\n信号量是有一个整数值的对象，可以用两个函数来操作它。在 POSIX 标准中，是 sem_wait() 和 sem_post()。因为信号量的初始值能够决定其行为，所以首先要初始化信号量，才能调用其他函数与之交互。\n\n```c++\n#include <semaphore.h> \nsem_t s; \nsem_init(&s, 0, 1);\n```\n\n其中申明了一个信号量 s，通过第三个参数，将它的值初始化为 1。sem_init() 的第二个参数，在我们看到的所有例子中都设置为 0，表示信号量是在同一进程的多个线程共享的。\n\n信号量初始化之后，我们可以调用 sem_wait()或 sem_post()与之交互：\n\n- 首先，sem_wait()要么立刻返回（调用 sem_wait()时，信号量的值大于等于 1），要么会让调用线程挂起，直到之后的一个 post 操作。当然，也可能多个调用线程都调用 sem_wait()，因此都在队列中等待被唤醒\n- 其次，sem_post()并没有等待某些条件满足。它直接增加信号量的值，如果有等待线程，唤醒其中一个\n- 最后，当信号量的值为负数时，这个值就是等待线程的个数。虽然这个值通常不会暴露给信号量的使用者，但这个恒定的关系值得了解，可能有助于记住信号量的工作原理\n\n下面开始应用信号量\n\n（一）用信号量作为锁\n\n```c++\nsem_t m; \nsem_init(&m, 0, X); // initialize semaphore to X; what should X be? \n\nsem_wait(&m); \n// 临界区\nsem_post(&m);\n```\n\n我们直接把临界区用一对 sem_wait()/sem_post()环绕。但是，为了使这段代码正常工作，信号量 m 的初始值（图中初始化为 *X*）是至关重要的。*X* 应该是多少呢？\n\n如果信号量 m 的初始化值 X 初始化为 1，线程 A 调用 sem_wait() 不会阻塞，调用之后会将 X - 1，并进入临界区。其它线程如果想要进入临界区，发现 X 为 0，会阻塞在临界区之外，因为X 为 0 ，sem_wait()会阻塞。线程 A已经进入临界区，完成相关操作之后，继续执行到 sem_post()，调用之后 X + 1，这个时候 X = 1，其它线程调用sem_wait() 不会阻塞，会有其中一个线程会被允许进入临界区。综上所述，X 初始化为 1 能够通过信号量实现锁的功能，因为锁只有两个状态（持有和没持有），所以这种用法有时也叫作二值信号量（binary semaphore）。\n\n（二）用信号量作为条件变量\n\n信号量也可以用在一个线程暂停执行，等待某一条件成立的场景。例如，一个线程要等待一个链表非空，然后才能删除一个元素。在这种场景下，通常一个线程等待条件成立，另外一个线程修改条件并发信号给等待线程，从而唤醒等待线程。因为等待线程在等待某些条件（condition）发生变化，所以我们将信号量作为条件变量（condition variable）。\n\n```c++\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n// 全局信号量\nsem_t s;\n\nvoid* child(void* arg) {\n    printf(\"child\\n\");\n    sem_post(&s); // 子线程完成后发出信号\n    return NULL;\n}\n\nint main(int argc, char* argv[]) {\n    // 初始化信号量，初始值为0\n    sem_init(&s, 0, 0);\n\n    printf(\"parent: begin\\n\");\n\n    pthread_t c;\n    pthread_create(&c, NULL, child, NULL); // 创建子线程\n\n    sem_wait(&s); // 等待子线程完成\n    printf(\"parent: end\\n\");\n\n    // 销毁信号量\n    sem_destroy(&s);\n\n    return 0;\n}\n```\n\n利用信号量实现父进程等待子进程再退出的功能，即父进程等待一个条件，如果条件满足就往下执行代码。比方说这里初始化信号量的值为 0，创建一个子线程去执行内部代码，主线程调用 sem_wait 等待子线程调用 sem_post之后才解除阻塞，才继续往下执行。\n\n---\n\n信号量还可以用于解决生产者/消费者问题，互斥锁+条件变量同样可以用于解决生产者/消费者问题。实际上，我们完全可以利用互斥锁+条件变量封装出信号量。\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n\ntypedef struct {\n    int count;\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n} Semaphore;\n\n// 初始化信号量\nvoid sem_init(Semaphore *sem, int value) {\n    sem->count = value;\n    pthread_mutex_init(&sem->mutex, NULL);\n    pthread_cond_init(&sem->cond, NULL);\n}\n\n// 等待信号量\nvoid sem_wait(Semaphore *sem) {\n    pthread_mutex_lock(&sem->mutex);\n    while (sem->count == 0) {\n        pthread_cond_wait(&sem->cond, &sem->mutex);\n    }\n    sem->count--;\n    pthread_mutex_unlock(&sem->mutex);\n}\n\n// 发出信号\nvoid sem_post(Semaphore *sem) {\n    pthread_mutex_lock(&sem->mutex);\n    sem->count++;\n    pthread_cond_signal(&sem->cond);\n    pthread_mutex_unlock(&sem->mutex);\n}\n\n// 销毁信号量\nvoid sem_destroy(Semaphore *sem) {\n    pthread_mutex_destroy(&sem->mutex);\n    pthread_cond_destroy(&sem->cond);\n}\n```\n\n## 常见并发问题\n\n![现代应用程序的缺陷统计.png](/images/2024/08/22/f0219850-606d-11ef-b5d8-395e250ad2a7.png)\n\n我们现在来深入分析这两种类型的缺陷。对于第一类非死锁的缺陷，我们通过该研究的例子来讨论。对于第二类死锁缺陷，我们讨论人们在阻止、避免和处理死锁上完成的大量工作。\n\n（一）非死锁缺陷\n\n我们现在主要讨论其中两种：违反原子性缺陷和错误顺序缺陷\n\n违反原子性可以加锁，错误顺序可以用条件变量\n\n（二）死锁缺陷\n\n双方各持有对方所需的资源，同时不会为了满足对方需求而自动释放来满足对方的需求，导致死锁（僵持不下，代码无法推进），对方更不可能从自己的手中抢占资源来满足个人，然后彼此傻傻等待需求被满足（即对方把资源释放）。\n\n![死锁.png](/images/2024/08/22/e95cce90-606d-11ef-b5d8-395e250ad2a7.png)\n\n死锁的产生需要如下 4 个条件：\n\n- 互斥：线程对于需要的资源进行互斥的访问（例如一个线程抢到锁）\n- 持有并等待：线程持有了资源（例如已将持有的锁），同时又在等待其他资源（例如，需要获得的锁）\n- 非抢占：线程获得的资源（例如锁），不能被抢占\n- 循环等待：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的\n\n**如上 4 个条件的任何一个没有满足，死锁就不会产生**。因此，我们首先研究一下预防死锁的方法；每个策略都设法阻止某一个条件，从而解决死锁的问题。\n\n（一）破坏互斥\n\n通过强大的硬件指令，我们可以构造出不需要锁的数据结构。\n\n（二）破坏持有并等待\n\n通过原子地抢锁来避免\n\n```c++\nlock(prevention); \nlock(L1); \nlock(L2); \n... \nunlock(prevention);\n```\n\n先抢到 prevention 这个锁之后，代码保证了在抢锁的过程中，不会有不合时宜的线程切换，从而避免了死锁。当然，这需要任何线程在任何时候抢占锁时，先抢到全局的 prevention锁。但是这种方法存在的问题是，你需要知道所有的锁，来保证所有锁的申请被 lock，不适宜于封装。\n\n（三）破坏非抢占\n\ntrylock()函数会尝试获得锁，或者返回−1，表示锁已经被占有。你可以稍后重试一下。\n\n注意，另一个线程可以使用相同的加锁方式，但是不同的加锁顺序（L2 然后 L1），程序仍然不会产生死锁。但是会引来一个新的问题：活锁（livelock）。两个线程有可能一直重复这一序列，又同时都抢锁失败。这种情况下，系统一直在运行这段代码（因此不是死锁），但是又不会有进展，因此名为活锁。也有活锁的解决方法：例如，可以在循环结束的时候，先随机等待一个时间，然后再重复整个动作，这样可以降低线程之间的重复互相干扰。\n\n关于这个方案的最后一点：使用 trylock 方法可能会有一些困难。第一个问题仍然是封装：如果其中的某一个锁，是封装在函数内部的，那么这个跳回开始处就很难实现。如果代码在中途获取了某些资源，必须要确保也能释放这些资源。例如，在抢到 L1 后，我们的代码分配了一些内存，当抢 L2 失败时，并且在返回开头之前，需要释放这些内存。当然，在某些场景下，这种方法很有效。\n\n（四）破坏循环等待\n\n最直接的方法就是获取锁时提供一个全序（total ordering）。假如系统共有两个锁（L1 和 L2），那么我们每次都先申请 L1 然后申请 L2，就可以避免死锁。这样严格的顺序避免了循环等待，也就不会产生死锁。但是这种方法存在的问题是，你需要知道所有的锁，来保证申请锁的顺序，不适宜于封装。\n\n---\n\n⭐️内容取自译者王海鹏《操作系统导论》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书","tags":["操作系统导论","OS"],"categories":["technology"]},{"title":"第三章：内存虚拟化","url":"/2024/08/22/第三章：内存虚拟化/","content":"\n<!-- toc -->\n\n## 抽象：地址空间\n\n当我们描述地址空间时，所描述的是操作系统**提供给运行程序的抽象**。程序不在物理地址 0～16KB 的内存中，而是加载在任意的物理地址。当操作系统这样做时，我们说操作系统在虚拟化内存，因为运行的程序**自认为**它被加载到特定地址（例如 0）的内存中，并且具有非常大的地址空间。\n\n比方说下图中进程 A 尝试在地址 0（我们将称其为虚拟地址）执行加载操作时，然而操作系统在硬件的支持下，出于某种原因，必须确保不是加载到物理地址 0，而是物理地址 320KB（这是 A 载入内存的地址）。\n\n![地址空间.png](/images/2024/08/22/7f264150-606d-11ef-b5d8-395e250ad2a7.png)\n\n虚拟系统内存的目标：\n\n- 透明：操作系统实现虚拟内存的方式，应该让运行的程序看不见。因此，程序不应该感知到内存被虚拟化的事实，相反，程序的行为就好像它拥有自己的私有物理内存。在幕后，操作系统（和硬件）完成了所有的工作，让不同的工作复用内存，从而实现这个假象\n- 效率：操作系统应该追求虚拟化尽可能高效，包括时间上（即不会使程序运行得更慢）和空间上（即不需要太多额外的内存来支持虚拟化）。在实现高效率虚拟化时，操作系统将不得不依靠硬件支持，包括 TLB 这样的硬件功能\n- 保护：操作系统应确保进程受到保护，不会受其他进程影响，操作系统本身也不会受进程影响。当一个进程执行加载、存储或指令提取时，它不应该以任何方式访问或影响任何其他进程或操作系统本身的内存内容（即在它的地址空间之外的任何内容）。因此，保护让我们能够在进程之间提供隔离的特性，每个进程都应该在自己的独立环境中运行，避免其他出错或恶意进程的影响\n\n## 机制：地址转换\n\n利用地址转换，硬件对每次内存访问进行处理（即指令获取、数据读取或写入），将**指令中的虚拟地址转换为数据实际存储的物理地址**。因此，在每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定位到内存中实际的位置。\n\n仅仅依靠硬件不足以实现虚拟内存，因为它只是提供了底层机制来提高效率。操作系统必须在关键的位置介入，设置好硬件，以便完成正确的地址转换。因此它**必须管理内存**，记录被占用和空闲的内存位置，并明智而谨慎地介入，保持对内存使用的控制。\n\n![地址转换.png](/images/2024/08/22/7750f1f0-606d-11ef-b5d8-395e250ad2a7.png)\n\n综述的一切，只是为了给程序营造一种假象，即每个程序都拥有私有的内存，那里存放着它自己的代码和数据。实际情况是，许多程序是在同一时间共享着内存。\n\n---\n\n为了一步步推导出当前操作系统真实的内存虚拟化情况，我们需要暂时做出如下假设：\n\n- 设用户的地址空间必须连续地放在物理内存中\n- 地址空间不是很大，具体来说，小于物理内存的大小\n- 每个地址空间的大小完全一样\n\n---\n\n前面介绍的基于硬件的地址转换，又称为动态重定位。具体来说，每个 CPU 需要两个硬件寄存器：基址（base）寄存器和界限（bound）寄存器。这组基址和界限寄存器，让我们能够将地址空间放在物理内存的任何位置，同时又能确保进程只能访问自己的地址空间。\n\n注：起始地址记录在基址寄存器中。\n\n```basic\nphysical address = virtual address + base\n```\n\n进程中使用的内存引用都是虚拟地址（virtual address），硬件接下来将虚拟地址加上基址寄存器中的内容，得到物理地址（physical address），再发给内存系统。如果进程需要访问超过这个界限或者为负数的虚拟地址，CPU 将触发异常，进程最终可能被终止。界限寄存器的用处在于，它确保了进程产生的所有地址都在进程的地址“界限”中。\n\n一个基址寄存器（重定位寄存器）将虚拟地址转换为物理地址，一个界限寄存器确保这个地址在进程地址空间的范围内。它们一起提供了既简单又高效的虚拟内存机制。\n\n![动态重定位.png](/images/2024/08/22/70519030-606d-11ef-b5d8-395e250ad2a7.png)\n\n这种基址寄存器配合界限寄存器的硬件结构是芯片中的（每个 CPU 一对）。有时我们将CPU 的这个负责地址转换的部分统称为内存管理单元（MMU）。\n\n补充：界限寄存器通常有两种使用方式。在一种方式中（像上面那样），它记录地址空间的大小，硬件在将虚拟地址与基址寄存器内容求和前，就检查这个界限。另一种方式是界限寄存器中记录地址空间结束的物理地址，硬件在转化虚拟地址到物理地址之后才去检查这个界限。这两种方式在逻辑上是等价的。\n\n简单总结一下需要的硬件支持，见下表。\n\n![硬件支持.png](/images/2024/08/22/6a1864a0-606d-11ef-b5d8-395e250ad2a7.png)\n\n为了支持动态重定位，硬件添加了新的功能，使得操作系统有了一些必须处理的新问题。硬件支持和操作系统管理结合在一起，实现了一个简单的虚拟内存。具体来说，在一些关键的时刻操作系统需要介入，以实现基址和界限方式的虚拟内存。\n\n![操作系统的职责.png](/images/2024/08/22/658fcf40-606d-11ef-b5d8-395e250ad2a7.png)\n\n对于基址/界限管理中，每个 CPU 毕竟只有一个基址寄存器和一个界限寄存器，但对于每个运行的程序，它们的值都不同，因为每个程序被加载到内存中不同的物理地址。因此，在切换进程时，操作系统必须保存和恢复基础和界限寄存器。具体来说，当操作系统决定中止当前的运行进程时，它必须将当前基址和界限寄存器中的内容保存在内存中，放在某种每个进程都有的结构中，如进程结构（process structure）或进程控制块（PCB）中。类似地，当操作系统恢复执行某个进程时（或第一次执行），也必须给基址和界限寄存器设置正确的值。\n\n---\n\n遗憾的是，这个简单的动态重定位技术有效率低下的问题。从下图中可以看到，重定位的进程使用了从 32KB 到 48KB 的物理内存，但**由于该进程的栈区和堆区并不很大，导致这块内存区域中大量的空间被浪费**（即图中*已分配但未使用*）。这种浪费通常称为内部碎片，指的是已经分配的内存单元内部有未使用的空间（即碎片），造成了浪费。\n\n在我们当前的方式中，即使有足够的物理内存容纳更多进程，但我们目前要求将地址空间放在固定大小的槽块中，因此会出现内部碎片。所以，我们需要更复杂的机制，以便更好地利用物理内存，避免内部碎片。第一次尝试是**将基址加界限的概念稍稍泛化，得到分段的概念**。\n\n![单个重定位.png](/images/2024/08/22/5f099520-606d-11ef-b5d8-395e250ad2a7.png)\n\n## 分段\n\n我们依旧需要用到前面那张图，来引出为什么需要考虑分段（尽管这还完全不够）。\n\n到目前为止，我们一直假设将所有进程的地址空间完整地加载到内存中。利用基址和界限寄存器，操作系统很容易将不同进程重定位到不同的物理内存区域。但是，对于这些内存区域，你可能已经注意到一件有趣的事：栈和堆之间，有一大块“空闲”空间。\n\n如果我们将整个地址空间放入物理内存，那么栈和堆之间的空间并没有被进程使用，却依然占用了实际的物理内存。因此，简单的通过基址寄存器和界限寄存器实现的虚拟内存很浪费。另外，如果剩余物理内存无法提供连续区域来放置完整的地址空间，进程便无法运行。这种基址加界限的方式看来并不像我们期望的那样灵活。\n\n没错，如果分配的物理内存没有被实际使用，又不能分配给他人使用就会浪费。为了解决这个问题，分段的概念应运而生。\n\n这个想法很简单，在 **MMU 中引入<u>不止一个</u>基址和界限寄存器对**，而是给地址空间内的每个逻辑段（segment）一对。一个段只是地址空间里的一个连续定长的区域，在典型的地址空间里有 3 个逻辑不同的段：代码、栈和堆。**分段的机制使得操作系统能够将不同的段放到不同的物理内存区域，从而避免了虚拟地址空间中的未使用部分占用物理内存**。\n\n![一个地址空间.png](/images/2024/08/22/551647c0-606d-11ef-b5d8-395e250ad2a7.png)\n\n上面是一个进程被分配内存大小的情况，有许多为使用的内存空间，我们用三组寄存器就能够把已经使用的内存空间（图中程序代码、栈和堆）标记出来，那么其余部分就是可以被利用的内存了。\n\n![记录值.png](/images/2024/08/22/4db19480-606d-11ef-b5d8-395e250ad2a7.png)\n\n---\n\n硬件在地址转换时使用段寄存器。它如何知道段内的偏移量，以及地址引用了哪个段？\n\n一种常见的方式，就是用虚拟地址的开头几位来标识不同的段。在我们之前的例子中，有 3 个段，因此需要两位来标识。如果我们用 14 位虚拟地址的前两位来标识，那么虚拟地址如下所示：\n\n![虚拟地址.png](/images/2024/08/22/4461b310-606d-11ef-b5d8-395e250ad2a7.png)\n\n那么在我们的例子中，如果前两位是 00，硬件就知道这是属于**代码段的地址**，因此使用代码段的基址和界限来重定位到正确的物理地址。如果前两位是 01，则是**堆地址**，对应地，使用堆的基址和界限。\n\n从下图中可以看到，前两位（01）告诉硬件我们引用哪个段。剩下的 12 位是段内偏移：0000 0110 1000（即十六进制 0x068 或十进制 104）。因此，硬件就用前两位来决定使用哪个段寄存器，然后用后 12 位作为段内偏移。偏移量与基址寄存器相加，硬件就得到了最终的物理地址。请注意，偏移量也简化了对段边界的判断。我们只要检查偏移量是否小于界限，大于界限的为非法地址。\n\n你或许已经注意到，上面使用两位来区分段，但实际只有 3 个段（代码、堆、栈），因此有一个段的地址空间被浪费。因此有些系统中会将堆和栈当作同一个段，因此只需要一位来做标识。\n\n![二进制形式.png](/images/2024/08/22/3dc9ecc0-606d-11ef-b5d8-395e250ad2a7.png)\n\n我们似乎还没有提及栈，这是因为栈的增长方向还需要进行识别。首先，我们需要一点硬件支持。除了基址和界限外，硬件还需要知道段的增长方向（用一位区分，比如 1 代表自小而大增长，0 反之）。\n\n![栈增长方向.png](/images/2024/08/22/377b8b80-606d-11ef-b5d8-395e250ad2a7.png)\n\n随着分段机制的不断改进，系统设计人员很快意识到，通过再多一点的硬件支持，就能实现新的效率提升。具体来说，要节省内存，有时候在地址空间之间**共享某些内存段**是有用的。尤其是，代码共享很常见，今天的系统仍然在使用。\n\n为了支持共享，需要一些额外的硬件支持，这就是保护位（protection bit）。基本为每个段增加了几个位，标识程序是否能够读写该段，或执行其中的代码。通过将代码段标记为只读，同样的代码可以被多个进程共享，而不用担心破坏隔离。虽然每个进程都认为自己独占这块内存，但操作系统秘密地共享了内存，进程不能修改这些内存，所以假象得以保持。\n\n![保护位.png](/images/2024/08/22/2bb37e20-606d-11ef-b5d8-395e250ad2a7.png)\n\n---\n\n现在你应该大致了解了分段的基本原理。系统运行时，地址空间中的不同段被重定位到物理内存中。与我们之前介绍的整个地址空间只有一个基址/界限寄存器对的方式相比，大量节省了物理内存。具体来说，栈和堆之间没有使用的区域就不需要再分配物理内存，让我们能将更多地址空间放进物理内存。\n\n分段也带来了一些新的问题，重点谈外部碎片的产生。前面我们没有讲分段的时候，之前的基址/界限寄存器对的方式会产生内部碎片，因为分配给进程的内存有大部分没有被使用。现在我们用分段机制解决内部碎片问题，却引出外部碎片问题，即物理内存很快充满了许多空闲空间的小洞，因而很难分配给新的段，或扩大已有的段。比方说，一个进程需要分配一个 20KB 的段。当前有 24KB 空闲，但并不连续（是3 个不相邻的块）。因此，操作系统无法满足这个 20KB 的请求。\n\n后面我们会谈解决内部碎片问题，但提前预告，无论算法多么精妙，都无法完全消除外部碎片，因此，好的算法只是试图减小它。\n\n比方说接下来要介绍的分页机制。内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而**采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。**但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对**内存分页机制会有内部内存碎片**的现象。\n\n## 分页\n\n将空间分割成固定长度的分片。在虚拟内存中，我们称这种思想为分页。分页不是将一个进程的地址空间分割成几个不同长度的逻辑段（即代码、堆、段），而是分割成固定大小的单元，每个单元称为一页。相应地，我们把物理内存看成是定长槽块的阵列，叫作页帧。每个这样的页帧包含一个虚拟内存页。\n\n**为了记录地址空间的每个虚拟页放在物理内存中的位置，操作系统通常为每个进程保存一个数据结构，称为页表。页表的主要作用是为地址空间的每个虚拟页面保存地址转换，从而让我们知道每个页在物理内存中的位置**。\n\n在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**（物理页号），这个基地址与页内偏移的组合就形成了物理内存地址。\n\n![分页地址转换.png](/images/2024/08/22/14c98e70-606d-11ef-b5d8-395e250ad2a7.png)\n\n总结一下，对于一个内存地址转换，其实就是这样三个步骤：\n\n- 把虚拟内存地址，切分成页号和偏移量\n- 根据页号，从页表里面，查询对应的物理页号\n- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址\n\n注：暂时假定页表信息存储在物理内存中\n\n### 分页：快速地址转换（TLB）\n\n使用分页作为核心机制来实现虚拟内存，可能会带来较高的性能开销。因为要使用分页，就要将内存地址空间切分成大量固定大小的单元（页），并且需要记录这些单元的地址映射信息。因为这些映射信息一般存储在物理内存中，所以在转换虚拟地址时，分页逻辑上需要一次额外的内存访问。每次指令获取、显式加载或保存，都要额外读一次内存以得到转换信息，这慢得无法接受。\n\n利用缓存来加速访问，即TLB（它就是频繁发生的虚拟到物理地址转换的硬件缓存）。对每次内存访问，硬件先检查 TLB，看看其中是否有期望的转换映射，如果有，就完成转换（很快），不用访问页表（其中有全部的转换映射）。\n\n那如果TLB没有命中，由谁来处理呢？可能有两个答案：硬件或软件（操作系统）\n\n- 硬件处理：为了做到这一点，硬件必须知道页表在内存中的确切位置（通过页表基址寄存器），以及页表的确切格式。发生未命中时，硬件会“遍历”页表，找到正确的页表项，取出想要的转换映射，用它更新 TLB，并重试该指令\n- 软件处理：更现代的体系结构。发生 TLB 未命中时，硬件系统会抛出一个异常，这会暂停当前的指令流，将特权级提升至内核模式，跳转至陷阱处理程序。接下来你可能已经猜到了，这个陷阱处理程序是操作系统的一段代码，用于处理 TLB 未命中。这段代码在运行时，会查找页表中的转换映射，然后用特别的“特权”指令更新 TLB，并从陷阱返回。此时，硬件会重试该指令（导致 TLB 命中）\n\n接下来讨论几个重要的细节：\n\n1. 这里的从陷阱返回指令稍稍不同于之前提到的服务于系统调用的从陷阱返回。在后一种情况下，从陷阱返回应该继续执行陷入操作系统之后那条指令，就像从函数调用返回后，会继续执行此次调用之后的语句。在前一种情况下，在从 TLB 未命中的陷阱返回后，硬件必须从导致陷阱的指令继续执行。这次重试因此导致该指令再次执行，但这次会命中 TLB。因此，根据陷阱或异常的原因，系统在陷入内核时必须保存不同的程序计数器，以便将来能够正确地继续执行\n2. 在运行 TLB 未命中处理代码时，操作系统需要格外小心避免引起 TLB 未命中的无限递归\n\n软件管理的方法，主要优势是灵活性：操作系统可以用任意数据结构来实现页表，不需要改变硬件。另一个优势是简单性。从 TLB 控制流中可以看出，硬件不需要对未命中做太多工作，它抛出异常，操作系统的未命中处理程序会负责剩下的工作。\n\n有了 TLB，在进程间切换时（因此有地址空间切换），会面临一些新问题。具体来说，**TLB 中包含的虚拟到物理的地址映射只对当前进程有效，对其他进程是没有意义的**。所以在发生进程切换时，硬件或操作系统（或二者）必须注意确保即将运行的进程不要误读了之前进程的地址映射。\n\n当一个进程（P1）正在运行时，假设TLB 缓存了对它有效的地址映射，即来自 P1 的页表。对这个例子，假设 P1 的 10 号虚拟页映射到了 100 号物理帧。假设还有一个进程（P2），操作系统不久后决定进行一次上下文切换，运行 P2。这里假定 P2 的 10 号虚拟页映射到 170 号物理帧。如果这两个进程的地址映射都在 TLB 中，TLB 的内容如下图所示。\n\n![TLB中的内容.png](/images/2024/08/22/f9ae0300-606c-11ef-b5d8-395e250ad2a7.png)\n\n这里很明显有一个问题：VPN 10 被转换成了 PFN 100（P1）和 PFN 170（P2），但硬件分不清哪个项属于哪个进程。所以我们还需要做一些工作，让 TLB 正确而高效地支持跨多进程的虚拟化。这个问题有些可能的解决方案：\n\n（一）上下文切换的时候清空 TLB\n\n上下文切换时，简单地清空（flush）TLB，这样在新进程运行前 TLB 就变成了空的。如果是软件管理 TLB 的系统，可以在发生上下文切换时，通过一条显式（特权）指令来完成。如果是硬件管理 TLB，则可以在页表基址寄存器内容发生变化时清空 TLB。不论哪种情况，清空操作都是把全部有效位（valid）置为 0，本质上清空了 TLB。\n\n上下文切换的时候清空 TLB，这是一个可行的解决方案，进程不会再读到错误的地址映射。但是，有一定开销：每次进程运行，当它访问数据和代码页时，都会触发 TLB 未命中。如果操作系统频繁地切换进程，这种开销会很高。\n\n（二）增加硬件支持，实现跨上下文切换的 TLB 共享\n\n为了减少这种开销（上下文切换的时候清空 TLB，进程频繁切换开销很高），一些系统增加了硬件支持，实现跨上下文切换的 TLB 共享。比如有的系统在 TLB 中添加了一个地址空间标识符（ASID）。可以把ASID 看作是进程标识符（PID），但通常比 PID 位数少（PID 一般 32 位，ASID 一般是 8 位）。\n\n![ASID.png](/images/2024/08/22/f2e604f0-606c-11ef-b5d8-395e250ad2a7.png)\n\n因此，有了地址空间标识符，TLB 可以同时缓存不同进程的地址空间映射，没有任何冲突。当然，硬件也需要知道当前是哪个进程正在运行，以便进行地址转换，因此操作系统在上下文切换时，必须将某个特权寄存器设置为当前进程的 ASID。\n\n补充一下，你可能想到了另一种情况，TLB 中某两项非常相似。如下图中，属于两个不同进程的两项，将两个不同的 VPN 指向了相同的物理页。\n\n![包含相似两项的TLB.png](/images/2024/08/22/eefeb8a0-606c-11ef-b5d8-395e250ad2a7.png)\n\n如果两个进程共享同一物理页（例如代码段的页），就可能出现这种情况。在上面的例子中，进程 P1 和进程 P2 共享 101 号物理页，但是 P1 将自己的 10 号虚拟页映射到该物理页，而 P2 将自己的 50 号虚拟页映射到该物理页。共享代码页（以二进制或共享库的方式）是有用的，因为它减少了物理页的使用，从而减少了内存开销。\n\n注：TLB 和其他缓存一样，还有一个问题要考虑，即缓存替换。具体来说，向 TLB 中插入新项时，会替换一个旧项，这样问题就来了：应该替换那一个？在讨论页换出到磁盘的问题时，我们将详细研究这样的策略。\n\n### 分页：较小的表\n\n（一）混合方法：分页和分段\n\n分段解决内部碎片引出外部碎片，分页解决外部碎片引出内部碎片，我们能否结合二者的优点而避开缺点呢？\n\n我们的杂合方法不是为进程的整个地址空间提供单个页表，而是为每个逻辑分段提供一个。在这个例子中，我们可能有 3 个页表，地址空间的代码、堆和栈部分各有一个。\n\n现在，回忆在分段中，有一个基址（base）寄存器，告诉我们每个段在物理内存中的位置，还有一个界限（bound）或限制（limit）寄存器，告诉我们该段的大小。在杂合方案中，我们仍然在 MMU 中拥有这些结构。在这里，我们使用基址不是指向段本身，而是保存该段的页表的物理地址。界限寄存器用于指示页表的结尾（即它有多少有效页）。\n\n![段页结合.png](/images/2024/08/22/e92e12e0-606c-11ef-b5d8-395e250ad2a7.png)\n\n我们通过一个简单的例子来澄清。假设 32 位虚拟地址空间包含 4KB 页面，并且地址空间分为 4 个段。在这个例子中，我们只使用 3 个段：一个用于代码，另一个用于堆，还有一个用于栈。\n\n要确定地址引用哪个段，我们会用地址空间的前两位。假设 00 是未使用的段，01 是代码段，10 是堆段，11 是栈段。因此，虚拟地址如下所示：\n\n![段页结合例子.png](/images/2024/08/22/e52757b0-606c-11ef-b5d8-395e250ad2a7.png)\n\n在硬件中，假设有 3 个基本/界限对，代码、堆和栈各一个。当进程正在运行时，每个段的基址寄存器都包含该段的线性页表的物理地址。因此，系统中的每个进程现在都有 3 个与其关联的页表。在上下文切换时，必须更改这些寄存器，以反映新运行进程的页表的位置。\n\n在 TLB 未命中时（假设硬件管理的 TLB，即硬件负责处理 TLB 未命中），硬件使用分段位（SN）来确定要用哪个基址和界限对。然后硬件将其中的物理地址与 VPN 结合起来，形成页表项（PTE）的地址。\n\n![计算地址.png](/images/2024/08/22/df8933a0-606c-11ef-b5d8-395e250ad2a7.png)\n\n杂合方案的关键区别在于，每个分段都有界限寄存器，每个界限寄存器保存了段中最大有效页的值。例如，如果代码段使用它的前 3 个页（0、1 和 2），则代码段页表将只有 3个项分配给它，并且界限寄存器将被设置为 3。内存访问超出段的末尾将产生一个异常，并可能导致进程终止。\n\n但是，你可能会注意到，这种方法并非没有问题。首先，它仍然要求使用分段。正如我们讨论的那样，分段并不像我们需要的那样灵活，因为它假定地址空间有一定的使用模式。例如，如果有一个大而稀疏的堆，仍然可能导致大量的页表浪费。其次，这种杂合导致外部碎片再次出现。尽管大部分内存是以页面大小单位管理的，但页表现在可以是任意大小（是 PTE 的倍数）。因此，在内存中为它们寻找自由空间更为复杂。出于这些原因，人们继续寻找更好的方式来实现更小的页表。\n\n（二）多级页表\n\n多级页表的基本思想很简单。首先，将页表分成页大小的单元。然后，如果整页的页表项（PTE）无效，就完全不分配该页的页表。为了追踪页表的页是否有效（以及如果有效，它在内存中的位置），使用了名为页目录的新结构。页目录因此可以告诉你页表的页在哪里，或者页表的整个页不包含有效页。\n\n下图的左边是经典的线性页表。即使地址空间的大部分中间区域无效，我们仍然需要为这些区域分配页表空间（即页表的中间两页）。右侧是一个多级页表。页目录仅将页表的两页标记为有效（第一个和最后一个）；因此，页表的这两页就驻留在内存中。因此，你可以形象地看到多级页表的工作方式：它只是让线性页表的一部分消失（释放这些帧用于其他用途），并用页目录来记录页表的哪些页被分配。\n\n![线性与多级比较.png](/images/2024/08/22/d87cb280-606c-11ef-b5d8-395e250ad2a7.png)\n\n多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了虚拟地址到物理地址转换的速度，也就是带来了时间上的开销。比方说二级页表中，在 TLB 未命中时，需要从内存加载两次，才能从页表中获取正确的地址转换信息（一次用于页目录，另一次用于 PTE 本身），而用线性页表只需要一次加载。\n\n## 超越物理内存：机制\n\n到目前为止，我们一直假定地址空间非常小，能放入物理内存。事实上，我们假设每个正在运行的进程的地址空间都能放入内存。实际情况是内存并没有想象中那么大，特别是在当前上百个进程运行的电脑上，我们需要把目标放到更大的磁盘空间上，尽管磁盘访问要比内存访问慢的多。\n\n为什么我们要为进程支持巨大的地址空间？答案还是方便和易用性。有了巨大的地址空间，你不必担心程序的数据结构是否有足够空间存储，只需自然地编写程序，根据需要分配内存。这是操作系统提供的一个强大的假象，使你的生活简单很多。\n\n我们要做的第一件事情就是，在硬盘上开辟一部分空间用于物理页的移入和移出。在操作系统中，一般这样的空间称为**交换空间**（swap space），因为我们将内存中的页交换到其中，并在需要的时候又交换回去。因此，我们会假设操作系统能够以页大小为单元读取或者写入交换空间。为了达到这个目的，操作系统需要记住给定页的硬盘地址。\n\n![物理内存和交换空间.png](/images/2024/08/22/d1312c90-606c-11ef-b5d8-395e250ad2a7.png)\n\n从上图中你可以看到一个 4 页的物理内存和一个 8 页的交换空间。在这个例子中，3 个进程（进程 0、进程 1 和进程 2）主动共享物理内存。但 3 个中的每一个，都只有一部分有效页在内存中，剩下的在硬盘的交换空间中。第 4 个进程（进程 3）的所有页都被交换到硬盘上，因此很清楚它目前没有运行。有一块交换空间是空闲的，从这你应该也能看出，使用交换空间如何让系统假装内存比实际物理内存更大。\n\n（一）存在位\n\n如果希望允许页交换到硬盘，必须添加更多的机制。具体来说，当硬件在 PTE中查找时，可能**发现页不在物理内存中**。硬件（或操作系统，在软件管理 TLB 时）判断是否在内存中的方法，是通过页表项中的一条新信息，即**存在位**。如果存在位设置为 1，则表示该页存在于物理内存中，并且所有内容都如上所述进行。如果存在位设置为零，则页不在内存中，而在硬盘上。访问不在物理内存中的页，这种行为通常被称为**页错误**。\n\n（二）页错误\n\n在页错误时，**操作系统被唤起来处理页错误**。一段称为“页错误处理程序”的代码会执行，来处理页错误。如果一个页不存在，它已被交换到硬盘，在处理页错误的时候，操作系统需要将该页交换到内存中。那么，问题来了：操作系统如何知道所需的页在哪儿？在许多系统中，页表是存储这些信息最自然的地方。因此，操作系统**可以用 PTE 中的某些位来存储硬盘地址**，这些位通常用来存储像页的 PFN 这样的数据。当操作系统接收到页错误时，它会在 PTE 中查找地址，并将请求发送到硬盘，将页读取到内存中。\n\n当硬盘 I/O 完成时，操作系统会更新页表，将此页标记为存在，更新页表项（PTE）的PFN 字段以记录新获取页的内存位置，并重试指令。下一次重新访问 TLB 还是未命中，然而这次因为页在内存中，因此会将页表中的地址更新到 TLB 中（也可以在处理页错误时更新 TLB 以避免此步骤）。最后的重试操作会在 TLB 中找到转换映射，从已转换的内存物理地址，获取所需的数据或指令。\n\n注意： I/O 在运行时，进程将处于阻塞状态。因此，当页错误正常处理时，操作系统可以自由地运行其他可执行的进程。因为 I/O 操作是昂贵的，一个进程进行I/O（页错误）时会执行另一个进程，这种交叠是多道程序系统充分利用硬件的一种方式。\n\n再注：如果内存满了，操作系统可能希望先交换出（page out）一个或多个页，以便为操作系统即将交换入的新页留出空间。选择哪些页被交换出或被替换（replace）的过程，被称为页交换策略（后面详解）。\n\n（三）页错误处理流程\n\n首先，操作系统必须为将要换入的页找到一个物理帧，如果没有这样的物理帧，我们将不得不等待交换算法运行，并从内存中踢出一些页，释放帧供这里使用。在获得物理帧后，处理程序发出 I/O 请求从交换空间读取页。最后，当这个慢操作完成时，操作系统更新页表并重试指令。重试将导致 TLB 未命中，然后再一次重试时，TLB 命中，此时硬件将能够访问所需的值。\n\n到目前为止，我们一直描述的是操作系统会等到内存已经完全满了以后才会执行交换流程，然后才替换（踢出）一个页为其他页腾出空间。正如你想象的那样，这有点不切实际的，因为操作系统可以更主动地预留一小部分空闲内存。\n\n为了保证有少量的空闲内存，大多数操作系统会设置高水位线和低水位线，来帮助决定何时从内存中清除页。原理是这样：当操作系统发现有少于低水位线个页可用时，后台负责释放内存的线程会开始运行，直到有高水位线个可用的物理页。这个后台线程有时称为交换守护进程或页守护进程，它然后会很开心地进入休眠状态，因为它毕竟为操作系统释放了一些内存。\n\n## 超越物理内存：策略\n\n由于内存只包含系统中所有页的子集，因此可以将其视为系统中虚拟内存页的缓存（cache）。因此，在为这个缓存选择替换策略时，我们的目标是让缓存未命中（cache miss）最少，即使得从磁盘获取页的次数最少。或者，可以将目标看成让缓存命中（cache hit）最多，即在内存中找到待访问页的次数最多。\n\n下面简单介绍一些缓存未命中的情况下的页交换策略。\n\n（一）简单策略：FIFO\n\n当发生替换时，队列尾部的页（“先入”页）被踢出。\n\n![FIFO.png](/images/2024/08/22/c89b9a70-606c-11ef-b5d8-395e250ad2a7.png)\n\n（二）简单策略：随机\n\n在内存满的时候它随机选择一个页进行替换。\n\n![随机.png](/images/2024/08/22/c30c9190-606c-11ef-b5d8-395e250ad2a7.png)\n\n（三）利用历史数据：LRU\n\n页替换策略可以使用的一个历史信息是频率（frequency）。如果一个页被访问了很多次，也许它不应该被替换，因为它显然更有价值。页更常用的属性是访问的近期性（recency），越近被访问过的页，也许再次访问的可能性也就越大。\n\n![LRU.png](/images/2024/08/22/bd0858b0-606c-11ef-b5d8-395e250ad2a7.png)\n\n---\n\n⭐️内容取自译者王海鹏《操作系统导论》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书","tags":["操作系统导论","OS"],"categories":["technology"]},{"title":"第二章：CPU虚拟化","url":"/2024/08/22/第二章：CPU虚拟化/","content":"\n<!-- toc -->\n\n作者用分配桃子举例说明虚拟化，为了让这个例子更加合理，我们假定拿到🍑的人并不食用，仅是占有就心满意足了（当我后面谈食用或品尝也只是占有的意思，享用完之后就会归还）。每个小朋友（进程）都希望得到一个完整的桃子，可现实情况是篮筐中只有一个桃子，我需要为这个篮筐遮上一层布，“欺骗”小朋友这里面有很多很多的桃子（虚拟化），好让他们齐聚于此。我对每个伸手要桃子的小朋友说，你手里现在已经被分配一个完整的桃子，等你真正想要占有实体的时候我会具体的分配到你的手里。每个小朋友不可能一口吃掉这颗桃，等他需要品尝的时候，我就用小刀切割一块他所需的桃子交到他手里面（这是实际分配的，至于允诺的其它部分的桃子由于他暂时没有申请，视为我的可调用资源），给他慢慢享用。这样，其它小朋友来请求吃桃子的时候，我依旧能够满足他们的需求，因为我还有可调用资源。只要我不让他们看到这块布之后的桃子数量，他们永远都以为自己占有一个桃子。\n\n## 抽象：进程\n\n将指令编译成可执行程序，而进程就是正在运行的可执行程序，进程是操作系统为正在运行的程序提供的抽象。\n\n事实表明，人们常常希望同时运行多个程序。比如：在使用计算机或者笔记本的时候，我们会同时运行浏览器、邮件、游戏、音乐播放器，等等。实际上，一个正常的系统可能会有上百个进程同时在运行。我们要完成的任务就是如何让一个CPU同时运行多个程序。\n\n操作系统通过虚拟化CPU 来提供这种假象。通过让一个进程只运行一个**时间片**，然后**切换**到其他进程，操作系统提供了存在多个虚拟 CPU 的假象。这就是时分共享CPU 技术，允许用户如愿运行多个并发进程。潜在的开销就是性能损失，因为如果 CPU 必须共享，每个进程的运行就会慢一点。\n\n为了理解构成进程的是什么，我们必须理解它的机器状态：程序在运行时可以读取或更新的内容。在任何时刻，机器的哪些部分对执行该程序很重要？\n\n- 内存：指令存在内存中，正在运行的程序读取和写入的数据也在内存中。因此进程可以访问的内存（称为地址空间）是该进程的一部分\n- 寄存器：许多指令明确地读取或更新寄存器，因此它们对于执行该进程很重要\n- 持久性设备：程序也经常访问持久存储设备。此类 I/O 信息可能包含当前打开的文件列表\n\n---\n\n那么程序是如何转换为进程的？具体来说，操作系统如何启动并运行一个程序？进程创建实际如何进行？\n\n操作系统运行程序必须做的第一件事是将代码和所有静态数据（例如初始化变量）加载到内存中，加载到进程的地址空间中。程序最初以某种可执行格式驻留在磁盘上。因此，将程序和静态数据加载到内存中的过程，需要操作系统从磁盘读取这些字节，并将它们放在内存中的某处，如下图所示：\n\n![程序转换为进程.png](/images/2024/08/22/e4518030-6063-11ef-b5d8-395e250ad2a7.png)\n\n现代操作系统惰性执行该过程，即仅在程序执行期间需要加载的代码或数据片段，才会加载（在举例桃子的时候我就特别强调过这件事情）。\n\n将代码和静态数据加载到内存后，操作系统在运行此进程之前还需要执行其他一些操作。必须为程序的运行时栈分配一些内存。C程序使用栈存放局部变量、函数参数和返回地址。操作系统分配这些内存，并提供给进程。操作系统也可能会用参数初始化栈。具体来说，它会将参数填入 main()函数，即 argc 和 argv 数组。\n\n操作系统也可能为程序的堆分配一些内存。在 C 程序中，堆用于显式请求的动态分配数据。程序通过调用 malloc()来请求这样的空间，并通过调用 free()来明确地释放它。\n\n操作系统还将执行一些其他初始化任务，特别是与输入/输出（I/O）相关的任务。例如，在 UNIX 系统中，默认情况下每个进程都有 3 个打开的文件描述符，用于标准输入、输出和错误。这些描述符让程序轻松读取来自终端的输入以及打印输出到屏幕。\n\n通过将代码和静态数据加载到内存中，通过创建和初始化栈以及执行与 I/O 设置相关的其他工作，OS 现在（终于）为程序执行搭好了舞台。然后它有最后一项任务：启动程序，在入口处运行，即 main()。**通过跳转到 main()例程，OS 将 CPU的控制权转移到新创建的进程中，从而程序开始执行**。\n\n---\n\n进程在给定时间可能处于的不同状态：\n\n- 创建：需要获取系统资源创建进程管理块（PCB）完成资源分配，表示可被调度。进入就绪态（这个动作很快）\n- 就绪：加入进程等待队列，等待被操作系统进程调度（分配CPU资源）。一旦被分配CPU资源，立即开始执行，即进入执行态\n- 执行：进程运行中，如果时间片用完会进入到就绪态，即进入进程等待队列；如果在时间片范围内运行完成就进入终止态；如果运行过程中出现I/O请求等阻塞操作，将进入阻塞态\n- 阻塞：I/O请求等阻塞操作完成后解除阻塞，进入就绪态，即进入进程等待队列\n- 终止：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行\n\n![进程的状态.png](/images/2024/08/22/db80b9d0-6063-11ef-b5d8-395e250ad2a7.png)\n\n注：PCB记录进程的相关消息\n\n## 机制：受限直接执行\n\n为了虚拟化 CPU，操作系统需要以某种方式让许多任务共享物理 CPU，让它们看起来像是同时运行。基本思想很简单：运行一个进程一段时间，然后运行另一个进程，如此轮换。通过以这种方式时分共享CPU，就实现了虚拟化。\n\n在构建这样的虚拟化机制时存在一些挑战：\n\n- 性能：如何在不增加系统开销的情况下实现虚拟化\n- 控制权：如何有效地运行进程，同时保留对 CPU 的控制\n\n控制权对于操作系统尤为重要，因为操作系统负责资源管理。如果没有控制权，一个进程可以简单地无限制运行并接管机器，或访问没有权限的信息。\n\n### 问题1：受限制的操作\n\n受限直接执行：只需直接在 CPU上运行程序即可。因此，当 OS 希望启动程序运行时，它会在进程列表中为其创建一个进程条目，为其分配一些内存，将程序代码（从磁盘）加载到内存中，找到入口点，跳转到那里，并开始运行用户的代码。\n\n但是这种执行方式存在问题如下：\n\n- 如果我们只运行一个程序，操作系统怎么能确保程序不做任何我们不希望它做的事，同时仍然高效地运行它？\n- 当我们运行一个进程时，操作系统如何让它停下来并切换到另一个进程，从而实现虚拟化 CPU 所需的时分共享？\n\n受限直接执行的问题非常明显，如果进程希望执行某种受限操作（如向磁盘发出 I/O 请求或获得更多系统资源），该怎么办？\n\n对于 I/O 和其他相关操作，一种方法就是让所有进程做所有它想做的事情。但是，这样做导致无法构建许多我们想要的系统。例如，如果我们希望构建一个在授予文件访问权限前检查权限的文件系统，就不能简单地让任何用户进程向磁盘发出 I/O。如果这样做，一个进程就可以读取或写入整个磁盘，这样所有的保护都会失效。\n\n因此我们引入两种模式，分别是**用户模式**和**内核模式**：\n\n- 用户模式下运行的代码会**受到限制**。例如，在用户模式下运行时，进程不能发出 I/O 请求。这样做会导致处理器引发异常，操作系统可能会终止进程\n- 内核模式下的所有行为皆**不受限制**，运行的代码可以做它喜欢的事，包括特权操作，如发出 I/O 请求和执行所有类型的受限指令\n\n如果用户非要执行特权操作等内核模式下才能做到的事情，操作系统会提供**系统调用**解决这个难题。它允许内核小心地向用户程序暴露某些关键功能，例如访问文件系统、创建和销毁进程、与其他进程通信，以及分配更多内存。\n\n要执行系统调用，程序必须**执行特殊的陷阱（trap）指令**。该指令同时**跳入内核并将特权级别提升到内核模式**。一旦进入内核，系统就可以执行任何需要的特权操作（如果允许），从而为调用进程执行所需的工作。完成后，操作系统调用一个**特殊的从陷阱返回指令**，如你期望的那样，该指令**返回到发起调用的用户程序中，同时将特权级别降低，回到用户模式**。具体流程为：\n\n1. **保存上下文**：内核保存当前进程的上下文（寄存器状态等），以便在系统调用完成后能够恢复。\n2. **调用内核功能**：内核根据请求的系统调用号找到相应的处理函数，并执行相应的操作。\n3. **返回结果**：系统调用完成后，内核将结果（如返回值或错误码）传回用户态，并恢复进程上下文。\n4. **恢复用户态**：最后，控制权返回用户程序，继续执行后续指令。\n\n所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换，即 用户态 `->` 内核态 `->` 用户态。\n\n![用户和内核切换.png](/images/2024/08/22/c67e9cf0-6063-11ef-b5d8-395e250ad2a7.png)\n\n内核根据请求的系统调用号找到相应的处理函数，那这个用以查询的地方叫什么？\n\n内核通过在启动时设置**陷阱表**（trap table）来实现。当机器启动时，它在特权（内核）模式下执行，因此可以根据需要自由配置机器硬件。操作系统做的第一件事，就是告诉硬件在发生某些异常事件时要运行哪些代码。操作系统通常通过某种特殊的指令，通知硬件这些陷阱处理程序的位置。一旦硬件被通知，它就会记住这些处理程序的位置，直到下一次重新启动机器，并且硬件知道在发生系统调用和其他异常事件时要做什么（即跳转到哪段代码）。\n\n### 问题2：进程的切换\n\n（一）协作方式：等待系统调用\n\n操作系统相信系统的进程会合理运行。运行时间过长的进程被假定会定期放弃 CPU，以便操作系统可以决定运行其他任务。但是这种方式太理想，容易被不怀好意的人利用，始终占用CPU资源。\n\n事实证明，没有硬件的额外帮助，如果进程拒绝进行系统调用（也不出错），从而将控制权交还给操作系统，那么操作系统无法做任何事情。事实上，在协作方式中，当进程陷入无限循环时，唯一的办法就是使用古老的解决方案来解决计算机系统中的所有问题——重新启动计算机。\n\n（二）非协作方式：操作系统进行控制\n\n前面介绍的协作方式不能保证CPU的控制权再次回到操作系统手里，利用**时钟中断**就能解决。时钟设备可以编程为每隔几毫秒产生一次中断。产生中断时，当前正在运行的进程停止，操作系统中预先配置的中断处理程序会运行。此时，操作系统重新获得 CPU 的控制权，因此可以做它想做的事：停止当前进程，并启动另一个进程。\n\n既然操作系统已经重新获得了控制权，无论是通过系统调用协作，还是通过时钟中断更强制执行，都必须决定：是继续运行当前正在运行的进程，还是切换到另一个进程。这个决定是由**调度程序**做出的。\n\n那这个从一个进程切换到另一个进程的过程，我们称之为进程的上下文切换（进程是由内核来管理和调度的，进程的切换只能发生在内核态）。\n\n进程的上下文通常保存在操作系统的内核空间中，具体由操作系统的内核负责管理。当一个进程被挂起或切换到另一个进程时，**内核会保存该进程的上下文信息**，包括寄存器的值、程序计数器、堆栈指针、内存管理信息等。这些信息通常存储在一个称为进程控制块（PCB）的数据结构中。在进程调度时，操作系统会根据需要保存当前进程的上下文，并加载下一个要运行的进程的上下文，从而实现进程间的切换。\n\n保存上下文和恢复上下文的过程开销是很大的，此外，考虑到进程之间的相互的保护，只有操作系统能操作其它进程和了解其它进程的状态，因此这个过程需要在内核态完成。另外，我们知道，现代操作系统通过 TLB来管理虚拟内存到物理内存的映射关系。如果发生运行时动态链接（进入系统态）、内存紧缩等情况，即虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢，不过这是进程上下文切换带来的副作用了。\n\n![上下文切换.png](/images/2024/09/26/ef7cd750-7c0d-11ef-b432-77d11040975b.png)\n\n## 进程调度：介绍\n\n（一）先进先出（FIFO）\n\n**谁先进入到队列中谁就会被先执行**。实现简单，但是如果前面的进程耗费时间长，会导致后面的进程饥饿（长期得不到执行，很可能还有短时间就能完成的进程）。\n\n（二）最短任务优先（SJF）\n\n既然 FIFO 无法避免短作业的饥饿问题，那就**让短作业被提前执行**。可是这明显建立在多个任务同时到达的前提下，如果多个任务没有同时到达，还是会回退到 FIFO。\n\n如下图所示，进程A先到达，B和C后到达，这个时候A已经在执行，B和C还是要等待A执行完成或时间片结束。\n\n![sjf.png](/images/2024/08/22/b78f5ef0-6063-11ef-b5d8-395e250ad2a7.png)\n\n（三）最短时间完成优先（STCF）\n\nSJF遇到的问题是多任务不能保证同时到达，如果长任务在前短任务在后，就彻底回退到FIFO，没有丝毫进步。那么如果可以**抢占CPU资源**就能有改观，即短任务到达之后，暂时终止长任务，把CPU资源抢占过来，执行短任务，等到短任务执行完毕，再把CPU资源给到未完成的长任务。那是如何都不可能回退到FIFO了，这就是STCF。\n\n---\n\n事实上，对于许多早期批处理系统，这些类型的调度算法有一定的意义。然而，引入分时系统改变了这一切。\n\n你看STCF抢占CPU资源来执行短任务，长作业就得一直等待，也进入到长期不能被执行的可能，对于响应时间和交互性也是相当糟糕的。假设你在终端前输入，不得不等待 10s 才能看到系统的回应，只是因为其他一些工作已经在你之前被调度：你肯定不太开心。\n\n因此，我们还有另一个问题：如何构建对响应时间敏感的调度程序？\n\n---\n\n（四）轮转\n\nRR **在一个时间片内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束**。它反复执行，直到所有任务完成。请注意，**时间片长度必须是时钟中断周期的倍数**。因此，如果时钟中断是每 10ms 中断一次，则时间片可以是 10ms、20ms 或 10ms 的任何其他倍数。\n\n![时钟.png](/images/2024/08/22/b1eaf950-6063-11ef-b5d8-395e250ad2a7.png)\n\n轮转的时间设置的值是需要权衡的，先假定这个值被设计的合理，那么轮转的问题就是进程间切换太频繁，尽管响应时间被优化，但是周转时间缺严重受到影响。\n\n上下文切换的成本不仅仅来自保存和恢复少量寄存器的操作系统操作。程序运行时，它们在 CPU 高速缓存、TLB、分支预测器和其他片上硬件中建立了大量的状态。切换到另一个工作会导致此状态被刷新，且与当前运行的作业相关的新状态被引入，这可能导致显著的性能成本。\n\n看来得到就意味着失去是不变的真理了，至少前面介绍的这些策略没一个不是这样的情况。\n\n---\n\n前面我们始终是没有引入I/O操作，但这个操作明显在现实系统中是常有的。\n\n调度程序显然要在工作发起 I/O 请求时做出决定，因为当前正在运行的作业在 I/O 期间不会使用 CPU，它被阻塞等待 I/O 完成。调度程序还必须在 I/O 完成时做出决定。发生这种情况时，会产生中断，操作系统运行并将发出 I/O 的进程从阻塞状态移回就绪状态。\n\n![IO.png](/images/2024/08/22/a9628690-6063-11ef-b5d8-395e250ad2a7.png)\n\n通过将每个 CPU 突发作为一项工作，调度程序确保“交互”的进程经常运行。当这些交互式作业正在执行 I/O 时，其他 CPU 密集型作业将运行，从而更好地利用处理器。\n\n## 调度：多级反馈队列\n\nMLFQ 中有许多独立的队列，每个队列有不同的优先级。任何时刻，一个工作只能存在于一个队列中。MLFQ 总是优先执行较高优先级的工作（即在较高级队列中的工作）。当然，每个队列中可能会有多个工作，因此具有同样的优先级。在这种情况下，我们就对这些工作采用轮转调度。\n\n![多级反馈队列.png](/images/2024/08/22/892707c0-6063-11ef-b5d8-395e250ad2a7.png)\n\nMLFQ 调度策略的关键在于如何设置优先级。MLFQ 没有为每个工作指定不变的优先级，而是根据观察到的行为调整它的优先级。例如，如果一个工作不断放弃CPU 去等待键盘输入，这是交互型进程的可能行为，MLFQ 因此会让它保持高优先级。相反，如果一个工作长时间地占用 CPU，MLFQ 会降低其优先级。通过这种方式，MLFQ 在进程运行过程中学习其行为，从而利用工作的历史来预测它未来的行为。\n\n至此，我们得到了MLFQ的两条基本规则：\n\n- 规则1：如果A的优先级 > B的优先级，运行A（不运行B）\n- 规则2：如果A的优先级 = B的优先级，轮转运行A和B\n\n仅仅只是这些规则是不行的，会让那些低优先级中的任务无法被执行或者很难被执行。因此，继续往下讨论并添加规则。\n\n### 尝试1：如何改变优先级？\n\n- 规则3：工作进入系统时，放在最高优先级（最上层队列）\n- 规则4a：工作用完整个时间片后，降低其优先级（移入下一个队列）\n- 规则4b：如果工作在其时间片以内主动释放CPU，其优先级不变\n\n我们基于以上这些规则，来看应对如下实例的情况。\n\n（一）实例1：单个长工作\n\n受限进入优先级最高的队列Q2，时间片用完之后降级到Q1，时间片用完之后继续降级到最低优先级Q0，一直留在那里。\n\n![单个长工作.png](/images/2024/08/22/80b7e960-6063-11ef-b5d8-395e250ad2a7.png)\n\n（二）实例2：来了一个短工作\n\nA（用黑色表示）在最低优先级队列执行（长时间运行的 CPU 密集型工作都这样）。B（用灰色表示）在时间 *T*=100 时到达，并被加入最高优先级队列。由于它的运行时间很短（只有 20ms），经过两个时间片，在被移入最低优先级队列之前，B 执行完毕。然后 A 继续运行（在低优先级）。\n\n![短工作.png](/images/2024/08/22/7bf11280-6063-11ef-b5d8-395e250ad2a7.png)\n\n如果不知道工作是短工作还是长工作，那么就在开始的时候假设其是短工作，并赋予最高优先级。如果确实是短工作，则很快会执行完毕，否则将被慢慢移入低优先级队列，而这时该工作也被认为是长工作了。通过这种方式，MLFQ 近似于 SJF。\n\n（三）实例3：如果有I/O呢？\n\n前面规则4b（如果工作在其时间片以内主动释放CPU，其优先级不变）就是针对I/O情况的，即阻塞会主动让出CPU，我们不会对该进程进行降级。\n\n交互型工作 B（用灰色表示）每执行 1ms 便需要进行 I/O操作，它与长时间运行的工作 A（用黑色表示）竞争 CPU。MLFQ 算法保持 B 在最高优先级，因为 B 总是让出 CPU。如果 B 是交互型工作，MLFQ 就进一步实现了它的目标，让交互型工作快速运行。\n\n![实例IO.png](/images/2024/08/22/7305e650-6063-11ef-b5d8-395e250ad2a7.png)\n\n那当前这些规则存在哪些不足呢？\n\n- 饥饿问题：这是规则4b带来的饥饿问题，如果系统有“太多”交互型工作，就会不断占用CPU，导致长工作永远无法得到 CPU（它们饿死了）。\n- 容易被恶意程序利用：进程在时间片用完之前，调用一个 I/O 操作（比如访问一个无关的文件），从而主动释放 CPU。如此便可以保持在高优先级，占用更多的 CPU 时间。\n- 某些待遇无法享受：一个计算密集的进程可能在某段时间表现为一个交互型的进程。用我们目前的方法，它不会享受系统中其他交互型工作的待遇。\n\n### 尝试2：提升优先级？\n\n- 规则5：经过一段时间S，就将系统中所有工作重新加入最高优先级队列\n\n该规则解决了两个问题。首先，进程不会饿死——在最高优先级队列中，它会以轮转的方式，与其他高优先级工作分享 CPU，从而最终获得执行。其次，如果一个 CPU 密集型工作变成了交互型，当它优先级提升时，调度程序会正确对待它。\n\n如下图所示，如果不采用优先级提升，长工作没过多久就掉入最低优先级，处于饥饿状态。而采用优先级提升之后，没过多久又会被加入到最高优先级，得到使用CPU的机会，避免长期处于饥饿状态。\n\n![优先级.png](/images/2024/08/22/61fd6540-6063-11ef-b5d8-395e250ad2a7.png)\n\n既然我们引入时间S，那么设置多少合适呢？\n\n（一）尝试3：更好的计时方式？\n\n现在还有一个问题要解决：如何阻止调度程序被愚弄？可以看出，这里的元凶是规则4a 和 4b，导致工作在时间片以内释放 CPU，就保留它的优先级。那么应该怎么做？\n\n这里的解决方案，是为 MLFQ 的**每层队列提供**更完善的 CPU 计时方式。调度程序应该记录一个进程在某一层中消耗的总时间，而不是在调度时重新计时。只要进程用完了自己的配额，就将它降到低一优先级的队列中去。不论它是一次用完的，还是拆成很多次用完。因此，我们重写规则 4a 和 4b。\n\n- 规则4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）\n\n没有规则 4 的保护时，进程可以在每个时间片结束前发起一次 I/O 操作，从而垄断 CPU 时间。有了这样的保护后，不论进程的 I/O 行为如何，都会慢慢地降低优先级，因而无法获得超过公平的 CPU 时间比例。\n\n![愚弄机制.png](/images/2024/08/22/54f50fb0-6063-11ef-b5d8-395e250ad2a7.png)\n\n---\n\n关于 MLFQ 调度算法还有一些问题。其中一个大问题是如何配置一个调度程序，例如，配置多少队列？每一层队列的时间片配置多大？为了避免饥饿问题以及进程行为改变，应该多久提升一次进程的优先级？这些问题都没有显而易见的答案，因此只有利用对工作负载的经验，以及后续对调度程序的调优，才会导致令人满意的平衡。\n\n我们把前面的规则列举出来：\n\n- 规则1：如果A的优先级 > B的优先级，运行A（不运行B）\n- 规则2：如果A的优先级 = B的优先级，轮转运行A和B\n- 规则3：工作进入系统时，放在最高优先级（最上层队列）\n- 规则4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）\n- 规则5：经过一段时间S，就将系统中所有工作重新加入最高优先级队列\n\nMLFQ 有趣的原因是：它不需要对工作的运行方式有先验知识，而是通过观察工作的运行来给出对应的优先级。通过这种方式，MLFQ 可以同时满足各种工作的需求：对于短时间运行的交互型工作，获得类似于 SJF/STCF 的很好的全局性能，同时对长时间运行的CPU 密集型负载也可以公平地、不断地稳步向前。因此，许多系统使用某种类型的MLFQ作为自己的基础调度程序。\n\n## 调度：比例份额\n\n比例份额算法基于一个简单的想法：调度程序的最终目标，是确保每个工作获得一定比例的 CPU 时间。\n\n彩票调度背后是一个非常基本的概念：彩票数（ticket）代表了进程（或用户或其他）占有某个资源的份额。一个进程拥有的彩票数占总彩票数的百分比，就是它占有资源的份额。假设有两个进程 A 和 B，A 拥有 75 张彩票，B 拥有 25 张。因此我们希望 A 占用 75%的 CPU 时间，而 B 占用 25%。\n\n假定彩票 100 张，调度程序抽取中奖彩票，这是从 0 和 99 之间的一个数，拥有这个数对应的彩票的进程中奖。假设进程 A 拥有 0 到 74 共 75 张彩票，进程 B 拥有 75 到 99 的 25 张，中奖的彩票就决定了运行 A 或 B。调度程序然后加载中奖进程的状态，并运行它。\n\n![中奖结果.png](/images/2024/08/22/4e8284a0-6063-11ef-b5d8-395e250ad2a7.png)\n\n尽管从调度结果来看，工作 B 运行了 20 个时间片中的 4 个，只是占了 20%，而不是期望的 25%。但是，这两个工作运行得时间越长，它们得到的 CPU 时间比例就会越接近期望。\n\n彩票调度还提供了一些机制，以不同且有效的方式来调度彩票：\n\n- 彩票货币：这种方式允许拥有一组彩票的用户以他们喜欢的某种货币，将彩票分给自己的不同工作。之后操作系统再自动将这种货币兑换为正确的全局彩票\n- 彩票转让：通过转让，一个进程可以临时将自己的彩票交给另一个进程。这种机制在客户端/服务端交互的场景中尤其有用，在这种场景中，客户端进程向服务端发送消息，请求其按自己的需求执行工作，为了加速服务端的执行，客户端可以将自己的彩票转让给服务端，从而尽可能加速服务端执行自己请求的速度。服务端执行结束后会将这部分彩票归还给客户端\n- 通货膨胀：利用通胀，一个进程可以临时提升或降低自己拥有的彩票数量。当然在竞争环境中，进程之间互相不信任，这种机制就没什么意义。一个贪婪的进程可能给自己非常多的彩票，从而接管机器。但是，通胀可以用于进程之间相互信任的环境。在这种情况下，如果一个进程知道它需要更多 CPU 时间，就可以增加自己的彩票，从而将自己的需求告知操作系统，这一切不需要与任何其他进程通信\n\n关于彩票调度，还有一个问题没有提到，那就是如何为工作分配彩票？这是一个非常棘手的问题，系统的运行严重依赖于彩票的分配。假设用户自己知道如何分配，因此可以给每个用户一定量的彩票，由用户按照需要自主分配给自己的工作。然而这种方案似乎什么也没有解决——还是没有给出具体的分配策略。因此对于给定的一组工作，彩票分配的问题依然没有最佳答案。\n\n还有，前面的彩票调度如果运行时间很短，会出现比例不匹配的情况，这是随机性导致的 。因此，我们下面学习一个确定性的公平分配算法，即步长调度。\n\n系统中的每个工作都有自己的步长，这个值**与票数值成反比**。假设A、B、C 这 3 个工作的票数分别是 100、50 和 250，我们通过用一个大数分别除以他们的票数来获得每个进程的步长。比如用 10000 除以这些票数值，得到了 3 个进程的步长分别为 100、200 和 40。我们称这个值为每个进程的步长。每次进程运行后，我们会让它的计数器 [称为行程值] 增加它的步长，记录它的总体进展。\n\n之后，调度程序使用进程的步长及行程值来确定调度哪个进程。基本思路很简单：当需要进行调度时，选择目前拥有最小行程值的进程，并且在运行之后将该进程的行程值增加一个步长。\n\n![步长调度.png](/images/2024/08/22/4750a130-6063-11ef-b5d8-395e250ad2a7.png)\n\n可以看出，C 运行了 5 次、A 运行了 2 次，B 一次，正好是票数的比例——200、100 和 50。彩票调度算法只能一段时间后，在概率上实现比例，而步长调度算法可以在每个调度周期后做到完全正确。\n\n但是彩票调度有一个步长调度没有的优势——不需要全局状态。假如一个新的进程在上面的步长调度执行过程中加入系统，应该怎么设置它的行程值呢？设置成 0 吗？这样的话，它就独占 CPU 了。而彩票调度算法不需要对每个进程记录全局状态，只需要用新进程的票数更新全局的总票数就可以了。因此彩票调度算法能够更合理地处理新加入的进程。\n\n## 多处理器调度（高级）\n\n（一）单队列调度\n\n将所有需要调度的工作放入一个单独的队列中，我们称之为单队列多处理器调度（SQMS）。存在的缺陷如下：\n\n- 缺乏可扩展性：为了保证在多CPU 上正常运行，调度程序的开发者需要在代码中通过加锁来保证原子性。锁可能带来巨大的性能损失，尤其是随着系统中的 CPU 数增加时。随着这种单个锁的争用增加，系统花费了越来越多的时间在锁的开销上，较少的时间用于系统应该完成的工作\n- 缓存亲和性：假设我们有 5 个工作（A、B、C、D、E）和 4 个处理器，具体情况见下图。由于每个 CPU 都简单地从全局共享的队列中选取下一个工作执行，因此每个工作都不断在不同 CPU 之间转移，这与缓存亲和的目标背道而驰。\n\n![缓存亲和性.png](/images/2024/08/22/414cb670-6063-11ef-b5d8-395e250ad2a7.png)\n\n为了解决这个问题，大多数 SQMS 调度程序都引入了一些亲和度机制，尽可能让进程在同一个 CPU 上运行。保持一些工作的亲和度的同时，可能需要牺牲其他工作的亲和度来实现负载均衡。\n\n这种调度中，A、B、C、D 这 4 个工作都保持在同一个 CPU 上，只有工作 E 不断地来回迁移（migrating），从而尽可能多地获得缓存亲和度。\n\n![负载均衡.png](/images/2024/08/22/3dce1700-6063-11ef-b5d8-395e250ad2a7.png)\n\n综上可知，SQMS 调度方式有优势也有不足。优势是能够从单 CPU 调度程序很简单地发展而来，根据定义，它只有一个队列。然而，它的扩展性不好（由于同步开销有限），并且不能很好地保证缓存亲和度。\n\n（二）多队列调度\n\n正是由于单队列调度程序的这些问题，有些系统使用了多队列的方案，比如每个 CPU一个队列。我们称之为多队列多处理器调度（MQMS）。\n\n在 MQMS 中，基本调度框架包含多个调度队列，每个队列可以使用不同的调度规则，比如轮转或其他任何可能的算法。当一个工作进入系统后，系统会依照一些启发性规则（如随机或选择较空的队列）将其放入某个调度队列。这样一来，每个 CPU 调度之间相互独立，就避免了单队列的方式中由于数据共享及同步带来的问题。\n\n![多队列.png](/images/2024/08/22/28115cb0-6063-11ef-b5d8-395e250ad2a7.png)\n\nMQMS 比 SQMS 有明显的优势，它天生更具有可扩展性。队列的数量会随着 CPU 的增加而增加，因此锁和缓存争用的开销不是大问题。此外，MQMS 天生具有良好的缓存亲和度。所有工作都保持在固定的 CPU 上，因而可以很好地利用缓存数据。\n\n但可能存在的问题是负载不均\n\n![负载不均.png](/images/2024/08/22/1ff36b90-6063-11ef-b5d8-395e250ad2a7.png)\n\n从图中可以看出，A 获得了 B 和 D 两倍的 CPU 时间，这不是期望的结果。更糟的是，假设 A 和 C 都执行完毕，系统中只有 B 和 D。调度队列看起来如下：\n\n![负载不均2.png](/images/2024/08/22/1c4e7f70-6063-11ef-b5d8-395e250ad2a7.png)\n\n最明显的答案是让工作移动，这种技术我们称为迁移（migration）。通过工作的跨 CPU迁移，可以真正实现负载均衡。\n\n![迁移.png](/images/2024/08/22/16080d70-6063-11ef-b5d8-395e250ad2a7.png)\n\n在这种情况下，单次迁移并不能解决问题。应该怎么做呢？答案是不断地迁移一个或多个工作。一种可能的解决方案是不断切换工作。\n\n![多次迁移.png](/images/2024/08/22/0fad2910-6063-11ef-b5d8-395e250ad2a7.png)\n\n---\n\n⭐️内容取自译者王海鹏《操作系统导论》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书","tags":["操作系统导论","OS"],"categories":["technology"]},{"title":"第一章：操作系统概述","url":"/2024/08/22/第一章：操作系统概述/","content":"\n<!-- toc -->\n\n## 概述\n\n一个正在运行的程序称之为进程，运行的动作发生就是不断从内存中取指令并执行指令，直到程序最终完成。\n\n实际上，有一类软件负责让程序运行变得容易（甚至允许你同时允许多个程序），允许程序共享内容，让程序能够与设备交互，以及其它类型的有趣的工作。这些软件称为**操作系统**，因为他们负责确保系统既易于使用又正确高效地运行。\n\n操作系统作为硬件和应用程序的中间人，负责把硬件资源更加方便地提供给应用程序使用。如果要实现这点，操作系统主要利用一种通用的技术，称为**虚拟化**。即操作系统将物理资源（如处理器、内存或磁盘）转换为更通用、更强大且更易于使用的虚拟形式。应用程序通过操作系统提供的一些接口（API），间接使用硬件资源。每个 CPU、内存和磁盘都是系统的资源（resource），因此操作系统扮演的主要角色就是管理这些资源，以做到高效或公平，或者实际上考虑其他许多可能的目标。\n\n![OS.png](/images/2024/08/22/31942a70-6062-11ef-b5d8-395e250ad2a7.png)\n\n## 虚拟化CPU\n\n```c++\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n\nvoid Spin(int seconds) {\n  usleep(seconds * 1000000);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    fprintf(stderr, \"usage: cpu <string>\\n\");\n    exit(1);\n  }\n  char *str = argv[1];\n  while (1) {\n    Spin(1);\n    printf(\"%s\\n\", str);\n  }\n  return 0;\n}\n```\n\n这个程序的功能是无限循环地输出用户传递给它的字符串，每次输出之间等待一秒钟。\n\n![单个程序.png](/images/2024/08/22/2679e940-6062-11ef-b5d8-395e250ad2a7.png)\n\n但这一次，让我们运行同一个程序的许多不同实例。\n\n![多个程序.png](/images/2024/08/22/2292c400-6062-11ef-b5d8-395e250ad2a7.png)\n\n尽管我们只有一个处理器，但这 3 个程序似乎在同时运行！\n\n操作系统负责提供这样一种假象，即让每个正在运行的程序觉得自己独占CPU资源，实际上是操作系统在各进程间来回快速切换分配资源。将单个 CPU（或其中一小部分）转换为看似无限数量的 CPU，从而让许多程序看似同时运行，这就是所谓的虚拟化 CPU。\n\n## 虚拟化内存\n\n程序运行时，一直要访问内存。程序将所有数据结构保存在内存中，并通过各种指令来访问它们，例如加载和保存，或利用其他明确的指令，在工作时访问内存。不要忘记，程序的每个指令都在内存中，因此每一读取指令都会访问内存。\n\n```c++\n#include <unistd.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n\nvoid Spin(int seconds) {\n  usleep(seconds * 1000000); \n}\n\nint main(int argc, char *argv[]) {\n  int *p = (int *)malloc(sizeof(int)); \n  assert(p != NULL);\n  printf(\"(%d) memory address of p: %p\\n\", getpid(), (void *)p); \n  *p = 0;\n  while (1) {\n    Spin(1);\n    *p = *p + 1;\n    printf(\"(%d) p: %d\\n\", getpid(), *p); \n  }\n  free(p); \n  return 0;\n}\n```\n\n这个程序的功能是不断地增加并打印一个整数，同时显示该整数所在的内存地址和当前进程的ID。\n\n![单个虚拟内存.png](/images/2024/08/22/1be504b0-6062-11ef-b5d8-395e250ad2a7.png)\n\n但这一次，让我们运行同一个程序的许多不同实例。\n\n![多个虚拟内存.png](/images/2024/08/22/16b029c0-6062-11ef-b5d8-395e250ad2a7.png)\n\n每个正在运行的程序都在相同的地址（00200000）处分配了内存，但每个似乎都独立更新了 00200000 处的值！就好像每个正在运行的程序都有自己的私有内存，而不是与其他正在运行的程序共享相同的物理内存。\n\n实际上程序给进程看到的是虚拟内存，操作系统拿到这个虚拟内存会自行转换到物理内存。每个进程访问自己的私有虚拟地址空间（有时称为地址空间），操作系统以某种方式映射到机器的物理内存上。一个正在运行的程序中的内存引用不会影响其他进程（或操作系统本身）的地址空间。对于正在运行的程序，它完全拥有自己的物理内存。尽管这也是操作系统营造的假象。\n\n## 并发\n\n并发来指代一系列问题，这些问题在同时（甚发地）处理很多事情时出现且必须解决。并发问题首先出现在操作系统本身中，可多线程程序中同样存在相同的问题。\n\n```c++\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n\n#define Pthread_create(thread, attr, start_routine, arg) \\\n    pthread_create(thread, attr, start_routine, arg)\n\n#define Pthread_join(thread, retval) pthread_join(thread, retval)\n\nvolatile int counter = 0;\nint loops;\n\nvoid *worker(void *arg) {\n  int i;\n  for (i = 0; i < loops; i++) {\n    counter++;\n  }\n  return NULL;\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    fprintf(stderr, \"usage: threads <value>\\n\");\n    exit(1);\n  }\n  loops = atoi(argv[1]);\n\n  pthread_t p1, p2;\n  printf(\"Initial value : %d\\n\", counter);\n\n  Pthread_create(&p1, NULL, worker, NULL);\n  Pthread_create(&p2, NULL, worker, NULL);\n\n  Pthread_join(p1, NULL);\n  Pthread_join(p2, NULL);\n\n  printf(\"Final value : %d\\n\", counter);\n\n  return 0;\n}\n```\n\n当我们让两个线程去求和，如果这个求和是较小不会出错，如果这个求和值很大就会不符合预期。\n\n如下图示，第二次的测试程序中最终结果应该为200000，但是结果却为172280，这就是并发带来的问题。\n\n![多线程.png](/images/2024/08/22/10e50240-6062-11ef-b5d8-395e250ad2a7.png)\n\n这些奇怪的、不寻常的结果与指令如何执行有关，指令每次执行一条。遗憾的是，上面的程序中的关键部分是增加共享计数器的地方，它需要 3 条指令：一条将计数器的值从内存加载到寄存器，一条将其递增，另一条将其保存回内存。因为这 3 条指令不是以原子方式（atomically）执行（所有的指令一次性执行）的，所以奇怪的事情可能会发生。\n\n## 持久性\n\n在系统内存中，数据容易丢失，因为像DRAM 这样的设备以易失的方式存储数值。如果断电或系统崩溃，那么内存中的所有数据都会丢失。因此，我们需要硬件和软件来持久地存储数据。\n\n操作系统中操理磁盘的软件通常称为**文件系统**。因此它负责以可靠和高效的方式，将用户创建的任何文件存储在系统的磁盘上。\n\n操作系统为了实际写入磁盘而做了什么？首先确定新数据将驻留在磁盘上的哪个位置，然后在文件系统所维护的各种结构中对其进行记录。这样做需要向底层存储设备发出 I/O 请求，以读取现有结构或更新（写入）它们。\n\n## 总结\n\n我们已经了解了操作系统实际上做了什么：它取得 CPU、内存或磁盘等物理资源，并对它们进行虚拟化。它处理与并发有关的麻烦且棘手的问题。它持久地存储文件，从而使它们长期安全。\n\n抽象是计算机科学中非常主要的手段，使得编写一个大型程序成为可能，将其划分为小而且容易理解的部分，用 C 这样的高级语言编写这样的程序不用考虑汇编，用汇编写代码不用考虑逻辑门，用逻辑门来构建处理器不用太多考虑晶体管。\n\n设计和实现操作系统：\n\n1. 提供高性能，即最小化操作系统的开销\n2. 安全性，即在应用程序之间以及在 OS 和应用程序之间提供保护\n3. 可靠性，即必须不间断运行\n\n---\n\n⭐️内容取自译者王海鹏《操作系统导论》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书","tags":["操作系统导论","OS"],"categories":["technology"]},{"title":"优化并发","url":"/2024/08/21/优化并发/","content":"\n<!-- toc -->\n\n## 优化多线程C++程序\n\n### 用 std::async 替代 std::thread\n\n如果你是启动一个线程去执行任务，那么应该用 std::async 替代 std::thread，因为你不用关心线程的关闭问题，它本身是异步的。\n\n### 创建与核心数量一样多的可执行线程\n\nC++ 提供了一个 `std::thread::hardware_concurrency()` 函数，它可以返回可用核心的数量。这个函数会计算由 hypervisor 分配给其他虚拟机的核心，以及因多线程同步而表现为两个或多个逻辑核心的核心的数量。通过这个函数，以后我们可以方便地将程序部署到包含更多（或少）核心的硬件上运行。\n\n### 实现任务队列和线程池\n\n解决不知道有多少个线程正在运行这个问题的方法是让线程更加明显：使用线程池（一种保持固定数量的永久线程的数据结构）和任务队列（一种存储待执行的计算的列表的数据结构），这些计算将由线程池中的线程负责执行。\n\n### 在单独的线程中执行I/O\n\n磁盘转速和网络连接距离等物理现实问题造成在程序请求数据和数据变为可用状态之间存在着延迟。因此， I/O 是适用并发的绝佳位置。另外一个典型的 I/O 问题是，程序在写数据之前或是读数据之后必须对它进行转换。例如，我们先从互联网上读取一个 XML 文件，接着解析它，从中提取程序所需信息。由于在对数据进行转换之前是无法直接使用它的，我们可以考虑将整个处理（包括读数据和解析数据）移动到一个单独的线程中。我们完全可以把这种I/O的计算工作也丢给线程池，我们称其为工作线程。\n\n就拿网络库来举例，接收客户端的请求，此后根据请求的类型提高相应的服务，为了能够让服务器继续接收客户端的请求，就把提供服务的工作交给工作线程去做，等工作线程执行完之后再把结果返回给客户端。那么服务器就把接收客户请求和处理客户请求分离开，效率得到提升，这就是分工带来的销量提高。\n\n### 没有同步的程序\n\n同步和互斥虽然能够解决并发问题，但是对性能的影响还是相当明显的，下面介绍三种简单方式和一个困难方式。\n\n（一）面向事件编程\n\n在面向事件编程中，程序的控制流完全由事件驱动。框架通常在一个循环中不断地从事件队列中取出事件，然后调用注册的处理函数。整个过程是单线程的，没有多线程的同步问题。\n\n也许你可以回想网络库中的 EventLoop。\n\n（二）协程\n\n协程比线程更加轻量级，并且C++20已经支持。与面向事件的程序相同，协程并非真正的多线程，因此只要它们不受多线程控制就不需要同步。\n\n协程有两种。第一种有自己的栈，而且可以在执行途中的任何位置将控制转交给另外一个协程。第二种是向另外一个线程借栈，并且只能在它的顶层转交控制。\n\n（三）消息传递\n\n在消息传递程序中，控制线程从一个或多个输入源中接收输入，对输入进行转换后将它放到一个或多个输出槽中。相互连接的输出和输入组成了一幅具有良好定义的入口节点和出口节点的图。这些被实现了一个消息传递程序的各个阶段的线程所读写的元素可以是网络数据报、字符 I/O 流或是隐式队列中的数据结构。\n\n比方说线程间通信或进程间通信的消息队列，分布式系统中的消息队列（Kafka）\n\n（四）无锁编程\n\n无锁编程是指无需互斥，允许多线程更新数据结构的编程实践。在无锁程序中，硬件同步的原子性操作取代了昂贵的互斥量。无锁数据结构远比由互斥量保护的传统容器要优秀，特别是当许多线程访问同一个容器时。\n\n无锁数据结构很难讨论清楚。即使是著名专家也会就已公布算法的正确性进行争论。出于这个原因，我**建议读者使用那些已经被广泛使用且有较好技术支持的无锁数据结构，而不要试图去构建自己的无锁数据结构**。\n\n### 移除启动和停止代码\n\n一个程序能够启动足够多的线程来满足并发执行任务的需求，或是充分使用多核 CPU。不过，程序中有部分代码难以并发执行，那就是在 main() 得到控制权前执行的代码以及在main() 退出后执行的代码。\n\n在 main() 开始执行前，所有具有静态存储期的变量都会被初始化。对于基本数据类型，初始化的性能开销是 0。链接器会让变量指向初始化数据。但是对于具有静态存储期的类类型，初始化过程会以标准所指定的特定顺序，在单独的线程中连续地调用各个变量的构造函数。这些开销单独看起来很小，但是加起来就会很大，导致大型程序在启动时会有几秒钟失去响应。\n\n各位可以回想一下单例模式，如果你编写的是饿汉式单例，并且在你的系统中有非常多的单例，那么你的系统就会变的很慢，因为它需要提前被创建，而这些并不能被并发解决，谁让它在main() 得到控制权前执行的代码呢。\n\n## 让同步更加高效\n\n尽管我们前面讲互斥和同步会降低效率，但它确实是最常用的解决并发问题的手段。\n\n### 减小临界区的范围\n\n临界区是指获取互斥量和释放互斥量之间所包围的区域。在临界区的执行过程中，没有其他线程能够访问该互斥量所控制的共享变量，这当然是最恰当的。如果在临界区中并没有访问共享变量而是只做其他事情，那么其他线程就会白白浪费等待时间。\n\n临界区的设计要点：\n\n1. **最小化临界区的范围**：理想情况下，临界区应该尽可能小，只包含对共享资源的访问。这样做可以最大限度地减少阻塞其他线程的时间，提高并发执行的效率。如果在临界区内包含了不必要的操作，如复杂的计算或 I/O 操作，就会导致其他线程在等待时浪费宝贵的处理时间\n2. **避免长时间锁定**：在临界区内执行耗时操作会增加锁定时间，导致其他线程长时间等待。这不仅降低了系统的并发性，还可能引发死锁或优先级反转等问题。因此，在设计临界区时，应将耗时操作移出临界区，确保只在必要时才进行锁定\n\n### 限制并发线程的数量\n\n如果线程数量比核心数量多，则只有一部分线程会被分配给核心，在某个时间点也只有一部分线程会实际运行。其他线程会在操作系统的“可运行”队列中等待被分配时间片。操作系统会因周期性的中断而醒来，决定运行哪个线程。与单独指令的执行速度相比，中断周期很长。因此，“可运行”队列中的线程可能会在操作系统为它分配核心之前等待许多毫秒。\n\n竞争临界区的理想线程数量是两个。当只有两个线程时，就不存在“公平”或是“饥饿”问题，也不会发生下一节中将要介绍的惊群问题。\n\n### 避免惊群\n\n当有许多线程挂起在一个事件——例如只能服务一个线程的工作——上时就会发生所谓的惊群现象。当发生这个事件时，所有的线程都会变为可运行状态，但由于只有几个核心，因此只有几个线程能够立即运行。其中只有一个线程能够拿到互斥量继续进行工作，操作系统会将其他线程移动到可运行队列中，并最终逐个运行线程。每个线程都会发现发出的事件已经被其他某个线程服务了，只得继续挂起在这个事件上，虽然消耗了很多时间但线程处理却没有任何进展。\n\n避免“惊群”问题的方法就是限制创建出的服务事件的线程的数量。两个线程可能比一个线程好，但是 100 个线程可能并不会更好。\n\n### 避免锁护送\n\n当大量线程同步，挂起在某个资源或是临界区上时会发生锁护送（lock convoy）。这会导致额外的阻塞，因为它们都会试图立即继续进行处理，但是每次却只有一个线程能够继续处理，仿佛是在护送锁一样。\n\n一种简单的情况是接二连三地发生“惊群”现象。大量线程竞争一个互斥量，这样大量线程会挂起在该互斥量的操作系统信号上。当持有互斥量的线程释放它时，事件就会发生，所有挂起的线程都会变为可运行状态。第一个被分配到处理器的线程会再次锁住互斥量。所有的其他线程最终都会被分配到处理器，看到互斥量仍然被锁住了，然后再次挂起。这对程序的整体影响是操作系统虽然花费了很多时间重启线程，但大多数线程都无法继续处理。更糟糕的是，所有的线程都仍然是同步的。当下个线程释放互斥量时它们会立即醒来，然后如此往复循环。\n\n一种更复杂的情况则是“惊群”线程都试图去获取第二个互斥量或执行读取文件等某种因设备的物理特性而成为性能瓶颈的操作。由于线程都是同步的，它们几乎会在同时试图去访问第二个资源。这些线程在同一个时间请求相同的资源会导致序列化，使性能下降。如果它们没有同步，那么它们可能都会继续处理。\n\n### 减少竞争\n\n（一）注意内存和 I/O 都是资源\n\n并非所有的开发人员都注意到内存管理器是一种资源。在多线程系统中，内存管理器必须序列化对它的访问，否则它的数据结构会被破坏。当大量线程都试图分配动态变量（std::string 是一个特别的敌人）时，程序的性能可能会随着线程数量的增加出现断崖式下降。\n\n文件 I/O 也是一种资源。磁盘驱动器一次只能读取一个地址。试图同时在多个文件上执行 I/O 操作会导致性能突然下降。\n\n网络 I/O 也是一种资源。相对于数据传输，以太网连接器是一条相对较窄的管道。现代处理器甚至能够使 1000 兆带宽的以太网线满负荷传输，更别提 WiFi 连接了。\n\n（二）复制资源\n\n有时候，我们可以复制表，让每个线程都有一份非共享的副本，来移除多线程对于共享的 map 或是散列表等资源的竞争。尽管维护一个数据结构的两份副本会带来更多的工作，但与使用一种共享数据结构相比，它可能还会减少程序运行时间。\n\n我们甚至能够复制磁盘驱动器、网卡等硬件资源来提高吞吐量。\n\n（三）切割资源\n\n有时候我们可以分割数据结构，让每个线程只访问它们所需的那部分数据，来避免多线程竞争同一个数据结构。\n\n（四）细粒度锁\n\n我们可以使用多个互斥量，而不是一个互斥量来锁住整个数据结构。例如，在散列表中，我们可以使用一个互斥量锁住散列表的骨干数组，防止其被修改（例如插入和删除元素），然后用另外一个互斥量锁住元素，防止它们被修改。这里， reader/writer 锁是一个不错的选择。要访问散列表的一条元素时，线程可以使用读锁锁住骨干数组，然后用一个读锁或写锁锁住元素。要插入或删除一条元素时，线程可以使用写锁锁住骨干数组。\n\n（五）无锁结构\n\n我们使用无锁散列表等无锁数据结构来摆脱对互斥的依赖。这是细粒度锁的终极形态。\n\n（六）资源的调度\n\n有些资源——例如磁盘驱动器——是无法被复制或分割的。但是我们可以调度磁盘活动，让它们不要同时发生，或是让访问磁盘相邻部分的活动同时发生。尽管操作系统会在细粒度级别调度读写操作，但是程序能够通过序列化读取配置文件等操作，避免它们同时发生。\n\n### 不要在单核系统上繁忙等待\n\n在单核处理器上，同步线程的唯一方法是调用操作系统的同步原语。繁忙等待太低效了。\n\n事实上，繁忙等待会导致线程浪费整个时间片，因为除非在等待的线程放弃使用处理器，否则持有互斥量的线程是无法运行出临界区的。\n\n### 不要永远等待\n\n当一个线程无条件地等待一个事件时会如何呢？如果程序正常运行，可能什么事情都不会发生。但是如果用户试图停止程序，会如何呢？用户界面关闭了，但是程序不会停止，因为线程仍然在运行。如果 main() 尝试加入正在等待的线程，它会挂起。如果正在等待的线程被分离了， main() 会退出。接下来发生的事情取决于线程如何等待了。如果它正在等待一个标识位被设值，它会一直等待下去；如果它是在等待操作系统的事件，它会一直等待下去；如果它是在等待一个 C++ 对象，那么这取决于是否会有某个非阻塞线程删除该对象。这可能会导致正在等待的线程终止，也可能不会。\n\n### 自己设计互斥量可能会低效\n\n自己编写一个简单的类来作为互斥量，繁忙等待直到另一个线程更新原子性变量，这并不难。当没有激烈的线程竞争且临界区很短时，这样的类可能甚至比系统提供的互斥量更快。不过，操作系统提供的互斥量更加了解操作系统的奥秘，以及它调度任务以改善性能或是在该操作系统上避免优先级反转问题的方式。\n\n### 限制生产者输出队列的长度\n\n在生产者 / 消费者程序中，任何时候只要生产者比消费者快，数据就会在生产者和消费者之间累积。这种情况会产生许多问题，其中包括如下几个：\n\n- 生产者竞争处理器、内存分配器和其他资源，进而降低了消费者的处理速度，使问题恶化。\n- 生产者将会最终消费所有的系统内存资源，导致整个程序异常终止。\n- 如果程序能够从异常中恢复过来，在重启之前它可能会需要处理队列中累积的所有数据，这将会增加程序的恢复时间。\n\n解决方法是限制队列长度并在列队满员后阻塞生产者。队列的长度只需足够应对消费者性能的变化就可以了。多数情况下，队列其实只需能容纳若干元素即可。队列中的任何多余元素都只会导致生产者的运行遥遥领先，增加资源消耗，却对并发没有任何益处。","tags":["C++性能优化"],"categories":["technology"]},{"title":"面向对象的设计原则","url":"/2024/08/20/面向对象的设计原则/","content":"\n<!-- toc -->\n\n设计的目标：**低**耦合、**高**内聚。\n\n何为耦合？强调类与类之间、模块与模块之间的**依赖程度。**\n\n**低耦合**意味着模块或类之间的依赖关系尽可能少，这样修改一个模块或类不会大规模影响其他模块或类。\n\n何为内聚？强调类的内部或者模块内部各元素之间的**关联程度。**\n\n**高内聚**意味着一个模块或类内的所有功能和数据都高度相关，模块或类的职责明确单一。\n\n![基本原则总结.png](/images/2024/08/20/d3eef420-5e97-11ef-a6e4-752a70472992.png)\n\n## 单一职责原则\n\n核心思想：一个类，最好只做一件事情。\n\n这个表述容易给人误解，特别是后面给的示意图让人误以为一个类只能有一个方法就代表类只做一件事情。一个类最好只做一件事的含义是，不包含本该由其它类完成的功能。\n\n![单一职责1.png](/images/2024/08/20/cf300c80-5e97-11ef-a6e4-752a70472992.png)\n\n如上图中的Rectangle类有两个功能：计算和绘图。\n\nGeometryApp只是用来计算，并不需要画图功能，那么就该把Rectangle类中的绘图功能抽离出一个新的类，以符合单一职责原则。\n\n![单一职责2.png](/images/2024/08/20/ca573440-5e97-11ef-a6e4-752a70472992.png)\n\n## 开闭原则\n\n核心思想：对于扩展是开放的，对于修改是封闭的。\n\n下图类有四个方法，但这个类不是封闭的，因为要增加新功能的话，就得改动这个类。\n\n![开闭原则1.png](/images/2024/08/20/c5306310-5e97-11ef-a6e4-752a70472992.png)\n\n为了实现“对于扩展是开放的，对于修改是封闭的”的原则，把该类改为抽象类，提供一个运算功能的抽象接口，派生类继承并实现即可。以后如果需要新增其它计算方式的功能，无需改动此类，只需要新建类并继承此类，然后实现抽象接口即可。\n\n![开闭原则2.png](/images/2024/08/20/c0f6ff20-5e97-11ef-a6e4-752a70472992.png)\n\n## 里氏代换原则\n\n核心思想：派生类可以扩展基类的功能，但不能改变基类原有的功能。\n\n即派生类如果函数名和基类的函数名相同，但这个函数在基类中已经实现对应功能，派生类就会重定义基类的方法，即隐藏基类原有的功能了。调用该方法不会调用基类的功能，而是调用派生类重定义的功能，就相当于改变基类原有的功能了。\n\n> 重定义（隐藏）\n>\n> - 派生类屏蔽了与其同名的基类函数\n> - 如果派生类的函数和基类的函数同名，但是参数不同，此时，不管有无 virtual，基类的函数被隐藏\n> - 如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有关键字，此时，基类的函数被隐藏\n\n如果这个函数基类没有实现（虚函数或纯虚函数）也就没有问题，就只是扩展基类的功能而已，称为重写。而重写是要派生类和基类的函数名以及参数列表相同，并且基类的此函数有 virtual 关键字。\n\n![里氏.png](/images/2024/08/20/bb09a9a0-5e97-11ef-a6e4-752a70472992.png)\n\n如上图中 VipUser 重定义基类的 consume 方法，违背里氏代换原则了。\n\n## 接口分离原则\n\n核心思想：使用多个小的专门的接口，而不要使用一个大的总接口。\n\n![接口分离.png](/images/2024/08/20/b5074580-5e97-11ef-a6e4-752a70472992.png)\n\nOstrich 类没有飞的功能，这样就不能直接继承 Bird 类了，需要把 fly 的虚函数单独抽离到一个类中，如下图那样解决这个问题。\n\n这种方式在类中会很少设计，因为会继承太多，我们通常不建议使用多继承（尽可能避免）。不过把一个函数中的功能拆分出子函数却很常见，利于代码阅读以及代码复用。\n\n![接口分离2.png](/images/2024/08/20/b04f62c0-5e97-11ef-a6e4-752a70472992.png)\n\n## 依赖倒转原则\n\n该原则初看容易和开闭原则混淆，但区别还是明显的，这里就以顾客去不同的商店买东西为例。\n\n顾客购买ShaoguanShop商店的商品代码如下：\n\n```c++\nclass Customer\n{\n    public void shopping(ShaoguanShop shop)\n    {\n        //购物\n        printf(\"shop.sell()\");\n    }\n}\n```\n\n但是顾客想要购买其它商品就需要更改代码，代码如下：\n\n```Java\nclass Customer\n{\n    public void shopping(WuyuanShop shop)\n    {\n        //购物\n        printf(\"shop.sell()\");\n    }\n}\n```\n\n不如把所有的商店抽象为一个基类Shop，所有商店继承此类并实现抽象函数 sell。\n\n那么顾客无需再更改代码，以后哪怕有新的商店增加也不用更改代码。\n\n```c++\nclass Customer\n{\n    public void shopping(Shop shop)\n    {\n        //购物\n        printf(\"shop.sell()\");\n    }\n}\n```\n\n具体的类图见下：\n\n![依赖倒转原则.png](/images/2024/08/20/aae93ea0-5e97-11ef-a6e4-752a70472992.png)\n\n程序的代码：\n\n```c++\n#include <iostream>\n#include <string>\n\n// 商店接口\nclass Shop {\npublic:\n    virtual ~Shop() = default;\n    virtual std::string sell() const = 0; // 卖\n};\n\n// 韶关网店\nclass ShaoguanShop : public Shop {\npublic:\n    std::string sell() const override {\n        return \"韶关土特产：香菇、木耳……\";\n    }\n};\n\n// 婺源网店\nclass WuyuanShop : public Shop {\npublic:\n    std::string sell() const override {\n        return \"婺源土特产：绿茶、酒糟鱼……\";\n    }\n};\n\n// 顾客\nclass Customer {\npublic:\n    void shopping(const Shop& shop) const {\n        // 购物\n        std::cout << shop.sell() << std::endl;\n    }\n};\n\nint main() {\n    Customer wang;\n    std::cout << \"顾客购买以下商品：\" << std::endl;\n    ShaoguanShop shaoguanShop;\n    WuyuanShop wuyuanShop;\n\n    wang.shopping(shaoguanShop);\n    wang.shopping(wuyuanShop);\n\n    return 0;\n}\n\n/*\n\n顾客购买以下商品：\n韶关土特产：香菇、木耳……\n婺源土特产：绿茶、酒糟鱼……\n\n*/\n```\n\n\n\n## 迪米特法原则\n\n核心思想：一个类或模块应该对其他类或模块保持最少的了解（只与朋友通信）。\n\n> 首先来解释一下什么是直接的朋友：每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系，我们就说这两个对象之间是朋友关系\n>\n> 耦合的方式很多，依赖、关联、组合、聚合等。其中，我们称出现成员变量、方法参数、方法返回值中的类为直接的朋友，而出现在局部变量中的类则不是直接的朋友\n>\n> 也就是说，陌生的类最好不要作为局部变量的形式出现在类的内部\n\n即局部变量的类 B 出现在类 A 的内部，那么类 B 不是类 A 的朋友。\n\n![迪米特法原则.png](/images/2024/08/20/a06968b0-5e97-11ef-a6e4-752a70472992.png)\n\n明星由于全身心投入艺术，所以许多日常事务由经纪人负责处理，如与粉丝的见面会，与媒体公司的业务洽淡等。这里的经纪人是明星的朋友，而粉丝和媒体公司是陌生人，所以适合使用迪米特法则。\n\n```c++\n#include <iostream>\n#include <string>\n\n// 明星类\nclass Star {\nprivate:\n    std::string name;\npublic:\n    Star(const std::string& name) : name(name) {}\n    std::string getName() const {\n        return name;\n    }\n};\n\n// 粉丝类\nclass Fans {\nprivate:\n    std::string name;\npublic:\n    Fans(const std::string& name) : name(name) {}\n    std::string getName() const {\n        return name;\n    }\n};\n\n// 媒体公司类\nclass Company {\nprivate:\n    std::string name;\npublic:\n    Company(const std::string& name) : name(name) {}\n    std::string getName() const {\n        return name;\n    }\n};\n\n// 经纪人类\nclass Agent {\nprivate:\n    Star* myStar;\n    Fans* myFans;\n    Company* myCompany;\npublic:\n    void setStar(Star* star) {\n        myStar = star;\n    }\n    void setFans(Fans* fans) {\n        myFans = fans;\n    }\n    void setCompany(Company* company) {\n        myCompany = company;\n    }\n    void meeting() const {\n        std::cout << myFans->getName() << \"与明星\" << myStar->getName() << \"见面了。\" << std::endl;\n    }\n    void business() const {\n        std::cout << myCompany->getName() << \"与明星\" << myStar->getName() << \"洽谈业务。\" << std::endl;\n    }\n};\n\nint main() {\n    Agent agent;\n    Star star(\"林心如\");\n    Fans fans(\"粉丝韩丞\");\n    Company company(\"中国传媒有限公司\");\n\n    agent.setStar(&star);\n    agent.setFans(&fans);\n    agent.setCompany(&company);\n\n    agent.meeting();\n    agent.business();\n\n    return 0;\n}\n```\n\n## 组合复用原则\n\n核心思想：使用关联、聚合取代继承关系。\n\n即通过将已有的对象纳入新对象中，作为新对象的成员对象来实现的，新对象可以调用已有对象的功能，从而达到复用。\n\n汽车按“动力源”划分可分为汽油汽车、电动汽车等；按“颜色”划分可分为白色汽车、黑色汽车和红色汽车等。如果同时考虑这两种分类，其组合就很多。\n\n![组合复用原则1.png](/images/2024/08/20/8aee2430-5e97-11ef-a6e4-752a70472992.png)\n\n上图可以看出用继承关系实现会产生很多子类，而且增加新的“动力源”或者增加新的“颜色”都要修改源代码，这违背了开闭原则，显然不可取。但如果改用组合关系实现就能很好地解决以上问题，见下图。\n\n![组合复用原则2.png](/images/2024/08/20/86f6f960-5e97-11ef-a6e4-752a70472992.png)\n\n以后想要增加什么颜色的车，只需要在Color类中添加即可，汽油汽车和电动汽车都无需因为颜色而新建类。\n\n---\n\n参考链接：https://docs.oldtimes.me/c.biancheng.net/view/1331.html","tags":["设计模式"],"categories":["technology"]},{"title":"第五章：纯洁性--避免可变状态","url":"/2024/08/19/第五章：纯洁性-避免可变状态/","content":"\n<!-- toc -->\n\n## 可变状态带来的问题\n\n```c++\nclass movie_t {\npublic:\n    double average_score() const;\n    ...\nprivate:\n    std::string name;\n    std::list<int> scores;\n};\n\ndouble movie_t::average_score() const\n{\n    return std::accumulate(scores.begin(), scores.end(), 0)\n           / (double) scores.size();\n}\n```\n\n计算某个电影的平均值，看似没有问题，但是由于 scores 容器没有大小限制，会出现如下两个问题：\n\n1. 当你在求平均值的时候，可能有新的数据添加，它可能被计入总和，也可能没有被计入总和\n2. 你不知道 ` scores.size()` 是不是会先求值，导致 后面新添加的元素没有被视为 size 大小的一部分\n\n那我们可以添加一个成员变量 scores_size 来记录链表中到底有多少数据（要加锁），到时候遍历的时候按照这个数量去遍历和求平均数。但是作者认为我们可能会忘记更新 scores_size 大小，那这属于代码逻辑层面的问题了，不意味着我前面这个想法有问题。\n\n作者的意思是如果 scores 和 scores_size 变量都不可变，即声明为 const，还会遇到这些问题吗?\n\n- 第一个问题在于计算得分的平均值时，有人可能改变得分列表。如果列表是不可改变的，那么在使用它时，就不会有人改变它，这个问题就不复存在\n- 第二个问题在于如果这些变量都是不可变的，那么就需要在创建 movie_t 类时初始化它们。变量 scores_size 可能初始化为一个错误的值，但这种错误应该比较明显。如果某人忘记了更新它的值--那一定是计算代码出了问题。另外，设置了错误的值以后，它就一直是错的，但这并不难调试出来\n\n我完全没有想到作者居然要把  scores 和 scores_size 变量都不可变，这样做的意义何在？难道我的这个 movie_t 类不能添加元素？作者究竟在想什么？那就视为作者只是想表达可变状态存在的问题吧。\n\n## 纯函数和引用透明\n\n所有这些问题都源自一个设计缺陷：软件系统中多个组件负责相同的数据，而不知道另外的组件何时更改数据。修改这些问题最简单的办法就是禁止修改任何数据，所有问题都会迎刃而解。但事实是不可能没有数据被修改。\n\n现在通过称为引用透明的概念，定义更加纯洁的函数。引用透明是表达式的一个特征，而不仅仅是函数。表达式是定义了一种计算并返回结果的任何东西。如果用表达式的结果替换整个表达式，而程序不会出现不同的行为，那么就说这个表达式是引用透明的。如果表达式是引用透明的，那它就没有任何可见的副作用，因此表达式中的所有函数都是纯函数。\n\n![查找和记录最大值.png](/images/2024/08/19/0d286a70-5e28-11ef-9da5-855b30face3e.png)\n\nmax 是 引用透明的吗？如果用 max 返回值替换 max 调用，发现程序的行为没有变化，即计算出结果依旧是 6。\n\n![max返回值替换.png](/images/2024/08/19/08f8f190-5e28-11ef-9da5-855b30face3e.png)\n\n尽管依旧有些不同，因为 max 里面会通过 cerr 输出计算的结果，但是我们可以宽松引用透明的概念。如果非要严苛一点，下面的这个就完全符合了。\n\n![引用透明.png](/images/2024/08/19/f6ef2d20-5e27-11ef-9da5-855b30face3e.png)\n\n## 无副作用编程\n\n在纯函数式编程中，不是去改变一个值，而是创建一个新的（值）。如果要改变对象的一个属性，就创建这个对象的副本，只不过属性的值要改变为新值。如果这样设计软件，就不会出现前面例子中的问题--当处理电影得分时，其他人改变了它。这时没人能够改变电影得分的列表，只能创建一个新的列表，插入新值。\n\n大型系统有许多可改变的部分。需要创建一个巨大的、包罗万象的结构，并在每次需要改变时，重新创建它。这将产生巨大的性能开销（即使使用针对函数式编程优化的数据结构，这将在第8章介绍），并大幅增加软件的复杂性。\n\n通常会有一些可变状态，如果经常复制和传递，将影响程序的效率。可以将函数设计为返回如何改变的语句，而不是返回改变后状态的复制。这种方式带来的是系统可变部分与 pure 部分进行了明确分离。\n\n```c++\n#include <iostream>\n#include <functional>\n\nclass State {\npublic:\n    int value1;\n    int value2;\n\n    State(int v1, int v2) : value1(v1), value2(v2) {}\n\n    // 用于应用状态变化的函数\n    void apply(const std::function<void(State&)>& change) {\n        change(*this);\n    }\n\n    void print() const {\n        std::cout << \"State(value1: \" << value1 << \", value2: \" << value2 << \")\\n\";\n    }\n};\n\n// 纯函数：返回一个表示状态变化的操作，而不是直接改变状态\nstd::function<void(State&)> incrementValue1(int amount) {\n    return [amount](State& state) {\n        state.value1 += amount;\n    };\n}\n\nstd::function<void(State&)> incrementValue2(int amount) {\n    return [amount](State& state) {\n        state.value2 += amount;\n    };\n}\n\nint main() {\n    State state(10, 20);\n\n    std::cout << \"Initial state: \";\n    state.print();\n\n    // 获取状态变化操作\n    auto change1 = incrementValue1(5);\n    auto change2 = incrementValue2(10);\n\n    // 应用状态变化\n    state.apply(change1);\n    state.apply(change2);\n\n    std::cout << \"Modified state: \";\n    state.print();\n\n    return 0;\n}\n```\n\n代码解释：\n\n1. State 类：包含两个可变的成员变量 `value1` 和 `value2`。`apply` 函数接受一个 `std::function<void(State&)>` 类型的参数，表示对状态的某种操作。\n2. 纯函数 `incrementValue1` 和 `incrementValue2`：这些函数不直接改变状态，而是返回一个 lambda 表达式，该表达式描述了如何修改状态。这些函数是纯函数，因为它们不改变任何外部状态，只生成描述状态变化的操作。\n3. 应用状态变化：在 `main` 函数中，我们创建了一个 `State` 对象，并通过 `apply` 函数来应用状态变化。`apply` 函数调用传入的 lambda 表达式，从而修改 `State` 对象的状态。\n\n## 并发环境中的可变状态和不可变状态\n\n并发问题只有在并行的进程间共享可变数据才会出现。因此，一种解决方案就是不使用并行，另一种方案就是不使用可变数据。但还有第三种选择：使用可变数据，但不共享它。如果不共享数据，则不会发生在不知情的情况下数据被修改的事情。\n\n## const 的重要性\n\n如果希望某个对象不被修改，可以使用 const 关键字。\n\n### 逻辑 const 与内部 const\n\n如果不希望修改内部类成员的数据，可以把成员变量加上 const ，甚至不需要创建访问函数，只需要加上 public 即可。\n\n```c++\nclass Person {\n public:\n  const string name_;\n  const int age_;\n}\n```\n\n这种方法有个缺陷：有些编译器的优化功能将停止工作。一旦声明成员常量，就会丢失移动构造函数和移动赋值操作符。\n\n```c++\nclass Person {\n public:\n  void name() const{}\n  void age() const{}\n private:\n  string name_;\n  int age_;\n}\n```\n\n虽然这种方式中，数据成员没有声明为 const，但类的用户却不能修改它们，因为在实现的所有成员函数中，this 都指向一个 Person 的 const 实例。这不但提供了逻辑上的 const（不能修改对象中的用户可见数据），还实现了内部const（不会修改对象的内部数据）。同时，还不会丢失任何优化机会，因为编译器会产生任何必需的移动操作。\n\n如果需要修改，但又想保证数据的不可变性（至少对外部调用者是这样的），那就用并发编程相关的技术来做了。\n\n### 对于临时值优化成员函数\n\n如果类设计为不可变的，则创建 setter 函数时，需要创建一个返回对象副本的函数，以保存特定变量修改后的值。创建对象副本保存修改后的对象是十分低效的（尽管编译器在某些场合下可以对此进行优化）。对于原对象不再需要的情况，这一点也是适用的。\n\n![普通值和临时值.png](/images/2024/08/19/ea895920-5e27-11ef-9da5-855b30face3e.png)\n\n现在声明了两个 with_name 的重载函数。正如 const 修饰符一样，给成员函数指定引用类型修饰符（&）只影响this 指针的类型。第二个重载函数只适用于借用数据的对象的调用--临时对象或其他右值引用。\n\n当第一个重载函数被调用时，创建一个新的 persont 对象的副本，并由 this 指向它，设置新的 name，并返回新创建的对象实例。在第二个重载函数中，创建一个新的 persont 对象实例，并把 this 所指对象的数据移动（不是复制）到新对象实例中。\n\n注意第二个重载函数没有声明为 const。如果是，就不能把当前对象中的数据移动到新的对象中，就需要像第一个重载函数一样复制数据。\n\n### const缺陷\n\n1. const 禁止对象移动\n2. const 可以被破坏\n\n```c++\n#include <iostream>\n\nvoid modifyConst(const int& x) {\n    int& nonConstX = const_cast<int&>(x);  // 通过 const_cast 移除 const 性质\n    nonConstX = 42;  // 修改了原始的 const 对象\n}\n\nint main() {\n    int value = 10;\n    const int& constRef = value;\n\n    modifyConst(constRef);\n\n    std::cout << \"Modified value: \" << value << std::endl;  // 输出 42\n\n    return 0;\n}\n```\n\nconst_cast 可以移除 const 性质，实际上还有很多方式可以移除 const 性质，就不逐一列举了，只是想说有 const 关键字并不一定始终跟随定义的对象。","tags":["函数式编程"],"categories":["technology"]},{"title":"欧绪弗洛篇","url":"/2024/08/18/欧绪弗洛篇/","content":"\n因为欧绪弗洛自称有关神的知识如此精确，懂得什么是虔敬，什么是亵渎，苏格拉底于是向他求教，希望他从本质上讲清楚什么是虔敬，什么是亵渎。欧绪弗洛回答道：“凡是诸神喜爱的就是虔敬的，凡是诸神不喜爱的就是亵渎的”。但是，对相同的事物诸神有各自的判断，那么意见不统一的情况下，欧绪弗洛的回答就有问题了。于是，欧绪弗洛修正自己的观点为“虔敬就是诸神所喜爱的，亵渎就是诸神所痛恨的”。\n\n然而，欧绪弗洛并没有回答出虔敬和亵渎的本质，哪怕直到文章的结束。因为虔敬和亵渎的本质与诸神是否喜爱无关，这是欧绪弗洛没有弄明白的地方。\n","tags":["柏拉图","柏拉图中短篇全集"],"categories":["article"]},{"title":"捭阖第一","url":"/2024/08/18/捭阖第一/","content":"\n<!-- toc -->\n\n本篇内容由两部分组成。前半部分言捭阖之原理，又可分为三层：即捭阖之定义，捭阖之术用于游说之原理及捭阖之术如何运用。后半部分言捭阖之术在游说中如何具体运用。\n\n本篇提出“捭”就是“开”，主要是针对对方而言，让对方“开”，暴露真实意图，从而为我所利用；“阖”则是针对己方而言，己方要“合”，要密而自保；这是运用捭阖之术的总原则。捭阖之术可用于游说。口开即阳，口默即阴。自己或以阴结阳，让对方夸夸其谈；自己或以阳求阴，以谈辩之锋逼对方哑口无言。如何为之，应伺机而动，因时而应，此即为“说人之法”。\n\n```tex\n变化无穷，各有所归 ，或阴或阳，或柔或刚，或开或闭，或弛或张\n\n万事万物的变化虽然是无穷无尽的，但是都以避亡趋存作为它们的归宿。有的表现为阴，有的表现为阳；有的表现为柔，有的表现为刚；有的表现为开，有的表现为闭；有的表现为弛，有的表现为张\n```\n\n## 如何了解对方的实际情况？\n\n顺应每个人的特点来驾驭他。如果要弄清对方是有还是无，搞清对方的实际情况，一般情况下，是**顺着他的爱好和欲望来推测出对方心里的真实意图**。可以暗暗排查对方言辞，然后依据已知情况反问过去，以得其实情，了解到他的旨意；先“阖”后“捭”，从中得到利益。\n\n或公开自己的真实情况显示给对方，或不公开自己的真实情况而将它隐藏起来，不让对方知道。当己方的实际情况或目的等与对方完全相同的时候，就可以公开显示给对方看；当己方的实际情况或目的等与对方不同的时候，就不能公开。如果要用“捭”的方式，一定要做到周到；如果要用“阖”的方式，一定要做到严密。周到、严密还要注意隐蔽，**隐蔽的最佳效果就像“道”一样微而不显**。\n\n## 只有开口才有实话的可能\n\n用捭使对方开，而对其虚实进行辨别；辨别清楚之后用阖，确定下来对方的实情。圣人都是根据对方实际需要的轻重缓急来揣度对方的所想，然后再顺其所想而为对方作出谋划。圣人即因势考虑，如果不合对方的心意或其实际所需，就替自己作谋划，留好退路。\n\n所以用捭或能使对方开而真实情况暴露出来，或能让对方开而使己方的观点被接纳；用阖或能使己方有所获取，或能使己方顺利地躲过祸患。\n\n## 如何进行游说？\n\n把凡是有关长生、安乐、富贵、尊荣、显名、爱好、财利、得意、喜欲的，都视作“阳”，称为“始”。把凡是有关死亡、忧患、贫贱、苦辱、弃损、亡利、失意、有害、刑戮、诛罚的，都视作“阴”，称为“终”。那些在言谈时采用“阳”一类的事情来立说的，我们都可以称之为“始”，因为他们是**从事情好的一面来进行游说，劝诱对方开始行动，促成游说得到成功**；那些在言谈时采用“阴”一类的事情来立说的，我们都可以称之为“终”，因为他们是**从事情恶的一面来进行游说，阻止对方的谋略策划实施，使它终止行动**。\n\n捭阖之道，就是反复地使用阴阳进行试探。所以与品行高尚的人言说，就要说“阳”类的事；与品行卑劣的人言说，就要说“阴”类的事。下与小，均为阴，故可以用低下的去求合志向渺小的人；高与大，均为阳，故可以用高尚的去求合志趣高远的人。","tags":["鬼谷子"],"categories":["article"]},{"title":"局限性","url":"/2024/08/17/局限性/","content":"\n<!-- toc -->\n\n我们将局限分为两类：可改变的局限和不可改变的局限。不管是哪种局限皆需要建立正确的看待方式，比方说不可改变局限中的天生残疾和容貌焦虑以及可改变局限中的认知局限。\n\n## 发现我们的认知局限，可以帮助我们提升向外兼容度\n\n阿伽门农一家三口的悲剧：父献女、妻弑夫、子杀母。这里存在一个人类古老的困境，即每个人皆认为自己手握正义和真理，但我们每个人都有自己的认知盲区。特别是**从某个特定角度去看待问题，会看到一部分真实，而另一部分的真实会被忽视掉**。古希腊贤哲之间会通过辩论来避免，辩论的目的不是输赢，而是为了看到对方眼中的真实，来弥补自身的认知局限。\n\n无法容纳别人的优点和长处，是等级制度带来的攀比思维。通常产生攀比心理的个体与被选作为参照的个体之间往往具有极大的相似性，导致自身被尊重的需要过分夸大，虚荣动机增强，甚至产生极端的心理障碍和行为。**正确的“攀比思维”是见贤思齐**，即优秀的人出现在身边，意味着优质的学习资源出现，只要你肯积极主动向他学习，也就实现共同进步带来的利益最大化了。\n\n## 发现我们自身能力和条件局限，可以帮助我们提升向内兼容度\n\n没有好不好，只有合适不合适。这是因为每个人都有自己的能力薄弱点，这不是羞耻，而看见自己身上的薄弱点很明智。\n\n社会存在很多看似正确的错误规训，往往就是把我们的弱势变成我们的耻辱，甚至变成我们的罪名。这就需要建立强大的免疫对抗系统，来防止用别人错误的观点伤害到自己。在那些惯常的看似正确的行为背后，反而隐藏着很多的不正常。\n\n人生的原点是不一样的，意味着我们的成长背景和资源是不一样的。人和人不同，意味着我们彼此的能力特点和条件也不同。在这些不同的前提下，跟别人横向比较，赢只是一种没有意义的虚荣，输只是一种毫无意义的精神自虐。除了说明我们不懂得爱自己，没有能力给自己一份正义，其他什么都说明不了。横向比较经常是用别人的尺子来丈量自己，用别人的图纸来建自己的房子。你追求的是别人的样子，成为的也是别人，而非你自己。","tags":["杜素娟","自我"],"categories":["article"]},{"title":"高质量伴侣","url":"/2024/08/17/高质量伴侣/","content":"\n爱情婚姻很难脱离现实，不可能做到只是一场风花雪月的事。在残酷的现实中，人们缺什么，往往会把缺乏的内容投射到婚恋的择偶目标之中。如果体谅人类生存的这些局限，人们如何理解高质量伴侣之间存在差异也就不难理解了。\n\n基于精神需求层面的亲密关系的理解来谈一谈什么才是高质量的亲密关系呢？\n\n- 在精神层面不消耗你\n- 在资源和能量上不消耗你\n\n归根结底，高质量的伴侣关系必然是双向付出，低质量的伴侣关系必然是单向或双向的消耗。双向付出看似是互相抵消，但是一来一回这个过程的价值便是对高质量的伴侣关系的赠予。\n\n> 在这个人面前，你知道对方知道你的不完美，但你也知道，你依然是对方心中最珍贵的、最不可替代的存在。\n>\n> 某一方在单方面输出资源和能量，甚至是某一方在不断地向下兼容，这个亲密关系其实是隐患重重的。\n>\n> 好的伴侣一定是比翼齐飞，而不是某一方变成了另一方的燃料或是垫脚石。\n>\n> 人性的基本规律是我们只会被自己所欣赏的人所吸引，我们只会被对自己有价值和意义的人所吸引。","tags":["亲密关系","杜素娟"],"categories":["article"]},{"title":"边界感","url":"/2024/08/17/边界感/","content":"\n没有边界感带来的两种隐患，即失守和越界。\n\n失守：没有守好自己的边界，随便把被人放进自己的领地来。\n\n越界：随意踏越别人的领地。\n\n- **空间边界**：包括个人空间、隐私和物理距离。例如，不经允许进入别人的房间或随意翻看别人的物品\n- **时间边界**：指的是对时间的管理和分配。例如，不尊重别人的时间安排，随意打扰别人的工作或休息时间\n- **资源边界**：包括金钱、物品和信息。例如，未经允许使用别人的物品或占用别人的资源\n- **情感边界**：涉及个人情感和情绪的界限。例如，不尊重别人的情感需求或强迫别人接受自己的情感\n- **情绪边界**：指的是对情绪的管理和表达。例如，把自己的情绪强加给别人，或者不顾别人的情绪感受\n- **行为边界**：包括个人行为和习惯。例如，强迫别人接受自己的行为方式或干涉别人的行为选择\n- **选择边界**：涉及个人选择和决策。例如，不尊重别人的选择和决定，试图替别人做决定\n- **评价边界**：指的是对别人的评价和意见。例如，随意评判别人的行为或生活方式\n\n面对自己的边界不失守，面对他人的边界不越界。","tags":["杜素娟","自我"],"categories":["article"]},{"title":"克里托篇","url":"/2024/08/17/克里托篇/","content":"\n<!-- toc -->\n\n## 克里托为什么要帮助苏格拉底？\n\n1. 不愿失去一位无法替代的朋友\n2. 如果苏格拉底没有被救助，那么外人会以为克里托重钱财轻朋友，实在不想背负这个骂名\n\n第二个理由会让人觉得克里托是为了自己的名声才来救助苏格拉底，但他完全可以选择不说出这个理由，而他说出来的目的就是告诉苏格拉底，你如果不逃狱，我和那些本来能够帮助你的朋友和亲人将获得不好的名声。克里托企图唤醒苏格拉底的愧疚，这种谈话方式克里托后面还会继续使用。\n\n## 苏格拉底驳支持众人意味着正确\n\n> 克里托：大多数人不会相信，尽管我们全力督促你离开此地，是你自己拒绝了。\n\n前面讲克里托企图唤醒苏格拉底的愧疚，但苏格拉底本意是拒绝逃狱，而是支持法官的判决，哪怕这个判决是错误的。因此，苏格拉底要驳斥支持众人意味着正确的观点来打消克里托的顾虑。\n\n克里托觉得苏格拉底不愿逃狱是因为心中还有顾忌：\n\n1. 担心离开，朋友和家人会遇到麻烦，如财产没收或赔付巨款\n2. 贿赂执法人员的钱财不够\n3. 离开雅典，会感受不适应\n\n于是，克里托逐一打消这些顾虑：\n\n1. 冒险救你是正当的\n2. 还有外邦人愿意支持，钱财足够\n3. 在其它地方，你同样是受欢迎，而且那些地方有我的朋友\n\n克里托接着用惯用的手法，来让苏格拉底意识到，如果不逃狱，你身边的人都会受到影响。\n\n> 另外，苏格拉底，我认为你的做法是不公正的，在能够得救的时候放弃自己的生命，像你的敌人一样加快你的命运进程，如他们所愿加速毁掉你自己。更有甚者，我认为你辜负了你的儿子，在能够抚养和教育他们的时候，你却要离开和抛弃他们。这样做，表明你不关心他们的命运。他们将来的命运可能就是孤儿的命运。要么不要孩子，要么就与他们在一起，精心抚养和教育他们。在我看来你似乎选择了一条最轻松的道路，而我认为你应当像一名善良、勇敢的人那样去选择，尤其是一个自称要终身关注德性的人。\n>\n> 我感到羞耻，既为你，也为我们这些朋友，省得你碰上的所有事情都被人归因于我们一方的胆怯；你上法庭去接受审判，这样做其实没有必要，而现在这个荒唐的结果会被人认为，由于我们一方胆小怕事，事情失控了，在我们有可能救你、也能够救你的时候，我们没能救你，或者说你没能救你自己，哪怕说我们还有一丁点儿用处。想一想吧，苏格拉底，这样做不仅是邪恶，而且是羞耻，既对你，也对我们。你仔细想一想吧，或者说，考虑的时间已经过了，现在到了该下决心的时候了，以后不会再有机会了，整件事今晚必须完成。如果我们再拖延，那就不可能了，就太迟了。让我用各种理由来说服你，苏格拉底，听我的话，不要再固执了。\n\n克里托讲完，苏格拉底说自己只接受正义的建议，希望克里托能和自己讨论该不该逃狱的问题。\n\n苏格拉底需要驳斥克里托最初的观点，驳斥逻辑如下：\n\n- 一个人要尊重好意见，而不是坏意见\n- 好意见就是聪明人的意见，坏意见就是愚蠢人的意见\n- 专家的意见是好的，应该听从专家的意见\n\n所以我们不应当过多地考虑大多数人会怎么说我们，而应当考虑那个懂得正义和不义的人会说些什么，这个人就是真理本身。在这个世上，能静下心来思考的人并不多，能深入思考的就更少了。大部分人的观点都不重要，只不过是它人观点的转述，只要听起来合理或合乎自己的利益就收纳过来，一传十，十传百，相信的人也就会越来越多。\n\n![墙头草.png](/images/2024/08/17/2d2daab0-5c3e-11ef-a3ac-cb9da6ad142e.png)\n\n## 苏格拉底为什么不选择逃狱？\n\n苏格拉底决意向克里托说明为什么不可以逃狱，但在此之前需要先确定几个观点：\n\n1. 不能以恶报恶\n2. 应当履行公正的协议\n\n在没有受到法律的制裁之前，我始终受到法律的恩惠，即法律对那些恶人进行的判决，让城邦的和平得以继续维持。城邦的人之所以被法律所保护，是因为大家共同和法律签订了协议；城邦的人之所以能够被法律制裁，也是因为大家共同和法律签订了协议。现如今，法律对我判处死刑，如果违背法律，那就是没有履行公正的协议。如果这个判决是错误的，我同样不能违背法律的判决，否则就是以恶报恶。看来，违背法律的判决与之前正确的观点相违背，所以不可以逃狱。\n\n## 苏格拉底意欲何为？\n\n苏格拉底如果讲这番话的目的是为了说服那些被误判的人接收法律的制裁，那他就是在痴心妄想，没有任何一个人能够接收被污蔑，并且受到身体的伤害而不反抗。苏格拉底维护法律的判决是以死明志，志为维护法律的不可侵犯性。他认为错误不在法律，而是在执行法律的人，法律本身是正义的。\n\n我想苏格拉底似乎没有弄清楚一个事实，正确的观点要看在怎样的场景下运用才能发挥正确性。如果我没有做任何不正义的事情，一个法官就对我执行判决，说我恶意杀人当判有期徒刑 5 年，这是不可理喻的。首先，恶意杀人判处有期徒刑 5 年是正义的，但是将其放在一个没有犯此法的人身上就是不正义的，难道苏格拉底你要支持不正义的行为吗？\n\n谁让内心真实的想法不可能说服克里托呢，不然也不必大费周章讲这么多与本意无关的话。","tags":["柏拉图","柏拉图中短篇全集"],"categories":["article"]},{"title":"理想国第一卷：苏格拉底与色拉叙马霍斯的对话","url":"/2024/08/16/理想国第一卷：苏格拉底与色拉叙马霍斯的对话/","content":"\n> 色：苏格拉底，你们见了什么鬼，你吹我捧，搅的什么玩意儿？如果你真是要晓得什么是正义，就不该光是提问题，再以驳倒人家的回答来逞能。你才精哩！你知道提问题总比回答容易。你应该自己来回答，你认为什么是正义。别胡扯什么正义是一种责任、一种权宜之计，或者利益好处，或者什么报酬利润之类的话。你得直截了当地说，你到底指的是什么。\n\n还是不要看色拉叙马霍斯和苏格拉底之间的争论了，但色拉叙马霍斯的攻击性确实很强，好在苏格拉底轻松应对。现在我们可以确定的是，苏格拉底需要正面回答正义是什么。\n\n只是我不知道为什么色拉叙马霍斯把话头给到自己了，明明他要让苏格拉底不要再提问了，因为提问总比回答容易。我想色拉叙马霍斯还是太急于表达，就如文中介绍“当我们正谈话的时候，色拉叙马霍斯几次三番想插进来辩论，都让旁边的人给拦住了，因为他们急于要听出个究竟来。等我讲完了上面那些话稍一停顿的时候，他再也忍不住了，他抖擞精神，一个箭步冲上来，好像一只野兽要把我们一口吞掉似的，吓得我和玻勒马霍斯手足无措。”\n\n> 色：那么，听着！我说正义不是别的，就是强者的利益。——你干吗不拍手叫好？当然你是不愿意的啰\n>\n> 苏：我先得明白你的意思，才能表态。可这会儿我还闹不明白。你说对强者有利就是正义。色拉叙马霍斯啊！你这到底说的是什么意思？总不是这个意思吧：因为浦吕达马斯是运动员，比我们大伙儿都强，顿顿吃牛肉对他的身体有好处，所以正义；而我们这些身体弱的人吃牛肉虽然也有好处，但是就不正义？\n>\n> 色：你真坏！苏格拉底，你成心把水搅混，使这个辩论受到最大的损害。\n>\n> 苏：绝没有这意思。我的先生，我不过请你把你的意思交代清楚些罢了。\n>\n> 色：难道你不晓得统治各个国家的人有的是独裁者，有的是平民，有的是贵族吗？\n>\n> 苏：怎么不知道？\n>\n> 色：政府是每一城邦的统治者，是不是？\n>\n> 苏：是的。\n>\n> 色：难道不是谁强谁统治吗？每一种统治者都制定对自己有利的法律，平民政府制定民主法律，独裁政府制定独裁法律，依此类推。他们制定了法律明告大家：凡是对政府有利的对百姓就是正义的；谁不遵守，他就有违法之罪，又有不正义之名。因此，我的意思是，在任何国家里，所谓正义就是当时政府的利益。政府当然有权，所以唯一合理的结论应该说：不管在什么地方，正义就是强者的利益。\n>\n> 苏：现在我明白你的意思了。这个意思对不对，我要来研究。色拉叙马霍斯，你自己刚才说，正义是利益，可是你又不准我这么说。固然，你在“利益”前面加上了“强者的”这么个条件。\n>\n> 色：这恐怕是一个无足轻重的条件。\n>\n> 苏：重要不重要现在还难说。但是明摆着我们应该考虑你说得对不对。须知，说正义是利益，我也赞成。不过，你给加上了“强者的”这个条件，我就不明白了，所以得好好想想。\n>\n> 色：尽管想吧！\n\n色拉叙马霍斯说：“正义不是别的，就是强者的利益。”\n\n首先苏格拉底最初的举例来明确色拉叙马霍斯的含义是没说错的，只是色拉叙马霍斯依旧选择反驳。不管怎样，色拉叙马霍斯选择换个例子，但是含义却没有变化。后面苏格拉底就追问，这个追问是想探讨出正义的本质是什么，可是色拉叙马霍斯明显谈的是现实中的正义是什么样子。二人从此刻已经分道扬镳，完全不在一个语言环境下。\n\n你会觉得色拉叙马霍斯说的正确，但你听苏格拉底一番言论之后也觉得没错。色拉叙马霍斯讲的是现实中的正义，你眼中的世界就是这样，符合经验的事情总是容易轻易得到支持。但是你对这份正义并不满意。不单是现实中的正义是理想中的正义的偏离，更因为强者必然引出弱者，那就说明总有人没有从中受益。\n\n如果你觉得色拉叙马霍斯的观点正确，可你又不是其中的受益者，那你必然适合做奴隶，因为你连争取自己的利益的想法都没有。而你所谓的正确居然就是你眼中所看到的，看来还蠢得厉害。理想无法实现，现实又处处与我为难。要么就去成为强者，利益就偏向于我。要么臣服于现实的残酷，不去招惹强者即可，至少能让利益少被搜刮些。如果此刻我说“我们每个人心中都要心怀正义，对于弱者应该多加照顾，博爱才是世间大道，唯有真理永恒不变”，你却是要说我像个疯子了。可我不过是把现实中的话语体系和理想中的话语体系都说出来了而已。\n\n我们现在要能够区分讲话者究竟是在描述现实，还是在描述理想。追求理想是为了让心中常善，接受现实是不让理想被误解。如果法律不追求绝对的正义，那么法律就不再正义。如果男女不追求爱情，那么遍地是演员了。\n\n> 色：因为在你想象中牧羊或牧牛的人把牛羊喂得又肥又壮是为牛羊的利益，而不是为他们自己或者他们主人的利益。你更以为各国的统治者当他们真正是统治者的时候，并不把自己的人民当作上面所说的牛羊；你并不认为他们日夜操心，是专为他们自己的利益。你离了解正义不正义，正义的人和不正义的人简直还差十万八千里。因为你居然不了解：正义也好，正义的人也好，反正谁是强者，谁统治，它就为谁效劳，而不是为那些吃苦受罪的老百姓，和受使唤的人效劳。不正义正相反，专为管束那些老实正义的好人。老百姓给当官的效劳，用自己的效劳来使当官的快活，他们自己却一无所得。头脑简单的苏格拉底啊，难道你不该好好想想吗？正义的人跟不正义的人相比，总是处处吃亏。先拿做生意来说吧。正义者和不正义者合伙经营，到分红的时候，从来没见过正义的人多分到一点，他总是少分到一点。再看办公事吧。交税的时候，两个人收入相等，总是正义的人交得多，不正义的人交得少。等到有钱可拿，总是正义的人分文不得，不正义的人来个一扫而空。要是担任了公职，正义的人就算没有别的损失，他自己私人的事业也会因为无暇顾及，而弄得一团糟。他因为正义不肯损公肥私，也得罪亲朋好友，不肯为他们徇私情干坏事。而不正义的人恰好处处相反。我现在要讲的就是刚才所说的那种有本事捞大油水的人。你如愿弄明白，对于个人不正义比起正义来是多么的有利这一点，你就去想想这种人。如果举极端的例子，你就更容易明白了：最不正义的人就是最快乐的人；不愿意为非作歹的人也就是最吃亏苦恼的人。极端的不正义就是大窃国者的暴政，把别人的东西，不论是神圣的还是普通人的，是公家的还是私人的，肆无忌惮巧取豪夺。平常人犯了错误，查出来以后，不但要受罚，而且名誉扫地，被人家认为大逆不道，当作强盗、拐子、诈骗犯、扒手。但是那些不仅掠夺人民的钱财，而且剥夺人民的身体和自由的人，不但没有恶名，反而被认为有福。受他们统治的人是这么说，所有听到他们干那些不正义勾当的人也是这么说。一般人之所以谴责不正义，并不是怕做不正义的事，而是怕吃不正义的亏。所以，苏格拉底，不正义的事只要干得大，是比正义更有力、更如意、更气派。所以像我一上来就说的：正义是为强者的利益服务的，而不正义对一个人自己有好处、有利益。\n\n色拉叙马霍斯对现实的观察真是太精准。这么多年过去了，世界依旧如此，《理想国》不愧为理想二字。\n\n> 苏：我们因此可以说匠人之得到报酬，是从他们在运用了自己特有的技术以外又运用了一种挣钱之术而得来的。\n>\n> 〔色拉叙马霍斯勉强同意。〕\n>\n> 苏：既然得到报酬的这种利益，并不是来自他本职的技术，严格地讲，就是：医术产生健康，而挣钱之术产生了报酬，其他各行各业莫不如此，——每种技艺尽其本职，使受照管的对象得到利益。但是如果匠人得不到报酬，他能从自己的本职技术得到利益吗？\n>\n> 色：看来不能。\n>\n> 苏：那么工作而得不到报酬，那对他自己不是确实没有利益吗？\n>\n> 色：的确没有利益。\n\n看得出苏格拉底是在探求本质，这是认识世界本源的方式，很多事物的本源在历史中掩盖。医生医治病人这个技艺本身并不会带来钱财，救人和钱财没有直接联系，只是救人得到钱财能够维持自身和家庭的生存，能激发更多人学习这份技艺。如果救人是善，那么善就在利益的绑定下得到扩张。我们从来不是不满于行善之后的适当利益，而是不满于医生心中为了利益而忘了救人才是本质。理想情况是行善而不求回报，但我们考虑到现实层面还是认可行善之后的适当利益已是善的彰显。而为了利益而忘了救人是不可能成立的，荒谬的事情必然会发生，但是必然不可能被允许存在。故而现实情况是救人依旧还在，但是利益的设定值存在相当大的泡沫，且不为外行所见。你要让我说关于医生最离谱的事情，那就是药房买药更多优惠更多的活动。以及救治病人只需一种药物，但为了利益却安排多种新药物来剥取病人的更多的钱财，因为新药物会给更多的广告费，药房的人自然优先给病人推送这种产品。\n\n\n\n关于他们的谈话就论述至此，后面还是一部分他们的讨论，但已无记录的必要。\n\n最后记录一下知乎某人的回答，其实和我前面所讲并无差别，只不过他的表述更为专业。\n\n> 因为两者对于真的定义是不一样。\n>\n> 柏拉图那里指的是，事实符合概念。比如说牧羊人的概念要求所谓的真，就是牧羊，而不是别的什么东西。因此他是目的论，以及偏向于应然\n>\n> 但是色拉叙马霍斯对于真的定义则是概念要符合事实。他是通过经验观察获得概念的内涵，偏向于实然。\n>\n> 正因为两者的这种差异，所以两者弄不到一块","tags":["柏拉图","理想国"],"categories":["article"]},{"title":"理想国第一卷：苏格拉底与玻勒马霍斯的对话","url":"/2024/08/16/理想国第一卷：苏格拉底与玻勒马霍斯的对话/","content":"\n> 苏：什么是烹调术所给的恰如其分的报答？给予什么人？给的什么东西？\n>\n> 玻：把美味给予食物。\n>\n> 苏：那么，什么是正义所给的恰如其分的报答呢？给予什么人？\n>\n> 玻：苏格拉底，假如我们说话要前后一致，那么，正义就是“把善给予友人，把恶给予敌人”。\n\n后面苏格拉底和玻勒马霍斯继续辩论，这个过程中苏格拉底引导玻勒马霍斯肯定两个观点：\n\n1. 其他有用正义就无用，其他无用正义就有用了\n2. 正义之人亦是熟悉如何不正义\n\n玻勒马霍斯坦白被弄得晕头转向，不顾之前肯定的观点，再次声明“我终归认为帮助朋友，伤害敌人是正义的”。\n\n> 玻：我们应该说朋友不是仅看起来可靠的人，而是真正可靠的人。看起来好，并不真正好的人只能当作外表上的朋友，不算作真朋友。关于敌人，理亦如此。\n>\n> 苏：照这个道理说来，好人才是朋友，坏人才是敌人。\n>\n> 玻：是的。\n>\n> 苏：我们原先说的以善报友，以恶报敌是正义。讲到这里我们是不是还得加上一条，即，假使朋友真是好人，当待之以善，假如敌人真是坏人，当待之以恶，这才算是正义？\n>\n> 玻：当然。我觉得这样才成为一个很好的定义。\n\n经过苏格拉底的追问，玻勒马霍斯觉得之前的观点确有不合理之处。因为朋友不一定都是好的，敌人也不一定都是坏的。当前玻勒马霍斯的观点是“假使朋友真是好人，当待之以善，假如敌人真是坏人，当待之以恶，这才算是正义”。\n\n辩论的意义不是为了输赢，而是为了接近真理。如果一个问题没有经过大脑长期而周密的思考，就进入到辩论中，不可避免地出现不恰当的语言表述。通过细问和反驳来修正原先观点的不恰当性，让此次辩论得以顺利且有意义的进行下去。如果辩论就是死守某句话和某个观点，而不能及时给予修正，那这场辩论哪还有继续进行下去的价值呢？\n\n> 苏：正义的人不是好人吗？\n>\n> 玻：当然是好人。\n>\n> 苏：玻勒马霍斯啊！伤害朋友或任何人不是正义者的功能，而是和正义者相反的人的功能，是不正义者的功能。\n>\n> 玻：苏格拉底，你的理由看来很充分。\n>\n> 苏：如果有人说，正义就是还债，而所谓“还债”就是伤害他的敌人，帮助他的朋友。那么，我认为说这些话的人不可能算是聪明人。因为我们已经摆明，伤害任何人无论如何总是不正义的。\n>\n> 玻：我同意。\n\n在苏格拉底持续追问之下，玻勒马霍斯赞成最新的观点：“正义的人不可能做出不正义的事，那是不正义者的功能。”\n\n至此，玻勒马霍斯最初的观点就被驳斥了，即“正义就是助友害敌。”","tags":["柏拉图","理想国"],"categories":["article"]},{"title":"理想国第一卷：苏格拉底与克法洛斯的对话","url":"/2024/08/16/理想国第一卷：苏格拉底与克法洛斯的对话/","content":"\n> 克法洛斯：我要告诉你，随着对肉体上的享受要求减退下来，我爱上了机智的清谈，而且越来越喜爱。我可是真的求你多上这儿来，拿这里当自己家一样，跟这些年轻人交游，结成好友。\n\n如果一个人说他不再喜欢什么，含义就是他曾经对此注入过不少的精力。克法洛斯对肉体的享受需求减退（性欲），看来还没有完全丢弃，可能想着精力充沛的时候再现当年风流。他还爱上了机智的清谈，这在后面会被他自行推翻，但这句话也能看出此前他是不喜欢清谈的，年轻的时候他在苦心积虑如何赚更多的钱财，哪怕不择手段。\n\n> 苏格拉底：说真的，克法洛斯，我喜欢跟你们上了年纪的人谈话。我把你们看作经过了漫长的人生旅途的老旅客。这条路，我们多半不久也是得踏上的，我应该请教你们：这条路是崎岖坎坷的呢，还是一条康庄坦途呢？克法洛斯，您的年纪已经跨进了诗人所谓的“老年之门”，究竟晚境是痛苦呢还是怎么样？\n>\n> 克法洛斯：上了年纪的确使人心平气和，宁静寡欲。到了清心寡欲，弦不再绷得那么紧的时候，这境界真像索福克勒斯所说的，像是摆脱了一帮子穷凶极恶的奴隶主的羁绊似的。苏格拉底，上面所说的许多痛苦，包括亲人朋友的种种不满，其原因只有一个，不在于人的年老，而在于人的性格。如果他们是大大方方，心平气和的人，年老对他们称不上是太大的痛苦。要不然的话，年轻轻的照样少不了烦恼\n\n克法洛斯声称自己喜欢清谈，苏格拉底就抛出一个问题，即已至晚年的克法洛斯对生活是怎样的感受？\n\n克法洛斯的看法是无关年纪，而取决于人的性格或境界。只要心态好，生活也会更好。可这种话也就家财万贯的人能去讲，生活贫困的人还被困在温饱问题之中，心态好可解决不了这些。\n\n> 苏格拉底：亲爱的克法洛斯，我想，一般人是不会以你的话为然的。他们会认为你觉得老有老福，并不是因为你的性格，而是因为你家财万贯。他们会说“人有了钱当然有许多安慰”\n>\n> 克法洛斯：一个好人，同时忍受贫困、老年，固然不容易，但是一个坏人虽然有钱，到了老年其内心也是得不到满足和宁静的\n\n克法洛斯的这个回复很有意思，他否定有钱就能晚年快乐的观点，这点他没有说谎，因为他现在正在受苦，受他幻想出来的死后面临的地狱之苦。所以，后面说“一个坏人虽然有钱，到了老年其内心也是得不到满足和宁静的”讲的就是他自己当前的处境。\n\n> 苏格拉底：真的，我还要向您讨教一个问题。据您看有了万贯家财最大的好处是什么？\n>\n> 克法洛斯：当一个人想到自己不久要死的时候，就会有一种从来不曾有过的害怕缠住他。关于地狱的种种传说，以及在阳世作恶，死了到阴间要受报应的故事，以前听了当作无稽之谈，现在想起来开始感到不安了——说不定这些都是真的呢！不管是因为年老体弱，还是因为想到自己一步步逼近另一个世界了，他把这些情景都看得更加清楚了，满腹恐惧和疑虑。他开始扪心自问，有没有在什么地方害过什么人？如果他发现自己这一辈子造孽不少，夜里常常会像小孩一样从梦中吓醒，无限恐怖。我并不是说每一个人都是这样，我是说对于一个通情达理的人来说，有了钱财他就用不着存心作假或不得已而骗人了。当他要到另一世界去的时候，他也就用不着为亏欠了神的祭品和人的债务而心惊胆战了。在我看来，有钱固然有种种好处，但比较起来，对于一个明白事理的人来说，我上面所讲的好处才是他最大的好处。\n\n克法洛斯已经暴露自己年轻时的种种恶行，现在他开始祭祀和行善也并非弥补和悔过，而是怕入地狱受苦。\n\n说到底克法洛斯只是描述自己的经历，并没有反省过自己的生活。所谓是未经审视的生活是不值得过的。\n\n> 苏格拉底：克法洛斯，您说得妙极了。不过讲到“正义”嘛，究竟正义是什么呢？难道仅仅有话实说，有债照还就算正义吗？这样做会不会有时是正义的，而有时却不是正义的呢？打个比方吧！譬如说，你有个朋友在头脑清楚的时候，曾经把武器交给你；假如后来他疯了，再跟你要回去；任何人都会说不能还给他。如果竟还给了他，那倒是不正义的。把整个真情实况告诉疯子也是不正义的。\n\n关于苏格拉底和克法洛斯的对谈已经结束，前面克法洛斯讲到地狱暗示自己年轻时很多的不正义的行为，苏格拉底在这里引出了正义的话题，这个话题就是后面苏格拉底和其他人的对话了。\n\n克法洛斯至此不会再出现了，我们从他年轻的经历中看到色欲和钱财，到晚年倒还显得虔诚和喜欢清谈了，只可惜他并没有改变，而是一如既往地为自己寻求利益。","tags":["柏拉图","理想国"],"categories":["article"]},{"title":"第四章：以旧函数创建新函数","url":"/2024/08/16/第四章：以旧函数创建新函数/","content":"\n<!-- toc -->\n\n**注意**：此文介绍很多[C++11新特性](https://xiaoyangst.github.io/tags/C-11%E6%96%B0%E7%89%B9%E6%80%A7/)的知识（bind绑定器），这不会在此读书笔记中记录，可以在我的其它地方找到相关的笔记，或者你可以自行去学习，毕竟，C++11 是现在 C++ 学习者必备的语法。\n\n## 偏函数的应用\n\n这种通过把已知函数的一个或多个参数设定为特定值的方法创建新函数的概念称为偏函数应用。偏的意思是在计算函数结果时，只需传递部分参数，而不需要传递所有参数。\n\n函数 std::bind1st 和 std::bind2nd 在 C++17中已经删除，C++11也不推荐使用，因为它们可以被更加通用的 std::bind 取代。std::bind 不再局限于二元函数，而是可用于任意数目参数的函数。也不限制用户指定绑定哪些参数，可以以任意顺序绑定任意数目的参数，而留下不需绑定的参数。\n\n还有提及的地方是 如何把 bind 绑定的函数 转化成用 Lambda 表示，示意图如下：\n\n![bind转lambda.png](/images/2024/08/16/5ebb8440-5bcf-11ef-a253-abb20d863bc2.png)\n\n## 柯里化\n\n柯里化的基本思想是将一个接受多个参数的函数转换为一系列只接受单个参数的函数的过程。换句话说，柯里化将一个多元函数（接受多个参数的函数）转换为一个嵌套的一元函数（每个只接受一个参数的函数）。\n\n```c++\nf(x, y, z)  # 原函数\n\n# 柯里化后的函数\nf(x)(y)(z)\n```\n\n在这个过程中，`f(x)` 返回一个新的函数，这个新函数接受参数 y，并返回另一个新的函数，这个函数接受参数 z 并返回最终结果。\n\n```c++\n#include <iostream>\n#include <functional>\n\nauto add = [](int a) {\n    return [a](int b) {\n        return [a, b](int c) {\n            return a + b + c;\n        };\n    };\n};\n\nint main() {\n    std::cout << add(1)(2)(3) << std::endl; // 输出 6\n    return 0;\n}\n```\n\n## 偏函数与柯里化\n\n正如读者看到的，虽然十分类似，但柯里化和偏函数应用各有优缺点，而且都有自己适用的场合。当有一个要绑定其参数的特定函数时，偏函数比较有用。在这种情况下，知道函数有几个参数，可以确切地选择哪些参数要绑定到特定的值。当函数可以有任意多个参数时，柯里化对这种通用情况十分有用。在这种情况下，std::bind 就没有用武之地了，因为既然不知道函数有几个参数，也就不知道有几个参数需要绑定到占位符，甚至不知道需要多少个占位符。\n\n## 函数组合\n\n作者通过一个单词统计列表的故事讲函数的组合，因为即每个函数自有其功能，并且该函数返回处理的结果，这些结果继续传递到下一个函数，直到完成自己的需求。\n\n![单词统计.png](/images/2024/08/16/58749d10-5bcf-11ef-a253-abb20d863bc2.png)\n\n## 函数提升\n\n在第一章接触了提升的概念，这里展开一下。一般来说，提升是种编程模式，它提供了一种方式，把给定的函数转换成一个类似可广泛应用的函数。例如，如果有一个操作字符串的函数，提升允许程序员容易地创建一个新的函数，该函数可以操作字符串向量、列表、字符串指针、整数-字符串 map 和其他包含字符串的结构。\n\n![操作字符串集合的函数.png](/images/2024/08/16/6c9310b0-5bcf-11ef-a253-abb20d863bc2.png)\n\n读者可以创建一个高阶函数，接收操作单个字符串的任意函数，并创建一个操作字符串指针的函数。前面已经分别创建了操作字符串向量和map的函数。这些函数称为提升函数，因为它们把操作某一类型的函数提升为操作包含这种类型的结构或集合的函数。\n\n![提升函数.png](/images/2024/08/16/540bc4b0-5bcf-11ef-a253-abb20d863bc2.png)\n\n---\n⭐️内容取自译者程继洪、孙玉梅、娄山佑《函数式编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["函数式编程"],"categories":["technology"]},{"title":"第三章：函数对象","url":"/2024/08/16/第三章：函数对象/","content":"\n<!-- toc -->\n\n**注意**：此文介绍很多[C++11新特性](https://xiaoyangst.github.io/tags/C-11%E6%96%B0%E7%89%B9%E6%80%A7/)的知识（auto 关键字、Lambda 表达式、function 包装器），这不会在此读书笔记中记录，可以在我的其它地方找到相关的笔记，或者你可以自行去学习，毕竟，C++11 是现在 C++ 学习者必备的语法。\n\n## 操作符包装器\n\n![操作符包装器.png](/images/2024/08/16/d632a100-5bc2-11ef-a253-abb20d863bc2.png)\n\nC++11 使用操作符包装器需要指明类型，如greater\\<int\\>()。但是 C++14 之后就可以不用了，如greater\\<\\>()。\n\n## std::function的性能问题和并发安全问题\n\n虽然前面的内容都证明 std::function 很有用，但不能滥用，因为它有明显的性能问题。为了隐藏包含的类型并提供一个对所有可调用类型的通用接口，std::function 使用类型擦除的技术。本书并不打算深入研究这个问题，只需要知道它是基于虚成员函数调用就足够了。因为虚调用是在运行时进行的，编译器不能在线调用，所以也就失去了优化的机会。\n\nstd::function 另一个需要注意的是，虽然它的调用操作符限定为 const，但它可以调用非const对象。在多线程代码中，容易导致各种问题。\n\n---\n⭐️内容取自译者程继洪、孙玉梅、娄山佑《函数式编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["函数式编程"],"categories":["technology"]},{"title":"82.删除排序链表中的重复元素 II","url":"/2024/08/16/82-删除排序链表中的重复元素-II/","content":"\n```c++\nclass Solution {\npublic:\n    ListNode* deleteDuplicates(ListNode* head) {\n        if(head == nullptr || head->next == nullptr){\n            return head;\n        }\n        ListNode* virtualHead = new ListNode(-101);\n        virtualHead->next = head;\n        ListNode* slow = head;\n        ListNode* fast = head->next;\n        ListNode* delPre = virtualHead; // 待删除节点的前一个节点\n\n        while(fast){\n            if(slow->val != fast->val){ // 如果不相等，三个指针集体前移\n                delPre = delPre->next;\n                slow = slow->next;\n                fast = fast->next;\n                continue;\n            }\n            while(fast != nullptr && slow->val == fast->val){   // fast 最终指向 不重复节点的位置\n                fast = fast->next;\n            }\n            if(fast != nullptr){    // 删除重复节点\n                delPre->next = fast;\n                slow = fast;\n                fast = fast->next;\n            }else{  // 如果 fast 为空，表明slow 和 fast 之间都是重复值，delPre 指向 fast 就代表删除这些重复值\n                delPre->next = fast;\n            }\n\n        }\n\n        return virtualHead->next;\n    }\n};\n```\n\n当我们的链表中删除某个节点，如果这个节点可能包含头结点，那么务必使用虚拟头结点，因为删除节点需要拥有待删除节点的前一个节点才能进行删除。","tags":["链表"],"categories":["leetcode"]},{"title":"83.删除排序链表中的重复元素","url":"/2024/08/16/83-删除排序链表中的重复元素/","content":"\n```c++\nclass Solution {  \npublic:  \n    ListNode* deleteDuplicates(ListNode* head) {  \n        if (head == nullptr || head->next == nullptr){  \n             return head;  \n        }  \n  \n        ListNode* slow = head;  \n        ListNode* fast = head->next;  \n  \n        while (fast) {  \n            // 由于 fast 进入循环，需要时刻检测 fast 不为空  \n            while (fast != nullptr && slow->val == fast->val) {  \n                fast = fast->next;  \n                slow->next = fast;  \n            }  \n            // 前面如果 fast 为空会退出循环，因此移动前需要检查是否是因为 fast为空退出  \n            if (fast != nullptr) {  \n                slow = fast;  \n                fast = fast->next;  \n            }  \n        }  \n  \n        return head;  \n    }  \n};  \n```\n\n这道题主要强调 while 循环，由于 fast 检测是否为空在最外层 while 中检测，但它只能保证当前这次循环不为空，所以 fast 如果进入下一个 while 循环（代码中内存 while 循环），记得要继续检测是否为空，不然出现未定义错误。之所以强调，是这种错误容易犯。\n","tags":["链表"],"categories":["leetcode"]},{"title":"206.反转链表","url":"/2024/08/16/206-反转链表/","content":"\n```c++\nclass Solution {\npublic:\n    ListNode* reverseList(ListNode* head) {\n        if(head == nullptr || head->next == nullptr){\n            return head;\n        }\n        ListNode* left = head;\n        ListNode* right = head->next;\n        while(right){\n            ListNode* node = right->next;\n            right->next = left;\n            left = right;\n            right = node;\n        }\n        head->next = nullptr;       // 容易被忘记，此时 head 已经是尾节点了，next 该指向 nullptr\n        return left;\n    }\n};\n```\n\n反转链表需要用到三个指针，left 和 right 指针用于反转链表，而 node 指针用来保存还未进行反转的链表。","tags":["链表"],"categories":["leetcode"]},{"title":"933.最近的请求次数","url":"/2024/08/16/933-最近的请求次数/","content":"\n```c++\nclass RecentCounter {\nprivate:\n    queue<int> data; \npublic:\n    RecentCounter() {}\n\n    int ping(int t) {\n        data.push(t);\n        while(data.front() < (t - 3000)){\n            data.pop();\n        }\n        return data.size();\n    }\n};\n```\n\n这道题只要想明白一件事情，即由于题目保证每次对 `ping` 调用所使用的 `t` 值都 **严格递增**，而我们只关心传递进来的 t 在 [t-3000,t] 范围内 ping 的总数，那就表明之前加入的所有数据并不是都有必要一直存在。\n\n简单举例说明：[1], [100], [3001], [3002]\n\n| 加入元素 | 范围内所有请求数 | 容器是否需要移除数据                       |      |\n| -------- | ---------------- | ------------------------------------------ | ---- |\n| 1        | [-2999,1]        | 不需要，还有元素1                          |      |\n| 100      | [-2900,100]      | 不需要，还有元素 1、100                    |      |\n| 3001     | [1,3001]         | 不需要，还有元素 1、100、3001              |      |\n| 3002     | [2,3002]         | 需要，移除元素 1，还有元素 100、3001、3002 |      |\n\n没错，到加入3002开始，由于后续加入的元素必然大于 3002，那么元素 1 没有存在的必要了，因为它都不在 [2,3002]范围，那么后续加入的元素它也必然不可能满足，因此 pop 掉。\n\n如果这道题没有想到这点，就会容易弄复杂，可能头脑清晰的时候一下子就想出来了，可若不是如此，很容易掉进陷阱中，比方说所有数据都保存，但实际上这是没必要的，因为递增的数据说明前面的数据并不一定有价值，在合适的地方就该删掉。","tags":["队列"],"categories":["leetcode"]},{"title":"解开之前的一个误会","url":"/2024/08/16/解开之前的一个误会/","content":"\n本来之前用的是 Gridea 把文章上传到博客，已经习惯使用，但是有天上传文章却出现问题，有些内容莫名其妙被加粗，让我相当不爽，我还以为是 Gridea 本身的问题，即 markdown 转到 HTML 出现的问题。直到今日问题才算解开，因为转到 hexo 这个问题还是出现了，询问 ChatGpt才算一目了然。\n\n原因是<>导致的错误识别，因为 Markdown 语法中的尖括号 `<` 和 `>` 被解释为 HTML 标签，导致内容被解析错误。等我删掉之后就解决了，如果非要保留，需要进行转移。这里就只介绍一种，即通过在尖括号前加上反斜杠 `\\` 来转义它们，使 Markdown 解析器不会将它们当作 HTML 标签处理。\n\n本人解析错误的内容如下： shared_ptr\\<A\\> 和 shared_ptr\\<B\\> 导致，如果你不进行转移，你根本看不到这里的 A 和 B，但我这里转移了，你可以看到。\n\n```tex\n创建 shared_ptr<A>对象 a 管理类 A 对象，a 的引用计数加 1，当前引用计数为 1。创建 shared_ptr<B> 对象 b 管理类 B 对象，b 的引用计数加 1，当前引用计数为 1。接下来将类对象 A 的 成员变量 b_ptr 赋值为前面创建的 b，b 的引用计数加 1，当前引用计数为 2。接下来将类对象 B 的 成员变量 a_ptr 赋值为前面创建的 a，a 的引用计数加 1，当前引用计数为 2。离开作用域之后，a 和 b 都被销毁，各自对应的引用计数减 1，且当前引用计数为 1。也就是说引用计数都没有归 0，这是没有析构的原因。\n```","tags":["一点小事"],"categories":["various"]},{"title":"tuple元组","url":"/2024/08/16/tuple元组/","content":"\n<!-- toc -->\n\nC++11 引入了 std::tuple，它是一种可以**包含多个不同类型元素的容器**（ 它是一个模板类，允许将多个不同类型的对象组合在一起。）。std::tuple 提供了一种方便的方法来将多个值组合在一起，而不需要定义一个结构体或类。\n\n```c++\nstd::tuple<int, double, std::string> myTuple(1, 2.5, \"Hello\");\n```\n\n## 创建和初始化\n\n```c++\nstd::tuple<int, double, std::string> t1;  // 默认构造\nstd::tuple<int, double, std::string> t2(10, 3.14, \"C++\");  // 值构造\nauto t3 = std::make_tuple(20, 6.28, \"Programming\");  // 使用 make_tuple 创建\n```\n\n## 访问元素\n\n```c++\nauto t = std::make_tuple(1, 2.5, \"Hello\");\nint i = std::get<0>(t);           // 获取第一个元素，类型为 int\ndouble d = std::get<1>(t);        // 获取第二个元素，类型为 double\nstd::string s = std::get<2>(t);   // 获取第三个元素，类型为 std::string\n\n// 通过类型访问元素\nauto s1 = std::get<std::string>(t);\n```\n\n## std::tuple_size 和 std::tuple_element\n\n`std::tuple_size<tuple_type>::value` 用于获取 `tuple` 中的元素数量。\n\n`std::tuple_element<N, tuple_type>::type` 用于获取 `tuple` 中第 N 个元素的类型。\n\n```c++\nauto t = std::make_tuple(1, 2.5, \"Hello\");\nconstexpr auto size = std::tuple_size<decltype(t)>::value;  // size = 3\n\nusing ElementType = std::tuple_element<1, decltype(t)>::type;  // ElementType = double\n```\n\n## 应用场景\n\n**返回多个值**：在函数需要返回多个值时，`std::tuple` 是一个很好的选择。\n\n**可变参数模板**：在泛型编程中，可以使用 `std::tuple` 处理不同数量和类型的参数\n\n**组合复杂类型**：将多个不同类型的数据组合在一起，避免定义专门的结构体","tags":["C++11新特性"],"categories":["technology"]},{"title":"auto 和 decltype","url":"/2024/08/16/auto-和-decltype/","content":"\n<!-- toc -->\n\n## auto\n\n使用了 auto 关键字以后，编译器会在编译期间自动推导出变量的类型，这样我们就不用手动指明变量的数据类型了。auto 仅仅是一个占位符，在编译器期间它会被真正的类型所替代。\n\n### 注意点\n\n1. auto 变量**必须在定义时初始化**，因为编译器需要根据初始化表达式来推导类型\n2. auto 不能在函数的参数中使用，因为 auto 后面的变量需要初始化，当时函数的参数还只是声明（哪怕你是给这个函数参数填上默认参数也不行）\n3. auto 其实在 C++11 不能用于推断函数的返回值，当时 C++14 支持了。在 C++11 不支持推断函数的返回值的情况下，利用 decltype 能解决这个问题\n4. 当 auto 用于数组或函数指针时，数组会退化为指针类型，函数会退化为函数指针类型\n5. 推导规则遵循 C++ 类型规则，如：如果表达式是按值传递的，那么 auto 推导出的类型是值类型，而不是引用类型\n6. 当 = 右边的表达式是一个引用类型时，auto 会把引用抛弃，直接推导出它的原始类型\n7. auto 关键字不能定义数组\n8. auto 只能用于类的静态成员，不能用于类的非静态成员（普通成员）\n9. 一旦类型被推导出来，变量的类型就固定了，不会因为初始化表达式的类型发生变化而改变\n\n最后一点可能不容易理解，举例说明：\n\n```c++\nauto x = 42;  // x 的类型被推导为 int\n```\n\n在这个例子中，x 的类型被推导为 int，因为 42 是一个整数字面值（int 类型）。即使你在以后改变 x 的值为不同类型的数据，x 的类型也不会改变，它仍然是 int。\n\n```c++\nx = 3.14;  // 虽然你尝试赋值一个 double 类型，但 x 仍然是 int\n```\n\n在这里，x 已经被推导为 int 类型，因此赋值时，3.14 会被截断为整数 3，因为 x 是 int 类型。\n\n### auto 与 const 结合\n\n- 当类型不为引用时，auto 的推导结果将不保留表达式的 const 属性\n- 当类型为引用时，auto 的推导结果将保留表达式的 const 属性\n\n## decltype\n\ndecltype 和 auto 功能相同，但 auto 有些无法做到的 decltype 可以完成。\n\n```c++\ndecltype(exp) varname = value;\n```\n\nauto 会根据 value 推断类型，当时decltype 根据 exp 表达式（变量、字面量、带有运算符的表达式）推导出变量的类型，跟 = 右边的 value 没有关系。\n\n当程序员使用 decltype(exp) 获取类型时，编译器将根据以下三条规则得出结果：\n\n- 如果 exp 是一个不被括号( )包围的表达式，或者是一个类成员访问表达式，或者是一个单独的变量，那么decltype(exp) 的类型就和 exp 一致，这是最普遍最常见的情况\n- 如果 exp 是函数调用，那么 decltype(exp) 的类型就和函数返回值的类型一致\n- 如果 exp 是一个左值，或者被括号( )包围，那么 decltype(exp) 的类型就是 exp 的引用；假设 exp 的类型为 T，那么 decltype(exp) 的类型就是 T&\n\n## auto和decltype的区别\n\n### 类型推导的时机和方式\n\nauto:\n\n- auto 在变量声明和初始化时，根据初始化表达式推导变量的类型。\n- auto 只能用于变量声明，并且必须在声明时进行初始化。\n- 如果表达式是一个引用或 const，auto 会去掉引用性和 const 修饰符（除非明确指定 auto& 或 const auto&）。\n\n```c++\ncppCopy codeint x = 10;\nconst int& ref = x;\n\nauto a = ref;  // a 的类型是 int，引用和 const 被去掉\nauto& b = ref; // b 的类型是 const int&，保持引用和 const\n```\n\ndecltype:\n\n- decltype 在编译时根据表达式的形式推导类型，表达式本身并不一定需要被执行。\n- decltype 不要求表达式初始化，并且可以用于任何有效的表达式。\n- decltype 会保留表达式的原始类型，包括引用性和 const 修饰符。\n\n```c++\ncppCopy codeint x = 10;\nconst int& ref = x;\n\ndecltype(x) a;      // a 的类型是 int\ndecltype(ref) b = x;  // b 的类型是 const int&\n```\n\n### 用途\n\nauto:\n\n- 用于推导变量的类型，简化代码。\n- 经常用于遍历容器、返回值复杂的函数调用、lambda 表达式等。\n\n```c++\ncppCopy codestd::vector<int> vec = {1, 2, 3};\nauto it = vec.begin();  // it 的类型是 std::vector<int>::iterator\n```\n\ndecltype:\n\n- 用于获取表达式的类型，而不是直接声明变量。它可以用于推导函数的返回类型，或者声明与另一个变量具有相同类型的新变量。\n- decltype 常用于模板编程、函数返回类型推导，以及需要精确获取类型的场合。\n\n```c++\ncppCopy codeint x = 10;\ndecltype(x) y = 20;  // y 的类型是 int\n```\n\n### 类型推到的结果\n\nauto:\n\n- auto 的推导结果通常是值类型，除非显式使用引用或指针。\n- 对于引用类型，auto 会去掉引用和 const 修饰符（除非使用 auto& 或 const auto&）。\n\n```c++\ncppCopy codeconst int x = 10;\nauto y = x;  // y 的类型是 int，不是 const int\n```\n\ndecltype:\n\n- decltype 会精确获取表达式的类型，包括引用性和 const 性质。\n- 可以区分左值引用、右值引用等不同情况。\n\n```c++\ncppCopy codeint x = 10;\ndecltype(x) a;    // a 是 int 类型\ndecltype((x)) b = x;  // b 是 int& 类型，因为 (x) 是一个左值表达式\n```","tags":["C++11新特性"],"categories":["technology"]},{"title":"thread库","url":"/2024/08/16/thread库/","content":"\n<!-- toc -->\n\n## 条件变量的正确使用方法\n\n这里只介绍 wait，至于其他如 wait_for和 wait_until 自己查阅即可，无外乎增加一些新的功能而已。wait 提供两种方式：无条件等待和有条件等待\n\n```c++\nvoid wait (unique_lock<mutex>& lck);\t// 无条件等待\n\ntemplate <class Predicate> void wait (unique_lock<mutex>& lck, Predicate pred);\t// 有条件等待\n```\n\n无条件等待只有在唤醒的情况下才会解除阻塞，否则一直阻塞。阻塞期间释放锁（即不占有锁），被唤醒就会重新获取锁，解除阻塞往下执行。\n\n有条件等待在阻塞前会判断谓词 pred，如果为 true 就不会阻塞，如果为false 就会阻塞。当条件变量被通知时，线程会尝试重新获取锁，然后再次评估谓词。如果谓词返回 `true`，线程继续执行；否则，它会再次阻塞。\n\n总的来说无条件等待一上来就会阻塞，直到被唤醒，唤醒就会立即解除阻塞。有条件等待不会立即阻塞，而是先判断谓词情况。也可以说不会立即解除阻塞，要先判断谓词情况。如果为 true 就不阻塞而往下执行，否则就会阻塞。直到下一次被唤醒，再次检测谓词情况，如果为 true 就不阻塞而往下执行，否则就会阻塞。如此反复。\n\n```c++\nwhile(!condition){\n    g_cnd.wait(g_mtx);\n}\n// 等价于 有条件等待\n```\n\n通常条件变量被唤醒，需要配合一个判断条件。当这个条件不满足时，线程应该会再次阻塞。如果条件满足则不会阻塞。\n\n为了对这段描述有清晰的认识，还是有必要看看如果不这么做会有什么不恰当的现象。\n\n```c++\n#include <iostream>\n#include <thread>\n#include <condition_variable>\n#include <mutex>\n\nusing namespace std;\n\ncondition_variable cond_;\nmutex mtx_;\nint share = 0;\n\nvoid func(){\n  std::cout<<\"--start--\"<<std::endl;\n  unique_lock<mutex> um(mtx_);\n  cond_.wait(um);\n  std::cout<<\"share = \"<<share<<std::endl;\n  std::cout<<\"--end--\"<<std::endl;\n}\n\nint main() {\n\n  thread t1(func);\n\n  while (true){\n    lock_guard<mutex> mtt(mtx_);\n    share++;\n    if (share == 18){\n      std::cout<<\"notify\"<<std::endl;\n      cond_.notify_all();\n      break;\n    }\n  }\n  \n  t1.join();\n  return 0;\n}\n```\n\n创建一个线程 t1 并执行线程函数 func，等待被外部线程唤醒并输出 share 的值。主线程中循环 自增share，如果share 等于 18 就唤醒其它线程。执行该程序情况如下：\n\n![条件变量1.png](/images/2024/08/16/0109d110-5b95-11ef-922f-4335b82b6d11.png)\n\n线程中还没有执行 wait 等待被唤醒，主线程这边已经满足 share 等于 18 的条件就执行唤醒操作，我们的线程 t1 就错过被唤醒的机会了，所以会一直阻塞。因为代码中 t1.join 代表 等待线程 t1 结束，否则阻塞。\n\n修改代码（while循环前面添加 sleep(3) 休眠三秒），让主线程必然在子线程 t1 执行到 wait 阻塞操作后 才执行 share 的自加操作并唤醒。\n\n![条件变量2.png](/images/2024/08/16/06806ff0-5b95-11ef-922f-4335b82b6d11.png)\n\n尽管已经解决这个问题，但是这种处理方式相当愚蠢，因为不可能在我们的代码中随意加入 sleep 这样的睡眠函数，如何设置恰当的时间？这个地方如果频繁执行，效率影响是否严重？最恰当的还是能够在合适的时候通知并必然能够接受到通知。\n\n这就是前面所讲通常条件变量被唤醒，需要配合一个判断条件。\n\n```c++\ncondition_variable cond_;\nmutex mtx_;\nbool isSuccess = false; // 让 条件变量合理地被正常唤醒\nint share = 0;\n\nvoid func(){\n  std::cout<<\"--start--\"<<std::endl;\n  unique_lock<mutex> um(mtx_);\n  cond_.wait(um,[](){\t\t\t// 添加等待条件\n    return isSuccess;\n  });\n  std::cout<<\"share = \"<<share<<std::endl;\n  std::cout<<\"--end--\"<<std::endl;\n}\n\nint main() {\n\n  thread t1(func);\n\n  while (true){\n    lock_guard<mutex> mtt(mtx_);\n    share++;\n    if (share == 18){\n      std::cout<<\"notify\"<<std::endl;\n      isSuccess = true;\t\t\t// 表明 share 满足要求\n      cond_.notify_all();\n      break;\n    }\n  }\n\n  t1.join();\n  return 0;\n}\n```\n\n先看现象是否合理：\n\n![条件变量3.png](/images/2024/08/16/0f43c8d0-5b95-11ef-922f-4335b82b6d11.png)\n\n我们有 t1.join 操作保证主线程不会先于子线程退出，所以子线程有**可能**会接收到主线程的唤醒。但如果我们继续添加一个变量来让 子线程中的 wait 操作不断检测 条件是否满足（isSuccess 是否为 true），并且主线程唤醒之前 提前把 isSuccess 设置为true 再进行唤醒。哪怕最后这个唤醒失效，也必然能保证线程 1 能正常获取 share 的值并安全退出。因为你从图中可以看到 主线程提前唤醒，我的子线程都还没有准备好，即子线程还没有执行到 wait 阻塞等待。可即便如此，由于在唤醒之前，isSuccess必然已经被 设置为 true。等到子线程真的执行到 wait 阻塞等待时，发现 阻塞条件居然已经满足（isSuccess 检测到为true），子线程就知道主线程已经通知过，只不过这边没有收到而已，share明显已经可以被获取（因为子线程希望share = 18的时候被接收）。\n\n到这个时候我们终于弄明白，条件变量被唤醒，需要配合一个判断条件（往往是bool值）是为了避免唤醒被错过而加的一层保护机制。\n\n最后有个条件变量中的虚假唤醒没有讲，这已经在我的另一篇文章中讨论，感兴趣的可以去阅读：[多线程中的虚假唤醒](https://xiaoyangst.github.io/post/duo-xian-cheng-zhong-de-xu-jia-huan-xing/)\n\n结合前面的讨论和另一篇虚假唤醒的讨论，我们对使用条件变量的人提出如下要求，即你必须谨记下面的这两句：\n\n- 判断条件是否满足使用while，不可以用if\n- 务必添加变量来保证等待线程不会错过其他线程发送的唤醒信号\n\n## 锁的选择\n\nC++11提供四种语义的互斥量：独占互斥量`std::mutex`，带超时的独占互斥量`std::timed_mutex`，递归互斥量`std::recursive_mutex`，带超时的递归互斥量`std::recursive_timed_mutex`。应该优先选择std::mutex，因为它满足我们所有的需要使用互斥的场景。\n\n对于 mutex 的关键两个操作是 lock 和 unlock，将需要保护的临界区用这两个方法包裹即可。C++11为了方便锁的使用，提供 std::lock_guard 和 unique_lock 给我们使用：\n\n`std::lock_guard`：只是对操作系统锁的API进行RAII的封装，构造时获得锁（加锁），析构时释放锁（解锁），并不提供额外的方法，也不提供 lock 和 unlock 方法。\n\n`unique_lock`：它除了对操作系统锁的API进行RAII的封装，还提供手动控制锁的方法，即 lock 和 unlock 方法。并且提供给多的 lock 策略，比如 try_lock，try_lock_until等。\n\n## 生产者-消费者队列\n\n### 生产者-消费者队列简介\n\n它是实现线程间协作，交互的一种重要手段。从一端放数据（生产者），从另一端取数据（消费者）。生产者和消费者可以有一个或多个。\n\n![生产者消费者队列.png](/images/2024/08/16/16a8ca30-5b95-11ef-922f-4335b82b6d11.png)\n\n- 队列作为临界区需要被保护，消费者与生产者间要互斥\n- 当有多个生产者或多个消费者时，生产者之间，消费者之间需要互斥\n- 生产者在队列满的时候，不能再往队列中放入数据\n- 消费者在队列空的时候，不能再从队列中取数据\n\n在用途这个方向的划分，对于队列的实现，没有太大区别。只是队列中放的数据类型不一样。一种是业务的数据，一种是可调用的对象。但是有界队列和无界队列恰恰相反，在队列的实现方式上是有很大的不同，也是后面会用代码实现的内容。\n\n（一）按用途将队列分为两类\n\n**数据分发的队列**\n\n队列中存放的业务数据，可以有一个或多个生产者，消费者线程。生产者线程产生不同类型的数据，通过队列分发给不同消费者线程。\n\n**任务队列**\n\n队列中存放的是可调用对象，可以有一个或多个生产者，消费者线程\n\n- 在调用**要求时序**的情况下，应该只有一个生产者和一个消费者线程，一个队列。时序的要求由队列的先进先出的特性保证\n- 在调用**不要求时序**的情况下，则可以有多个生产者，消费者线程\n\n通过任务队列，来实现异步调用。**发起业务操作的线程不会被阻塞，业务执行函数被放到另外一个线程执行**，比如释放过程耗时高的资源且释放操作不能并发进行时。可以将释放操作专门放到一个线程中去做，此时可以有多个生产者线程，一个消费者线程，生产者将需要释放的资源对象放入队列，消费者线程依次取出后进行释放操作。此时就需要队列来实现异步操作。\n\n（二）根据队列的容量划分\n\n**有界队列**\n\n容量有大小限制，当满了后，生产者线程需要等待，为空的时候，消费者线程需要等待。这种队列可以用于数据分发的场景，但不能用于异步调用(异步调用的特性是生产者调用能马上返回，所以如果生产者阻塞在等待容器空闲显然是不满足要求的)。\n\n**无界队列**\n\n容量大小无限制，生产者线程可以一直放数据，队列为空的时候，消费者线程需要等待。这种队列即可以用于数据分发，也可以用于异步操作。这种情况下，消费者线程数量要大于生产者线程，是让数据或任务及时被处理，避免堆积。\n\n### 生产者-消费者队列（有界队列）\n\n```c++\ntemplate<class T>\nclass BoundQueue {\n private:\n  int maxSize_{1024}; // 最大容量\n  int size{0};  // 当前队列容量\n  mutex mutex_;\n  condition_variable full_;     // 每次生产每次唤醒消费者\n  condition_variable empty_;    // 每次消费每次唤醒生产者\n  queue<T> boundQueue_;\n\n public:\n  explicit BoundQueue(int maxSize) : maxSize_(maxSize) {}\n  ~BoundQueue() = default;\n\n  T get() { // 消费\n    unique_lock<mutex> um(mutex_);\n    full_.wait(um, [this](){\n      return !isEmpty();\n    });\n    T re = boundQueue_.front();\n    boundQueue_.pop();\n    size--;\n    empty_.notify_all();\n    return re;\n  }\n\n  void post(const T &data) {  // 生产\n    unique_lock<mutex> um(mutex_);\n    empty_.wait(um, [this](){\n      return !isFull();\n    });\n    boundQueue_.push(data);\n    size++;\n    full_.notify_all();\n  }\n\n private:\n  bool isEmpty(){\n    return boundQueue_.empty();\n  }\n\n  bool isFull(){\n    return size >= maxSize_;\n  }\n};\n```\n\n### 生产者-消费者队列（无界队列）\n\n```c++\ntemplate<class T>\nclass UnBoundQueue{\n private:\n  mutex mutex_;\n  condition_variable full_;     // 每次生产每次唤醒消费者\n  queue<T> unboundQueue_;\n public:\n  explicit UnBoundQueue() {};\n  ~UnBoundQueue() = default;\n  T get() { // 消费\n    unique_lock<mutex> um(mutex_);\n    full_.wait(um, [this](){\n      return !isEmpty();\n    });\n    T re = unboundQueue_.front();\n    unboundQueue_.pop();\n    return re;\n  }\n\n  void post(const T &data) {  // 生产\n    {\n      lock_guard<mutex> lock_guard(mutex_);\n      unboundQueue_.push(data);\n    }\n\n    full_.notify_all();\n  }\n private:\n  bool isEmpty(){\n    return unboundQueue_.empty();\n  }\n};\n```\n\n## 异步操作\n\n### future 与 promise\n\n它提供了一种机制可以获取异步操作的结果，因为一个异步操作的结果不能马上获取，只能在未来某个时候从某个地方获取。这个异步操作的结果是一个未来的期待值，所有称为 future，可以称它为未来量。\n\nstd::future 通常结合 std::promise，std::package_task，std::async使用。因为 future 本身只是用来存储某个结果，所以实际代码的执行还是需要借助其它函数。获取 future  存储结果的方法是 get()，并且只能获取一次，再次获取会异常。\n\n```c++\n//std::future 是一个类模板，模板参数需要传入一个类型\ntemplate <class T>\nfuture;template <class R&> future<R&>;\n```\n\nstd::promise 是一个协助线程赋值的类，它能够将数据和 future 对象绑定起来，为获取线程函数中的某个值提供便利。std::future 通常结合 std::promise 就相当于给线程间**建立一个通道**，分为以下几步：\n\n1. 在主线程中创建一个 std::promise 对象，promise<int> count_value\n2. 将 count_value 传给线程 t1\n3. 线程 t1 使用 std::promise 对象 count_value 的 get_future 方法获得一个 std::future对象，因为前面说过 std::future对象 可以存储异步操作的结果。截止到这个时候，通道已经建立，就可以使用通道了\n4. 在主线程中调用调用std::promise 对象 count_value 的 get 方法，如果 count_value 没有被设置只，主线程就会一直阻塞\n5. 在子线程中调用 set_value 方法给 count_value 设置一个值\n\n```c++\n#include <iostream>\n#include <future>\n\nusing namespace std;\n\nvoid thr_func(int num,promise<int> &p){\n    int count = 0;\n    for (int i = 0; i < num; ++i) {\n        count += i;\n    }\n    p.set_value(count);\t//将需要的结果存储起来\n}\n\nint main(){\n\n    promise<int> count_value;\n\n    thread t1(thr_func,10, ref(count_value));\n    \n    \n    t1.join();\n\n    cout<<\"0~10之间数字的总和：\"<<count_value.get_future().get()<<endl;\t//获取返回值\n\n    return 0;\n}\n```\n\n### future 与 package_task\n\n`packaged_task` 包装了一个可调用对象，并允许其结果以异步方式获取。它类似于 `std::function`，但会将结果**自动传递**给一个 `future` 对象。它的内部包含两个元素：\n\n1. 存储的任务（用户传递），这是某种可调用对象（如函数指针、成员函数指针或函数对象）\n2. 共享状态（自动传递），能够存储调用存储任务的结果（类型为 `Ret`），并通过 `future` 异步访问\n\n通过调用成员函数 `get_future`，共享状态与 `future` 对象关联。调用后，这两个对象共享相同的共享状态。\n\n比方说下面的代码中，先把普通函数 thr_func 包装成 packaged_task 类型的对象（返回值类型和参数列表要一直） task，最终的得到的这个 task 需要通过**引用的方式传递到子线程内部**，这样才能在主线程的最后通过任务对象的 get_future 方法得到 future 对象，打包的 task 代码中 return 的返回值就存储在 future 对象里。前面我们讲过 future 对象 获取存储结果的方式就是 get 方法。\n\n```c++\n#include <iostream>\n#include <future>\n\nusing namespace std;\n\nint thr_func(int num){      //  普通函数\n    int count = 0;\n    for (int i = 0; i < num; ++i) {\n        count += i;\n    }\n    return count;\n}\n\nint main(){\n\n    packaged_task<int(int)> task(thr_func);     //将函数thr_func 打包为 task函数\n\n    future<int> result = task.get_future();     //返回值存储在future中\n\n    thread t1(ref(task),10);        //将打包的函数task传递进去，包括这个函数所需要的参数\n\n    t1.join();\n\n    cout<<\"0~10之间数字的总和：\"<<result.get()<<endl;       //拿到返回值\n\n    return 0;\n}\n```\n\n### future 与 async\n\n可以直接启动一个子线程并在这个子线程中执行对应的任务函数，异步任务执行完成返回的结果也是存储到一个future对象中。也就是说调用 async 的返回值是一个 future 对象，里面存储返回值。这么看要比 package_task 方便很多，因为不需要取打包可调用对象，直接传递进去即可。\n\n```c++\ntemplate< class Function, class... Args>\nstd::future<std::result_of_t<std::decay_t<Function>(std::decay_t<Args>...)>>\n    async( Function&& f, Args&&... args );\n\n\ntemplate< class Function, class... Args >\nstd::future<std::result_of_t<std::decay_t<Function>(std::decay_t<Args>...)>>\n    async( std::launch policy, Function&& f, Args&&... args );\n```\n\n函数参数:\n\n- f：可调用对象，这个对象在子线程中被作为任务函数使用\n- Args：传递给 f 的参数（实参）\n- policy：可调用对象f的执行策略（std::launch::async 创建新线程启动函数，std::launch::deferred 在主线程中启动函数）\n\n```c++\n#include <iostream>\n#include <future>\n\nusing namespace std;\n\nint thr_func(int num){      //  普通函数\n    int count = 0;\n    for (int i = 0; i < num; ++i) {\n        count += i;\n    }\n    return count;\n}\n\nint main(){\n\n\n    future<int> result = async(launch::async,thr_func,10);      //自动创建线程，并返回thr_func的返回值\n\n    cout<<\"0~10之间数字的总和：\"<<result.get()<<endl;       //拿到返回值\n\n    return 0;\n}\n```\n\n### future 与 shared_future\n\n`std::funture` 只支持移动语义，它要求类型参数也支持移动语义。它的get方法只能调用 1 次，调用get相当于将结果移走(移动语义的通俗意义)。再次调用会抛异常。\n\n`std:shared_future` 可以共享结果，可以多次调用get方法，它要求类型参数支持复制语义。\n\n### 总结\n\n1. future 是异步函数存储结果的所在\n2. promise 异步函数相当于创建一个变量给到线程，然后在线程中把值存储到变量中之后，主线程再进行获取\n3. packaged_task 异步函数对函数进行封装，这样线程函数可以有 return 返回值，不像 promise 是将在线程函数中把值存储起来，但是 packaged_task 却可以有 return 返回值\n4. async 异步函数更加高级，前面需要的两个线程函数需要创建子线程，但是它自动创建并且返回传递可调用对象的返回值\n\nfuture 存储结果，其它三个异步函数中 async 要更灵活且简单，能够真正做到异步（可以自启动一个线程去执行函数）","tags":["C++11新特性"],"categories":["technology"]},{"title":"chrono库","url":"/2024/08/16/chrono库/","content":"\n<!-- toc -->\n\n> 之前浅学这块内容，C++11封装的如此冗长，于是“重学”加深影响，方便后续查阅\n\n在`std::chrono`命名空间下定义。\n\nC语言虽然也有时间处理方法，但是精度只到秒。Linux 和 Windows 都有提供相应的方法精确到微秒，但是用法不同，显然不支持跨平台。**chrono 库精度更高，同时支持跨平台**，因此C++11之后使用chrono 库处理时间和日期是有必要的，至于到后面的C++版本是否会继续加强，那是以后的事情。\n\n对于时间、日期的处理，它引入了三个基本概念：\n\n- 时间（时钟）：时间点的同上概念，包含时间点、时间间隔、日期\n- 时间间隔（时间段）：两个时间点的差值\n- 时间点：比如 12:05:00 表示一个时间点，比如 2021-01-01 13:00:00 也表示一个时间点\n\n![时间库.png](/images/2024/08/16/cdf3a940-5b94-11ef-922f-4335b82b6d11.png)\n\n## 时间段duration\n\n```c++\ntemplate <class Rep, class Period = ratio<1> >\nclass duration;\n\nRep: 表示时间的数量（例如，整数或浮点数）\nPeriod: 表示时间单位（例如，秒、毫秒、微秒等）\n```\n\n提供 count方法 获得计数值，还能进行运算符运算（加减乘除）\n\n```c++\n#include <iostream>\n#include <chrono>\n\nint main() {\n    using namespace std::chrono;\n    \n    // 创建两个时间段\n    seconds five_seconds(5);\n    seconds three_seconds(3);\n    \n    // 加法运算\n    seconds total = five_seconds + three_seconds;\n    \n    // 减法运算\n    seconds difference = five_seconds - three_seconds;\n    \n    // 乘法运算\n    seconds double_time = five_seconds * 2;\n    \n    // 除法运算\n    seconds half_time = five_seconds / 2;\n    \n    std::cout << \"Total time: \" << total.count() << \" seconds\" << std::endl;\n    std::cout << \"Difference in time: \" << difference.count() << \" seconds\" << std::endl;\n    std::cout << \"Double time: \" << double_time.count() << \" seconds\" << std::endl;\n    std::cout << \"Half time: \" << half_time.count() << \" seconds\" << std::endl;\n\n    return 0;\n}\n\n/*\n\nTotal time: 8 seconds\nDifference in time: 2 seconds\nDouble time: 10 seconds\nHalf time: 2 seconds\n\n*/\n```\n\n时间段可以应用于 wait_until 这种等到某个时间段的语句，下面介绍的时间点可以应用于 wait_for 这种等到某个时间点的语句\n\n## 时间点time_point\n\n用于表示时间点的类模板，和下面要介绍的clocks结合使用\n\n创建对象不填写参数，代表构造一个以纪元为值的对象\n\n```c++\n#include <iostream>\n#include <chrono>\n\nint main(){\n\n  std::chrono::system_clock::time_point time_point1;\n  time_t  tt1 = std::chrono::system_clock::to_time_t(time_point1);\n  std::cout<<ctime(&tt1);\n\n  return 0;\n}\n\n/*\n\tThu Jan  1 08:00:00 1970\n*/\n```\n\n有两个成员方法：min和max代表time_point的最小值和最大值\n\n测试最小值为空，最大值为Sat Apr 12 07:47:16 2262\n\n前面介绍无参构造函数，还有两个构造函数没有介绍\n\n```c++\n// 使用一个时间段 d 来初始化时间点，从时钟的时间零点开始计算\nexplicit time_point(const duration& d);\n\n/*\n\n    // 创建一个时间段\n    std::chrono::seconds duration(10);\n    \n    // 使用时间段构造 time_point\n    std::chrono::system_clock::time_point tp_with_duration(duration);\n    \n    auto duration_since_epoch = tp_with_duration.time_since_epoch();\n    \n    std::cout << \"Constructed time_point with duration: \"\n              << duration_since_epoch.count() << \" seconds since epoch\\n\";\n             \n     输出结果：\n     Constructed time_point with duration: 10000000000 seconds since epoch\n\n*/\n\n```\n\n```c++\n// 使用另一个时间点来拷贝构造新的时间点\ntime_point(const time_point& other) = default;\n\n/*\n\n    // 获取当前时间点\n    std::chrono::system_clock::time_point tp_now = std::chrono::system_clock::now();\n    \n    // 使用拷贝构造函数\n    std::chrono::system_clock::time_point tp_copy(tp_now);\n    \n    auto duration_since_epoch_now = tp_now.time_since_epoch();\n    auto duration_since_epoch_copy = tp_copy.time_since_epoch();\n    \n    std::cout << \"Original time_point: \"\n              << duration_since_epoch_now.count() << \" ticks since epoch\\n\";\n    std::cout << \"Copied time_point: \"\n              << duration_since_epoch_copy.count() << \" ticks since epoch\\n\";\n              \n     输出结果：\n     Original time_point: 1719716264027922800 ticks since epoch\n     Copied time_point: 1719716264027922800 ticks since epoch\n*/\n```\n\n## 系统时钟clocks\n\n（一）std::chrono::system_clock\n\nnow：可以用于获取当前时间\n\nto_time_t：转换为 time_t \n\nfrom_time_t：从time_t 转换\n\n```c++\n#include <iostream>\n#include <chrono>\n\nint main(){\n\n  std::chrono::system_clock::time_point curTime = std::chrono::system_clock::now(); // 获取当前时间\n  time_t showTime = std::chrono::system_clock::to_time_t(curTime);  // 转换为 time_t 类型\n  std::cout<<\"当前时间: \"<<std::ctime(&showTime)<<std::endl;\n\n  return 0;\n}\n\n/*\n\t当前时间: Sun Jun 30 10:29:03 2024\n*/\n```\n\ntime_t 类型是C语言的时间类型，这就是实现C++和C语言时间类型的转换的\n\n（二）std::chrono::steady_clock\n\n不会被系统时间的调整所影响，且它的滴答频率是稳定的，适合用于**测量时间间隔**\n\n只提供 now方法用于获取当前时间，测量时间间隔只需要调用两次now方法求差即可\n\n（三）std::chrono::high_resolution_clock\n\n提供了最高可能的时间分辨率。通常，它是 `system_clock` 或 `steady_clock` 的别名，但具体实现依赖于系统和标准库实现\n\n同样只提供 now 方法用于获取当前时间\n\n---\n\n看来，测试时间间隔采用std::chrono::steady_clock（稳定，不受系统时间影响，因为原点是计算机启动的时刻），希望将时间转换为日历显示效果或者转换为C语言风格的时间类当采用std::chrono::system_clock（不稳定，如果被恶意修改系统时间，这里跟着受影响，通过 is_steady 判断是否稳定）\n\n##  表示不同的时间单位\n\n通过在构造函数中传递值，表示不同的时间类型，比方说你在 hours(1)代表一个小时，seconds(1)代表一秒\n\n`std::chrono::hours`：表示小时的持续时间\n\n`std::chrono::minutes`：表示分钟的持续时间\n\n`std::chrono::seconds`：表示秒的持续时间\n\n`std::chrono::milliseconds`：表示毫秒的持续时间\n\n`std::chrono::microseconds`：表示微秒的持续时间\n\n`std::chrono::nanoseconds`：表示纳秒的持续时间\n\n## 转换为duration或time_point\n\n（一）duration_cast\n\n用于将时间段从一种单位转换为另一种单位\n\n```c++\ntemplate <class ToDuration, class Rep, class Period>\nconstexpr ToDuration duration_cast(const duration<Rep, Period>& d);\n```\n\n把 秒 转换为 分钟，把 秒 转换为毫秒 \n\n```c++\n#include <iostream>\n#include <chrono>\n\nint main() {\n    std::chrono::seconds sec(120); // 120 seconds\n\n    // 将秒转换为分钟\n    std::chrono::minutes min = std::chrono::duration_cast<std::chrono::minutes>(sec);\n    std::cout << sec.count() << \" seconds is \" << min.count() << \" minutes.\" << std::endl;\n\n    // 将秒转换为毫秒\n    std::chrono::milliseconds millisec = std::chrono::duration_cast<std::chrono::milliseconds>(sec);\n    std::cout << sec.count() << \" seconds is \" << millisec.count() << \" milliseconds.\" << std::endl;\n\n    return 0;\n}\n```\n\n（二）time_point_cast\n\n用于将时间点从一种单位转换为另一种单位\n\n```c++\ntemplate <class ToDuration, class Clock, class Duration>\nconstexpr time_point<Clock, ToDuration> time_point_cast(const time_point<Clock, Duration>& tp);\n```\n\n将当前时间点 转换为 毫秒精度，将当前时间点转换为秒精度\n\n```c++\n#include <iostream>\n#include <chrono>\n\nint main() {\n    auto now = std::chrono::system_clock::now(); // 获取当前时间点\n\n    // 将当前时间点转换为毫秒精度\n    auto now_ms = std::chrono::time_point_cast<std::chrono::milliseconds>(now);\n    auto epoch = now_ms.time_since_epoch();\n    auto value = std::chrono::duration_cast<std::chrono::milliseconds>(epoch);\n\n    std::cout << \"Current time in milliseconds since epoch: \" << value.count() << \"ms\" << std::endl;\n\n    // 将当前时间点转换为秒精度\n    auto now_sec = std::chrono::time_point_cast<std::chrono::seconds>(now);\n    epoch = now_sec.time_since_epoch();\n    auto value_sec = std::chrono::duration_cast<std::chrono::seconds>(epoch);\n\n    std::cout << \"Current time in seconds since epoch: \" << value_sec.count() << \"s\" << std::endl;\n\n    return 0;\n}\n```","tags":["C++11新特性"],"categories":["technology"]},{"title":"移动语义","url":"/2024/08/16/移动语义/","content":"\n<!-- toc -->\n\n## 复制语义和移动语义\n\nC++11 之前只有复制（拷贝）语义，定义了**析构函数，复制构造函数，赋值函数**就称为有了拷贝控制。对对象的非指针，非引用的行为都会使用复制语义。在拥有内存资源对象中，都会定义这三个函数以实现**深拷贝**。\n\n复制语义不会销毁用来复制的对象，同时还得到一个和其一模一样的对象。但是在某些场景中，我们希望对象拷贝后立即被销毁，这种情况我们就是移动语义，即只是移动而非拷贝对象以大幅度提升性能。\n\n![copymove.png](/images/2024/08/16/94175820-5b94-11ef-922f-4335b82b6d11.png)\n\n我们的重点还是集中在移动语义上，谈及复制语义是为了更清楚地知道移动语义出现的意义。移动语义就是从给定对象“窃取”资源而不是拷贝资源，源对象不再拥有资源，资源的所有权已经归属于新创建的对象。那么实现移动语义有哪些要求呢？\n\n1. 移动语义可以将一个对象中的资源移走，而不是赋值，所以它们**并不分配内存**\n2. 移动后的源对象会被销毁（形参是右值引用），所以内部资源会被置为无效（比如指针会被置为 nullptr ）\n3. 它们都需要声明为noexcept（不能抛异常）\n\n如果需要移动语义，建议自己定义，不要编译器合成。因为编译器会优先考虑使用复制语义，而不是移动语义，除非对象明确的定义了移动语义。\n\n## 代码实现复制语义和移动语义\n\n复制语义：拷贝构造函数，拷贝赋值函数\n\n移动语义：移动构造函数，移动赋值函数\n\n```c++\n#include <iostream>\n#include <cstring>\n\nclass MyString {\n private:\n  char* str_;\n  int size_;\n public:\n  MyString(char* str, int size) : size_(size) {\n    str_ = new char[size_ + 1]; // 分配内存，并加1用于终止符\n    std::memset(str_, 0, size_ + 1); // 使用size_ + 1，确保包含终止符\n    std::strncpy(str_, str, size_);\n    str_[size_] = '\\0'; // 确保字符串以终止符结束\n  }\n\n  ~MyString() {\n    delete[] str_;\n  }\n\n  // 拷贝构造函数\n  MyString(const MyString& other) : size_(other.size_) {\n    std::cout << \"拷贝（复制）构造函数\" << std::endl;\n    str_ = new char[size_ + 1];\n    std::memset(str_, 0, size_ + 1);\n    std::strncpy(str_, other.str_, size_);\n    str_[size_] = '\\0';\n  }\n\n  // 拷贝赋值操作符\n  MyString& operator=(const MyString& other) {\n    std::cout << \"拷贝（复制）赋值函数\" << std::endl;\n    if (this != &other) {\n      delete[] str_;\n      size_ = other.size_;\n      str_ = new char[size_ + 1];\n      std::memset(str_, 0, size_ + 1);\n      std::strncpy(str_, other.str_, size_);\n      str_[size_] = '\\0';\n    }\n    return *this;\n  }\n\n  // 移动构造函数\n  MyString(MyString&& other) noexcept : str_(other.str_), size_(other.size_) {\n    std::cout << \"移动构造函数\" << std::endl;\n    other.str_ = nullptr;\n    other.size_ = 0;\n  }\n\n  // 移动赋值操作符\n  MyString& operator=(MyString&& other) noexcept {\n    std::cout << \"移动赋值函数\" << std::endl;\n    if (this != &other) {\n      delete[] str_;\n      str_ = other.str_;\n      size_ = other.size_;\n      other.str_ = nullptr;\n      other.size_ = 0;\n    }\n    return *this;\n  }\n};\n```\n\n这些代码实现并不难，只有弄清楚实际的语义就好，说明如下：\n\n- 构造函数是没有返回值的，不管是哪种构造函数（普通构造函数，拷贝构造函数和移动构造函数）\n- 赋值函数 就是对赋值运算符 = 的重载\n- 赋值操作要考虑不能自我赋值的情况，所以要判断是否为自我赋值，false 的情况下再进行赋值操作，true 的情况下直接返回 当前对象即可\n- 移动语义（移动构造函数和移动赋值函数）下需要移动的对象必须是右值引用\n- 类中的成员变量需要分配内存的务必分配内存之后再进行操作\n- 复制语义只是把传递进来的对象中的成员变量拷贝到当前对象中，并不会销毁对象，代码中仅涉及拷贝操作。移动语义需要把传递进来的对象中的成员变量拷贝到当前对象中，同时需要销毁传递进来的对象，代码中不仅涉及拷贝操作，还涉及清理内存操作（传递进来的对象）\n- 复制语义每次都为当前对象分配内存，然后把传递进来的对象拷贝到当前对象。移动语义是把一个对象的资源移交给另一个对象，无需为当前对象分配内存，所以移动语义发生在两个已经存在的对象之间。\n\n测试代码：\n\n```c++\nint main() {\n  // 测试构造函数\n  char text[] = \"Hello, World!\";\n  MyString str1(text, strlen(text));\n\n  // 测试拷贝构造函数\n  MyString str2 = str1;\n\n  // 测试拷贝赋值操作符\n  MyString str3(text, strlen(text));\n  str3 = str1;\n\n  // 测试移动构造函数\n  MyString str4 = std::move(str1);\n\n  // 测试移动赋值操作符\n  MyString str5(text, strlen(text));\n  str5 = std::move(str2);\n\n  return 0;\n}\n```\n\n输出结果：\n\n```tex\n拷贝（复制）构造函数\n拷贝（复制）赋值函数\n移动构造函数\n移动赋值函数\n```\n\n## move函数\n\nstd::move 的功能仅是**将左值转换成右值引用**。它本身不会产生移动操作，只是产生一个右值引用，真正的移动操作是在移动构造函数和移动赋值函数中完成的。总的来说，如果你没有实现移动语义，std::move 产生一个右值引用是无法触发移动语义的，从而去调用复制语义了。\n\n## 移动语义的合理使用\n\n似乎 移动语义带来的性能提升让我们觉得可以无处不在，实际情况也非如此：\n\n1. 编译器为自定义类型自动生成移动语义的是有要求的，必须没有声明复制操作，移动操作以及析构函数\n2. 即使在标准库中都已经支持移动操作，但是也可能不会像希望的那样带来那么大利好。这样取决于具体的实现\n   - 比如list，它的实现通常是会在堆上分配内存，将容器元素放在这个堆内存上，内部只是会维护指向堆内存的指针。那么对list的移动，只算交换指针，那么效率自然会有提升\n   - 比如array，它是C++ 11引入的新的容器类型，就是数组。它的内存就是对象内部的一个缓存区(比如是在栈上分配的一段顺序的空间)，所以对它的移动操作，还是要将元素进行复制\n\n## 补充：编译器自动生成移动操作的要求\n\n如果我们在类中没有定义拷贝操作，那么编译器会自动为我们生成默认的拷贝操作，但是对移动操作，编译器是有条件满足才会生成的：\n\n1. 类中没有自定义拷贝控制成员（拷贝构造函数、赋值操作、析构函数）\n2. 它的所有数据成员都能够移动构造或移动赋值\n\n如果需要移动语义，我们还是自己定义，免得去计较它需要的条件。\n\n## 补充：为什么用右值引用实现移动语义，而不是左值引用？\n\n在有拥有内存资源的对象中，通过复制语义(深拷贝)来转移内存，将源对象赋值给目标对象，源对象中资源很可能是不需要再保留的，这时直接将源对象中的资源转移给目标对象(浅拷贝，只移动指针)，就更贴切。但是使用左值引用来实现有两个限制:\n\n- 为了满足所有的表示移动的场景，它必须是一个构造函数，并且形参需为const &(为了能引用临时对象这样的右值)，为了与其它构造函数作区分，形参个数需不同(显然是没有这样的语法的)\n- 对 const 引用的形参，在函数中并不能改变的它\n\n引入右值引用就是来实现移动语义的，解决实现上的限制。","tags":["C++11新特性"],"categories":["technology"]},{"title":"Lambda 表达式","url":"/2024/08/16/Lambda-表达式/","content":"\n<!-- toc -->\n\n任何需要可调用对象的接口，都可以传入一个lambda表达式\n\n![lambda.png](/images/2024/08/16/5a9cfd20-5b94-11ef-922f-4335b82b6d11.png)\n\n`捕获`：捕获 lambda 表达式以外的参数，可以按值捕获（不可修改外部捕获的变量或对象）或按引用捕获（可修改外部捕获的变量或对象）\n\n`形参 和 ret`：lambda表达式又名匿名函数，函数当然可以有形参和返回值，这里的形参有类型并且支持默认参数\n\n`函数体`：函数的功能，即实际的逻辑代码\n\n一个普通函数不仅可以没有实参，也可以无需具体的返回值类型，但是必须要有函数体。lambda表达式又名匿名函数，即没有函数名的函数，形参和返回值也可以不必有，但是函数体不能丢。至于捕获也可以不进行任何捕获，但是却必须标识它的存在。\n\n1. `[]` ：不捕捉任何变量\n2. `[&]` ：按引用捕获\n3. `[=]`： 按值捕获\n4. `[=, &foo]` ： 按值捕获外部作用域中所有变量, 并按照引用捕获外部变量 foo\n5. `[bar]`： 按值捕获 bar 变量, 同时不捕获其他变量\n6. `[&bar]`： 按引用捕获 bar 变量, 同时不捕获其他变量\n7. `[this]`： 捕获当前类中的this指针\n   1. 让lambda表达式拥有和当前类成员函数同样的访问权限\n   2. 如果已经使用了 & 或者 =，默认添加此选项\n\n\n关于 lambda 表达式捕获 this 需要注意的一个问题，即操作 this对象的时候，需要确保对象没有被销毁。如下由于我们已经提前把对象 e 删除，在此之前尽管已经保存其返回的lambda，但由于这个函数操作对象的成员变量，再调用就是不合法的。\n\n```c++\n#include <iostream>\n#include <vector>\n#include <functional>\n\nclass Example {\n public:\n  Example() {}\n\n  std::function<void()> getShowLambda() {\n    // 捕获 this 指针并返回 lambda\n    return [this]() {\n      // 访问类成员\n      for (auto i : data) {\n        std::cout << i << \" \";\n      }\n      std::cout << std::endl;\n    };\n  }\n\n private:\n  std::vector<int> data = {1, 2, 3, 4};\n};\n\nint main() {\n  Example* e = new Example();\n  auto f = e->getShowLambda(); // 获取 lambda\n\n  delete e; // 销毁对象\n  e = nullptr;\n\n  f(); \n\n  return 0;\n}\n```\n\nlambda表达式是可调用对象，因此当你按照前面所讲的格式写出来之后，你有两种方式进行调用：原地调用和后续调用。\n\n```c++\n  // 原地调用\n  [](int num1,int num2) -> int {\n    return num1 + num2;\n  }(10,20);\n\n  // 后续调用\n  auto f1 =   [](int num1,int num2) -> int {\n    return num1 + num2;\n  };\n  f1(10,20);\n```","tags":["C++11新特性"],"categories":["technology"]},{"title":"function 和 bind","url":"/2024/08/16/function-和-bind/","content":"\n<!-- toc -->\n\n## 可调用对象的类型和调用形式\n\n在 C++ 中函数、函数指针、指向类的成员函数指针、函数对象（重载了调用运算符的类）、lambda 表达式都属于**可调用对象**。可调用对象都是有类型的，比方说函数对象，它本质就是一个重载了调用运算符的类，不同的类当然类型也不相同。还有函数和函数指针，它们的类型是有其返回值类型和实参类型决定，`int func(int a,int b)` 和 `void func()` 就不是同一个类型。它们对应的指针也是不同的类型，不能相互赋值。\n\n虽然它们的类型不尽相同，但是它们的调用形式却有相同之处。调用形式指明了调用返回的类型和传递给调用的实参类型。如下面的代码所示，尽管 函数 和 lambda表达式 类型不同（不能相互赋值），但是调用形式一样。\n\n```c++\n#include <iostream>\nusing namespace std;\n\nint addA(int num1,int num2){  // 函数\n  return num1 + num2;\n}\n\nauto addB = [](int num1,int num2)->int {  // lambda表达式\n  return num1 + num2;\n};\n\nint main() {\n  \n  // 调用形式一样\n  addA(1,2);\n  addB(1,2);\n\n  return 0;\n}\n```\n\n## function的用法\n\n同一种调用形式的可调用对象的类型可能不同，可以通过 function 将其**统一**起来，function 是一个模板，当创建一个具体的 function 类型时必须提供该 function 类型能够表示的对象的调用信息。\n\n```c++\nfunction<int(int,int)>\n```\n\n声明了一个 function 类型，它表示接受两个 int 实参，返回一个 int 结果的可调用对象。\n\n注：当你知道 function 是一个模板，就理解为什么外层是一对尖括号<>\n\n---\n\n既然 function 是把不同的可调用对象的类型统一起来，那就把之前的例子拿过来统一看看。\n\n```c++\n#include <iostream>\n#include <vector>\n#include <functional>\nusing namespace std;\n\nint addA(int num1,int num2){  // 函数\n  return num1 + num2;\n}\n\nauto addB = [](int num1,int num2)->int {  // lambda表达式\n  return num1 + num2;\n};\n\nint main() {\n\n  using  funCallback = function<int(int,int)>;\n\n  funCallback f1 = addA;\n  funCallback f2 = addB;\n\n  f1(1,2);\n  f2(1,2);\n  return 0;\n}\n```\n\n我们可以看到在赋值给 function 类型时，我们没有传递任何参数（实际上也不支持），而是把可调用对象的名称传递过去。还有 function 把不同的可调用对象的类型统一起来，这在上面这个例子中已经证明，即f1、f2接受不同类型的可调用对象了。\n\nfunction 类型的对象（如上面的f1、f2）只是把可调用对象存储起来，需要的时候调用，就像调用普通函数那样，传递所需的实参即可。如果声明的 function 类型的对象没有存储可调用对象，我们去执行是没有任何效果的，为了避免这种情况，可以在调用之前检查是否为空。\n\n```c++\nif(!f1){\t\n\tstd::cout<<\"f1 is nullptr\"<<std::endl;\n}\n```\n\n难道我们的 function 就没有不足吗？有个可调用对象 function 无法存储，即类成员（函数）指针。这是因为成员函数指针和普通函数指针有一些重要的区别。成员函数指针需要一个对象实例来调用，而普通函数指针不需要。\n\n```c++\nclass Test{\n public:\n  Test() = default;\n  ~Test() = default;\n  int AddC(int num1,int num2){\n    return num1 + num2;\n  }\n};\n\nint main() {\n\n  using  funCallback = function<int(int,int)>;\n  funCallback f1 = &Test::AddC;\t// 报错，这是不允许的\n\n  return 0;\n}\n```\n\n## bind的用法\n\n接受一个可调用对象，生成一个新的可调用对象来适应原对象的参数列表。即用来将可调用对象与其参数一起进行绑定，绑定后的结果可以使用 function 进行保存。\n\n使用 std::bind 绑定对象时，**会拷贝新对象，作为内部调用成员函数的对象**（非常关键，因为如果绑定的是共享智能指针就会让计数加 1 ，意识到这点可以应用到网络库中来延长连接的生命周期）。那么在回调前，如果删除了指针，会引发崩溃，这是非常需要注意的地方。\n\nbind 必须把函数所需的参数进行绑定，如果不填写默认参数进行绑定，就用占位符placeholders::_N（1、2、3...N）填充，等后续调用时再自行填写。\n\n```c++\n// 绑定非类成员函数/变量\nauto f = std::bind(可调用对象地址, 绑定的参数/占位符);\n// 绑定类成员函/变量\nauto f = std::bind(类函数/成员地址, 类实例对象地址, 绑定的参数/占位符);\n```\n\n前面讲 function的时候，讲到两个问题。首先 function 存储可调用对象，只有在实际调用的情况下才允许传递实参。其次，function 无法存储 类成员（函数）指针。这两个问题 bind 都可以解决。\n\n为什么这里通常用 auto 来推断类型？因为 bind 绑定占位符之后，类型就会发生改变，如果手动去指定会比较麻烦，看下面这个例子：\n\n```c++\nusing  funCallback = function<int(int,int)>;\nTest t1;\nfunction<int(int)> f1 = bind(&Test::AddC,t1,placeholders::_1,2);\nf1(1);\n```\n\n我们明显可以看到填写具体的参数之后，类型就从 `function<int(int,int)>` 变成 `function<int(int)>`。所以，当我们想对 function 对象的参数列表进行操作（填写默认参数，以减少后续调用所需填写的参数）可以想到用 bind来辅助。但是 bind 是不可以对 function 对象的返回值进行操作的，除非是隐式转换，比方说原 function 对象 是 int 返回值，你这边的新 function 对象返回值是 float 是可以编译通过的。\n\n```c++\nusing  funCallback = function<int(int,int)>;\nTest t1;\nfunction<float(int)> f1 = bind(&Test::AddC,t1,placeholders::_1,2);  // 返回值存在隐式转换可以编译通过\nfunction<int*(int)> f1 = bind(&Test::AddC,t1,placeholders::_1,2);   // 返回值不存在隐式转换无法编译通过\n```\n\n## 回调机制的实现\n\nfunction 可以存储任意类型的可调用对象，bind 可以将一个可调用对象转换成新的可调用对象，那么我们可以通过 bind 将一个可调用对象转换成指定的 funtcion 类型。function 和 bind 是 C++11 中实现回调机制的常用组合。\n\n从网上借鉴一句话来阐述：**回调函数是你写一个函数，让预先写好的系统来调用。你调用系统的函数，是直调。让系统调用你的函数，就是回调**。比方说网络库中，你传递一个回调函数，这个回调函数的功能是处理连接上客户端发送的消息，那么这个回调函数究竟什么时候调用并不用你管，这是由系统（网络库）来选择合适的时机进行调用的，毕竟网络库要管理很多的连接。\n\n```c++\n#include <iostream>\n#include <functional>\n#include <vector>\n\n// 定义回调类型\nusing Callback = std::function<void(int)>;\n\nclass EventSystem {\npublic:\n    // 注册回调函数\n    void registerCallback(Callback cb) {\n        callbacks.push_back(cb);\n    }\n\n    // 触发事件，调用所有注册的回调函数\n    void triggerEvent(int value) {\n        for (const auto& cb : callbacks) {\n            cb(value);\n        }\n    }\n\nprivate:\n    std::vector<Callback> callbacks;\n};\n```\n\n这个系统可以注册回调函数（即存储回调函数），还支持执行回调函数。作为用户如果想要系统执行某个功能，你只需要把功能函数（可调用对象）传递给系统即可，系统会自行安排调用时机（即调用 triggerEvent 方法）。\n\n```c++\nvoid myCallbackFunction(int value) {\n    std::cout << \"Callback function called with value: \" << value << std::endl;\n}\n\nint main() {\n    EventSystem eventSystem;\n\n    // 注册普通函数回调\n    eventSystem.registerCallback(myCallbackFunction);\n\n    // 触发事件（系统执行回调）\n    eventSystem.triggerEvent(42);\n\n    return 0;\n}\n```","tags":["C++11新特性"],"categories":["technology"]},{"title":"智能指针","url":"/2024/08/16/智能指针/","content":"\n<!-- toc -->\n\n程序员可以自由分配堆内存，而栈内存由编译器申请和释放。内存管理针对的就是堆内存，在C++11的智能指针没有出现之前，为了保证内存合理的申请释放，需要配对操作，即new和delete，malloc和free，来避免内存泄漏。\n\n![智能指针所有权.png](/images/2024/08/16/996afb20-5b93-11ef-922f-4335b82b6d11.png)\n\n## 内存管理及C++ RAII手法\n\nRAII 是 C++ 所特有的资源管理方式，它**依托栈和析构函数**，来对所有的资源(包括堆内存在内)进行管理。它提供了一种**异常安全的资源管理方式**，对RAII的使用，使C++不需要类似于 Java 那样的垃圾收集方法，也能有效的内存进行管理。\n\n```c++\ntemplate<class T>\nclass manageMemory{\n public:\n  explicit manageMemory(T *data):data_(data){\n    std::cout<<\" manageMemory \"<<std::endl;\n  }\n  ~manageMemory(){\n    std::cout<<\" ~manageMemory \"<<std::endl;\n    delete data_;\n    data_ = nullptr;\n  }\n private:\n  T* data_;\n};\n\nclass Test{\n public:\n  explicit Test(int num):num_(num){\n    std::cout<<\" Test \"<<std::endl;\n  }\n  ~Test(){\n    std::cout<<\" ~Test \"<<std::endl;\n  }\n private:\n  int num_ = 0;\n};\n\nint main() {\n\n  {\n    Test* t = new Test(10);\n    manageMemory<Test> mt(t);\n  }\n\n  system(\"pause\");\n\n  return 0;\n}\n```\n\n前面讲 RAII 这种内存管理方法是依托 栈和析构函数，从上面的代码中可以看到 manageMemory 类中的析构函数将传递进来的对象进行 delete（清理类对象的成员变量），并且明显是在 函数中完成对内存进行管理的（这里是在 main 函数中），即栈中（退出栈，清理类对象本身）。\n\n那么还提到异常安全的资源管理方式又是那里体现的呢？假定现在没有采用RAII 这种内存管理方法，而是用之前 delete 裸指针进行内存管理，看如下简略代码：\n\n```c++\nvoid func(){\n  Test* t = new Test(10);\n  \n  // 出现异常\n\n  delete t;\n}\n```\n\n按理我们也写出已申请内存对应的 delete，可如果在 delete 之前出现异常，那么内存泄漏还是出现了。但是我们的 RAII 这种内存管理方法就不会，因为内部不会出现异常。\n\n## 共享智能指针 shared_ptr\n\n| 构造函数                              | 说明                     |\n| ------------------------------------- | ------------------------ |\n| `shared_ptr()`                        | 默认构造函数，指针为空   |\n| `shared_ptr(T* ptr)`                  | 用裸指针构造，拥有对象   |\n| `shared_ptr(const shared_ptr& other)` | 拷贝构造函数，共享所有权 |\n| `shared_ptr(shared_ptr&& other)`      | 移动构造函数，转移所有权 |\n\n| 方法                      | 说明                         |\n| ------------------------- | ---------------------------- |\n| `reset()`                 | 释放当前持有对象，指针为空   |\n| `reset(T* ptr)`           | 释放当前持有对象并拥有新对象 |\n| `get()`                   | 返回原始指针（裸指针）       |\n| `use_count()`             | 返回引用计数                 |\n| `unique()`                | 判断是否是唯一所有者         |\n| `swap(shared_ptr& other)` | 交换两个 `shared_ptr` 的内容 |\n\n共享所有权，具有复制语义，多个 shared_ptr 指向同一个对象时，每个 shared_ptr 的引用计数都会记录指向该对象的 shared_ptr 的数量，当最后一个指向对象（和共享计数）的 shared_ptr 析构时，它会删除对象和共享计数，通过 use_count 方法可以获取 shared_ptr 对象的共享计数值。正以为是共享所有权，那么在多线程中要注意数据竞争问题，当操作同一个对象时记得加锁。\n\n![共享智能.png](/images/2024/08/16/a0b54890-5b93-11ef-922f-4335b82b6d11.png)\n\n### 智能指针的大小\n\nstd::shared_ptr 的尺寸大于裸指针，一般是裸指针的两倍，因为它内部既包含一个指向到资源的裸指针，也包含一个指向该资源的引用计数的裸指针。其中引用计数的内存是动态分配的，且递增和递减是原子操作。\n\n![shared_ptr计数细节.png](/images/2024/08/16/a5c25030-5b93-11ef-922f-4335b82b6d11.png)\n\n下面通过 sizeof 看看是否如此：\n\n```c++\nclass Test{\n public:\n  explicit Test(int num):num_(num){\n    std::cout<<\" Test \"<<std::endl;\n  }\n  ~Test(){\n    std::cout<<\" ~Test \"<<std::endl;\n  }\n private:\n  int num_ = 0;\n};\n\nint main() {\n\n  Test* t1 = new Test(10);\n  std::shared_ptr<Test> s1(t1);\n\n  std::cout<<\"单独的对象 t1 = \"<<sizeof(t1)<<std::endl;\n  std::cout<<\"共享智能指针管理的对象 s1 = \"<<sizeof(s1)<<std::endl;\n\n  return 0;\n}\n```\n\n输出结果：\n\n![智能指针大小.png](/images/2024/08/16/abf9ce10-5b93-11ef-922f-4335b82b6d11.png)\n\n### 避免通过同一个裸指针创建多个 shared_ptr 对象 \n\n:star: shared_ptr 对象**只能通过复制其值来共享所有权**：如果两个 shared_ptr 是从同一个（非 shared_ptr）指针构造（或创建）的，它们将各自拥有该指针而不共享它，这可能导致访问问题，因为当其中一个释放它（删除其管理的对象）时，另一个将指向一个无效的位置。\n\n```c++\nvoid func(){\n  Test* t1 = new Test(10);\n\n  // 两个指针指针分别指向 t1对象\n  std::shared_ptr<Test> s1(t1);\n  std::shared_ptr<Test> s2(t1);\n\n  std::cout<<\"s1 use_count = \"<<s1.use_count()<<std::endl;\n  std::cout<<\"s2 use_count = \"<<s2.use_count()<<std::endl;\n\n  // 其中一个智能指针 释放管理的对象\n  s1.reset();\n  std::cout<<\"s1 use_count = \"<<s1.use_count()<<std::endl;\n  std::cout<<\"s2 use_count = \"<<s2.use_count()<<std::endl;\n}\n```\n\n输出结果：\n\n![重复析构.png](/images/2024/08/16/b46717b0-5b93-11ef-922f-4335b82b6d11.png)\n\n这边有提示重复析构的错误，这是错误使用智能指针出现的问题。 shared_ptr 对象只能通过复制其值来共享所有权，否则会导致计数错误，而 shared_ptr  恰恰是通过 计数来决定管理对象是否析构的，如果计数出现错误，那么管理对象也就会出现错误。在上面的代码中创建两个智能指针 s1 和 s2，直接管理 同一个对象 t1，但是这种错误示范导致无法跟踪真实的计数，导致两个智能指针 s1 和 s2都自以为最开始就管理这个对象。由于接管的这个对象计数是0，它们各自加 1，所以打印智能指针 s1 和 s2的计数情况都是 1，这位后面埋下隐患，即多重析构。我们通过 reset 方法重置 智能指针 s1 的计数为0，那么就会析构管理的对象，但是 s2 却始终以为管理的对象还存在（从输出情况中可以看出，智能指针 s1 的计数已经为 0，但是 s2 的计数还为 1 ），等到退出函数作用域，智能指针 s2 查看计数为 1 并去执行析构函数，导致出现重复析构的错误。\n\n下面修正代码的错误，再看看是否管理内存正确\n\n```c++\nvoid func(){\n  Test* t1 = new Test(10);\n\n  // 两个指针指针分别指向 t1对象\n  std::shared_ptr<Test> s1(t1);\n  std::shared_ptr<Test> s2(s1);\n\n  std::cout<<\"s1 use_count = \"<<s1.use_count()<<std::endl;\n  std::cout<<\"s2 use_count = \"<<s2.use_count()<<std::endl;\n\n  // 其中一个智能指针 释放管理的对象\n  s1.reset();\n  std::cout<<\"s1 use_count = \"<<s1.use_count()<<std::endl;\n  std::cout<<\"s2 use_count = \"<<s2.use_count()<<std::endl;\n}\n```\n\n输出结果：\n\n![正确析构.png](/images/2024/08/16/ba198710-5b93-11ef-922f-4335b82b6d11.png)\n\n### 避免通过 this 指针创建 shared_ptr 对象\n\n```c++\nclass Test{\n public:\n  explicit Test(int num){\n    std::cout<<\" Test \"<<std::endl;\n  }\n  ~Test(){\n    std::cout<<\" ~Test \"<<std::endl;\n  }\n  void process(){\n    data.emplace_back(this);\n    std::cout<<\" data[0] count = \" << data[0].use_count() <<std::endl;\n  }\n private:\n  using pTest = std::shared_ptr<Test>;\n  std::vector<pTest> data;\n};\n\nvoid func(){\n  Test* t1 = new Test(10);\n\n  std::shared_ptr<Test> s1(t1);\n  std::cout<<\" before count = \" << s1.use_count() <<std::endl;\n  s1->process();\n  std::cout<<\" end count = \" << s1.use_count() <<std::endl;\n}\n```\n\n输出结果：\n\n![避免this.png](/images/2024/08/16/c1fa2110-5b93-11ef-922f-4335b82b6d11.png)\n\n创建一个 shared_ptr 对象 s1，并用 t1 初始化它，引用计数加 1，当前引用计数为 1。然后调用 `process` 方法，将 shared_ptr 对象 s1 传递给 shared_ptr 对象 管理，并将其添加到 data 容器中，按理来说引用计数加 1，当前引用计数为 2，但是输出显示当前引用计数为 1，说明 this 不是返回的shared_ptr 对象 s1，而返回的裸指针 t1。\n\nC++11 提供这个问题的解决方案，即 enable_shared_from_this 和 shared_from_this。\n\n如果一个类继承自 std::enable_shared_from_this，那么这个类的实例对象可以通过调用 shared_from_this() 成员函数，**获得一个指向自己的 std::shared_ptr 智能指针**。这个指针可以和其他 std::shared_ptr 共享控制块，从而安全地管理对象的生命周期。\n\n```c++\n#include <iostream>\n#include <vector>\n#include <memory>\n\nclass Test : public std::enable_shared_from_this<Test> {\npublic:\n    explicit Test(int num) {\n        std::cout << \" Test \" << std::endl;\n    }\n    ~Test() {\n        std::cout << \" ~Test \" << std::endl;\n    }\n    void process() {\n        data.emplace_back(shared_from_this());\n        std::cout << \" data[0] count = \" << data[0].use_count() << std::endl;\n    }\nprivate:\n    using pTest = std::shared_ptr<Test>;\n    std::vector<pTest> data;\n};\n\nvoid func() {\n     Test* t1 = new Test(10);\n     std::shared_ptr<Test> s1(t1);\n    std::cout << \" before count = \" << s1.use_count() << std::endl;\n    s1->process();\n    std::cout << \" end count = \" << s1.use_count() << std::endl;\n}\n\nint main() {\n    func();\n    return 0;\n}\n```\n\n输出结果：\n\n![保活.png](/images/2024/08/16/c9cb03a0-5b93-11ef-922f-4335b82b6d11.png)\n\n从输出结果可以看出，没有出现前面的重复析构，并且计数得到正确的增加，因为确实是被两个智能指针指向，计算就应该为 2。但同时我们也看到析构没有被执行，表明 Test 没有被正确管理，这是因为 s1 销毁之后，裸指针 t1 的成员变量 data中还存储着 t1的 shared_ptr 对象，导致引用计数没有归 0。如果你在 Test 的析构函数中对其进行清理是无效的，计数不为 0 的情况下析构函数不会被执行，下面通过一个公共方法来清理内部成员。\n\n```c++\nclass Test : public std::enable_shared_from_this<Test> {\n public:\n  explicit Test(int num) {\n    std::cout << \" Test \" << std::endl;\n  }\n  ~Test() {\n    std::cout << \" ~Test \" << std::endl;\n  }\n  void process() {\n    data.emplace_back(shared_from_this());\n    std::cout << \" data[0] count = \" << data[0].use_count() << std::endl;\n  }\n  void clearData(){\n    data.clear();\n  }\n  int getCount(){\n    if (!data.empty()){\n      return data[0].use_count();\n    }\n    return 0;\n  }\n private:\n  using pTest = std::shared_ptr<Test>;\n  std::vector<pTest> data;\n};\n\nvoid func() {\n  Test* t1 = new Test(10);\n  {\n    std::shared_ptr<Test> s1(t1);\n    std::cout << \" s1 count = \" << s1.use_count() << std::endl;\n    s1->process();\n  }\n\n  std::cout << \" clearData before count = \" << t1->getCount() << std::endl;\n\n  t1->clearData();\n  std::cout << \" clearData end count = \" << t1->getCount() << std::endl;\n}\n\nint main() {\n  func();\n  return 0;\n}\n```\n\n输出结果：\n\n![正确析构2.png](/images/2024/08/16/d2d21c40-5b93-11ef-922f-4335b82b6d11.png)\n\nTest类对象 t1 被创建，执行构造函数。被 shared_ptr对象 s1 管理，引用计数加 1，当前引用计数为 1。调用 process 方法，把对象 t1 加入到 data容器中被 shared_ptr 管理，引用计数加 1，当前引用计数为 2。s1 离开作用域之后被销毁，引用计数减 1，当前引用计数为 1。调用 clearData 方法，清理 data 中的一个 shared_ptr 对象，引用计数减 1，当前引用计数为 0，调用管理的对象 t1 的析构函数。shared_ptr 就是等到管理对象的引用计数为 0 就调用管理对象的析构函数，析构函数本身就是对对象的成员变量的清理，至于对象本身要等到离开作用域之后才会被栈清理。\n\n### 优先使用 make_shared 创建 shared_ptr 对象\n\n- make_shared 会在一个连续的内存块中同时分配控制块和对象本身，即只会产生一次内存分配，对象与计数对象共用一块区域。而使用 new 则需要两次内存分配，一次是对象本身，另一次是为 shared_ptr 的控制块\n- 异常安全的构造 shared_ptr\n\n```c++\nvoid func(std::shared_ptr<Test> t1,int Ret){\n  std::cout<<\"func\"<<std::endl;\n}\n\nint process(){\n  // 可能发生异常\n  return 0;\n}\n\nint main() {\n  func(std::shared_ptr<Test>(new Test(10)), process());\n  return 0;\n}\n```\n\n这种创建 shared_ptr 对象的方式可能出现问题，可能的执行顺序如下：\n\n1. new Test(10)\n2. process()\n3. 构造一个 shared_ptr 对象\n\n但如果 process 出现异常，那么 构造一个 shared_ptr 对象 失败，导致内存泄漏，因为 new Test(10) 已经创建成功。我们现在推荐 make_shared 来创建 shared_ptr 对象。\n\n```c++\nfunc(std::make_shared<Test>(10), process());\n```\n\n## 弱引用指针 weak_ptr\n\n| 构造函数                            | 说明                                 |\n| ----------------------------------- | ------------------------------------ |\n| `weak_ptr()`                        | 默认构造函数，指针为空               |\n| `weak_ptr(const weak_ptr& other)`   | 拷贝构造函数，共享被管理对象的弱引用 |\n| `weak_ptr(const shared_ptr<T>& sp)` | 从 `shared_ptr` 构造，创建弱引用     |\n\n| 方法                    | 说明                                                         |\n| ----------------------- | ------------------------------------------------------------ |\n| `reset()`               | 释放当前持有对象的弱引用                                     |\n| `use_count()`           | 返回被管理对象的引用计数                                     |\n| `expired()`             | 判断被管理对象是否已被销毁（非线程安全）                     |\n| `lock()`                | 返回 `shared_ptr`，如果被管理对象已被销毁则返回空 `shared_ptr` |\n| `swap(weak_ptr& other)` | 交换两个 `weak_ptr` 的内容                                   |\n\nweak_ptr 用来表示临时所有权(弱引用，不会增加引用计数)，它需要配合 shared_ptr 使用，追踪 shared_ptr 所管理的对象是否有效。当需要临时所有权时，则将其转换为 shared_ptr，这样对象的引用计数会加 1，来保证正在访问的对象有效性。也就是说，你如果用 weak_ptr 是无法调用监视对象的成员方法的，需要提升为 shared_ptr 对象才可以。\n\nweak_ptr 具有复制语义，可以通过一个 weak_ptr 对象构造另一个 weak_ptr 对象，通过一个 shared_ptr 构造一个 weak_ptr 对象。\n\n### expired 和 lock \n\n可以利用 expired 先检查管理的对象是否已被销毁，然后选择把 weak_ptr 转换为 shared_ptr 对象。就像下面这样：\n\n```c++\nstd::shared_ptr<Test> t1 = std::make_shared<Test>(10);\nstd::weak_ptr<Test> w1(t1);\nstd::cout<<\"w1 use_count = \"<<w1.use_count()<<std::endl;\nif (!w1.expired()){ // false 意味着没有被销毁\n  std::shared_ptr<Test> t2(w1);\n  std::cout<<\"w1 use_count = \"<<t2.use_count()<<std::endl;\n}\n```\n\n但是这里有个问题，如果`!w1.expired()`通过，但是正准备创建 shared_ptr 对象t2，发现被其它线程已经把 t1销毁，就会出现未定义错误，这不是线程安全的写法。\n\nlock 方法可以很好的解决这个问题，因为如果 t1 没有被销毁，就会 lock 成功，否则失败。\n\n```c++\nstd::shared_ptr<Test> t1 = std::make_shared<Test>(10);\nstd::weak_ptr<Test> w1(t1);\nstd::cout<<\"w1 use_count = \"<<w1.use_count()<<std::endl;\nif (w1.lock ()){ //  true 意味着 还没有被销毁\n  std::shared_ptr<Test> t2(w1);\n  std::cout<<\"w1 use_count = \"<<t2.use_count()<<std::endl;\n}\n```\n\n### weak_ptr 与 shared_ptr 避免循环引用\n\n```c++\n#include <iostream>\n#include <memory>\n\nclass B; // 前向声明\n\nclass A {\n public:\n  std::shared_ptr<B> b_ptr;\n  A(){std::cout << \"A\\n\";}\n  ~A() { std::cout << \"~A\\n\"; }\n};\n\nclass B {\n public:\n  std::shared_ptr<A> a_ptr;\n  B(){std::cout << \"B\\n\";}\n  ~B() { std::cout << \"~B\\n\"; }\n};\n\nint main() {\n  {\n    // 创建循环引用\n    std::shared_ptr<A> a = std::make_shared<A>();\n    std::shared_ptr<B> b = std::make_shared<B>();\n    a->b_ptr = b;\n    b->a_ptr = a;\n  }\n  // 循环引用导致 A 和 B 没有被销毁\n\n\n  return 0;\n}\n```\n\n输出结果：\n\n![循环引用.png](/images/2024/08/16/dc0c79e0-5b93-11ef-922f-4335b82b6d11.png)\n\n从结果上可以看到，没有执行所创对象的析构函数，这明显是 shared_ptr 管理的对象引用计数没有 归 0。\n\n创建 shared_ptr 对象 a 管理类 A 对象，a 的引用计数加 1，当前引用计数为 1。创建 shared_ptr 对象 b 管理类 B 对象，b 的引用计数加 1，当前引用计数为 1。接下来将类对象 A 的 成员变量 b_ptr 赋值为前面创建的 b，b 的引用计数加 1，当前引用计数为 2。接下来将类对象 B 的 成员变量 a_ptr 赋值为前面创建的 a，a 的引用计数加 1，当前引用计数为 2。离开作用域之后，a 和 b 都被销毁，各自对应的引用计数减 1，且当前引用计数为 1。也就是说引用计数都没有归 0，这是没有析构的原因。\n\n只需要把其中任意一方从 shared_ptr 用 weak_ptr 替代即可，因为 weak_ptr 不增加引用计数。\n\n```c++\nclass B; // 前向声明\n\nclass A {\n public:\n  std::shared_ptr<B> b_ptr;\n  A(){std::cout << \"A\\n\";}\n  ~A() { std::cout << \"~A\\n\"; }\n};\n\nclass B {\n public:\n  std::weak_ptr<A> a_ptr;\n  B(){std::cout << \"B\\n\";}\n  ~B() { std::cout << \"~B\\n\"; }\n};\n```\n\n输出结果：\n\n![解决循环引用.png](/images/2024/08/16/e2174270-5b93-11ef-922f-4335b82b6d11.png)\n\n## 独占智能指针 unique_ptr\n\n| 构造函数                     | 说明                     |\n| ---------------------------- | ------------------------ |\n| `unique_ptr()`               | 默认构造函数，指针为空   |\n| `unique_ptr(T* ptr)`         | 用裸指针构造，拥有对象   |\n| `unique_ptr(unique_ptr&& u)` | 移动构造函数，转移所有权 |\n| `operator=(unique_ptr&& u)`  | 移动赋值，转移所有权     |\n\n| 方法                      | 说明                             |\n| ------------------------- | -------------------------------- |\n| `reset()`                 | 释放当前持有对象，指针为空       |\n| `reset(T* ptr)`           | 释放当前持有对象并拥有新对象     |\n| `release()`               | 释放所有权并返回裸指针           |\n| `get()`                   | 返回裸指针                       |\n| `swap(unique_ptr& other)` | 交换两个 `unique_ptr` 的内容     |\n| `make_unique<T>(...)`     | 创建并返回一个 `std::unique_ptr` |\n\nunique_ptr 代表的是独占私有权，它没有拷贝语义（没有赋值构造函数和赋值函数），只可以通过移动操作move来转移所有权。\n\n注：make_unique 是C++14 才补充的\n\n### move 转移所有权\n\n```c++\n#include <iostream>\n#include <memory>\n#include <unistd.h>\n\nclass Test{\n public:\n  Test(const std::string &str):str_(str){\n    std::cout<<\"Test \"<<str_<<std::endl;\n  }\n  ~Test(){\n    std::cout<<\"~Test \"<<str_<<std::endl;\n  }\n private:\n  std::string str_;\n};\n\nint main() {\n\n  std::unique_ptr<Test> t1 = std::make_unique<Test>(\"t1\");\n  std::unique_ptr<Test> t2 = std::make_unique<Test>(\"t2\");\n  t1 = std::move(t2);   // t2 所有权转移给 t1\n\n  pause();\n  return 0;\n}\n```\n\n输出结果：\n\n![独占.png](/images/2024/08/16/e8987380-5b93-11ef-922f-4335b82b6d11.png)\n\n把 unique_ptr 对象 t2 的所有权转移给 unique_ptr 对象 t1，执行 t1 的析构函数。也就是说接受所有权的 t1 会把之前管理的对象进行析构，然后接受最新对象的所有权。\n\n### release 和 get 的区别\n\n release 释放所有权并返回裸指针，并不会销毁管理的对象，即不会调用其析构函数。只是单纯的不再用 unique_ptr 管理这个对象而已，所以要必须在某个时候负责删除该对象，避免内存泄漏。\n\nget 不会释放所有权并返回裸指针，它仍负责在某个时间点删除托管数据。因此，此函数返回的值不得用于构造新的托管指针。\n\n```c++\n#include <iostream>\n#include <memory>\n\nclass MyClass {\npublic:\n    MyClass() { std::cout << \"MyClass Constructor\\n\"; }\n    ~MyClass() { std::cout << \"MyClass Destructor\\n\"; }\n};\n\nint main() {\n    // 创建一个 unique_ptr，管理一个 MyClass 实例\n    std::unique_ptr<MyClass> up1(new MyClass());\n\n    // 使用 get() 方法获取裸指针\n    MyClass* rawPtr = up1.get();\n\n    // 尝试用裸指针构造新的 unique_ptr\n    // 这是错误的，因为两个 unique_ptr 都会尝试管理同一个指针\n    std::unique_ptr<MyClass> up2(rawPtr);\n\n    // 当 up1 和 up2 作用域结束时，都会尝试删除同一个 MyClass 实例，导致未定义行为\n    return 0;\n}\n```\n\n### unique 的实际应用\n\n1. 配合 shared_ptr 实现工厂模式\n2. unique_ptr 不支持拷贝语义，直接将一个 unique_ptr 对象存入容器是不行的，必须通过 std::move 将 unique_ptr 对象\"移动\"到容器\n3. unique_ptr 有个数组版本，支持动态数组（shared_ptr 就不可以）\n\n## shared_ptr 与 uinque_ptr 的删除器\n\n删除器决定了智能指针在销毁时如何释放所管理的资源。shared_ptr 不能删除数组，但是 unique_ptr 可以删除数组。\n\n```c++\n#include <iostream>\n#include <memory>\n\nvoid customDeleter(int* ptr) {\n    std::cout << \"Custom deleter called\\n\";\n    delete ptr;\n}\n\nint main() {\n    std::shared_ptr<int> sp(new int(42), customDeleter);\n\n    std::cout << \"Value: \" << *sp << std::endl;\n\n    // 当 sp 超出作用域时，customDeleter 会被调用\n    return 0;\n}\n```\n\n```c++\n#include <iostream>\n#include <memory>\n\nint main() {\n    std::unique_ptr<int[]> up(new int[5]);\n\n    for (int i = 0; i < 5; ++i) {\n        up[i] = i * 10;\n    }\n\n    for (int i = 0; i < 5; ++i) {\n        std::cout << up[i] << \" \";\n    }\n    std::cout << std::endl;\n\n    // 当 up 超出作用域时，delete[] 会被调用\n    return 0;\n}\n```","tags":["C++11新特性"],"categories":["technology"]},{"title":"第二章：函数式编程之旅","url":"/2024/08/16/第二章：函数式编程之旅/","content":"\n<!-- toc -->\n\n## 函数使用函数\n\n所有函数式编程语言的主要特色就是函数可被看作一个普通的值。它们可被存储于变量中，放到集合或结构中，作为参数传递给其他函数，并可以作为其他函数的返回结果中。能够接收函数作为参数或返回函数作为结果的函数称为**高阶函数**。\n\n我们来看一个实例：假设有一组人，需要写出组内所有女性的名字。如下图所示。\n\n![一个实例.png](/images/2024/08/16/0b7c66c0-5b78-11ef-ad1f-31ad8bab6002.png)\n\n也就是说组内由男性和女性组成，先要把男性过滤掉而剩下女性（过滤），然后获取这些女生的名字（转换）。\n\n这里使用的首个高阶结构是集合过滤。通俗地讲，过滤是一个简单的算法，它主要检查原集合中的每个条目是否满足一定的条件。如果满足，则该条件被放入结果集中。**过滤算法并不能事先知道用户对他们的集合使用什么样的谓词函数进行过滤**。过滤可以针对一个特定的属性（如本例中的性别属性的值），也可以同时针对多个属性（如找到所有黑头发的女性），或更复杂的过滤条件（获取最近购买新车的所有女性）。因此，这种结构必须提供一种方法，可以让用户指定所需的谓词。在这个例子中，这个结构需要提供一个接收人的谓词，并返回这个人是不是女性。因为过滤允许传递一个谓词函数，按照定义，它是一个高阶函数。如果想从 STL 中找到具体的例子，常用的 sort 的第三个参数接受谓词，用户可以自实现谓词来筛选集合中的元素满足条件的情况下返回，比方说集合中所有元素从小到大进行排序。\n\n过滤任务完成后，还有获取姓名的任务。需要一个结构，它接收一组人并可返回他们的名字。与过滤类似，这个结构也不能事先知道要从原集合中选取哪些值。用户可能想获取一个特定的属性(如这个例子中的姓名)、多个属性组合(可能需要找到姓和名并把它们拼接起来)，或更复杂的操作(获取一个人的所有孩子)。同样，这个结构也需要允许用户指定一个函数，从集合中获取一个条目，对条目进行某些操作，并返回一个值，把这个值放在结果集中。请注意，输出集合没必要与输入集合包含相同的类型（这一点与过滤不同）。这种结构称为映射（map）或转换（transform）。\n\n## STL实例\n\nSTL 中有很多高阶函数，这里简单介绍几个，后续有可能会单独写一篇实践常用的 STL 中提供的高阶函数\n\n### 求平均值\n\nstd::accumulate 用来求和，其中：\n\n- first 和 fast 代表容器的起始迭代器和结尾迭代器\n- init 指定累加器的初始值\n- 二元运算符，用于指定累加操作的类型。如果不指定，默认为加法（二进制操作将类型为T的元素（即 init）作为第一个参数，将范围内的元素作为第二个参数，并返回可以分配给类型T的值）\n\n```c++\ntemplate <class InputIterator, class T>  \nT accumulate (InputIterator first, InputIterator last, T init);\n\ntemplate <class InputIterator, class T, class BinaryOperation>   \nT accumulate (InputIterator first, InputIterator last, T init,BinaryOperation binary_op);\n\n\n// 等价于\n\n{\n  while (first!=last) {\n    init = init + *first;  // or: init=binary_op(init,*first) for the binary_op version\n    ++first;\n  }\n  return init;\n}\n```\n\n不指定函数对象的实践代码。\n\n```c++\n#include <iostream>\n#include <vector>\n#include <numeric>\nusing namespace std;\nint main() {\n\n  vector<int> s = {2,1,0,25,-32,78,-21,-10,21};\n  int result = 0;\n  result = std::accumulate(s.begin(),s.end(),0);\n\n  std::cout<<\"result = \"<<result<<std::endl;\n\n  return 0;\n}\n/*\n\tresult = 64\n*/\n```\n\n指定函数对象的实践代码，使用了乘法运算符 `std::multiplies<int>()`，计算了所有元素的乘积。\n\n本质上是将 init 和 容器中每一个元素逐一相乘，如下代码含义为 2 * 1 * 2 * 3 * 4 * 5。\n\n```c++\n#include <iostream>\n#include <vector>\n#include <numeric>\nusing namespace std;\nint main() {\n\n  vector<int> s = {1,2,3,4,5};\n  int result = 0;\n  result = std::accumulate(s.begin(),s.end(),2,std::multiplies<int>());\n    \n   /*\n   \t等价于\n   \t  result = std::accumulate(s.begin(),s.end(),2,[](int a,int b){\n    \treturn a * b;\n \t });\n   */\n\n  std::cout<<\"result = \"<<result<<std::endl;\n\n  return 0;\n}\n\n/*\n\tresult = 240\n*/\n```\n\n### 折叠\n\nstd::accumulate 算法是折叠的一种实现。这是一个高阶函数，它提供了对递归结构，如向量、列表和树等的遍历处理，并允许逐步构建自己需要的结果。\n\n![折叠计算.png](/images/2024/08/16/01cfbf50-5b78-11ef-ad1f-31ad8bab6002.png)\n\n上面关于 std::accumulate 的实践代码，会让大家决定 init 的类型 要和 容器中元素的类型相同，实际上并没有这个要求，类型可以不同。下面的代码中，我们统计字符串 data 中字母的个数。\n\n```c++\n#include <iostream>\n#include <vector>\n#include <numeric>\nusing namespace std;\nint main() {\n\n  std::string data = \"www.baidu.com\";\n  auto result = std::accumulate(data.begin(),data.end(),0,[](int count,char c){\n    if (isalpha(c)){\n      count++;\n    }\n    return count;\n  });\n\n  std::cout<<\"result = \"<<result<<std::endl;\n\n  return 0;\n}\n\n/*\n\tresult = 11\n*/\n```\n\n折叠中有两种类型，一种是左折叠（从左往右开始遍历元素），一种是右折叠（从右往左开始遍历元素）。前面都是左折叠，C++ 也没有也没有提供独立的右折叠算法，但是我们可以通过传递反向迭代器来实现右折叠算法（crbegin 和 crend）。\n\n### 删除字符串空白符\n\nstd::find_if：查找集合中第一个满足指定谓词的元素。\n\n```c++\ntemplate <class InputIterator, class UnaryPredicate>   \nInputIterator find_if (InputIterator first, InputIterator last, UnaryPredicate pred);\n\n//等价于\n\n{\n  while (first!=last) {\n    if (pred(*first)) return first;\n    ++first;\n  }\n  return last;\n}\n```\n\n下面演示删除一个字符串左右两边的空白。\n\n```c++\n#include <iostream>\n#include <vector>\n#include <numeric>\nusing namespace std;\n\nstd::string trim_left(std::string str){\n  str.erase(str.begin(),std::find_if(str.begin(),str.end(),[](char c){\n    return !isspace(c);\n  }));\n  return str;\n}\n\nstd::string trim_right(std::string str){\n  str.erase(std::find_if(str.rbegin(),str.rend(),[](char c){\n    return !isspace(c);\n  }).base(),str.end());\n  return str;\n}\n\nint main() {\n\n  std::string data = \"   www.baidu.com   \";\n\n  std::cout<<trim_right(trim_left(data));\n\n  return 0;\n}\n\n/*\n\twww.baidu.com\n*/\n```\n\nstd::find_if 返回值为满足条件的所处位置的迭代器。trim_right 有用到 反向迭代器，`.base()` 返回的是反向迭代器的正向迭代器，指向找到的非空白字符的下一个位置。\n\n### 基于谓词分割集合\n\n在学习更多知识之前，假设有一个人的集合，需要把所有女性移到集合的前面。为了实现这一功能，可以使用 std::partition 和它的变体 std::stable_partition（相较于std::partition，可以保持集合中原来的顺序）。\n\n```c++\ntemplate <class ForwardIterator, class UnaryPredicate>  \nForwardIterator partition (ForwardIterator first,ForwardIterator last, UnaryPredicate pred);\n\n\ntemplate <class BidirectionalIterator, class UnaryPredicate>  \nBidirectionalIterator stable_partition (BidirectionalIterator first,BidirectionalIterator last,UnaryPredicate pred);\n```\n\n两个算法都接收一个集合和一个谓词。它们对原集合中的元素进行重排，把符合条件的与不符合条件的分开。符合谓词条件的元素移动到集合的前面，不符合条件的元素移动到集合的后面。算法返回一个迭代器，指向第二部分的第一个元素(不符合谓词条件的第一个元素)。返回的迭代器和原集合开头的迭代器配合，获取集合中满足谓词条件的元素(构成的集合)，与原集合尾端迭代器配合，可获得原集合中不符合谓词条件的元素(构成的合)。即使这些集合中存在空集合也是正确的。\n\n```c++\nint main() {\n\n  vector<int> data = {1,7,-2,10,-10,43,55,-99,-89};\n  auto its = std::partition(data.begin(),data.end(),[](int num){\n    return num > 0;\n  });\n\n  std::cout<<\"正数集合 = \";\n  auto itBegin = data.begin();\n  for (; itBegin != its ; itBegin++) {\n    std::cout<< *itBegin << \" \";\n  }\n\n  std::cout << std::endl;\n\n  std::cout<<\"负数集合 = \";\n  for (; its != data.end(); its++) {    \n    std::cout<< *its << \" \";\n  }\n  \n  return 0;\n}\n\n/*\n\t正数集合 = 1 7 55 10 43 \n\t负数集合 = -10 -2 -99 -89 \n*/\n```\n\n可以看到 std::partition 返回的迭代器 its 就是一个分界线，data.begin() ~ its 是符合条件的元素，its ~ data.end() 是不符合条件以外的元素。\n\n还有明显看到输出没有保持顺序性，只需要把 std::partition 替换成 std::stable_partition 即可。\n\n```c++\n正数集合 = 1 7 10 43 55 \n负数集合 = -2 -10 -99 -89\n```\n\n### 过滤和转换\n\n```c++\ntemplate <class ForwardIterator, class UnaryPredicate>  \nForwardIterator remove_if (ForwardIterator first, ForwardIterator last, UnaryPredicate pred);\n\ntemplate <class InputIterator, class OutputIterator, class UnaryPredicate>  \nOutputIterator copy_if (InputIterator first, InputIterator last, OutputIterator result, UnaryPredicate pred);\n```\n\nremove_if 删除指定范围内满足条件的元素，对容器会有改动。\n\ncopy_if 复制指定范围内满足条件的元素到另一个容器中，对容器不会有改动。\n\n```c++\nint main() {\n  std::vector<int> data = {1,7,-2,10,-10,43,55,-99,-89};\n\n  // 复制负数到 Fdata\n  std::vector<int> Fdata;\n  std::copy_if(data.begin(), data.end(), std::back_inserter(Fdata), [](int num) {\n    return num < 0;\n  });\n\n  std::cout << \"复制负数到指定容器中 = \";\n  for (int i : Fdata) {\n    std::cout << i << \" \";\n  }\n  std::cout << std::endl;\n\n  // 移除 data 中的负数\n  auto it = std::remove_if(data.begin(), data.end(), [](int num) {\n    return num < 0;\n  });\n  data.erase(it, data.end());\n\n  std::cout << \"移除容器中负数后 = \";\n  for (int i : data) {\n    std::cout << i << \" \";\n  }\n  std::cout << std::endl;\n\n  return 0;\n}\n/*\n\t复制负数到指定容器中 = -2 -10 -99 -89 \n\t移除容器中负数后 = 1 7 10 43 55 \n*/\n```\n\nstd::copy_if  和 std::back_inserter ：使用 std::back_inserter 可以直接将元素追加到 Fdata 中，因此不需要手动调整容器大小。\n\nstd::remove_if 和 erase：在 std::remove_if 后，通过 erase 函数真正删除负数元素，因为 std::remove_if 是把移除的元素放到后面并没有真正移除。\n\n## STL算法的可组合性\n\n基于 STL 的实现会生成不必要的 people 集合的副本（这是一个耗时的操作，甚至可能在拷贝构造函数被删除或私有时被禁用），并且会创建一个实际上并不需要的附加向量。为了解决这些问题，可使用引用或指针而不是副本，或者创建一个智能的迭代器，它可跳过所有不是女性的人员等。但这些额外的工作表明STL在这场战斗中已经输了，手写循环更好、更省力。\n\n![STL可组合性.png](/images/2024/08/16/f7765d20-5b77-11ef-ad1f-31ad8bab6002.png)\n\n虽然标准的算法提供了一种编写函数式风格代码的方式，而没必要手动编写循环和分支，但它们并没有设计成其他函数式编程库或语言一样的可组合的。后续使用 range 可以有所改观，到时候再谈。\n\n## 编写自己的高阶函数\n\n### 接收函数作为参数\n\n在 C++ 中，许多东西的行为类似于函数，但没有通用的类型用于存放类似函数的东西，而不损害程序的性能。可以把函数类型用作模板参数，让编译器在编译时确定具体的类型，而不是猜测哪种类型更好：\n\n```c++\ntemplate <typename FilterFun>\nstd::vector<std::string> names_for(\n\tconst std::vector<person_t> & people,\n\tFilterFun filter);\n```\n\n这将允许用户传递任何类似函数的东西作为参数，可以向普通的函数一样调用它。\n\n### 用循环实现\n\n几乎所有的STL算法都是由循环实现的，当你决定自己实现某个算法需要考量这样做的必要性，否则应该使用STL算法。这有几个原因。首先是简单。使用别人的代码节省时间。这也就引出了第二个好处：正确性。如果同样的东西写了一遍又一遍，一时疏忽产生错误也理所当然。STL经过了严格的测试，对于任何输入都能正常工作。基于同样的原因，使用硬编码循环实现的常用函数（我们自己实现的），也必须通过测试。\n\n虽然很多STL算法不是纯的，但它们被设计成高阶函数，这样它们就更通用，适用于更多的场合。如果某些东西被经常使用，它也不太可能包含前面不可见的缺陷。\n\n### 递归和尾调用优化\n\n前面的解决方案从外面看是“纯”的，但具体的实现却不是。当发现一个新的符合条件的人员时，它就要修改结果向量。在纯函数式编程语言中是不存在循环的，遍历集合的函数通常是由递归实现的。本书并不深入研究递归，因为读者并不常用到它，但需要说明一些重要的东西。\n\n对于一个非空向量，可以递归地处理它的头（第一个元素）和尾（所有其他元素），这又可以被看作一个向量。如果头满足谓词，则把它包含在结果中。如果接收到一个空向量，则什么也不需要处理，也就返回一个空向量。\n\n![相互递归实现.png](/images/2024/08/16/eebc7a20-5b77-11ef-ad1f-31ad8bab6002.png)\n\n这种实现是低效的。首先，由于某种原因导致向量的 tail 函数不存在：它需要创建一个新向量并将旧向量中的所有数据复制到其中（第一个元素除外）。tail 函数的问题可用一对迭代器代替向量作为输入来解决。在这种情况下，获取向量尾变得很简单--只需要移动迭代器，使它指向第一个元素即可如下图所示。\n\n![递归实现.png](/images/2024/08/16/e8d69eb0-5b77-11ef-ad1f-31ad8bab6002.png)\n\n这种实现的第二个问题是，把元素插入在向量的前端。这种情况并不多。在硬编码的循环中使用添加，在向量连接时，比前置(插入)更高效。最后也可能是最重要的问题是如果集合大量调用这个函数，可能会出现问题。每次递归都要占用堆栈中的内存，如果堆栈溢出则程序崩溃。即使集合不够大，不会导致堆溢出，但函数调用也要付出代价，简单的循环比它更高效。\n\n虽然前面的问题容易解决，但这个不同。这里需要**依赖编译器把递归转换成循环**。**为了让编译器进行转换，必须实现称为尾递归的形式**。在尾递归中，递归调用是函数的最后一件事情：递归后不能做任何事情。\n\n**尾递归函数**是一种递归函数，其中递归调用发生在函数的最后一步。在尾递归中，递归调用之后不再需要执行任何其他操作，因此可以直接返回递归调用的结果。尾递归函数的一个重要特性是，它可以被编译器或解释器优化为迭代形式，从而节省栈空间，避免递归调用过深导致的栈溢出。\n\n```c++\n普通递归\n\nint factorial(int n) {\n    if (n == 0) {\n        return 1;\n    } else {\n        return n * factorial(n - 1);\n    }\n}\n\n尾递归\n\nint factorial_tail(int n, int acc = 1) {\n    if (n == 0) {\n        return acc;\n    } else {\n        return factorial_tail(n - 1, n * acc);\n    }\n}\n```\n\n普通递归的实现中，`factorial(n - 1)` 的结果需要与 `n` 相乘，然后才返回给上层调用，因此这不是尾递归。\n\n在尾递归的实现中，递归调用 `factorial_tail(n - 1, n * acc)` 是函数的最后一步操作，并且将累积的结果通过 `acc` 参数传递下去。这里没有其他操作依赖于递归调用的返回值，因此这是尾递归。\n\n递归是一种强大的机制，可以让用户在不支持循环的语言中实现循环。但递归仍然属于低水平的结构。可以通过递归实现内部的“纯洁”性，但在许多情况下这样做没有意义。递归，就像手写循环，有它的一席之地。但在C++中，代码评审时就会出现问题。需要C++函数式编程检查它的正确性，并且保证在所有情况下都不会堆栈溢出。\n\n### 使用折叠实现\n\n前面已经见过折叠，但还没有从根本上理解它。折叠（Folding）一次取得一个元素，并对以前积累的值（是一个集合）和当前元素施加指定的函数，产生一个新的累积值。实质上，折叠只不过是编写尾递归函数遍历集合的一种更好的方式。共同的部分被抽取出来，用户只需要指定集合、初始值和必需的累加处理过程，而没必要编写递归函数。\n\n![折叠实现.png](/images/2024/08/16/e30e5d60-5b77-11ef-ad1f-31ad8bab6002.png)\n\n---\n\n⭐️内容取自译者程继洪、孙玉梅、娄山佑《函数式编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["函数式编程"],"categories":["technology"]},{"title":"第一章：前言","url":"/2024/08/15/第一章：前言/","content":"\n<!-- toc -->\n\n## 无处不在的分工\n\n### 分工\n\n如果他们各自独立工作，不专习一种特殊业务，那么他们不论是谁，绝对不能一日制造二十枚针，说不定一天连一枚也制造不出来。\n\n社会的发展需要分工，专门的人干专门的事，才能提高社会的生成效率，有了分工就必须要有合作，分工越是精细，那么合作的方式就越复杂，合作的这种模式就是我们说的架构。而计算机和互联网的发展，也出现了分工的现象。\n\n### 为什么分工\n\n首先是人的精力有限，不可能把所有需要的知识学完再去制作，效率极低。再者就是分工和分工可以组合，比方说电脑由多个组件构成，可以根据用户的需求进行定制。有些人用电脑只是办公，也就不需要性能很强的CPU；有些人用电脑需要打3A游戏大作，就需要性能很强的CPU，可以说越强越好。我们只要把电脑拆分成一个一个组件，才会有组合的可能，同样的商品却可以有极大的区别。况且独立出来，如果出问题也不至于导致整体失效，比方说键盘坏掉，可以单独修理键盘（希望你不是把水倒进电脑里面了，那就不只是键盘了）。\n\n### 分工带来的问题\n\n分工越细，各组件的关系可能会越复杂，协调成本也逐渐增高，而且由于建立联系了，彼此之间还会相互影响，如果某个组件损坏，可能导致整个系统不可用，尽管这也是架构师应该未雨绸缪的地方。\n\n1. 关系复杂\n2. 协调成本\n3. 相互影响\n\n### 解决方式\n\n设计规则和协议用以协调各个分工的组件，让整个系统按照逻辑正常运行。\n\n1. 制定规则\n2. 遵守协议\n3. 协调关系\n\n## 软件行业里面的分工\n\n### 软件的分工\n\n就简单用通信协议举例，TCP适用于尽可能保证信息不丢失的场景，UDP适用于快速响应且允许丢失小部分数据的场景。各有各的应用场景，确定场景选择合适的组合。\n\n存储特性：MYSQL、HBase、TiDB、Elastic、Redis、ETCD、Zookeeper、Druid\n\n语言特性：C、C++、Java、Python、Go、JavaScript\n\n通信特性：TCP、UDP、HTTP、HTTPS、MQTT\n\n协议特性：protobuffer、brpc、dubbo、RMI、Hessian、Thrift\n\n场景特性：To C、物联网、金融、电商、网游、社交、门户、AI\n\n### 架构设计的目的\n\n软件系统由于分工带来的复杂问题，需要通过架构进行组合协调，架构就是为了解决这些复杂问题而生的。\n\n## 什么是架构\n\n为了满足特定需求，根据各个部件的特性进行组合一种方式，就是架构。\n\n建房子需要架构，钢筋混凝土如何搭配、承重墙放在哪、圈梁怎么设计、顶梁柱放到哪？\n\n一个企业需要架构，部门划分、职责划分、决策组成、协调规则。\n\n一个国家需要结构，是联邦政府、还是中央集权（《盐铁论》，桑弘羊，析骨而炊）、分封制（商周，石器）。\n\n## 架构师的职责\n\n### 架构设计\n\n需求挖掘（发现问题）、整理方案（技术选型、演进方向、权衡取舍）、多方评审。\n\n### 落地推动\n\n制定计划、安排人力、协调资源、处理意外、质量保证、按期交付、汇报结果。\n\n### 管理\n\n这恐怕要单独出一个教程。","tags":["架构设计入门"],"categories":["technology"]},{"title":"946.验证栈序列","url":"/2024/08/15/946-验证栈序列/","content":"\n```c++\nclass Solution {\npublic:\n    bool validateStackSequences(vector<int>& pushed, vector<int>& popped) {\n        stack<int> data;\n        int len = pushed.size();\n        int pushLine = 0;\n        int popLine = 0;\n\n        for(pushLine; pushLine < len;){\n            if(pushed[pushLine] == popped[popLine]){\n                popLine++;\n                pushLine++;\n            }else{\n                if(!data.empty() && (popped[popLine] == data.top())){\n                    data.pop();\n                    popLine++;\n                }else{\n                    data.push(pushed[pushLine]);\n                    pushLine++;\n                }\n            }\n        }\n\n        for(popLine; popLine < len; popLine++){\n            if(popped[popLine] != data.top()){\n                return false;\n            }\n            data.pop();\n        }\n\n        return true;\n    }\n};\n```\n\n上面这份代码较为原始，明显感受出是按照正常思维去解题，就让我想起《最小栈》那道题，在简单思考可行性之后就开始写代码，也没想过有些地方可以被优化。优化的代码如下：\n\n```c++\nclass Solution {\npublic:\n    bool validateStackSequences(vector<int>& pushed, vector<int>& popped) {\n        stack<int> data;\n        int len = pushed.size(); \n        int popLine = 0; \n\n        for (int pushLine = 0; pushLine < len; ++pushLine) {\n            data.push(pushed[pushLine]);\n\n            while (!data.empty() && data.top() == popped[popLine]) {\t// 核心优化\n                data.pop(); \n                ++popLine;  \n            }\n        }\n        \n        return data.empty();\n    }\n};\n```\n\n其实就相当于把我源代码中的最后一个 for 循环的操作放到第一个 for 循环中用 while 循环处理了。","tags":["栈"],"categories":["leetcode"]},{"title":"844.比较含退格的字符串","url":"/2024/08/15/844-比较含退格的字符串/","content":"\n```c++\nclass Solution {\npublic:\n    string clearBK(string &str){\n        string data;\n        for(auto s : str){\n            if(s != '#'){\n                data.push_back(s);\n            }else{\n                if(!data.empty()){\n                    data.pop_back();\n                }\n            }\n        }\n        return data;\n    }\n    bool backspaceCompare(string s, string t) {\n        return clearBK(s) == clearBK(t);\n    }\n};\n```\n\n这道题我要提及的点是，当我们企图利用栈的对称性解决问题，如果这个返回值为字符串，那我们可以直接利用字符串作为栈来使用，因为它支持向后插入和向后弹出，这样我们就处理完就可以直接返回结果，也是相当方便了。\n\n也许我不该强调这道题的对称性，而应该表述为 利用栈实现消消乐。","tags":["栈"],"categories":["leetcode"]},{"title":"739.每日温度","url":"/2024/08/15/739-每日温度/","content":"\n```c++\nclass Solution {\npublic:\n    vector<int> dailyTemperatures(vector<int>& temperatures) {\n        vector<int> result(temperatures.size(), 0);\n        stack<int> data; // 存储下标\n\n        for (int i = 0; i < temperatures.size(); i++) {\n            while (!data.empty() && temperatures[i] > temperatures[data.top()]) {   // 单调递减栈\n                result[data.top()] = i - data.top();\n                data.pop();\n            }\n            data.push(i);\n        }\n        return result;\n    }\n};\n```\n\n前面做的一些关于栈的题目，通常只涉及两类：\n\n- 一类是利用栈的对称性（20.有效的括号）\n- 另一类是利用栈的接口，这本质上是在熟悉使用栈接口的基础上再加上一些与题目相关的思路解题（155.最小栈和232.用栈实现队列）\n\n然而，此题并不在上面之中，也是极容易被忘记的题型，即[单调栈](https://www.yuque.com/xiaoyang-wyxle/gfavbr/tgfk50tuyw1dalb6)。这也是我为何给单独给此类题型一个标签，这本身属于栈这个范围，因为单调栈就是在栈的基础上保留顺序的特性，但是又因为这种题的技巧容易被遗忘（反正我是这样），必须单独拎出来强调一番。\n\n当我们想要维持顺序，且有如下要求：\n\n1. 寻找数组中每个数左边第一个比它小的数，使用单调递增栈\n2. 寻找数组中每个数左边第一个比它大的数，使用单调递减栈\n3. 寻找数组中每个数右边第一个比它小的数，使用单调递增栈\n4. 寻找数组中每个数右边第一个比它大的数，使用单调递减栈\n\n在此题中，我们要寻找数组中每个数右边第一个比它大的数，使用单调递减栈。","tags":["栈","单调栈"],"categories":["leetcode"]},{"title":"232.用栈实现队列","url":"/2024/08/15/232-用栈实现队列/","content":"\n```c++\nclass MyQueue {  \npublic:  \n    MyQueue() {}  \n      \n    void push(int x) {   // 将元素 x 推到队列的末尾  \n        dataSrc.push(x);  \n    }  \n      \n    int pop() { // 从队列的开头移除并返回元素  \n        int val = peek();  \n        dataTop.pop();  \n        return val;  \n    }  \n      \n    int peek() {    // 返回队首元素  \n  \n        if(dataTop.empty()){  \n            while(!dataSrc.empty()){  \n                dataTop.push(dataSrc.top());  \n                dataSrc.pop();  \n            }  \n        }  \n  \n        return dataTop.top();  \n    }  \n      \n    bool empty() {  \n        if(dataTop.empty() && dataSrc.empty()) return true;  \n        return false;  \n    }  \nprivate:  \n    stack<int> dataSrc;  \n    stack<int> dataTop;  \n}; \n```\n\n这里面巧妙的地方在于，返回队首元素时：\n\n- 如果 dataTop 不为空就返回对应的 top 即可\n- 如果 dataTop 为空，就把 dataSrc 全部转移到 dataTop  中即可，返回对应的 top 之后，并不需要把 dataTop 中的元素返回到 dataSrc 中（我记得第一次做这道题是这么搞的，其实可以被这样优化）","tags":["栈"],"categories":["leetcode"]},{"title":"225.用队列实现栈","url":"/2024/08/15/225-用队列实现栈/","content":"\n```c++\nclass MyStack {\nprivate:\n    queue<int> storage; //数据往此处存储\n    queue<int> hub; //中转站\npublic:\n    MyStack() {\n\n    }\n    \n    //\n    void push(int x) {\n        storage.push(x);\n    }\n    \n    //即弹出队尾元素\n    int pop() {\n        if(storage.empty()) return -1;\n        int len = storage.size();\n        for(int i = 0; i < len - 1; i++){\n            hub.push(storage.front());  \n            storage.pop();\n        }\n        int val = storage.back();    //把最后一个元素弹出并得到\n        storage.pop();\n        int len1 = hub.size();\n\n        for(int j = 0; j <len1; j++){\n            storage.push(hub.front());\n            hub.pop();\n        }\n\n        return val;\n\n    }\n    \n    //即返回队尾元素\n    int top() {\n        return storage.back();\n    }\n    \n    bool empty() {\n        return storage.empty();\n    }\n};\n```\n\n因为队列只能从队头移除元素，必然单个队列也就无法实现栈了，所以核心实现就在移除最后的元素。我们利用一个队列作为中转队列，即待移除最后一个元素的时候，先把 storage 中全部元素转移到中转队列中，然后取得中转队列的队头元素并移除（就是要获取的 storage 中的队头元素），然后在转移回 storage 队列中去即可。","tags":["队列"],"categories":["leetcode"]},{"title":"155.最小栈","url":"/2024/08/15/155-最小栈/","content":"\n```c++\nclass MinStack{  \n private:  \n  stack<pair<int,int>> minStack_;  \n  vector<int> data_;  \n private:  \n public:  \n  MinStack(){  \n  \n  }  \n  void push(int val){  \n    data_.push_back(val);  \n    sort(data_.begin(),data_.end(), [](int a,int b){    // 从小到大排序  \n      return a < b;  \n    });  \n    pair<int,int> result(val,data_.front());  \n    minStack_.push(result);  \n  }  \n  void pop(){  \n    int delData = minStack_.top().first;  \n    minStack_.pop();  \n    auto its = std::find(data_.begin(), data_.end(),delData); // 找到 待删除元素的迭代器  \n    if (its != data_.end()){  // 找到了 就删除它  \n      data_.erase(its);  \n    }  \n  }  \n  int top(){  \n    return minStack_.top().first;  \n  }  \n  int getMin(){  \n    return minStack_.top().second;  \n  }  \n};  \n```\n\n早先做这道题的时候，采用的是双栈，想法简单，却也要在两个栈中来回移动，极其愚蠢。后面看别人的题解的时候看到利用 pair<int,int> 的应用，甚是美妙，可我还是走错了（data_ 的使用是画蛇添足）。直到再次看到另一个人的题解，我才明白我的思想究竟错误在哪里，也回忆起之前感叹美妙的原由，即采用 pair<int,int> 只需一个栈；加入元素就与 top 元素 进行 min 求值，就能保证当前 元素记录着对应 栈的最小元素。\n\n```c++\nclass MinStack{\n private:\n  stack<pair<int,int>> minStack_;\n public:\n  MinStack(){\n\n  }\n  void push(int val){\n    pair<int,int> result;\n    if (minStack_.empty()){\n      result = pair<int,int>(val,min(val,val));\n    }else{\n      result = pair<int,int>(val,min(val,minStack_.top().second));\n    }\n    minStack_.push(result);\n  }\n  void pop(){\n    minStack_.pop();\n  }\n  int top(){\n    return minStack_.top().first;\n  }\n  int getMin(){\n    return minStack_.top().second;\n  }\n};\n```","tags":["栈"],"categories":["leetcode"]},{"title":"20.有效的括号","url":"/2024/08/15/20-有效的括号/","content":"\n```c++\nclass Solution {  \npublic:  \n    bool isValid(string s) {  \n        stack<char> data;  \n        int len = s.size();  \n  \n        for(int i = 0; i < len; i++){  \n            if(data.empty()){  \n                data.push(s[i]);  \n                continue;  \n            }  \n  \n            if((data.top() != s[i]) && ((data.top() == '(' && s[i] == ')') || (data.top() == '[' && s[i] == ']') || (data.top() == '{' && s[i] == '}'))){ // 有希望  \n                data.pop();  \n            }else{  \n                data.push(s[i]);  \n            }  \n        }  \n  \n        if(data.empty()) return true;  \n  \n        return false;  \n    }  \n};  \n```\n\n逐一从字符串 s 中取字符：\n\n1. 如果 data 栈为空，直接加入其中\n2. 如果 data 栈不为空，即将加入的字符 s[i] 与 栈中的顶部元素比较\n   1. 如果不相等【data.top() != s[i]】，表明**有希望**匹配\n   2. 如果相等，必然不可能匹配，将其加入栈中即可\n\n栈 适合解决对称性问题，这也是栈的一个特点","tags":["栈"],"categories":["leetcode"]},{"title":"第一章：函数式编程简介","url":"/2024/08/12/第一章：函数式编程简介/","content":"\n<!-- toc -->\n\n## 什么是函数式编程？\n\n我们常用的是命令式编程，它关心“怎么做”，而函数式编程关心“做什么”。通俗来讲，函数式编程更关注结果的定义，而命令式编程更关注实现的步骤。\n\n### 命令式编程\n\n在命令式编程中，我们会明确地告诉计算机每一个步骤应该怎么做。在如下这个代码中，我们使用了一个循环，逐个元素地累加到 `sum` 变量上。我们需要明确地描述每一步操作。\n\n```c++\n#include <iostream>\n#include <vector>\n\nint main() {\n    std::vector<int> numbers = {1, 2, 3, 4, 5};\n    int sum = 0;\n\n    for(int i = 0; i < numbers.size(); ++i) {\n        sum += numbers[i];\n    }\n\n    std::cout << \"Sum: \" << sum << std::endl;\n\n    return 0;\n}\n```\n\n### 函数式编程\n\n在声明式编程中，我们更关注的是“做什么”，而不是“怎么做”。使用函数式编程的风格，我们可以使用递归或者标准库的算法来实现这一点。在如下这个代码中，`std::accumulate` 函数定义了如何计算数列的和，而不需要手动地进行循环和累加。这里编程语言提供的库函数实现了所有细节，程序员只需要指定“想要什么”，而不需要关心“如何去做”。\n\n```c++\n#include <iostream>\n#include <vector>\n#include <numeric>\n\nint main() {\n    std::vector<int> numbers = {1, 2, 3, 4, 5};\n    int sum = std::accumulate(numbers.begin(), numbers.end(), 0);\n\n    std::cout << \"Sum: \" << sum << std::endl;\n\n    return 0;\n}\n```\n\n## 纯函数\n\n函数式编程的核心思想是纯函数，即函数只使用（而不修改）传递给它们的实际参数计算结果。如果使用相同的实参多次调用纯函数，将得到相同的结果，并不会留下调用痕迹（无副作用）。这都意味着纯函数不能修改程序的状态。\n\n但是这样的要求未必过于苛刻，意味着纯函数不能从标准输入读取内容，不能向标准输出写入内容，不能创建或删除文件，也不能像数据库插入记录等。如果要追求彻底的“不变性”，甚至要禁止纯函数改变处理器的寄存器、内存或其它硬件的状态。这样的纯函数的定义就没意义了。\n\nCPU 一条一条地执行指令，他需要跟踪下一条要执行的指令。如果连 CPU 的内部状态都不可修改，那么在计算机上将无法执行任何操作。另外，如果不能与用户或其它软件系统交互，程序就毫无作用。\n\n正是因为如此，我们降低一下纯函数的要求，重新定义如下：**任何没有可见副作用的函数称为纯函数**。纯函数的调用者除了接受它的返回结果外，看不到任何它执行的痕迹。本书不提倡只使用纯函数，而只是限制非纯函数的数量。\n\n---\n\n下面通过命令式实现的统计文件集合中每个文件的行数的例子额，引入函数式编程的风格。\n\n![命令式编程.png](/images/2024/08/12/1b6afab0-58b7-11ef-b8eb-03ab487c67e2.png)\n\n上面的这份代码 count_lines_in_files 就是常见的命令式编程方式，里面包含多个可变状态，相当“不纯”。\n\n1. get 方法每次都会更改字符的值\n2. 如果遇到换行，line_count 会自加更改值\n3. 退出 while 循环之后，results 容器会加入新的元素\n\n但要考虑的不仅仅是这些，另一个很重要的方面是这个函数的“不纯”性是不是外部可见的。**这个函数的所有可变变量都是局部的--计时函数的并发调用也不会共享--不会被调用者或其它实体看到。虽然它的实现不是纯函数，但它的使用者可以认为这是一个“纯函数”**。这对它的调用者是有利的，因为不需要修改它们的状态，而只需要管理自己的（状态）。这样做的话，**必须保证不能更改不属于自己的任何东西**。如果限制修改属于自己的状态，以纯函数的方式实现，那就再好不过了。如果能够保证以纯函数实现，那就没必要考虑是否漏掉了任何状态改变，因为没有修改任何东西。\n\n第二种解决方案把统计功能分离到另一个函数 count_lines 函数中，这个函数也是外表上看起来像个纯函数，虽然它的内部声明了一个输入流并且修改它。\n\n![命令式编程改进.png](/images/2024/08/12/1730d370-58b7-11ef-b8eb-03ab487c67e2.png)\n\n实际上这份代码并没有对之前的程序 count_lines_in_files 没有什么实质性的提高。它只是把“不纯”的部分转移到其它地方，但依旧保留了两个可变的变量。与此不同的是，count_lines_in_files 不需要 I/O，但还是用它（count_lines 函数）的思想实现的，所以作为调用者，可以认为它是纯函数，而不论是不是含有“不纯”的部分。\n\n下面的代码使用了范围操作符实现 count_lines_in_files 函数，没有局部状态--没有可变状态也没有不可变状态。它的实现只是对给定的输入调用了其它的函数：\n\n![函数式编程.png](/images/2024/08/12/120dd2d0-58b7-11ef-b8eb-03ab487c67e2.png)\n\n这个解决方案就是函数式编程很好的例子。它简明扼要，浅显易懂。更重要的是，其他的事情（除统计行数外）它一概没做--没有任何可见的副作用。它只是对给定的输入给出期望的结果。\n\n## 以函数方式思考问题\n\n先写出命令式编程的代码，再去转换为函数式编程的代码是低效的，应该在拿到任务之前思考输入是什么，输出是什么，输入到输出需要怎样的转换，而不是去思考算法的步骤（命令式编程）。\n\n给定一个文件名字的列表（集合），需要计算出每一个文件中的行数。首先想到的应该是简化这个问题，即一次只处理一个文件。虽然给定了一个文件名的集合，但可以一次一个地处理它们。如果能找出解决统计一个文件行数的办法，就可以很容易地解决这个问题。\n\n![函数方式思考.png](/images/2024/08/12/0bd23640-58b7-11ef-b8eb-03ab487c67e2.png)\n\n现在问题转化为，定义一个函数，接收一个文件名并计算该文件中行数的问题。从这个角度分析，很明显给定了一个东西（文件名），但需要的却是另一个东西（文件的内容，这样才可以统计出文件的行数）。因此，需要一个函数，它可以接收一个文件名，并给出它的内容。至于内容是字符串、文件流、或其他形式由用户决定。它只需要每次提供一个字符，用户把这个字符传递给统计行数的函数就可以了。\n\n当有了给出文件内容的函数（std::string → std::ifstream），就可以用它的结果调用统计行数的函数（std::ifstream -> int）。把第一个函数返回的 ifstream 类型的结果传递给第二个统计行数的函数，就可以得到想要的结果。\n\n![拆解.png](/images/2024/08/12/044b2df0-58b7-11ef-b8eb-03ab487c67e2.png)\n\n这样问题就解决了。现在需要提升这两个函数用于处理一个文件的集合，而不再是单一的一个文件了。从概念上讲，std::transform 就是这样实现的（还有很多复杂的 API）：它需要一个可以应用于单个值的函数，并创建一个可以处理整个值集合的转换，如下图所示。把处理单个值的函数提升为处理该类型复杂数据结构的函数，是一种通用技术。\n\n![提升.png](/images/2024/08/12/00575e80-58b7-11ef-b8eb-03ab487c67e2.png)\n\n通过这个例子，读者已经学会了利用函数式的方法，把一个大的问题分解成小的问题、独立的任务，并且方便地把它们组合起来。与函数组合和提升比较类似的例子是动态流水线，如下图所示。最初是制作产品的原料。这些原料通过机器的转换，最后得到最终产品。在流水线中，关心的是产品经过哪些转换，而不是机器加工产品的具体步骤。\n\n![流水线.png](/images/2024/08/12/faa3b6a0-58b6-11ef-b8eb-03ab487c67e2.png)\n\n在这个例子中，原料是输入，机器是施加于输入的函数。每个函数只做自己的工作而不关心其他的函数。每个函数只需要一个有效的输入，而不论这个输入来自何处。输入条目逐个放在流水线中（或有多个流水线，那就可以并行处理多个条目了）。每个条目经过转换，最终得到想要的东西。\n\n## 函数式编程的优点\n\n### 代码简洁易读\n\n有许多情况下，循环和分支也过于原始。就好像 GOTO 一样，循环和分支使程序难以编写和理解，可以使用层次更高的函数式编程结构替代。程序员在多处编写相同的代码，却没有发现它们是相同的，因为它们用于不同的类型或有不同的行为，但可以很容易地把它们重构出来。\n\n通过使用STL或第三方库提供的抽象，并通过创建自己的抽象，可以使代码更安全更简短。同时，更易于暴露这些抽象中的缺陷，因为这些相同的代码将被用于不同的场合。\n\n### 并发和同步\n\n开发并发系统的主要难点在于共享可变的状态。必须保证组件不能相互干扰。使用纯函数编写并行程序就很简单，因为这些函数并不修改任何东西。不需要原子或信号量进行显式同步，可以把用于单线程的代码，几乎不加修改地用于多线程系统。\n\n### 持续优化\n\n使用抽象层次更高的 STL 或其他可信的库函数还有另一个优点：即使不修改任何一行代码，程序也在不断地提高。编程语言、编译器实现或正在使用的库的实现的每一个改进都将改进程序。虽然函数式或非函数式的高层次抽象都会得到改进，但函数式编程概念显著增加了可以用这些抽象来覆盖的代码量。\n\n这看起来有点简单，但很多程序员倾向于手动编写低层次的关键性能代码，有时甚至用汇编语言。这种做法有一定的好处，但这种优化只针对特定的平台，而且阻碍了编译器对其他平台代码的优化。\n\n再来看一下 sum 函数。针对预取指令的系统进行优化，可以在内部循环中一次取两个（或更多）条目，而不是一次只取一个。这可以减少代码中的跳转次数，因此 CPU 一般会预取到正确的指令，而且在目标系统中可大幅提高性能。但如果在另一不同的平台上运行这个程序会怎样呢？对于某些平台来说，其原始的循环可能已经是优化了的；对于其他平台，有可能每次循环能对更多的条目进行累加。有些系统甚至可以提供CPU级的指来实现这个函数的功能。\n\n通过这种方式手动优化代码，针对的只有一个平台，而失去了其他所有平台的优化。如果使用高层次抽象，就可以依赖其他的人对代码进行优化。绝大多数STL实现都对目标平台和编译器进行了特定的优化。\n\n---\n\n⭐️内容取自译者程继洪、孙玉梅、娄山佑《函数式编程》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["函数式编程"],"categories":["technology"]},{"title":"不要用 TIME-WAIT暗杀来关闭一条连接","url":"/2024/08/10/不要用-TIME-WAIT暗杀来关闭一条连接/","content":"\n<!-- toc -->\n\n## 认识 TIME-WAIT\n\n主机 2 关闭连接并释放资源。从主机 2 的角度来看，连接不再存在了。但主机 1 还没有关闭连接，而是会进入 TIME_WAIT状态，并在这个状态停留 2MSL，等待 2MSL智慧，主机 1 也将连接关闭，并释放其资源。\n\n![time_wait.png](/images/2024/08/10/1f7d2ce0-571d-11ef-a7b6-1b323923df30.png)\n\n关于 TIME-WAIT 状态，还要弄清楚三点：\n\n1. 主动关闭的那一端才会进入 TIME-WAIT 状态\n2. RFC 将 MSL 定义为 2 分钟\n3. 如果连接处于 TIME-WAIT 状态时有分组到达，就重启 2MSL 的定时器\n\n## 为什么要使用它\n\n1. 维护连接状态，以防主动关闭连接的那端发送的最后一条 ACK 丢失后照成另一端重新发送 FIN 信号\n2. 为耗尽网络中所有此连接的“走失段”提供时间（确保在原有连接的所有分段从网络中消失之前，不会再次使用原来用过的套接字对，以此来防止这类问题的产生）\n\n## TIME-WAIT 暗杀\n\n不幸的时，TIME-WAIT 状态可以被提前终止，这被称为 TIME-WAIT 暗杀。它可能时“碰巧”产生的，也可能是故意造成的。不管是哪种情况，提前终止 TIME-WAIT 状态 都是不明智的。\n\n### 碰巧发生的情况\n\n首先来看看怎么会碰巧发生这种情况。当一条连接处于 TIME-WAIT 状态并收到一个 RST 时，应该立即将连接关闭。假设有一条处于 TIME-WAIT 状态的连接，并有一个原有的重复分段到达，而这个分段是 TCP 无法接受的（比如，序列号在当前接收窗口之外）。TCP 会以一个 ACK 响应，说明它所期待的序列号（就是对等实体的 FIN 之后的序列号）。但对等实体中已经没有这个连接的记录了，所以会以一个 RST 来进行 ACK。当这个 RST 回到连接处于 TIME-WAIT 状态的主机时，会使连接立即关闭--TIME-WAIT 状态被暗杀了。\n\n可能会影响到原有连接的再生，还包含了对原有数据的错误接收，造成无线 ACK 循环的连接不同步现象，以及新连接的错误行终止。\n\n### 故意造成的\n\n另一种 TIME-WAIT 暗杀方式是故意造成的。如下所述，即使应用程序正在主动关闭连接，程序员也可以用套接字选项 SO_LINGER 迫使连接立即关闭。有时会推荐用这种可疑的方式使服务器跳出 TIME-WAIT状态，这样就可以在崩溃或终止之后重启服务器了。\n\n---\n\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"使用前将结构sockaddr_in清零","url":"/2024/08/10/使用前将结构sockaddr-in清零/","content":"\n我们看到下面两种实现中确实都有另外一个字段 sin_zero。尽管很少用到这个字段（用于将sockaddr_in结构补足 16 字节长），但还是必须将其设置为 0。\n\n因为必须要将 sin_zero 清零，所以在使用之前，将整个地址结构清零就成了一种惯常的做法。通过这种方式，可以清除所有其它字段，而且还可以避免于未正式说明的字段及用法发送可能的冲突。\n\n![sockaddrin.png](/images/2024/08/10/58b102a0-5715-11ef-a7b6-1b323923df30.png)\n\n---\n\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"不要低估 TCP 的性能","url":"/2024/08/10/不要低估-TCP-的性能/","content":"\nTCP 是一个复杂的协议，在基本数据报服务的基础上添加了可靠性和流量控制功能，而 UDP 只添加了一个校验和,所以看起来 UDP 可能要比 TCP 快一个数量级或更多。基于这种假设很多应用程序的程序员都认为只有使用 UDP 才能获得可接受的性能。在某些情况下，UDP 运行的是比 TCP 快得多，但并不总是这样的。我们会看到，**有时 TCP 比 UDP 运行的好得多**。\n\n1. 两种协议的 CPU 处理主要都是在进行数据复制和校验，因此，这部分看不出太大的差别\n2. 为了提供可靠性，接收端 TCP 必须发送 ACK，这就增加了两端程序必须处理的内容，但是工作量可能不会有我们预想的那么多。首先，接受端可用通过它要发回给对等实体的数据来捎带给ACK。实际上，很多 TCP 实现都会将 ACK 延迟几个毫秒发送，以防止本端应用程序有对输入分段的应答要发送。第二，TCP 没必要为每个段产生一个 ACK。正常情况下，大部分 TCP 实现都是隔一段发送一次 ACK 的\n3. TCP 和 UDP 之间另一个主要区别在于 TCP 是个面向连接的协议，必须进行连接的建立和拆除，即三次握手和四次挥手。我们假设拆除连接（四次挥手）的时间基本上可用并入数据交换的时间之中，将注意力集中在连接建立阶段发生的事情上。如下图所示，分组从一台主机发送到其对等实体再发送回来所需的时间。正如我们看到的那样，连接建立要花费一又二分之一个往返时间。如果客户端和服务器之间的连接维持的时间足够长(比如,有大量数据在客户端和服务器之间传送)，这一个半 RTT会由所有的数据传输分摊，不会对性能产生很严重的影响。但如果有个简单事务，客户端发送一条请求，服务器对其进行应答，那么连接建立时间在整个事务所用时就会占据很大一部分\n\n![TCP性能.png](/images/2024/08/10/13151a80-5713-11ef-a7b6-1b323923df30.png)\n\n我们预计，应用程序中仅包含简单的请求/应答会话时，UDP 的性能会比 TCP 好，当连接持续的时间很长，并且传输了大量数据时，TCP 的性能会比 UDP 好得多。实际情况中，还需要各写一份代码进行测试。\n\n---\n\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"高并发、高可用和高性能","url":"/2024/08/10/高并发、高可用和高性能/","content":"\n## 概述\n\n（一）高并发\n\n用QPS/TPS来衡量系统对任务的处理能力：\n\n- **QPS**（Queries Per Second）：每秒**查询**数，指一台服务器每秒能够响应的查询次数\n- **TPS**（Transactions Per Second）：每秒事务（**增删改**）数，可以是一个接口、多个接口、一个业务流程\n\nQPS只是一个简单查询的统计，不能描述增删改等操作（TPS来描述）。如果只有查询操作，我们认为TPS = QPS\n\n（二）高可用\n\n**SLA**衡量一个系统可用性有多高，目标系统7 x 24不间断服务\n\n大云厂商在宣传自己产品SLA时是多少个9\n\n![高可用.png](/images/2024/08/10/69949cc0-56f8-11ef-a7b6-1b323923df30.png)\n\n9 越多代表全年服务可用时间越长服务更可靠，停机时间越短\n\n大厂多数业务 4个9是刚需，5个9是目标，6个9是理想\n\n（三）高性能\n\n**RT**来衡量系统的响应速度，程序处理速度非常快、延迟低、所占内存少、CPU占用率低\n\n比如系统处理一个HTTP请求需要100ms，这100ms就是系统的响应时间\n\n## 技术方案\n\n（一）高并发和高性能\n\n1. 负载均衡：常用的Nginx中间件就有实现\n2. 缓存：有本地缓存和分布式缓存\n3. 池化复用：线程池、连接池、内存池等\n4. 异步：异步日志等\n5. 预处理：你刷的视频即便后面有部分还没有看也会被提前获取\n6. 分而治之：Master-Worker工作架构，可参考主从Reactor模型\n\n（二）高可用\n\n1. 集群架构：有节点故障会有其它节点顶替\n2. 熔断降级：为了防止整个系统故障，抛弃一些非核心的接口和数据，返回兜底数据\n3. 限流：访问频率或者并发请求超过承受范围，考虑限流来保证接口的可用性\n4. 隔离：服务和资源相互隔离，比如网络资源、机器资源、线程资源等，不会因为某个服务的资源不足而抢占其它服务的资源\n5. 多活架构：同城双活-双机房和异地多活-两地三中心\n\n![高可用方案.png](/images/2024/08/10/62a5b5c0-56f8-11ef-a7b6-1b323923df30.png)","tags":["网络编程"],"categories":["technology"]},{"title":"水平触发和边缘触发","url":"/2024/08/10/水平触发和边缘触发/","content":"\n<!-- toc -->\n\n## 水平触发\n\n- 读事件：如果 epoll_wait 触发了读事件，表示有数据可读，如果程序没有把数据读完，再次调用 epoll_wait 的时候，将立即再次触发读事件。\n- 写事件：如果发生缓冲区没有满，表示可以写入数据，只要缓冲区没有被写满，再次调用epoll_wait的时候，将立即再次触发写事件。\n\n## 边缘触发\n\n- 读事件：如果 epoll_wait 触发了读事件，不管程序有没有处理读事件，epoll_wait 都不会再触发读事件，只有当新的数据到达时，才再次触发读事件。\n- 写事件：epoll_wait 触发写事件之后，如果发送缓冲区任可以写（发送缓冲区没有满），epoll_wait 不会再次触发写事件，只有当发送缓冲区由 满 变成 不满 时，才再次触发写事件。\n\n## 实例说明\n\n这里就以读事件举例，客户端发生长度为 6 的字符串sssbbb，服务器这边一次读只能读取长度为 3 的字符串。下面看看水平触发和边缘触发的现象：\n\n水平触发：epoll_wait触发读事件，读取字符串sss，epoll_wait再次触发读事件，读取字符串bbb\n\n边缘触发：epoll_wait触发读事件，读取字符串sss\n\n客户端再次发送长度为6的字符串sssbbb：\n\n水平触发：epoll_wait触发读事件，读取字符串sss，epoll_wait再次触发读事件，读取字符串bbb\n\n边缘触发：epoll_wait触发读事件，读取字符串bbb（把之前没读完的字符串读完）\n\n实践效果图如下：\n\n![水平触发.png](/images/2024/08/10/0ab7cab0-56f8-11ef-a7b6-1b323923df30.png)\n\n![边缘触发.png](/images/2024/08/10/10951aa0-56f8-11ef-a7b6-1b323923df30.png)","tags":["网络编程"],"categories":["technology"]},{"title":"网络编程中结构体的区分","url":"/2024/08/10/网络编程中结构体的区分/","content":"\n<!-- toc -->\n\n## sockaddr结构体和sockaddr_in结构体\n\n```c++\nstruct sockaddr {\n    unsigned short sa_family;    // 协议族 (AF_INET, AF_INET6, etc.)\n    char sa_data[14];            // 地址数据 (协议相关)\n};\n```\n\n存放协议族、端口和地址信息。客户端的 connect 函数和服务端的 bind 函数需要这个结构体。\n\nsockaddr 结构体是为了统一地址结构的表示方法，统一接口函数，但是这个结构体并不方便使用，因此定义了等价的 sockaddr_in 结构体，它的大小和 sockaddr 结构体相同，可以强制转换成 sockaddr。\n\n```c++\nstruct sockaddr_in {\n    short int sin_family;         // 协议族 (AF_INET)\n    unsigned short int sin_port;  // 16位端口号 ，大端序。用htons(整数的端口)转换。\n    struct in_addr sin_addr;      // IP地址\n    unsigned char sin_zero[8];    // 填充，使得结构体大小与sockaddr一致（不用管）\n};\n\nstruct in_addr {\n    unsigned long s_addr;         // 32位的IP地址，大端序 (使用网络字节序)\n};\n```\n\n因此，在实际的网络编程中，先定义 sockaddr_in结构体把相关信息存储之后，再强制转换成 sockaddr，毕竟提供的API接受的类型是 sockaddr。\n\n## gethostbyname函数\n\n```c++\n#include <netdb.h>\n\nstruct hostent *gethostbyname(const char *name);\n\nstruct hostent {\n    char  *h_name;       \t   // 主机的正式名称\n    char **h_aliases;   \t // 主机的别名列表\n    int    h_addrtype;   \t // 地址类型，通常为 AF_INET\n    int    h_length;     \t   // 地址长度，通常为 4（对于 IPv4）\n    char **h_addr_list;  \t//地址列表，可能包含多个 IP 地址（网络字节序）\n};\n\n#define h_addr h_addr_list[0] // For backward compatibility.\n```\n\n这个函数的优点就是不仅可以直接传递IP地址（字符串类型或字符数组类型），还支持传递域名。根据返回的hostent结构体中的成员，添加到所需的其它结构体中。\n\n如下是部分应用核心代码：\n\n```c++\n    // 定义主机名\n    const char* hostname = \"www.example.com\";\n    \n    // 获取主机信息\n    struct hostent* host_info = gethostbyname(hostname);\n\n    // 设置服务器地址结构\n    struct sockaddr_in server_addr;\n    std::memset(&server_addr, 0, sizeof(server_addr));\n    server_addr.sin_family = AF_INET;\n    server_addr.sin_port = htons(80); // HTTP 端口号\n    std::memcpy(&server_addr.sin_addr, host_info->h_addr_list[0], host_info->h_length);\n```\n\n## 字符串IP与大端序IP地址的转换\n\nC语言提供几个库函数，用于字符串格式的IP和大端序IP的相互转换，用于网络通讯的服务端程序中。\n\n`inet_addr`：将字符串形式的 IP 地址转换为 `in_addr_t`\n\n```c++\nin_addr_t inet_addr(const char *cp);\n\n/*\n    const char *ip = \"127.0.0.1\";\n    in_addr_t addr = inet_addr(ip);\n*/\n```\n\n`inet_aton`：将字符串形式的 IP 地址转换为 `in_addr` 结构体\n\n```c++\nint inet_aton(const char *cp, struct in_addr *inp);\n\ncp: 指向一个以点分十进制表示的IPv4地址的字符串\ninp: 指向一个 in_addr 结构体，用于存储转换后的IP地址\n    \n/*\n    const char *ip = \"127.0.0.1\";\n    struct in_addr addr;\n\n    if (inet_aton(ip, &addr) == 0) {\n        std::cerr << \"Invalid IP address\" << std::endl;\n    } else {\n        std::cout << \"inet_aton: \" << addr.s_addr << std::endl;\n    }\n*/\n```\n\n`inet_ntoa`：将 `in_addr` 结构体中的 IP 地址转换为字符串形式\n\n```c++\nchar *inet_ntoa(struct in_addr in);\n\n/*\n    struct in_addr addr;\n    addr.s_addr = inet_addr(\"127.0.0.1\");\n\n    char *ip = inet_ntoa(addr);\n    if (ip == nullptr) {\n        std::cerr << \"Error converting address\" << std::endl;\n    } else {\n        std::cout << \"inet_ntoa: \" << ip << std::endl;\n    }\n*/\n```\n\n注：typedef unsigned int in_addr_t\t代表32位大端序的IP地址。","tags":["网络编程"],"categories":["technology"]},{"title":"主机字节序和网络字节序","url":"/2024/08/10/主机字节序和网络字节序/","content":"\n<!-- toc -->\n\n## 主机字节序\n\n主机字节序是指在特定计算机系统中数据的存储顺序。常见的字节序有两种：\n\n- **大端字节序（Big-endian）：** 数据的高字节存储在低地址端。例如，数值 0x12345678 将按顺序存储为 0x12 0x34 0x56 0x78\n- **小端字节序（Little-endian）：** 数据的低字节存储在低地址端。例如，数值 0x12345678 将按顺序存储为 0x78 0x56 0x34 0x12\n\n```c++\nint main(int argc, char* argv[]) {\n\n    int num = 0x61626364;   // abcd\n\n    // 大端 ： 0x61626364 --》 abcd\n    \n    // 小端 ： 0x64636261 --》 dcba\n\n    char* str = (char*)&num;  // 将num的地址转为char*类型，逐字节检查;如果是 a，大端；如果是 d，小端\n\n    if (*str == 'd') {  // 检查最低字节\n        printf(\"小端\\n\");\n    }\n    else if (*str == 'a') {\n        printf(\"大端\\n\");\n    }\n\n    return 0;\n}\n```\n\n核心还是取到一个可识别的字节对应的内容，一般取 int 类型数据的地址，转换为 char* 代表第一个字节（从左往右看）。因此，也可以有如下代码，原理相同：\n\n```c++\n#include <iostream>\n\nint main() {\n    unsigned int num = 1; // 定义一个整数\n    char *byte = reinterpret_cast<char*>(&num); // 将整数的地址转换为字符指针\n\n    if (byte[0] == 1) {\n        std::cout << \"小端字节序\" << std::endl; // 如果最低位字节在最前面，说明是小端\n    } else {\n        std::cout << \"大端字节序\" << std::endl; // 如果最高位字节在最前面，说明是大端\n    }\n\n    return 0;\n}\n\n```\n\n## 网络字节序\n\n网络字节序是一种标准化的数据表示方式，用于在不同计算机系统之间传输数据。为了确保数据在网络传输中保持一致，**网络协议（如 TCP/IP）规定采用大端字节序**。\n\n## 主机字节序和网络字节序的转换\n\n`htons`（Host to Network Short）：将 16 位主机字节序转换为网络字节序\n\n`htonl`（Host to Network Long）：将 32 位主机字节序转换为网络字节序\n\n`ntohs`（Network to Host Short）：将 16 位网络字节序转换为主机字节序\n\n`ntohl`（Network to Host Long）：将 32 位网络字节序转换为主机字节序\n\n在网络编程中，数据收发的过程中有自动转换机制，不需要程序员手动转换，**只有向 sockadd_in 结构体成员变量填充数据时，才需要考虑字节序的问题**。\n\n```c++\nstruct sockaddr_in server_addr;\nmemset(&server_addr, 0, sizeof(server_addr));\nserver_addr.sin_family = AF_INET;\nserver_addr.sin_port = htons(port);\t\t// 端口号转换为网络字节序\nserver_addr.sin_addr.s_addr = inet_addr(ip.c_str());  \n```\n\nsockaddr_in 结构体成员 sin_port 接受 16位的大端序，因此用 htons 处理端口 port\n\ninet_addr 函数已经返回了网络字节序（big-endian）的地址，也就用不着 htonl 处理网络地址 ip","tags":["网络编程"],"categories":["technology"]},{"title":"服务器应该设置SO_REUSEADDR选项","url":"/2024/08/10/服务器应该设置SO-REUSEADDR选项/","content":"\n你可能看到过这个错误提示：Address already in use（地址已经被使用了）。往往要几分钟后才能重启，那我们如何立即重启服务器呢？在此之前，先理解如下两件事情：\n\n1. TCP 的 TIME-WAIT状态\n2. TCP 连接的四元组（本地地址、本地端口、远端地址、远端端口）\n\nTCP 连接中进行主动关闭（发送第一个FIN）的那一端会进入 TIME-WAIT 状态，并在此状态停留 2MSL，在此期间，该套接字的地址和端口仍然被占用，无法立即重新绑定到同样的地址和端口。这为我们在看到的行为提供了第一条线索：客户端主动关闭时，可以重启连接的任意一端，不会有什么问题，但当服务器主动关闭时，就无法重启，这是由于前一个连接仍然处于 TIME-WAIT 状态。\n\n如果服务器重启，并且有客户端连接上来，就会有一条新的连接，这条连接可能都不是连接到同一台远端主机上的。如前所述，一条 TCP 连接可以由本地和远程地址以及端口号完全指定，所以，即使来自同一台远程主机的客户端连接到服务器上，只要它使用的端口号和前一个连接不同，就不会有什么问题。这是因为 `TIME_WAIT` 状态仅影响特定的四元组（`<源IP, 源端口, 目标IP, 目标端口>`），而不是整个服务器或客户端。\n\n基于这些事实，重启服务器时 TCP 返回的错误就会让我们感到很疑惑。实际上问题并不在于 TCP，而是出在套接字API 上，TCP 只要求四元组是唯一的，而套接字 API 则需要两个调用才能完整地指定四元组。当 API 调用 bind 时，并不知道接下来是否会调用 connect，如果调用还需要在指定一个唯一的连接，还是尝试重用已经存在的那个连接之间作出选择。\n\n幸运的是，这个问题有一种很简单的解决方案。可以先设置套接字选项 SO_REUSEADDR，允许一个套接字在 TIME_WAIT 状态下立即重新绑定到相同的地址和端口。\n\n如果不设置 `SO_REUSEADDR`，当你尝试重新启动一个服务器程序（特别是在调试时），由于旧连接仍在 TIME_WAIT 状态，尝试绑定到相同的端口会导致 \"Address already in use\" 错误。这时服务器无法重新绑定到原有端口，可能会导致服务不可用。\n\n在某些情况下，多个进程可能希望绑定到相同的地址和端口进行监听。这种情况通常出现在使用 UDP 协议或多个服务进程间共享一个监听端口时。在这种情况下，`SO_REUSEADDR` 允许多个套接字绑定到相同的地址和端口（只要每个套接字的协议不同，或者每个套接字是加入了不同的多播组的 UDP 套接字）。\n\n---\n\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"理解TCP的有序释放操作","url":"/2024/08/10/理解TCP的有序释放操作/","content":"\n<!-- toc -->\n\n## shutdown调用\n\nclose 函数会关闭读写，但如果你想控制关闭读端、关闭写端或者全部关闭，那么 shutdown 可以做到。\n\n```c++\nint shutdown(int sockfd, int how);\n\n/*\nsockfd: 套接字描述符，表示要操作的连接\n\nhow: 指定如何关闭连接，可以取以下三个值：\n\tSHUT_RD (0): 关闭读取功能。该套接字不再接收数据，任何到达的数据包将被丢弃。如果有未处理的接收数据，会继续保留，直到被读取完毕\n\tSHUT_WR (1): 关闭写入功能。该套接字不再允许发送数据。此时，TCP 会发送一个 FIN 包，告诉对端本地已完成数据发送，但仍可以接收数据\n\tSHUT_RDWR (2): 关闭读写功能。相当于同时执行 SHUT_RD 和 SHUT_WR，既不能发送数据，也不能接收数据\n*/\n```\n\n关闭套接字和调用 shutdown 之间有很大的区别。首先，即使将 how 设置为 2 来调用 shutdown，实际上也并没有“关闭”套接字。也就是说，并没有释放套接字及其资源（how 被设置为 0 或 2 时可能会将接收缓冲区释放掉）。\n\n同时还要注意，调用 shutdow 时，会影响到所有打开了那个套接字的进程。比如，将 how 设置为 1 调用 shutdow 会使套接字的所有持有者都无法对其进行写操作。相反，如果调用 close 或 closesocket，套接字的其他持有者仍然能够像什么事情都没有发生一样使用它。\n\n最后这一点通常可以为我们提供一些便利。用 how = 1 来调用shutdow 时，不管其他进程是否打开了这个套接字，都可以保证对等实体会收到一个EOF。调用 close 或 closesocket 就无法确保这一点，因为在套接字的引用计数减少到 0 之前，它都不会将 FIN 发送给对等实体。也就是说，所有进程关闭套接字后，它才将 FIN 发送给对等实体。\n\n## 有序释放\n\n有序释放的目的是确保两端都能在连接拆除之前收到所有来自其对等实体的数据。\n\n在需要通知对端自己已经完成发送但仍希望接收对端的数据时，可以使用 `shutdown(sockfd, SHUT_WR)`，这种方式可以实现连接的有序释放，而不是突然中断连接。因为立即关闭连接是非常粗暴的，对于想要关闭连接的一方，可以选择仅关闭当前套接字的写入功能，读取功能依旧还在，这是为了防止对等实体发送的数据丢失。\n\n对等实体收到 EOF，会关闭连接。在知道我这边已经关闭写入功能，就明白我后续不会发送任何数据了，这是要断开连接的意思，而我这边读取功能还没有关闭，所以对等实体会把所有消息和一个FIN一起发给我。我这边把对等实体发送过来的数据处理之后，收到 EOF，就知道我已经收到对等实体所有的数据，也就关闭连接了。\n\n---\n\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"理解TCP的写操作","url":"/2024/08/10/理解TCP的写操作/","content":"\n<!-- toc -->\n\n## 从应用程序角度看写操作\n\n用户程序对一条 TCP 连接进行写调用时，首先会将数据从用户缓冲区复制到内核中去。从此之后，可能发生的情况就与连接的状态有关了。TCP 可能发送全部、部分或者不发送数据。稍后会对 TCP 的这个决定做进一步的研究，但首先要从用户应用程序的角度来看看这个写操作的动作。\n\n![write.png](/images/2024/08/10/ae7fcf20-56d1-11ef-9064-ddcfd7bb5524.png)\n\n假设一个 n 字节的写操作返回值 n 时，这 n 字节已经被发送给对等实体，甚至已经被确认了，这是很有诱惑力的一种想法。但事情并不是这样的。TCP 会尽可能地将它所能发送的数据都发送出去（有可能一个也没有），然后立即返回值 n。应用程序无法判定发送了多少数据，也无法判断对等实体是否对其进行了确认。\n\n总的来说，除非 TCP 发送缓冲区满了，否则写操作是不会被阻塞的。也就是说，写操作基本上总是能立即返回的，但它们返回时并不能保证对所写数据进行了哪些处理。\n\n从应用程序的角度来看，数据已经写入，因此 TCP 的“可靠传输”要保证它抵达对等实体。实际上，写操作返回时，写操作写出的部分或全部数据可能还在排队等待传输，所以，此时不管是主机还是对等应用程序崩溃了，数据都会丢失。\n\n通过对这些情况进行总结，我们认为，对 TCP 连接使用写操作时，最好将写操作理解成将数据复制到发生队列，并通知 TCP 此队列中有新数据的一种操作。可以将 TCP 的行为作为收到这种通知后的结果，但要把它看作本质上异步于写操作的一种行为。\n\n## 从TCP角度看写操作\n\n如前所述，写操作负责将数据从应用程序的写缓冲区搬移到内核中去，并通知 TCP 有来自应用程序的新数据需要处理。现在来看看 TCP 使用的一些标准，这些标准决定了 TCP 能否将刚到达的数据立即发送出去，如果可以，发送多少。\n\n满足下列一项就会发送：\n\n![满足一项就发送.png](/images/2024/08/10/a8fd2250-56d1-11ef-9064-ddcfd7bb5524.png)","tags":["网络编程"],"categories":["technology"]},{"title":"要认识到TCP是一个可靠的，但并不绝对可靠的协议","url":"/2024/08/10/要认识到TCP是一个可靠的，但并不绝对可靠的协议/","content":"\n<!-- toc -->\n\n我们会误以为只要基于 TCP 编程，那么通信的数据必然能够到达对端主机，毕竟 TCP 是可靠的传输协议。然而， TCP 是处在传输层的协议，其可靠性只针对传输层，但是消息最终要达到应用层才算有价值。从传输层到应用层的消息会不会出现问题，可不由 TCP 来保证。\n\n数据流从应用程序 A 通过它所在主机的 TCP/IP 栈向下传输，经过几台中间路由器，通过应用程序 B 所在主机的TCP/IP 栈向上传输，最后抵达应用程序 B。一个 TCP 段离开应用程序 A 所在主机的 TCP 层时，会被封装到一个数据报中，传送给其对等实体主机。它所走的路由可能要经过很多路由器，但如下图所示，这些路由器都没有TCP层，它们只是转发了IP数据报。\n\n![TCP可靠之处.png](/images/2024/08/10/ba1a28b0-56c4-11ef-a3e6-51327ae276c7.png)\n\n当一个段抵达应用程序 B 所在主机的 TCP 层时，唯一可以确定的就是这个段已经到达了，但它可能损坏了，可能是重复的数据，可能是错序的，或者是由于其他一些原因无法接受的。注意，发送端 TCP 无法对这些抵达接收端 TCP的段做出任何保证。但接收端 TCP 要向发送端 TCP 确认，也就是说它 ACK 的数据以及在此数据之前到达的所有数据在 TCP 层都已经正确收到了，发送端 TCP 可以安全地删除这些数据的副本了。这并不意味着已经将数据传送，或者总是可以将数据传送给应用程序。比如，接收端主机可能在刚刚对数据进行了 ACK，但应用程序还没有将其读走之前，就崩溃了。\n\n## 故障模式\n\nTCP 是一个端对端协议，也就是说它自己要在对等实体之间提供可靠的传输机制。但是，认识到“端点”位于对等的 TCP层，而不是对等的应用程序中是非常重要的。要求进行端到端确认的应用程序必须自身提供此项功能。\n\n看看其他一些“常见的”故障模式。只要两个对等实体仍然连着，TCP 就能保证将数据按序无损坏地传送。只有连接中断时才会出现故障。什么类型的事件会造成这种中断呢?有三种情况可能引发这类问题：\n\n1. 永久或临时的网络中断\n2. 对等的应用程序崩溃\n3. 运行对等应用程序的主机崩溃\n\n## 网络中断\n\n路由器或骨干链路损毁，某人被本地以太网电缆绊倒，踢松了网线……很多原因都会造成网络的中断。在端点之外发生的损坏通常都是临时的，因为路由协议会发现问题，并使路由绕开出问题的节点。\n\n端点出现问题，通常没有备用的路径，所以问题会一直存在，直到端点修复为止。\n\n除非中间路由器发送一条ICMP报文，说明目的网络或主机不可达，否则应用程序及其 TCP/IP 栈都无法立即获知中断的发生。在这种情况下，发送端最终会超时，并重新发送所有未被确认的段。在发送端 TCP 放弃发送、丢弃连接并报告错误之前会一直持续这种操作。\n\n在传统 BSD 栈中，发送端 TCP 会在重传 12 次(大约 9 分钟)之后放弃。如果读操作被挂起，会返回一条错误状况，并将 errno 置为 ETIMEDOUT。如果没有挂起的读操作，接下来的写操作就会失败，根据信号是忽略还是捕获，写操作失败时会携带一个 SIGPIPE 信号，或 EPIPE 错误。\n\n如果某个中间路由器无法转发包含段的 IP 数据报，它会向源端主机发送一个 ICMP 报文，说明目的网络或主机不可达。在这种情况下，有些实现会返回 ENETUNREACH 或 EHOSTUNREACH 作为错误原因。\n\n## 对等实体崩溃\n\n接下来，我们来看看如果对等应用程序崩溃或者终止，会发生什么情况。首先要意识到从应用程序的角度来看，对等实体崩溃与对等实体调用 c1ose 及 exit 是无法区分的。**在这两种情况下，对等实体的 TCP 都会向我们的 TCP 发送一个 FIN**。FIN 作为 EOF 使用，表示发送它的那一端已经没有数据发送了。这并不（一定）表示发送 FIN 的这一端已经退出了，甚至无法说明它不愿意接收更多数据。\n\n## 对等实体的主机崩溃\n\n要研究的最后一种故障模式是对等实体主机的崩溃。这种故障模式与对等实体崩溃不同，因为对等实体的 TCP 无法通过 FIN 来通知我们的应用程序，其对等实体已经不在运行了。\n\n在对等实体主机重启之前，这个错误看起来和网络故障一样：对等实体的TCP不再应答了。和网络故障的情况一样，我们的应用程序 TCP 会持续重传未经确认的段。最终，如果对等实体主机没有重启，它就会放弃并向应用程序返回一条 ETIMEDOUT 错误。\n\n如果在我们的 TCP 放弃并丢弃连接之前，对等实体主机就重启了，会发生什么情况呢？在这种情况下，会有重传的段到达对等实体刚刚重启的主机，而这台主机并没有连接记录。在这种情况下，TCP 技术规范要求接收端主机向发送端主机回送一个 RST。这样发送端主机才会丢弃连接，应用程序才会收到一条 ECONNRESET 错误(如果它有挂起的读操作的话)，或者会在下一条写操作时得到一个 SIGPIPE 信号或 EPIPE 错误。\n\n---\n\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"记住：TCP是一种流协议","url":"/2024/08/10/记住：TCP是一种流协议/","content":"\n<!-- toc -->\n\nTCP 是一种流协议，这就意味着数据是以字节流的形式传递给接收者的，**没有固有的”报文”或”报文边界”的概念**。从这方面来说，读取 TCP 数据就像从串行端口读取数据一样——无法预先得知在一次指定的读调用中会返回多少字节。\n\n## 流协议存在的问题\n\n发送的数据没有边界，接收方可能对接收到的数据存在多读或少读的问题。为了说明这一点，我们假设在主机 A 和主机 B 的应用程序之间有一条 TCP 连接，主机 A 上的应用程序向主机 B 发送一条报文。进一步假设主机 A 有两条报文要发送，并两次调用 send 来发送，每条报文调用一次。很自然就会想到从主机 A 向主机 B 发送的两条报文是作为两个独立实体，在各自的分组中发送的。\n\n![主机A和主机B通信.png](/images/2024/08/10/b584bcb0-56b1-11ef-9b76-6d6092cc6dd4.png)\n\n但不幸的是，实际的数据传输过程很可能不会遵循这个模型。\n\n主机A上的应用程序会调用send，我们假设这条写操作的数据被封装在一个分组中传送给B。**实际上，send通常只是将数据复制到主机A的TCP/IP栈中，就返回了。由TCP来决定（如果有的话）需要立即发送多少数据**。做这种决定的过程很复杂，取决于很多因素，比如发送窗口（当时主机B能够接收的数据量），拥塞窗口（对网络拥塞的估计），路径上的最大传输单元（沿着主机A和B之间的网络路径一次可以传输的最大数据量），以及连接的输出队列中有多少数据。\n\n下图只显示了主机A的TCP封装数据时可能使用的诸多方法中的4种\n\n![数据分割.png](/images/2024/08/10/44a4f210-56b3-11ef-9b76-6d6092cc6dd4.png)\n![注解M1和M2.png](/images/2024/08/10/487b0050-56b3-11ef-9b76-6d6092cc6dd4.png)\n\n现在，我们从主机 B 应用程序的角度来看这种情形。总的来说，主机 B 应用程序任意一次调用 recv 时，都不会对 TCP 发送给它的数据量做任何假设。比如，当主机 B 应用程序读取第一条报文时，可能会出现下列 4 种结果：\n\n1. 没有数据可读，应用程序阻塞，或者 recv 返回一条指示说明没有数据可读。到底会发生什么情况取决于套接字是否标识为阻塞，以及主机B的操作系统为系统调用 recv 指定了什么样的语义\n2. 应用程序获取了报文 M1 中的部分而不是全部数据。比如，发送端TCP像上图 D 那样对数据进行分组就会发生这种情况\n3. 用程序获取了报文 M1 中所有的数据，除此之外没有任何其他内容。如果像上图 A 那样对数据分组就会发生这种情况\n4. 应用程序获取了报文M1的所有数据，以及报文M2的部分或全部数据。如果像上图 B 或上图 C 那样对数据进行分组就会发生这种情况\n\n注：实际可能的结果不止4种，但我们忽略了出错和EOF之类的结果。我们还假设应用程序读取了所有可读的数据。\n\nTCP 是一个流协议（stream protocol），**尽管数据是以 IP 分组的形式传输的，但分组中的数据量与 send 调用中传送给 TCP 多少数据并没有直接关系**。而且，接收程序也没有什么可靠的方法可以判断数据是如何分组的，因为在两次 recv 调用之间可能会有多个分组到来。\n\n**TCP会记录它发送了多少字节，以及确认的字节，但它不会记录这些字节是如何分组的**。实际上，有些实现在重传丢失分组的时候传送的数据可能比原来的多一些或少一些。\n\n## 解决方法\n\n- 固定报文长度\n- 记录结束标记来分割记录，要注意在数据中如果出现结束标记，需要转义以表明此为数据而非结束标记\n- 每条报文前面加一个首部，首部至少记录有实际数据的长度\n\n![自实现协议.png](/images/2024/08/10/baf4a4d0-56b1-11ef-9b76-6d6092cc6dd4.png)\n\n---\n\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"基本套接字 API 的回顾","url":"/2024/08/10/基本套接字-API-的回顾/","content":"\n<!-- toc -->\n\n![客户端和服务端的通信.png](/images/2024/08/10/06fe8b80-56b1-11ef-9b76-6d6092cc6dd4.png)\n\n基本套接字 API 概览\n\n`socket()`: 创建一个套接字\n\n`bind()`: 绑定套接字到一个地址和端口\n\n`listen()`: 监听端口上的连接请求（用于服务器）\n\n`accept()`: 接受连接请求（用于服务器）\n\n`connect()`: 连接到一个远程地址（用于客户端）\n\n`send()`: 发送数据\n\n`recv()`: 接收数据\n\n`close()`: 关闭套接字\n\n注：在 UNIX 中，可以像文件描述符那样，直接用套接字描述符来调用 read 和 write。但正如我们曾经提到的那样，Windows 并没有用套接字语法重载这些系统调用，因此，只能用 recv 和 send 来代替。除了包含一个额外参数，这些调用与 read 和 write 是一样的。如果你用的UDP的话，那么你应该使用 recvform 和 sendto。\n\n## socket\n\n功能：返回一个文件描述符，它是一个用于标识新创建的套接字的引用\n\n```c++\n#include <sys/types.h>         \n#include <sys/socket.h>\n\nint socket(int domain, int type, int protocol);\n\n/*\n  int socket_fd = socket(AF_INET, SOCK_STREAM, 0);\n  if (socket_fd < 0) {\n    perror(\"socket error\");\n    return -1;\n  }\n  */\n```\n\n`domain`（指定通信的协议族） 核心参数:：\n\n- AF_LOCAL: 本地进程间通信\n- AF_INET（常用）: 远端基于IPV4进程间通信\n- AF_INET6: 远端基于IPV6进程间通信\n\n`type`（指定套接字的类型） 核心参数：\n\n- SOCK_STREA（常用）: 流套接字，提供面向连接的稳定数据传输（TCP）\n- SOCK_DGRAM: 数据报套接字，提供无连接的数据传输（UDP）\n- SOCK_RAW: 原始套接字，提供对底层协议的直接访问\n\n`protocol`（指定要使用的协议） 核心参数：通常为 0，表示自动选择合适的协议。对于 AF_INET 和 SOCK_STREAM ，0 通常表示 TCP，对于 AF_INET 和 SOCK_DGRA，0 通常表示 UDP\n\n## bind\n\n功能：绑定套接字到一个地址和端口\n\n```c++\n#include <sys/types.h>         \n#include <sys/socket.h>\n\nint bind(int sockfd, const struct sockaddr *addr,socklen_t addrlen);\n\n/*\n  struct sockaddr_in server_addr;\n  memset(&server_addr, 0, sizeof(server_addr));\n  server_addr.sin_family = AF_INET;\n  server_addr.sin_port = htons(port);\n  server_addr.sin_addr.s_addr = inet_addr(ip.c_str());\n  \n  int ret = bind(socket_fd, (struct sockaddr *)&server_addr, sizeof(server_addr));\n  if (ret < 0) {\n    perror(\"bind error\");\n    return -1;\n  }\n*/\n```\n\nsockfd: 就是前面 socket 创建成功的返回值\n\naddr: 结构体 sockaddr，用于**存放服务端的协议族、端口和地址信息**。客户端的 connect 函数和服务端的 bind 函数需要这个结构体\n\naddrlen: 是参数 addr 的长度，用 sizeof 计算 \n\n---\n\n```c++\nstruct sockaddr {\n    unsigned short sa_family;    // 协议族 (AF_INET, AF_INET6, etc.)\n    char sa_data[14];            // 地址数据 (协议相关)\n};\n```\n\n存放协议族、端口和地址信息。客户端的 connect 函数和服务端的 bind 函数需要这个结构体。\n\nsockaddr 结构体是为了统一地址结构的表示方法，统一接口函数，但是这个结构体并不方便使用，因此定义了等价的 sockaddr_in 结构体，它的大小和 sockaddr 结构体相同，可以强制转换成 sockaddr。\n\n```c++\nstruct sockaddr_in {\n    short int sin_family;         // 协议族 (AF_INET)\n    unsigned short int sin_port;  // 16位端口号 ，大端序。用htons(整数的端口)转换。\n    struct in_addr sin_addr;      // IP地址\n    unsigned char sin_zero[8];    // 填充，使得结构体大小与sockaddr一致（不用管）\n};\n \nstruct in_addr {\n    unsigned long s_addr;         // 32位的IP地址，大端序 (使用网络字节序)\n};\n```\n\n因此，在实际的网络编程中，先定义 sockaddr_in结构体把相关信息存储之后，再强制转换成 sockaddr，毕竟提供的API接受的类型是 sockaddr。\n\n## listen\n\n功能：将一个套接字设置为被动模式，以便接收来自远程主机的连接请求\n\n```c++\n#include <sys/types.h>          \n#include <sys/socket.h>\n\nint listen(int sockfd, int backlog);\n\n/*\n  #define LISTEN_NUM 10\n  \n  ret = listen(socket_fd, LISTEN_NUM);\n  if (ret < 0) {\n    perror(\"listen error\");\n    return -1;\n  }\n*/\n```\n\n`sockfd`: 就是前面 socket 创建成功的返回值，而且必须 bind 之后的 sockfd\n\n`backlog`: 会影响到半连接队列和全连接队列的大小\n\n![全连接半连接队列.png](/images/2024/08/10/ff2c2250-56b0-11ef-9b76-6d6092cc6dd4.png)\n\n从上面这种图可以看到，listen 接受到客户端连接请求之后，开始进行三次握手。如果第一次握手成功，连接被加入到半连接队列；如果第三次握手也成功，连接被加入到全连接队列。三次握手成功，加入到全连接队列的连接可以用于后续通信，而 accept 实际上就是去全连接队列里面去取这些连接出来用于通信的。\n\n那么多大的 backlog 是合适的？\n\n- 如果你的接口处理连接的速度要求非常高，或者做压力测试，很有必要调高这个值\n- 如果业务接口本身性能不好，accept 取走已连接的速度较慢，那么把 backlog 调的再大也没有用，只会增加连接失败的可能性\n\n关于 backlog 传递的值究竟会为多少（你传递的值未必就会成为实际的 backlog 最终值），需要去看内核的实现，详细可见此文：[三次握手背后的秘密：半连接队列和全连接队列](https://www.yuque.com/xiaoyang-wyxle/gdb3m3/xntqpx4a75l074qg)\n\n## accept\n\n功能： 系统调用 sockfd 的全连接队列中的第一个连接请求，创建一个新的连接套接字，并返回一个新的文件描述符\n\n```c++\n#include <sys/types.h>  \n#include <sys/socket.h>\n\nint accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);\nint accept4(int sockfd, struct sockaddr *addr, socklen_t *addrlen, int flags);\n\n/*\n  struct sockaddr_in client_addr;\n  socklen_t client_len = sizeof(client_addr);\n  int listen_fd = accept(socket_fd, (struct sockaddr *)&client_addr, &client_len);\n  if (listen_fd < 0) {\n    perror(\"accept error\");\n    return -1;\n  }\n*/\n```\n\n`sockfd`: 就是前面 socket 创建成功的返回值，而且必须 listen 之后的 sockfd\n\n`addr`: 指向 `sockaddr` 结构体的指针，用于**存储客户端的地址信息**（新连接的对等实体地址）。如果不需要客户端地址，可以传递 `NULL`。\n\n`flags` (accept4 专用): 额外的标志，可以是以下值的按位或组合：\n\n- SOCK_NONBLOCK: 使返回的文件描述符变为非阻塞模式\n- SOCK_CLOEXEC: 在执行 exec 系列函数时自动关闭文件描述符\n\n也就是，我们后续服务器和客户端实际通信的套接字是 accept 函数返回的文件描述符。此前的 socket 创建并返回的文件描述符仅仅用于添加相关信息并和客户端成功建立连接，并不用于后续通信，却是后续通信不可或缺的基础。\n\n注：这里的 addr 参数是新建的客户端的结构体，而非之前创建用于 bind 参数的 addr 参数（它属于服务端）。\n\n## recv\n\n功能：用于从套接字接收消息\n\n```c++\n#include <sys/types.h>\n#include <sys/socket.h>\n\nssize_t recv(int sockfd, void *buf, size_t len, int flags);\n\n/*\n  char buf[1024] = {0};\n  ssize_t bytes_read = recv(listen_fd, buf, sizeof(buf) - 1,0);\n  if (bytes_read < 0) {\n    perror(\"read error\");\n  } else if (bytes_read == 0) {\n    std::cout << \"Client disconnected.\" << std::endl;\n  } else {\n    buf[bytes_read] = '\\0'; \n    std::cout << \"Received data: \" << buf << std::endl;\n  }\n*/\n```\n\n`sockfd`: 一个有效的套接字文件描述符，从中接收数据。就是之前调用 accept 之后返回的套接字文件描述符\n\n`buf`: 一个指向接收数据的缓冲区的指针\n\n`len`: 缓冲区的长度，即最多接收的字节数\n\n`flags`: 控制接收操作的标志。常用的标志包括：\n\n- 0: 默认标志，无特殊行为。\n- MSG_DONTWAIT: 使操作非阻塞\n- MSG_PEEK: 查看数据但不将其从缓冲区中移除\n- MSG_WAITALL: 等待所有请求的数据被接收\n\n## send\n\n功能：用于从套接字发送消息\n\n```c++\n#include <sys/types.h>\n#include <sys/socket.h>\n\nssize_t send(int sockfd, const void *buf, size_t len, int flags);\n\n/*\n  const char *message = \"Hello, client!\";\n  ssize_t bytes_sent = send(listen_fd, message, std::strlen(message), 0);\n  if (bytes_sent < 0) {\n    std::cerr << \"Error sending message\" << std::endl;\n  } else {\n    std::cout << \"Sent \" << bytes_sent << \" bytes to client\" << std::endl;\n  }\n*/\n```\n\n`sockfd`: 一个有效的套接字文件描述符，通过该套接字发送数据\n\n`buf`: 指向包含待发送数据的缓冲区的指针\n\n`len`: 缓冲区中待发送数据的长度\n\n`flags`: 控制发送操作的标志。常用的标志包括：\n\n- 0: 默认标志，无特殊行为\n- MSG_DONTWAIT: 使操作非阻塞\n- MSG_OOB: 发送带外数据\n- MSG_NOSIGNAL: 阻止发送 SIGPIPE 信号\n\n## connect\n\n功能：用于连接服务端\n\n```c++\n#include <sys/types.h>          /* See NOTES */\n#include <sys/socket.h>\n\n int connect(int sockfd, const struct sockaddr *addr,socklen_t addrlen);\n\n/*\n    // 配置服务器地址\n    server_addr.sin_family = AF_INET;\n    server_addr.sin_port = htons(12345); // 服务器端口号\n    server_addr.sin_addr.s_addr = inet_addr(\"127.0.0.1\"); // 服务器地址\n\n    // 连接到服务器\n    if (connect(sockfd, (struct sockaddr *)&server_addr, sizeof(server_addr)) < 0) {\n        perror(\"connect\");\n        close(sockfd);\n        exit(EXIT_FAILURE);\n    }\n*/\n```\n\n## 阻塞与非阻塞\n\n阻塞：在进程/线程中，发起一个调用时，**在调用返回之前，进程/线程会阻塞等待**，等待中的进程/线程会让出CPU\n\n非阻塞：在进程/线程中，发起一个调用时，**会立即返回**\n\n前面介绍的 API 中，会阻塞的四个函数有 connect()、accept()、send()、recv()\n\n阻塞IO与非阻塞IO的应用场景：\n\n- 在穿透的网络服务端程序中（每连接每线程/进程），采用阻塞IO\n- 在IO复用的模型中，事件循环（select、poll、epoll）不能被阻塞在任何环节，应该采用非阻塞IO\n\n## 实战代码\n\n服务端\n\n```c++\n#include <iostream>\n#include <cstring>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include <sys/socket.h>\n#include <unistd.h>\n\n#define LISTEN_NUM 10\n\nint main(int argc, char *argv[]) {\n  if (argc != 3) {\n    std::cout << \"./server 172.17.32.175 8888\" << std::endl;\n    return -1;\n  }\n\n  std::string ip = argv[1];\n  int port = std::stoi(argv[2]);\n\n  int socket_fd = socket(AF_INET, SOCK_STREAM, 0);\n  if (socket_fd < 0) {\n    perror(\"socket error\");\n    return -1;\n  }\n\n  struct sockaddr_in server_addr;\n  memset(&server_addr, 0, sizeof(server_addr));\n  server_addr.sin_family = AF_INET;\n  server_addr.sin_port = htons(port);\n  server_addr.sin_addr.s_addr = inet_addr(ip.c_str());\n\n  int ret = bind(socket_fd, (struct sockaddr *)&server_addr, sizeof(server_addr));\n  if (ret < 0) {\n    perror(\"bind error\");\n    return -1;\n  }\n\n  ret = listen(socket_fd, LISTEN_NUM);\n  if (ret < 0) {\n    perror(\"listen error\");\n    return -1;\n  }\n\n  struct sockaddr_in client_addr;\n  socklen_t client_len = sizeof(client_addr);\n  int listen_fd = accept(socket_fd, (struct sockaddr *)&client_addr, &client_len);\n  if (listen_fd < 0) {\n    perror(\"accept error\");\n    return -1;\n  }\n\n  char buf[1024] = {0};\n  ssize_t bytes_read = recv(listen_fd, buf, sizeof(buf) - 1,0);\n  if (bytes_read < 0) {\n    perror(\"read error\");\n  } else if (bytes_read == 0) {\n    std::cout << \"Client disconnected.\" << std::endl;\n  } else {\n    buf[bytes_read] = '\\0';\n    std::cout << \"Received data: \" << buf << std::endl;\n  }\n\n  const char *message = \"Hello, client!\";\n  ssize_t bytes_sent = send(listen_fd, message, std::strlen(message), 0);\n  if (bytes_sent < 0) {\n    perror(\"send error\");\n    return -1;\n  } else {\n    std::cout << \"Sent message: \" << message << std::endl;\n  }\n\n\n  close(listen_fd);\n  close(socket_fd);\n\n  return 0;\n}\n```\n\n客户端\n\n```c++\n#include <iostream>\n#include <cstring>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include <sys/socket.h>\n#include <unistd.h>\n\nint main(int argc, char *argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <server_ip> <server_port> <message>\" << std::endl;\n    return -1;\n  }\n\n  std::string server_ip = argv[1];\n  int server_port = std::stoi(argv[2]);\n  std::string message;\n  std::cout<<\"input message : \";\n  std::cin>>message;\n\n  int sock_fd = socket(AF_INET, SOCK_STREAM, 0);\n  if (sock_fd < 0) {\n    perror(\"socket error\");\n    return -1;\n  }\n\n  struct sockaddr_in server_addr;\n  memset(&server_addr, 0, sizeof(server_addr));\n  server_addr.sin_family = AF_INET;\n  server_addr.sin_port = htons(server_port);\n  inet_pton(AF_INET, server_ip.c_str(), &server_addr.sin_addr);\n\n  int ret = connect(sock_fd, (struct sockaddr *)&server_addr, sizeof(server_addr));\n  if (ret < 0) {\n    perror(\"connect error\");\n    return -1;\n  }\n\n  ssize_t bytes_sent = send(sock_fd, message.c_str(), message.size(), 0);\n  if (bytes_sent < 0) {\n    perror(\"send error\");\n    return -1;\n  } else {\n    std::cout << \"Sent message: \" << message << std::endl;\n  }\n\n  char buf[1024] = {0};\n  ssize_t bytes_read = recv(sock_fd, buf, sizeof(buf) - 1,0);\n  if (bytes_read < 0) {\n    perror(\"read error\");\n  } else if (bytes_read == 0) {\n    std::cout << \"Server disconnected.\" << std::endl;\n  } else {\n    buf[bytes_read] = '\\0';\n    std::cout << \"Received data: \" << buf << std::endl;\n  }\n\n  close(sock_fd);\n  return 0;\n}\n```\n\n通信效果：\n\n![实战TCP通信.png](/images/2024/08/10/ef5a9aa0-56b0-11ef-9b76-6d6092cc6dd4.png)\n\n---\n\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"记住：TCP不是轮询的","url":"/2024/08/10/记住：TCP不是轮询的/","content":"\n<!-- toc -->\n\nTCP 无法将连接的丢失立即通知应用程序，我们下面就探讨为什么 TCP 不提供这种通知机制，不这么做的优点和缺点，以及应用程序程序员必须完成哪些工作以检测连接的丢失。\n\n## 为什么不设计连接丢失即时通知机制\n\n显然，对可用网络带宽的耗费是 TCP 不提供连接丢失即时通知的原因之一。大部分应用程序都不需要即时通知，因此**不应该为之付出降低带宽的代价**。如果应用程序确实需要及时获得对等实体不可达的信息，可以像稍后讨论的那样，实现自己的丢失发现机制。比方说 HTTP 只支持客户端向服务端主动通信，服务端却不可以主动给客户端推送消息。如果非要服务端主动和客户端通信，就可以利用轮询机制，即让客户端定时发送消息给服务端，服务端再给客户端回消息来营造服务端主动和客户端通信的假象。尽管轮询机制是常见的思想，但是非常容易被替代，因为对资源有太多不必要的消耗，这就是为什么 WebSocket 有出现的必要。\n\n但 TCP 不提供连接丢失即时通知最重要的原因与其主要设计目标之一有关：出现网络故障时维护通信的能力。国防部赞助的一项研究要提供一种即使在发生战争或自然灾害这种严重网络损坏的情况下，也能维护可靠网络通信的网络协议，TCP就是这种研究的产物。**通常，网络故障只是暂时的，有时路由器会为连接找到另一条路径。TCP允许临时的连接丢失，但通常可以在终端应用程序还没意识到的情况下处理好这些网络中断**。\n\n强制应用程序去监视网络的缺点在于必须将代码构建到每个（需要它的）应用程序中去，如果实现上考虑不周，就会浪费带宽，还可能产生一些对网络及其他用户有不利影响的行为。但也有人持不同的意见，认为应该在应用程序去监视网络，就可以对其进行精细调整以适应应用程序的需要，并尽可能地与应用程序协议无缝结合。\n\n## 如何在应用层实现连接丢失即时通知机制\n\n这里不介绍POSIX套接字提供的保持活跃机制，而是着重介绍心跳信号机制。书里面介绍两种实现方式：\n\n- `规定通信格式`来确定客户端的存活，即只需要为心跳报文增加一个报文类型\n  1. **定义心跳消息类型**：在协议中定义一个特殊的消息类型，例如 `HEARTBEAT`\n  2. **定期发送心跳消息**：客户端和服务器定期发送心跳消息以表示连接仍然活跃\n  3. **接收并处理心跳消息**：接收方收到心跳消息后，更新最后一次接收到心跳消息的时间\n- `没有规定通信格式`，那么通信的数据中就无法找到客户端发送的消息，心跳信号机制也就失效。对于没有规定通信格式的这种，启动一个独立的连接来发送和接受心跳信号\n  1. **建立心跳连接**：客户端和服务器建立一个独立的连接专门用于心跳信号\n  2. **定期发送心跳消息**：在心跳连接上定期发送心跳消息\n  3. **接收并处理心跳消息**：接收方在心跳连接上接收并处理心跳消息\n---\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"理解面向连接和无连接协议之间的区别","url":"/2024/08/10/理解面向连接和无连接协议之间的区别/","content":"\n**面向连接和无连接指的都是协议**。也就是说，这些术语指的**并不是物理介质本身**，而是用来**说明如何在物理介质上传输数据的**。面向连接和无连接协议可以，而且通常也确实会共享同一条物理介质。\n\n如果两者的区别与承载数据的物理介质无关，又和什么有关呢？它们的本质区别在于，对无连接协议来说，每个分组的处理都独立于所有其他分组，而对面向连接的协议来说，协议实现则维护了与后继分组有关的状态信息。\n\n请看如下表格：\n\n| 面向连接/无连接 | 具体协议 | 可靠/不可靠 |\n| --------------- | :------: | ----------- |\n| 面向连接        |   TCP    | 可靠传输    |\n| 面向无连接      |   UDP    | 不可靠传输  |\n\n**无连接协议**中的分组被称为数据报（datagram），每个分组都是独立寻址，并由应用程序发送的。从协议的角度来看，**每个数据报都是一个独立的实体，与在两个相同的对等实体之间传送的任何其他数据报都没有关系**，这就意味着协议很可能是不可靠的。也就是说，网络会尽最大努力传送每一个数据报，但并不保证数据报不丢失、不延迟或者不错序传输。\n\n另一方面，**面向连接的协议**则**维护了分组之间的状态**，使用这种协议的应用程序通常都会进行长期的对话。记住这些状态，协议就可以提供可靠的传输。比如，发送端可以记住哪些数据已经发送出去了但还未被确认，以及数据是什么时候发送的。如果在某段时间间隔内没有收到确认，发送端可以重传数据。接收端可以记住已经收到了哪些数据，并将重复的数据丢弃。如果分组不是按序到达的，接收端可以将其保存下来，直到逻辑上先于它的分组到达为止。\n\n使用无连接协议就像寄信，而使用面向连接的协议就像打电话。前者不管对方是否已经和自己连接成功，直接把数据发送出去，也就不关心数据是否真的到达了。后者和对方发送数据之前务必保证连接已经成功，通过三次握手来确保双方发送和接受能力以及连接成功，后续的数据发送也有相应的防丢失机制，比方说重传机制等。\n\n---\n\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"提防对等实体的不友好动作","url":"/2024/08/10/提防对等实体的不友好动作/","content":"\n<!-- toc -->\n\n亦如在程序中接受用户的输入前，要对用户的输入进行“安全检测”，以防止恶意输入破坏应用程序的正常运行。可见，防御性编程在编码中是必备的意识，网络编程中也要考虑各种概率看似很小的事件，做出相应的处理动作。\n\n## 检测客户端的终止\n\n![检测客户端的终止.png](/images/2024/08/10/ddfaa030-56af-11ef-9b76-6d6092cc6dd4.png)\n\n这段代码中，如果客户端发送字符串\"quit\"代表客户端要退出，服务器这边就可以正常和客户端断开连接。如果客户端发生故障或者异常导致没有发生字符串\"quit\"，那么服务器这边就会频繁执行最后一条分支语句。\n\n可以只在读操作上设置一个定时器，如果客户端在某段时间区间内没有发出请求，服务器就假定客户端已经不存在了。很多 FTP 服务器就是这么做的：如果客户端在某段时间区间内没有发送任何请求，服务器就放弃连接。用一个显式定时器或者像心跳实例那样使用 select 定时器，就可以很方便地解决这个问题。\n\n## 检测无效输入\n\n即客户端恶意输入无效字符，服务器如果没有进行“拦截检测”，可能会造成程序崩溃。崩溃最常见的两种原因是缓冲器溢出和指针丢失。\n\n`缓冲区溢出`是由于写入的数据超过了缓冲区的大小，从而覆盖了相邻的内存区域。为了防止缓冲区溢出，可以采取以下措施：\n\n1. **使用安全函数**：使用库中提供的安全函数，例如 `strncpy` 代替 `strcpy`，`snprintf` 代替 `sprintf` 等\n2. **手动检查长度**：在写入数据之前，手动检查输入数据的长度是否超过了缓冲区的大小\n\n`指针丢失`通常是由于未正确初始化指针或错误释放内存导致的。为了防止指针丢失，可以采取以下措施：\n\n1. **初始化指针**：确保所有指针在使用之前都被初始化\n2. **检查指针有效性**：在使用指针之前，检查指针是否为空（`nullptr`）\n3. **正确管理内存**：C++11 提供的智能指针\n---\n⭐️内容取自译者陈涓、赵振平《TCP/IP高效编程：改善网络程序的44个技巧》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书。","tags":["网络编程"],"categories":["technology"]},{"title":"实践论","url":"/2024/08/09/实践论/","content":"\n再多的想法，还只是停留在认识阶段，而认识终归是要落实的，如果只是认识而不去实践，永远不可能和真理沾边。人类的理性是有限的，没人能够绝对保证自己认识的准确性，一定要把自己的认识投身于实践中去，在实践中证明认识的准确性，在实践中修正认识的不足性。真正长久的智慧不可能来源于一成不变的理论，而是来源于持续迭代并且保持学习的理论。\n\n> 判定认识或理论之是否真理，不是依主观上觉得如何而定，而是依客观上社会实践的结果如何而定。真理的标准只能是社会的实践。\n\n经验可分为直接经验和间接经验，如书本中获取的经验就属于间接经验，结合书本中的知识去实践得到的经验是直接经验。我们不能说间接经验一定是认识的低级阶段，首先间接经验也来源于直接经验，其次历史也不断从直接经验中迭代间接经验，从间接经验中依旧能获取高阶的认识，甚至是绝大部分获取高阶认识的来源，这同样源于间接经验比直接经验更容易获得并掌握。然而，回顾间接经验之所以能作为高阶认识的来源，恰恰就是在历史场合中接受直接经验的更正，如果我们依旧想要后面的人能够从间接经验中获取更高的认识，那么通过实践获得直接经验并丰富或修正间接经验依旧是必不可少的。前面这种为后人考虑的说法确实伟大，但从个体角度来看，这同样是适用的。常言到“尽信书不如无书”，恰恰就是对人类理性的尊重，并且强调要用直接经验检验间接检验。\n\n> 我们的实践证明：感觉到了的东西，我们不能立刻理解它，只有理解了的东西才更深刻地感觉它。感觉只解决现象问题，理论才解决本质问题。这些问题的解决，一点也不能离开实践。无论何人要认识什么事物，除了同那个事物接触，即生活于（实践于）那个事物的环境中，是没有法子解决的。不能在封建社会就预先认识资本主义社会的规律，因为资本主义还未出现，还无这种实践。\n\n拥有足够多大的信息，理性才能充分发挥。这叫好像一堆拼图碎片，如果能够尽可能获取更多的碎片，那么距离得到此拼图的本质模样就更容易。\n\n> 认识的过程，第一步，是开始接触外界事情，属于感觉的阶段。第二步，是综合感觉的材料加以整理和改造，属于概念、判断和推理的阶段。只有感觉的材料十分丰富（不是零碎不全）和合于实际（不是错觉），才能根据这样的材料造出正确的概念和论理来。\n\n通过循环再次回来，但每次回来都拿着进一步地正确认识，就好像注入新的生命力一样。认识、实践、再认识、再实践，如此反复，永无止尽。\n\n> 通过实践而发现真理，又通过实践而证实真理和发展真理。从感性认识而能动地发展到理性认识，又从理性认识而能动地指导革命实践，改造主观世界和客观世界。实践、认识、再实践、再认识，这种形式，循环往复以至无穷，而实践和认识之每一循环的内容，都比较地进到了高一级的程度。这就是辩证唯物论的全部认识论，这就是辩证唯物论的知行统一观。","tags":["毛泽东","毛泽东选集"],"categories":["article"]},{"title":"接受毛泽东的思想批评之没有把握是缺乏认识和实践","url":"/2024/08/09/接受毛泽东的思想批评之没有把握是缺乏认识和实践/","content":"\n常常听到一些同志在不能勇敢接受工作任务时说出来的一句话：没有把握。为什么没有把握呢？因为他对于这项工作的内容和环境没有规律性的了解，或者他从来就没有接触过这类工作，或者接触得不多，因而无从谈到这类工作的规律性。及至把工作的情况和环境给以详细分析之后，他就觉得比较地有了把握，愿意去做这项工作。如果这个人在这项工作中经过了一个时期，他有了这项工作的经验了，而他又是一个肯虚心体察情况的人，不是一个主观地、片面地、表面地看问题的人，他就能够自己做出应该怎样进行工作的结论，他的工作勇气也就可以大大地提高了。只有那些主观地、片面地和表面地看问题的人，跑到一个地方，不问环境的情况，不看事情的全体（事情的历史和全部现状），也不触到事情的本质（事情的性质及此一事情和其他事情的内部联系），就自以为是地发号施令起来，这样的人是没有不跌交子的。","tags":["反省"],"categories":["various"]},{"title":"40.组合总和 II","url":"/2024/08/09/40-组合总和-II/","content":"\n```c++\nclass Solution {\npublic:\n    vector<vector<int>> result;\n    vector<int> path;\n    void backtrace(vector<int>& candidates, int target,int start,bool note) {\n        if (target == 0) {\n            result.push_back(path);\n            return;\n        }\n        if (target < 0) {\n            return;\n        }\n        for (int i = start; i < candidates.size(); i++) {\n            if(!note && i > 0 && candidates[i-1] == candidates[i]) continue; // 应对重复元素\n            path.push_back(candidates[i]);\n            target -= candidates[i];\n            backtrace(candidates, target, i + 1,true);\n            note = false;\n            path.pop_back();\n            target += candidates[i];\n        }\n    }\n\n    vector<vector<int>> combinationSum2(vector<int>& candidates, int target) {\n        sort(candidates.begin(),candidates.end());\n        backtrace(candidates,target,0,false);\n        return result;\n    }\n};\n```\n\n前面做的组合题，不管强调与否，我们都知道数组中的元素是没有重复的，但这道题恰恰相反。看来只要解决重复元素可能带来的问题就可以了。\n\n首先需要对元素进行排序，这样益于跳过重复的元素，可以说必须做这一步。难道我们只需要判断 前后两个数据是否相同就能忽略重复的元素带来的问题吗？\n\n```c++\ni > 0 && candidates[i-1] == candidates[i]\n```\n\n不是，因为进入 backtrace 中导致本来用来满足需求的元素被忽略，仔细看下面这个例子：\n\n```bash\ncandidates = {1，1，1，2，1}，target = 2\n```\n\n第一个元素和第二个元素可以组合，但是由于如上的判断条件导致忽略。造成这个的原因是，我们本意忽略的元素是处于同一层的相同元素，但是进入 backtrace  中的元素属于要和上一层元素进行组合的，不应该忽略。\n\n那么我们就用一个布尔值 note 标记，如果 note 为 false 表明在同一层（同一个栈），否则在不同层（不同栈）。同层的元素相同可被忽略，不同层的元素相同不可被忽略。","tags":["回溯"],"categories":["leetcode"]},{"title":"39.组合总和","url":"/2024/08/09/39-组合总和/","content":"\n```c++\nclass Solution {\npublic:\n    vector<vector<int>> result;\n    vector<int> path;\n    void backtrace(const vector<int>& candidates, int target,int start) {\n        if (target == 0) {\n            result.push_back(path);\n            return;\n        }\n        if (target < 0) {\n            return;\n        }\n        for (int i = start; i < candidates.size(); i++) {\n            path.push_back(candidates[i]);\n            target -= candidates[i];\n            backtrace(candidates, target,i);\n            path.pop_back();\n            target += candidates[i];\n        }\n    }\n    vector<vector<int>> combinationSum(vector<int>& candidates, int target) {\n        backtrace(candidates, target,0);\n        return result;\n    }\n};\n```\n\n相较于之前的题目，数组中的元素**同一个**数字可以**无限制重复被选取**，我们就得保证当前元素在下一次选择中依旧可以选择自己。要记住这是一道组合题，后续的元素是不能往前看的，即不能再选择之前的元素。要想同时达到前面两个条件，我们的做法是 传递到 backtrace 中的 start 参数 不在 自加，既 传递 i 作为参数，而不是 i + 1 作为参数。\n\n为什么组合中，其后的元素不能往前看，即不能再选择之前的元素？\n\n因为我们的回溯会把当前元素和后面的元素所有可能都尝试一遍，而组合不强调顺序性，这就是为什么组合中其后的元素没有必要往前看。","tags":["回溯"],"categories":["leetcode"]},{"title":"17.电话号码的字母组合","url":"/2024/08/09/17-电话号码的字母组合/","content":"\n```c++\nclass Solution {\npublic:\n    const string list[10] = {\"\",    \"\",    \"abc\",  \"def\", \"ghi\",\n                             \"jkl\", \"mno\", \"pqrs\", \"tuv\", \"wxyz\"};\n\n    vector<string> result;\n    string path;\n    void backtrace(string digits, int size, int note, int start) {\n        if (note == size) {\n            result.push_back(path);\n            return;\n        }\n        for (int i = start; i < size; i++) {\n            int num = digits[i] - '0';\n            for (int j = 0; j < list[num].size(); j++) {\n                path.push_back(list[num][j]);\n                note++;\n                backtrace(digits, size, note, i + 1);\n                path.pop_back();\n                note--;\n            }\n        }\n    }\n\n    vector<string> letterCombinations(string digits) {\n        if (!digits.empty()) {\n            backtrace(digits, digits.size(), 0, 0);\n        }\n        return result;\n    }\n};\n```\n\n在完成《77.组合》基础上，这道题你要会两个技能，分别是建立映射关系（通常是数组）和单个数字字符转换为对应的整数（ch - '0'）。\n\n","tags":["回溯"],"categories":["leetcode"]},{"title":"218.组合III","url":"/2024/08/09/218-组合III/","content":"\n```c++\nclass Solution {\npublic:\n    int SIZE = 9;\n    vector<vector<int>> result;\n    vector<int> path;\n    void backtrace(int k, int n,int start,int note,int sum) {\n        if(k == note && sum == n){\n            result.push_back(path);\n            return;\n        }\n        for(int i = start; i <= SIZE; i++){\n            path.push_back(i);\n            sum += i;\n            note++;\n            backtrace(k,n,i + 1,note,sum);\n            path.pop_back();\n            sum -= i;\n            note--;\n        }\n    }\n\n    vector<vector<int>> combinationSum3(int k, int n) {\n        backtrace(k,n,1,0,0);\n        return result;\n    }\n};\n```\n\n在完成《77.组合》基础上，这道题无外乎增加一个额外的条件，即需要 path 中数的总和为 n，其中限制元素个数为 k。至于题目中明确强调的“每个数字**最多使用一次** ”无需多言，在《77.组合》中就已经没有重复利用已用过的数字，因为我们都是从当前数的下一个数开始遍历，并不会回头看。","tags":["回溯"],"categories":["leetcode"]},{"title":"77.组合","url":"/2024/08/09/77-组合/","content":"\n```c++\nclass Solution {\npublic:\n    vector<vector<int>> result;\n    vector<int> path;\n    void backtrace(int n, int k, int start, int note) {\n        if (note == k) { // 终止条件\n            result.push_back(path);\n            return;\n        }\n        for (int i = start; i <= n; i++) {\n            path.push_back(i);\n            note++;\n            backtrace(n, k, i + 1, note);\n            path.pop_back();\n            note--;\n        }\n    }\n\n    vector<vector<int>> combine(int n, int k) {\n        backtrace(n, k, 1, 0);\n        return result;\n    }\n};\n```\n\nnote 记录已存储路径的长度，用以终止回溯，终止条件是回溯当中不可获取的。\n\n组合不在意顺序，因此 [1,4] 和 [4,1] 属于同一个路径，不能同时加入到总路径中，只能取其一。为了方便，按照有序进行排布会容易做题，在代码中也是通过 i + 1 传递 到 backtrace 中作为 start 参数，表示遍历路径的起始位置。\n\n回溯的体现就在于，你添加的操作在从 backtrace 结束之后对应的删除操作，比方说 `path.push_back(i)` 对应 `path.pop_back()`，`note++` 对应 `note--`。\n\n![组合.png](/images/2024/08/09/bc6fb5b0-55f9-11ef-9ecf-d962743c35c1.png)","tags":["回溯"],"categories":["leetcode"]},{"title":"8. 字符串转换整数 (atoi)","url":"/2024/08/09/8-字符串转换整数-atoi/","content":"\n```c++\nclass Solution {\npublic:\n    void clearSpaces(std::string& str) {\n        size_t i = 0;\n        while (i < str.size() && str[i] == ' ') {\n            ++i;\n        }\n        str.erase(0, i);\n    }\n\n    std::string readNum(const std::string& str) {\n        std::string reStr;\n        for (char s : str) {\n            if (isdigit(s)) {\n                reStr += s;\n            } else {\n                break;\n            }\n        }\n        return reStr;\n    }\n\n    void clearZero(std::string& str){\n        int i;\n        for(i = 0; i < str.size(); i++){\n            if(str[i] != '0'){\n                break;\n            }\n        }\n        str.erase(str.begin(),str.begin() + i);\n    }\n\n    unsigned long long strToNum(string& str, bool note) {\n        if(str.size() > 10){\n            if(note){\n                return INT32_MIN;\n            }\n            return INT32_MAX;\n        }\n        reverse(str.begin(), str.end());\n        unsigned long long chen = 1;\n        unsigned long long renum = 0;\n        for (auto s : str) {\n            int num = s - '0';\n            renum += chen * num;\n            chen *= 10;\n            if (renum >= INT32_MAX) {\n                if(note){\n                    if(renum != INT32_MAX){\n                        return INT32_MIN;\n                    }else{\n                        return -renum;\n                    }\n                }\n                return INT32_MAX;\n            }\n        }\n        if(note){\n            return -renum;\n        }\n        return renum;\n    }\n\n    int myAtoi(std::string s) {\n        if (s.empty()) {\n            return 0;\n        }\n        bool isNegative = false;\n\n        // 去除字符串中无用的空格\n        clearSpaces(s);\n\n        // 如果第一个字符是字母，直接返回0\n        if (s.empty() || isalpha(s[0])) {\n            return 0;\n        }\n\n        // 处理正负号\n        if (s[0] == '-') {\n            isNegative = true;\n            s.erase(s.begin());\n        } else if (s[0] == '+') {\n            s.erase(s.begin());\n        }\n\n        // 读取完整的字符型数字\n        std::string numStr = readNum(s);\n        if (numStr.empty()) {\n            return 0;\n        }\n        // 排除前面的0\n        clearZero(numStr);\n\n        // 一切准备工作完成，开始把 字符串 转换为 数字\n        long long re = strToNum(numStr,isNegative);\n\n        return re;\n    }\n};\n```\n\n这道题在力扣上的通过率非常低，当前是21.3%的通过率。我花费一个早上写的代码，最终还有一个测试用例没有通过，由于有其他事情暂时搁置。直到明天的早上，也就是今天早上，没过多久就把测试用例给过了，因为在搁置之后发现最后一个没有通过的测试用例可以通过判断数字是否过大而直接返回 INT32_MAX 或 INT32_MIN。\n\n我们在进行字符串转换为数字之前，需要做很多预备工作，因为字符串里面有很多混杂的非数字字符：\n\n1. 如果是空字符，直接返回 0\n2. 去除字符串中无用的空格\n3. 如果第一个字符是字母，直接返回 0\n4. 记录正负号\n5. 读取完整的字符型数字\n6. 排除前面的 0\n\n按照这个顺序来，我们的字符串就必然是全部由数字组成，就可以真正的去做字符串转数字的工作了\n\n```c++\nunsigned long long strToNum(string& str, bool note) {\n    if(str.size() > 10){\n        if(note){\n            return INT32_MIN;\n        }\n        return INT32_MAX;\n    }\n    reverse(str.begin(), str.end());\n    unsigned long long chen = 1;\n    unsigned long long renum = 0;\n    for (auto s : str) {\n        int num = s - '0';\n        renum += chen * num;\n        chen *= 10;\n        if (renum >= INT32_MAX) {\n            if(note){\n                if(renum != INT32_MAX){\n                    return INT32_MIN;\n                }else{\n                    return -renum;\n                }\n            }\n            return INT32_MAX;\n        }\n    }\n    if(note){\n        return -renum;\n    }\n    return renum;\n}\n```\n\n按照题目要求，应该返回[INT32_MIN,INT32_MAX]区间内的数字，下面部分说明\n\n1. 如果字符串的长度大于 10，表明必然已经越界。如果这个数为负数，那么返回INT32_MIN，否则返回INT32_MAX\n2. 在循环取值计算的过程中，如果 renum 有 大于等于 INT32_MAX情况就要进行处理，避免后续没有意义的计算\n\n下面这个地方容易让人不理解，但这实际是由 INT32_MIN（2147483648） 和 INT32_MAX（2147483647）不对称导致的。由于 INT32_MIN 绝对值 大于 INT32_MAX 绝对值，所以当 renum >= INT32_MAX 进入判断的时候，我们继续考虑当这个数为负数情况下，如果 renum = INT32_MAX，应该返回 -renum，而不能直接返回 INT32_MIN。\n\n```c++\nif (renum >= INT32_MAX) {\n    if (note) {\n        if (renum != INT32_MAX) {\n            return INT32_MIN;\n        } else {\n            return -renum;\n        }\n    }\n    return INT32_MAX;\n}\n```","tags":["字符串"],"categories":["leetcode"]},{"title":"CPP 中 cctype 库的常用方法","url":"/2024/08/08/CPP-中-cctype-库的常用方法/","content":"\n`std::isalpha`: 判断是否为字母\n\n`std::isdigit`: 判断是否为数字\n\n`std::isalnum`: 判断是否为字母或数字\n\n`std::iscntrl`: 判断是否为控制字符\n\n`std::isgraph`: 判断是否为除空格外的可打印字符\n\n`std::islower`: 判断是否为小写字母\n\n`std::isupper`: 判断是否为大写字母\n\n`std::isprint`: 判断是否为可打印字符（包括空格）\n\n`std::ispunct`: 判断是否为标点符号\n\n`std::isspace`: 判断是否为空白字符（如空格、换行、制表符等）\n\n`std::isxdigit`: 判断是否为十六进制数字\n\n如上这些方法是用来判断是否为某种字符的，如果是返回true，如果不是返回false\n\n通常我们在处理哪种需要判断给定的字符串中有多少数字、多少字母等会非常好用\n\n下面再介绍此头文件中的另外两个方法，即大小写字母转换\n\n`std::tolower`：转换为小写\n\n`std::toupper`：转换为大写","tags":["CPP"],"categories":["technology"]},{"title":"66.加一","url":"/2024/08/08/66-加一/","content":"\n```c++\nclass Solution {\npublic:\n    vector<int> plusOne(vector<int>& digits) {\n        bool flag = true;   // 存在进位\n        vector<int> data;\n        if(digits[digits.size() - 1] + 1 != 10){    // 如果加1不会进位，返回最后一个元素加1的原数组\n            digits[digits.size() - 1]++;\n            return digits;\n        }\n\n        for(int i = digits.size() - 1; i >= 0; i--){\n            if(flag){\n                if(digits[i] + 1 != 10){    // 后续不会有进位，flag = false;\n                    data.push_back(digits[i] + 1);\n                    flag = false;\n                }else{  // 后续还有进位，flag保持不变\n                    data.push_back(0);\n                }\n            }else{  // 没有进位，添加原数组元素即可\n                data.push_back(digits[i]);\n            }\n        }\n        if(flag){   // 如果有进位，代表这个数是 N 个 9组成，所以添加元素 1\n            data.push_back(1);\n        }\n        reverse(data.begin(),data.end());   // 反转\n        return data;\n    }\n};\n```\n\n这道题容易让人误解，应该把题意讲得清楚些。有一个自然数，被拆分成个位数存储在数组中，对这个自然数进行加 1 操作。很明显，如果我们的自然是99，那么加 1 的结果就是 100，显然原数组是存储不下的，因为vector容器不支持头部插入元素。\n\n如果数组中的末尾元素 加 1 之后不存在进位，只需要把原数组的末尾元素加 1 之后返回即可。\n\n如果存在进位，就需要声明一个新的容器 data 来存储元素，避免原数组因为进位操作导致无法存储超过原长度的元素个数。基于存在进位的这种情况开始对原数组进行计算，第一次进入 for 循环中肯定是存在进位的情况。如果当前元素加 1 依旧满足进位，那么 flag 保持不变，添加元素 0 到 data 容器中。如果当前元素 加 1 不满足进位，flag 设置为 false，添加当前元素 加 1 之后的结果到 data容器中。\n\n前面讲，进入 for 循环的第一次必然存在进位，那么此后就会出现两种情况：如果 flag 为 false ，后续的原数组元素添加到 data 容器中即可。如果 flag 依旧为 true，那不过是重复上面的逻辑，直到 flag 为 false 才进入到”原数组元素添加到 data 容器中即可“阶段。\n\n如果 flag 始终为 true ，那么还需要添加元素 1 到 data 容器中。假定自然数为99，那么上面的逻辑执行下来，数组中存储的元素是 0 0。所以，如果 flag 依旧为 true，我们需要继续添加 元素 1 进来，否则不进行新的元素添加。然后就可以 data 容器反转之后进行返回，得到符合题意的结果。","tags":["数组"],"categories":["leetcode"]},{"title":"26.删除有序数组中的重复项","url":"/2024/08/08/26-删除有序数组中的重复项/","content":"\n```c++\nclass Solution {\npublic:\n    int removeDuplicates(vector<int>& nums) {\n        if(nums.size() == 1) return 1;\n        int left = 0;       // 用于比较是否重复\n        int right = 1;      // 用于指定更新值的下标\n        for(int i = 1; i < nums.size(); i++){\n            while(nums[left] != nums[i]){\n                nums[right] = nums[i];\n                right++;\n                left = i;\n            }\n        }\n        return right;\n    }\n};\n```\n\n双指针法，right 用于指向更新值的下标，left 用于比较是否重复。\n\n如果nums[left] 和 nums[i] 不相等，表明遇到不是重复的新值，然后把这个新值赋值给 nums[right]，继而把 right 和 left 的下标进行更新。\n\n## 二刷（2024/9/22）\n\n```c++\nclass Solution {\npublic:\n    int removeDuplicates(vector<int>& nums) {\n        if(nums.size() == 1) return 1;\n\n        int cover_index = 1;\n        int same_first = 0;\n\n        for(int i = 1; i < nums.size(); i++){\n            if(nums[same_first] != nums[i]){    // 要覆盖了\n                nums[cover_index] = nums[i];\n                cover_index++;\n                same_first = i;\n            }\n        }\n\n        return cover_index;\n    }\n};\n```\n和之前的一刷对比，我这里并没有用 while 循环，也想不起来为什么要这样做了。\n\n实际上认真看这道题的话，我们需要三个指针：\n\n- 一个指向接下来要用来覆盖元素的指针\n- 一个是用来遍历数组的指针\n- 一个用来指向第一次出现不同元素的下标\n\n我们首先保证数组中至少两个元素，用 cover_index 初始化为 1，因为第一个下标必然不用被修改，要修改也是从下标 1 开始。至于遍历数组，用 for 循环中的 i 持续递增即可。而指向第一次出现不同元素的下标，看似需要单独用一个指针记录，也是因为这个考虑，二刷第一次的写法如上。\n\n但你仔细想一想，非严格递增排列 的数组特性，是完全没必要单独用一个指针记录第一次出现不同元素的下标。也就有下面这种更加简洁的写法。\n\n可这明显是思考后的成果，如果没有形成对此题的记忆也未必想到这里，就像 环形链表II 这道题，如果你记不得判断环和判断第一次交汇点的数学推理，你真吃不下。如此，我觉得优先要考虑到的是，你懂得用 cover_index 记录接下来要被覆盖的下标，这就很不错了。\n\n```c++\nclass Solution {\npublic:\n    int removeDuplicates(vector<int>& nums) {\n        if(nums.size() == 1) return 1;\n\n        int cover_index = 1;    // 指向 接下来要被 覆盖的 下标 \n\n        for(int i = 1; i < nums.size(); i++){\n            if(nums[i] != nums[i-1]){\n                nums[cover_index++] = nums[i];\n            }\n        }\n\n        return cover_index;\n    }\n};\n```","tags":["数组"],"categories":["leetcode"]},{"title":"关心群众生活，注意工作方法","url":"/2024/08/07/关心群众生活，注意工作方法/","content":"\n要想动员群众，就得关心群众生活，否则只是向人民群众提出要求，不仅没想着解决矛盾，倒还创造矛盾，激化矛盾，这是不可以的。我们的党和政府始终要与群众保持联系，否则提出的新规划不能解决当下的矛盾，群众得不到实际的好处，就会被认为是大话，空话，甚至沦为笑话。\n\n> 在我们的工作人员中，曾经看见这样的情形：他们只讲扩大红军，扩充运输队，收土地税，推销公债，其他事情呢，不讲也不管，甚至一切都不管。\n\n> 就得和群众在一起，就得去发动群众的积极性，就得关心群众的痛痒，就得真心实意地为群众谋利益，解决群众的生产和生活的问题，盐的问题，米的问题，房子的问题，衣的问题，生小孩子的问题，解决群众的一切问题。\n\n理论和实践有很大的差距，提出利于群众的政策，下面有实权的人就要实打实地去做，不要群众没得到实惠，就用假数据假信息蒙骗上级。不要让下级成为过滤网，过滤好的留在自己手里，留些残渣渗下去，层层滤网，还能流出多少实惠给到群众？需要严格把关下级传递上来的信息，保证信息的准确性、完整性、可靠性，若有半点偷奸耍滑者，立即处置。\n\n> 我们的任务是过河，但是没有桥或没有船就不能过。不解决桥或船的问题，过河就是一句空话。不解决方法问题，任务也只是瞎说一顿。不注意扩大红军的领导，不讲究扩大红军的方法，尽管把扩大红军念一千遍，结果还是不能成功。","tags":["毛泽东","毛泽东选集"],"categories":["article"]},{"title":"19.删除链表的倒数第 N 个结点","url":"/2024/08/07/19-删除链表的倒数第-N-个结点/","content":"\n```c++\nclass Solution {  \npublic:  \n    ListNode* removeNthFromEnd(ListNode* head, int n) {  \n        ListNode* getLen = head;  \n  \n        ListNode* virtualHead = new ListNode(-1);  \n        virtualHead->next = head;  \n        ListNode* delNode = virtualHead;  \n  \n        int len = 0;  \n        while(getLen){  // 获取链表长度   \n            getLen = getLen->next;  \n            len++;  \n        }  \n        len = len - n;  \n        for(int i = 0; i < len; i++){   // 找到需要移除节点的前一个节点  \n            delNode = delNode->next;  \n        }  \n  \n        delNode->next = delNode->next->next;    // 删除节点  \n          \n        return virtualHead->next;   // 返回头节点  \n    }  \n}; \n```\n\n只要明白链表的特性，以及删除的特点就很容易想到该怎么处理这道题，不会想复杂。我们要删除链表的倒数第 N 个节点，只需要找到这个节点的前一个节点，因为删除链表节点的准则就是找到待删除节点的前一个节点。由于我们是要找倒数第 N 个节点，就要先获取链表长度（只能遍历一次得到），然后`len = len - n`计算出 len ，用于找到待删除节点的前一个节点。","tags":["链表"],"categories":["leetcode"]},{"title":"2.两数相加","url":"/2024/08/07/2-两数相加/","content":"\n```c++\nclass Solution {\npublic:\n    ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) {\n        bool note = false;\n        ListNode* head = new ListNode(-1);\n        ListNode* rehead = head;\n        while (l1 != nullptr && l2 != nullptr) {\n            int num = l1->val + l2->val;\n            if (note) {\n                num++;\n                note = false;\n            }\n            if (num >= 10) {\n                num = num % 10;\n                note = true;\n            }\n            ListNode* tmp = new ListNode(num);\n            rehead->next = tmp;\n            rehead = rehead->next;\n            l1 = l1->next;\n            l2 = l2->next;\n        }\n        if (l2) {\n            swap(l1, l2);\n        }\n        while (l1 != nullptr) {\n            int num = l1->val;\n            if (note) {\n                num++;\n                note = false;\n            }\n            if (num >= 10) {\n                num = num % 10;\n                note = true;\n            }\n            ListNode* tmp = new ListNode(num);\n            rehead->next = tmp;\n            rehead = rehead->next;\n            l1 = l1->next;\n        }\n        if (note) {\n            ListNode* tmp = new ListNode(1);\n            rehead->next = tmp;\n        }\n        return head->next;\n    }\n};\n```\n\n还是要看懂题目，实际上就是将两个链表从头到尾取相同位置的节点相加，这可能出现以下情况：\n\n- 两个链表长度相同且最后没有产生进位，返回 head->next 即可\n- 两个链表长度相同且最后有产生进位，创建一个值为 1 的新节点 tmp，然后 rehead->next 指向 tmp节点，最后返回 head->next 即可\n- 两个链表长度不同，那么对于没有处理完的链表中的节点逐一移动到 rehead 节点之后，接着进入上述的两种情况中继续处理\n\n```\n输入：l1 = [5,6,4,9], l2 = [2,4,9]\n输出：[7,0,4,0,1]\n解释：9465 + 942 = 10407\n```\n\n当然，还有就是关于进位的处理，这并不难，只需要用一个标记位 note 来标识是否有进位，还有要记得正确更新 note 的情况。\n\n```c++\nif (note) {\n      num++;\n      note = false;\n }\nif (num >= 10) {\n      num = num % 10;\n      note = true;\n}\n```","tags":["链表"],"categories":["leetcode"]},{"title":"143.重排链表","url":"/2024/08/07/143-重排链表/","content":"\n```c++\nclass Solution {\npublic:\n    ListNode* reverseList(ListNode* head) {\n        if (head == nullptr || head->next == nullptr) {\n            return head;\n        }\n        ListNode* left = head;\n        ListNode* right = head->next;\n        while (right) {\n            ListNode* node = right->next;\n            right->next = left;\n            left = right;\n            right = node;\n        }\n        head->next = nullptr;\n        return left;\n    }\n\n    void reorderList(ListNode* head) {\n        if (head == nullptr || head->next == nullptr) {\n            return;\n        }\n        // 找到中间节点进行切割，左半部分链表保持不变，反转右半部分链表\n        ListNode* slow = head;\n        ListNode* fast = head;\n        while (fast != nullptr && fast->next != nullptr) {\n            slow = slow->next;\n            fast = fast->next->next;\n        }\n        ListNode* left = head;\n        ListNode* right = slow->next;\n        slow->next = nullptr;\n        right = reverseList(right);\n\n        // 准备工作已做好，开始重排\n        ListNode* virtualHead = new ListNode(-1);\n        ListNode* tmp = virtualHead;\n        while (left != nullptr && right != nullptr) {\n            tmp->next = left;\n            left = left->next;\n            tmp->next->next = right;\n            right = right->next;\n            tmp = tmp->next->next;\n        }\n\n        if (left != nullptr) {\n            tmp->next = left;\n        }\n\n        head = virtualHead->next;\n    }\n};\n```\n\n这道题只要能够把题目看明白，即它究竟是如何重排，逻辑上理清楚并不难\n\n1. 先找到中间节点，将当前链表分割成两部分，即左链表和右链表\n2. 左链表的尾节点要指向 nullptr，右链表需要反转\n3. 创建一个虚拟头节点用来链接后续重排的节点，先链接左链表的第一个节点，接着链接右链表的第一个节点，如此循环\n4. 如果左链表当前节点和右链表当前节点有一个不满足不为空就退出循环。由于左链表的长度大于或等于右链表（如果大于，也只会比其多一个节点），退出循环之后，继续判断左链表当前节点是否为空，不为空就代表还有一个节点被遗漏，tmp 指向这个节点即可\n5. 最后，记得更换 head 节点为 virtualHead->next\n\n---\n\n完成本题的过程中，犯下的错误是 tmp 节点的移动，错误的逻辑代码如下：\n\n```c++\nwhile (left != nullptr && right != nullptr) {\n  tmp->next = left;\n  tmp = tmp->next;\t\t// 错误的逻辑代码，后续代码也没价值\n  tmp->next = right;\n  tmp = tmp->next;\t\t\n  left = left->next;\n  right = right->next;\n}\n```\n\n因为我们的 left 和 right 节点后面也跟着很多的节点，如果你 tmp = tmp->next，然后再 tmp->next = right，就失去 left 链表的掌控了（left 链表被污染），从而出现错误。\n\n![重排链表.png](/images/2024/08/07/802b1dd0-549e-11ef-996a-6b29d9dcc7bf.png)\n\n所以，只需要每次让 tmp 指向 left 或 right 的节点之后，及时更新 left 和 right 指针即可，保证不被污染\n\n```c++\nwhile (left != nullptr && right != nullptr) {\n     tmp->next = left;\n     left = left->next;\n     tmp->next->next = right;\n     right = right->next;\n     tmp = tmp->next->next;\n }\n```","tags":["链表"],"categories":["leetcode"]},{"title":"142.环形链表II","url":"/2024/08/07/142-环形链表II/","content":"\n```c++\nclass Solution {  \npublic:  \n    ListNode* detectCycle(ListNode* head) {  \n        if (head == NULL || head->next == NULL) {  \n            return nullptr;  \n        }  \n        // 快慢指针，有环必相遇  \n        ListNode* node = head;  \n        ListNode* slow = head;  \n        ListNode* fast = head;  \n        while (fast != nullptr && fast->next != nullptr) {  \n            slow = slow->next;  \n            fast = fast->next->next;  \n            if (slow == fast) { // 有环  \n                while (true) {  \n                    if (node == slow) {  \n                        return slow;  \n                    }  \n                    node = node->next;  \n                    slow = slow->next;  \n                }  \n            }  \n        }  \n        return nullptr;  \n    }  \n};  \n```\n\n此题建立在你已经完成 《141.环形链表》题目，我们重点就关注判断有环之后如果找到第一次相遇的节点。\n\n![环形链表II.png](/images/2024/08/07/fcf6ef00-5490-11ef-996a-6b29d9dcc7bf.png)\n\n我们可以确定如下信息：\n\n- 慢指针必然不可能环绕圆形一圈，快指针至少环绕环形一圈\n- 快指针和慢指针从同一个起点出发，并且快指针是慢指针的两倍\n\n设定 相应的变量之后，得到如下等式：n >= 1，且 n 为正整数 （因为快指针至少环绕环形一圈）\n\n```tex\n(x + y) * 2 = x + y + n ( y + z ) \n\t\t↓\nx = (n - 1)(x + y) + z\n```\n\n我们假定 n == 1，那么 x = z。这个时候再看图，就发现只要 快慢指针的相遇节点和头节点同时向前移动，它们两个的相遇点就是链表开始入环的第一个节点。\n\n---\n\n在完成《141.环形链表》题目的时候，我的第一份代码如下：\n\n```c++\nclass Solution {\npublic:\n    bool hasCycle(ListNode *head) {\n        if(head == NULL || head->next == NULL){\n            return false;\n        }\n        ListNode* slow = head;\n        ListNode* fast = head->next;\n        while(fast != nullptr && fast->next != nullptr){\n            if(slow == fast){\n                return true;\n            }\n            slow = slow->next;\n            fast = fast->next->next;\n        }\n        return false;\n    }\n};\n```\n\n我企图用这份代码来套用到本题，却发现犯了一个大错误，那就是 slow 和 fast 不是同一个起点开始，导致上面的推导公式失效。所以，我们务必保证最初的快慢指针的起点是一致的，即指向头节点。如果是这样，上面的代码还需要改正的地方是，要先进行指针移动，再判断快慢指针是否指向同一个节点，从而判断是否为环形链表。\n\n```c++\nclass Solution {\npublic:\n    bool hasCycle(ListNode* head) {\n        if (head == NULL || head->next == NULL) {\n            return false;\n        }\n        \n        ListNode* slow = head;\n        ListNode* fast = head;\n        while (fast != nullptr && fast->next != nullptr) {\n            slow = slow->next;\n            fast = fast->next->next;\n            if (slow == fast) { // 快慢指针，有环必相遇\n                return true;\n            }\n        }\n        return false;\n    }\n};\n```","tags":["链表"],"categories":["leetcode"]},{"title":"141.环形链表","url":"/2024/08/07/141-环形链表/","content":"\n```c++\nclass Solution {\npublic:\n    bool hasCycle(ListNode* head) {\n        if (head == NULL || head->next == NULL) {\n            return false;\n        }\n        ListNode* slow = head;\n        ListNode* fast = head;\n        while (fast != nullptr && fast->next != nullptr) {\n            slow = slow->next;\n            fast = fast->next->next;\n            if (slow == fast) { // 快慢指针，有环必相遇\n                return true;\n            }\n        }\n        return false;\n    }\n};\n```\n\n定义快慢指针：\n\n- 慢指针 slow：指向头节点\n- 快指针 fast：指向头节点的下一个节点（在此之前已经有判断条件，保证当前链表至少有一个节点，不会出现未定义行为）\n\n指针的移动在 while 循环中进行，暂且不管 while 得以进行的条件，先假定作用域中的代码能够正常往下推进。先移动快慢指针，慢执行移动一个节点，快指针移动两个节点。如果两个指针指向同一个节点表明有环，如果不是就继续循环。如果最终退出循环，说明这个链表没有环。\n\n这个时候我们再回头看 while中的条件应该怎么写？\n\nfast 指针比 slow 指针更容易指向 nullptr，我们保证 fast 不为 nullptr 就能保证 slow 不为 nullptr。从 while 循环中的移动情况来看，fast 会移动两个节点，那我们就需要保证 fast != nullptr && fast->next != nullptr 。\n\n为什么快慢指针能判断环形链表呢？\n\n如果这是一条直线，快的车永远不可能遇到慢的车，如果遇到必然就是一个环。","tags":["链表"],"categories":["leetcode"]},{"title":"1. 两数之和","url":"/2024/08/07/1-两数之和/","content":"\n```c++\nclass Solution {\npublic:\n    vector<int> twoSum(vector<int>& nums, int target) {\n        unordered_map<int,int> data;\n        vector<int> result;\n        for(int i = 0; i < nums.size(); i++){\n            int re = target - nums[i];\n            auto it = data.find(re);\n            if(it != data.end()){\t\n                result.push_back(i);\t// 当前元素下标\n                result.push_back(it->second);\t// 配对元素下标\n                break;\n            }\n            data[nums[i]] = i;\n        }\n        return result;\n    }\n};\n```\n\n拿到此题个人的解题思路是采用哈希表\n\nC++中具有哈希表特征的是 set 和 map 容器，题目要求获取下标同时又需要参考`target - nums[i]`的结果。因此采用unordered_map容器最佳，即 key 存储`target - nums[i]`的结果，value 存储下标\n\n个人遇到的问题是记不清 map 容器的 find 的方法究竟寻找的 key 还是 value？答案是 key！！！\n\n`std::unordered_map::find` 用于查找键，并返回一个指向该 键-值对 的迭代器","tags":["数组"],"categories":["leetcode"]},{"title":"常用网站","url":"/2024/08/06/常用网站/","content":"\n@[TOC]\n\n## API 查阅网站\n\n[cppreference](https://zh.cppreference.com/w/%E9%A6%96%E9%A1%B5)：C 和 CPP 库查询\n\n[cplusplus](https://cplusplus.com/reference/)：C 和 CPP 库查询","tags":["推荐"],"categories":["various"]},{"title":"百香果","url":"/2024/08/06/百香果/","content":"\n<!-- toc -->\n\n## 介绍\n\n西番莲，又名百香果、热情果、鸡蛋果，产于美洲的热带及亚热带地区。原产于巴西，巴拉圭，1610年间传入欧洲西番莲的果汁**常被用作香料，加在其他果汁中**\n\n黄色百香果：营养价值最高，最优选择\n\n![黄色百香果.png](/images/2024/08/06/5b61dc60-5394-11ef-ba61-71329f1643ea.png)\n\n紫色百香果\n\n![紫色百香果.png](/images/2024/08/06/578628d0-5394-11ef-ba61-71329f1643ea.png)\n\n紫红色百香果\n\n![紫红色百香果.png](/images/2024/08/06/4fd02140-5394-11ef-ba61-71329f1643ea.png)\n\n## 名称的来源\n\n西番莲自西班牙语转译至英语称passion fruit，**意即“受难果”**，“百香果”这个名称实际上是“passion”一字为音译。当时西班牙传教士发现其花的形状极似基督之十字架刑具，柱头上3个分裂，极似3根钉，花瓣红斑、恰似耶稣头部被荆棘刺出血形象，5个花药，恰似钉子或伤痕。西班牙人以Passioflos名之，直译为受难花（Passion Flower）。**但英语中passion一词还有“热情”之意，故也常被误译为“热情果”，与原意无关**\n\n## 营养\n\n| 名称       | 含量 |\n| ---------- | ---- |\n| 水分       | 73%  |\n| 碳水化合物 | 22%  |\n| 蛋白质     | 2%   |\n| 脂肪       | 0.7% |\n\n每100克（3.5盎司）的生西番莲提供97卡路里的热量，是**维生素C（33%每日摄入量）的丰富来源**（指比每日摄入量的20%更多），也是**核黄素与钾的中等来源（10-19%每日摄入量）**。其他微量营养素的含量不显著\n\n## 注意点\n\n 一般3~4个就好，多了容易胃酸\n\n因此，对于部分患有胃肠炎、胃溃疡、十二指肠溃疡的患者应谨慎食用\n\n## 挑选方法\n\n1. 观察百香果果皮的质感：最佳选择是**果皮微皱**的略带深紫色的果子，这样的果子最成熟也最甜。可能你想买干净的卖相好的果子，但实际上这并不重要，因为你只吃里面的果肉。果壳越软，果实越成熟\n2. 摇一摇：如果晃动强，说明果肉与果皮分离，很可能是坏的\n3. 闻一闻：通过闻也可以判断口味。如果闻起来有热带水果的香味，一定很香甜；如果闻不出任何味道，果肉要么很酸要么淡而无味\n\n果皮微皱\n\n![挑选百香果.png](/images/2024/08/06/433b9c20-5394-11ef-ba61-71329f1643ea.png)\n\n颜色深，为深紫色（紫红色百香果）\n\n![看颜色.png](/images/2024/08/06/3dc7bc60-5394-11ef-ba61-71329f1643ea.png)\n\n## 参考链接\n\n[维基百科](https://zh.wikipedia.org/wiki/西番莲)\n\n[百度百科](https://baike.baidu.com/item/%E7%99%BE%E9%A6%99%E6%9E%9C/1484850)\n\n[wikiHow](https://zh.wikihow.com/%E4%BA%AB%E7%94%A8%E7%99%BE%E9%A6%99%E6%9E%9C)","tags":["水果"],"categories":["life"]},{"title":"适当谈心的益处","url":"/2024/08/05/适当谈心的益处/","content":"\n回忆学生时代，大家会有过类似的体验：和朋友闹矛盾和好之后，关系比以往更加亲密了。这是因为通过上次不友好的碰撞事件，彼此发现双方的底线位置，相比之前没有距离感的关系，自然离健康的关系更近些。可是，这样的成本未免过高，毕竟以不好的情绪收场，能不能重归于好也只能画个问号。况且，人脱离教室这种空间限制之后，会因为更多的选择而轻易放弃掉这种因不美好收场而暂时破裂的友情，并作为最终结局。\n\n谈心是可行的，能够低成本知道对方的喜恶，以及很多你需要花费智力和感受能力才得知的信息。袒露自己给对方更多就是相信对方的表现，自然而然会距离眼前这个人更加亲近，亲密感、舒适感和熟悉感呈现递增趋势。但不要谈的过多，要选择自己能够谈的内容去谈，如果谈的内容会让你感到恐惧和被威胁的可能，就不要去谈了，除非这个人永远不会和你产生半点联系。","tags":["零碎之思"],"categories":["article"]},{"title":"模板元编程的意义","url":"/2024/08/05/模板元编程的意义/","content":"\n<!-- toc -->\n\n## 模板、元编程和泛型编程\n\n**模板**是一种能够产生代码的代码，本身不进入程序中\n\n**元编程**意味着你撰写一段程序A（前面提到的模板），程序A会运行后生成另外一个程序B，程序B才是真正实现功能的程序。那么这个时候程序A可以称作程序B的元程序，撰写程序A的过程，就称之为“元编程”\n\n如果元编程中所有的变化的量（或者说元编程的参数）都是类型，那么这样的编程，我们称为**泛型编程**\n\n区分泛型编程和元编程，可参考王建伟老师的区分：\n\n- 泛型编程：重点突出的是“通用”的概念，这个“泛”字就是通用的意思。例如函数模板、类模板代码，这些代码很多都以类型作为模板参数进行传递，程序员不需要关心具体的类型，编译器会进行相关的类模板或函数模板的实例化工作。模板的设计初衷也是用于泛型编程--对数据类型和算法等进行抽象\n- 元编程：重点突出的是一种程序设计技巧，达到用常规的编程手段难以达到的效果。这种程序设计技巧非常注重模板在实例化过程中的一些推导过程，而这些推导过程恰恰是解决问题和体现程序设计技巧的过程\n\n```C++\ntemplate <typename T>\nT const& Max (T const& a, T const& b) \n{ \n    return a < b ? b:a; \n} \n```\n\n如上是函数模板，但它并不算是代码，而是用来生成代码（实例化的时候会生成对应的代码），假定你调用如下方法（`Max(3,5)` 和 `Max(1.2,3.1)`）\n\n那么你的程序中只有两部分代码（函数代码 A 和函数代码 B），函数模板并不在其中\n\n从这点我们就明白，模板会在编译期间帮我们把代码生成，而不是在运行时（说此是为了强调和多态机制的不同）\n\n**模板本身并不是最终可执行代码的一部分，而是用于生成最终可执行代码的“蓝图”。模板定义了一个通用的模式，但真正的代码是在模板实例化时生成的**\n\n```c++\nMax(3,5);\n\n//生成函数代码 A\nint const& Max (int const& a, int const& b) \n{ \n    return a < b ? b:a; \n} \n\nMax(1.2,3.1);\n\n//生成函数代码 B\n\nfloat const& Max (float const& a, float const& b) \n{ \n    return a < b ? b:a; \n} \n```\n\n通过模板，我们可以将形形色色的堆栈代码分为两个部分，一个部分是不变的接口，以及近乎相同的实现；另外一部分是元素的类型，它们是需要变化的。因此同函数类似，需要变化的部分，由模板参数来反应；不变的部分，则是模板内的代码。可以看到，使用模板的代码，要比不使用模板的代码简洁许多\n\n## 模板、宏和重载\n\n宏只是替换，没有类型安全检查，代码永远只有一份\n\n模板用来生成代码，编译期间就确定程序所需的代码并实际产生\n\n宏既然是替换，意味着是在运行期间运作，如果暂时不考虑安全问题，效率问题也是不可忽视（通常宏用于短小代码）。函数重载倒是可以编译期间确定，却也因为不具备模板“变化莫测”的特性，略输一筹。这样看来，模板倒是非常强大了，既是在编译期间确定且能应对变化\n\n> 编译期间确定（编译期决策）通常比运行时确定（运行时决策）效率更高。这主要是因为编译期决策在程序运行之前已经确定好了具体的操作，而运行时决策需要在程序执行时进行额外的计算和判断\n>\n> 比方说 if 判断语句，编译期间就已经判断完成，而运行期间会在运行时才去做这个判断\n\n## 面向过程编程、面向对象编程和模板元编程\n\n以牲口圈舍举例谈三种编程，即有三种动物（马羊猪），要给它们分别搭建一个棚（马棚、羊圈、猪圈）\n\n（1）面向过程\n\n一种动物一个棚，种类越多类越多，代码量增多（关键是得自己一个一个写）\n\n但不得不承认，这种编程符合现实世界，即每种动物放在各自的棚里面\n\n![面向过程.png](/images/2024/08/05/ffded890-5323-11ef-8091-ed2d3d2eaedb.png)\n\n（2）面向对象\n\n把棚抽象为一个类，所有动物都放在一个棚里面，继承者只需要实现抽象基类的虚函数即可\n\n相对于面向过程，尽管方法getHeight依旧需要实现，但是无需每次都创建一个棚了，代码量明显减少\n\n可是这脱离现实了，因为没人会把所有动物放在一个棚里面管理（这个棚也是不存在的，是虚拟的）\n\n![面向对象.png](/images/2024/08/05/f8511980-5323-11ef-8091-ed2d3d2eaedb.png)\n\n（3）模板元编程\n\n面向过程要手写很多代码，因为每个动物的类型不同\n\n面向对象又不符合现实情况，按理改为每种动物在不同的棚中，而不是放在一个棚中管理\n\n模板元编程可以只需要设计一份代码，传入不同的类型并生成实际的代码，完美解决面向过程和面向对象的不足\n\n![模板元编程.png](/images/2024/08/05/f249fa70-5323-11ef-8091-ed2d3d2eaedb.png)\n\n## 模板函数和模板类的语法\n\n（1）函数模板\n\n```c++\ntemplate <typename type> \nret-type func-name(parameter list)\n{\n   // 函数的主体\n}\n\n// 举例\ntemplate <typename T>\ninline T const& Max (T const& a, T const& b) \n{ \n    return a < b ? b:a; \n} \n```\n\n（2）类模板\n\n```c++\ntemplate <class type> \nclass class-name \n{\n\t//成员变量、成员方法\n}\n\n// 举例\ntemplate <class T>\nclass Stack { \n  private: \n    vector<T> elems;     // 元素 \n \n  public: \n    void push(T const&);  \t\t// 入栈\n    void pop();                 // 出栈\n    T top() const;             // 返回栈顶元素\n}; \n```\n\n------\n\n参考链接\n\nhttps://sg-first.gitbooks.io/cpp-template-tutorial/content/TMP_ji_chu_md.html","tags":["CPP","模板元编程"],"categories":["technology"]},{"title":"为什么在你的进程退出时没有内存泄露？","url":"/2024/08/05/为什么在你的进程退出时没有内存泄露？/","content":"\n当你编写一个短时间运行的程序时，可能会使用 malloc()分配一些空间。程序运行并即将完成：是否需要在退出前调用几次 `free() `？虽然不释放似乎不对，但在真正的意义上，没有任何内存会“丢失”。原因很简单：系统中实际存在两级内存管理。\n\n第一级是由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出（或以其他方式结束）时将其回收。第二级管理在每个进程中，例如在调用 `malloc()` 和  `free()` 时，在堆内管理。即使你没有调用 `free()`（并因此泄露了堆中的内存），操作系统也会在程序结束运行时，收回进程的所有内存（包括用于代码、栈，以及相关堆的内存页）。无论地址空间中堆的状态如何，操作系统都会在进程终止时收回所有这些页面，从而确保即使没有释放内存，也不会丢失内存。\n\n因此，对于短时间运行的程序，泄露内存通常不会导致任何操作问题（尽管它可能被认为是不好的形式）。如果你编写一个长期运行的服务器（例如 Web 服务器或数据库管理系统，它永远不会退出），泄露内存就是很大的问题，最终会导致应用程序在内存不足时崩溃。当然，在某个程序内部泄露内存是一个更大的问题：操作系统本身。这再次向我们展示：编写内核代码的人，工作是辛苦的……\n\n---\n\n内容取自译者王海鹏《操作系统导论》，仅从中取出个人以为需要纪录的内容。不追求内容的完整性，却也不会丢失所记内容的逻辑性。如果需要了解细致，建议读原书","tags":["技术摘录"],"categories":["technology"]},{"title":"多线程中的虚假唤醒","url":"/2024/08/05/多线程中的虚假唤醒/","content":"\n当一个正在等待条件变量的线程由于条件变量被触发而唤醒时，却发现它等待的条件（共享数据）没有满足。\n\n避免虚假唤醒，就不应该采用 if 条件判断，而应该采用 while 循环判断。\n\n这样，即便生产者唤醒所有消费者，由于消费者这边采用 while 循环判断，确保`wait`方法会在唤醒后重新检查条件，哪怕 g_deque 中已经没有可消费对象，也不会导致这边出现虚假唤醒。\n\n如果消费者这边采用 if 条件判断，由于生产者唤醒，消费者接收到信号不重新检查g_deque中是否还有可消费对象（有可能已经被其它消费者消费），导致可能出现虚假唤醒。\n\n```c++\n// 虚假唤醒\n\nif (g_deque.empty())\n{\n    g_cond.wait(lck);\n}\n\n// 避免虚假唤醒\n\nwhile (g_deque.empty())\n{\n    g_cond.wait(lck);\n}\n```\n\n还有通过Lambda表达式，同样可以避免虚假唤醒。\n\n即在wait方法的第二个参数提供Lambda表达式，如果返回值为true就获取锁往下执行代码。这种代码就不必像前面那样显示地 `while` 循环来检查条件，从而使代码更加简洁和安全。它确保在条件不满足时继续等待，减少逻辑错误。\n\n```c++\ng_cond.wait(lock, []{ return !g_deque.empty(); });\n```\n\n如上两种写法的产生，就是C++11提供wait的两种方法，只是参数列表不同。\n\n```c++\nvoid wait (unique_lock<mutex>& lck);\n\ntemplate <class Predicate>  \nvoid wait (unique_lock<mutex>& lck, Predicate pred);\n```\n\n第一个 wait 方法只有被唤醒才会解除阻塞，但我们通常不会用，因为无法应对虚假唤醒。\n\n第二个 wait 方法的第二个参数 pred 代表一个可调用的对象或函数，它不接受任何参数，并返回一个可以计算为 bool 的值。当 bool 值为 true 的时候，才会解除阻塞。这句话我需要再重申一下，信号来唤醒是无法真正解除阻塞的，真正能让其解除阻塞的是 pred 返回值为 true的时候，正因为如此，它才可以解决虚假唤醒问题。信号可以被忽视，pred 是否为 true 才是唯一判定标准。\n\n我用下面这个例子举例：\n\n```c++\ntemplate<typename T>\nvoid SafeQueue<T>::push(T data) {\n  std::lock_guard<std::mutex> lg(m_mtx);\n  m_queue.push(std::move(data));\n  m_have.notify_one();\n}\n\ntemplate<typename T>\nvoid SafeQueue<T>::wait_pop(T &data) {\n  std::unique_lock<std::mutex> ul(m_mtx);\n  m_have.wait(ul,[this](){\n    return !m_queue.empty();\n  }); // m_queue have data\n  data = std::move(m_queue.front());\n  m_queue.pop();\n}\n```\n\n如果你提前创建 5 个线程 执行 push 方法，等到 队列中数据之后，再创建 5 个线程 执行 wait_pop 方法。你觉得会 wait_pop 成功吗？因为 push 早就执行完成，并且 notify_one。那后面的 push 会因为 没有再也收不到 notify_one 的信号而阻塞吗？\n\n不会！当你调用 wait_pop 的时候，尽管没有收到信号，但是队列不为空，那么 pred 为 true，解除阻塞，继续往下执行。\n\n那你就疑惑了，还要这个信号提醒有啥用？`void wait (unique_lock<mutex>& lck, Predicate pred)`虽然可以解决虚假唤醒问题，但我们还是应该建立正确的唤醒机制，这边我们是主动去调用 wait_pop ，但是有时候我们建立逻辑关系是被唤醒才会执行这里的 wait_pop。因为你不可能每次都是主动 push，再去主动 wait_pop 吧？往往是 push 成功就 notify_one，然后这边的 wait_pop 被唤醒，检查 pred 情况。push 接口提供给外界，wait_pop 在一个循环中被调用，如果出现虚假唤醒也不会有影响，因为有 pred 做保障。","tags":["并发编程"],"categories":["technology"]},{"title":"确定剧情和不确定剧情的思考方式","url":"/2024/08/05/确定剧情和不确定剧情的思考方式/","content":"\n时常犯一个错误，就是将对文学作品的思考方式套用到现实剧情中。这种倾向容易导致一个令人困扰的现象：深思熟虑的分析有面临剧情的反转的可能。\n\n对于不确定的剧情，我们不妨避免过度的细致讨论，可以选择用武断且不失道理的话回复，或者采用模糊的措辞来回避真正的问题。不细致之故，还在于涉及到具体到人物上容易造成误会的是像大家聚堆议论他，可能出现不利于个体的情况，这种现实层面的考虑也必不可少。\n\n我不必列举文学作品的价值有哪些，你若在意答案可去别人那里寻，尽管我不知道这样的价值在哪里。从上面的认识可知，至少有一点价值可以肯定，即文学作品的剧情确定无疑由读者把握。\n\n你会注意到，同样的剧情，放到小说中更容易被接受和理解，而在现实中由于信息的不足，人们往往不得不做出最坏的设想来思考角色的所作所为。回顾《仙剑奇侠传三》，我发现龙葵的行为在某种程度上类似于绿茶，至少从晴雪的角度来看是这样。但为什么观众没有这样认为呢？因为观众站在上帝的视角，知道二人前世是兄妹关系，不可能对晴雪和景天的关系构成威胁。龙葵以血献祭来帮助哥哥（即现在的景天）铸剑，使得龙葵的心中永远只有景天，能让她感到难过的也只有景天，因此观众可以理解并同情龙葵在锁妖塔中的遭遇，了解她一路的坎坷经历。\n\n智慧只能在确定性的基础上产生，对于不确定的事情，我们应该保持一定的距离，学会倾听别人的看法，同时保留自己的意见。因为不确定的事情就像眼前的迷雾，想要看得清楚，拨雾的动作只会显得多余。更好的做法是耐心等待迷雾散去的时刻。当然，你若急于弄清真相，就要实事求是地收集资料求证，而不是对自己的言论持不负责任的态度。","tags":["零碎之思"],"categories":["article"]},{"title":"分手以后的两种方案","url":"/2024/08/05/分手以后的两种方案/","content":"\n尽管我们讲一段关系走向破碎并不是瞬时发生的事情，在此之前会有一段双方不断消耗的过程。即便如此，分手之后的后悔与无奈的情绪难免浮现，可这种随时可能复合的情感和之前记忆犹新的失望比起来略输一筹，给周边人讲起经典玻璃破碎即使修复也无法还原的故事，让众人明白没有可能回去了。\n\n如果以理性的角度来看待，尽管这可能看起来有些不近人情，快速的寻找下一任对象会得到最佳的收益。如果你是被动分手的一方，寻找下一任对象，能够回击对方带给你的伤害，而斩断两人之前错觉下的唯一性观点是最关键的一点，不用困在深情的愚蠢道德约束里面。而对于主动分手的一方，自是不用多提。\n\n恋爱初期是充满甜蜜的，因为陌生和神秘感带来的探索和占有欲。在这种感觉还没有被满足之前，恋爱的价值逐渐增加，对于刚刚分手的人来说，忘记悲伤，享受快乐，仿佛恋爱又恢复如此。而选择保持单身的人就需要付出很大的代价，自我愈合伤口，从过去的生活抽离出来，这让虚弱的身体还要去主动调动积极性去对抗的人而言属实不易，却绝非不可。然而，选择下一个伴侣可以将这些任务委托给新的伴侣，从容享受成果。\n\n从长远来看，保持单身并且努力过上健康丰富的生活，价值就比急匆匆选择下一任对象更高，因为后者的行为把自己表现的毫无价值，证明自己价值的方式不是依赖别人的肯定，而是恰如其是的自我肯定。\n\n如果一件事情只有利而无害，傻子才去做选择，而如上的两种选择的利弊关系有种很强的互补性。此外，这两种选择与道德无关，而是反映了当时你的内在状态。我知道，通常情况下，人们很少会在事情进展顺利时质疑自己的选择，问题出现时才会开始寻找原因。在那之前，很少有人会愿意深入思考这个问题。","tags":["亲密关系","零碎之思"],"categories":["article"]},{"title":"虚析构函数的场景","url":"/2024/08/05/虚析构函数的场景/","content":"\n<!-- toc -->\n\n如果这个类不作为任何类的基类，析构函数是否为虚函数并不重要，因为它不必承担回收派生类资源的责任。那什么情况下给析构函数声明为虚函数是必要的？\n\n**通过基类的指针来删除派生类的对象时，基类的析构函数应该是虚函数**。\n\n## 会被继承但不需要虚析构函数\n\n```c++\nclass NonCopyable {\n protected:\n  NonCopyable(const NonCopyable &) = delete; // 阻止拷贝\n  NonCopyable &operator=(const NonCopyable &) = delete;  // 阻止赋值\n  NonCopyable() = default;\n  ~NonCopyable() = default;\n};\n```\n\n任何需要防止被拷贝和赋值都需要删除拷贝构造函数和赋值运算符函数，为了方便，继承 NonCopyable类 即可。既然这个类就是用来给其它类继承，为何却没有把析构函数声明为虚函数呢？因为我们不会通过 NonCopyable类 来创建对象，仅仅只是提供阻止拷贝和阻止赋值的功能给到派生类。\n\n## 会被继承且需要虚析构函数\n\n```c++\nclass Derived : public NonCopyable {\npublic:\n    virtual ~Derived() {  // 添加虚析构函数\n        // Derived 的清理代码\n    }\n    void doSomething() {\n        // 示例方法\n    }\n};\n\nclass MoreDerived : public Derived {\npublic:\n    ~MoreDerived() override {\n        // MoreDerived 的清理代码\n    }\n};\n```\n\nDerived 类是 NonCopyable 的派生类，是 MoreDerived 的基类。我们前面讲过 NonCopyable 类不可能用来创建对象，现在Derived 类作为MoreDerived 的基类，当Derived 类作为MoreDerived 类对象的指针的时候，Derived 类就需要承担回收MoreDerived 类对象资源的责任（调用MoreDerived 类对象的析构函数）。基于上述分析，我们需要把Derived 类的析构函数声明为虚函数。\n\n## 析构函数的调用顺序\n\n当删除一个基类指针指向的派生类对象时，首先调用派生类的析构函数，然后调用基类的析构函数。这是为了确保派生类的资源先被正确释放，然后再释放基类的资源。\n\n```c++\nclass Base {\npublic:\n    virtual void func() {\n        std::cout << \"Base::func\" << std::endl;\n    }\n    virtual ~Base() {\n        std::cout << \"Base destructor\" << std::endl;\n    }\n};\n\nclass Derived : public Base {\npublic:\n    void func() override {\n        std::cout << \"Derived::func\" << std::endl;\n    }\n    ~Derived() override {\n        std::cout << \"Derived destructor\" << std::endl;\n    }\n};\n\nint main() {\n    Base* ptr = new Derived();\n    ptr->func(); // 调用 Derived::func\n    delete ptr;  // 确保调用 Derived 析构函数，然后调用 Base 析构函数\n    return 0;\n}\n```\n\n那我们就要提出一些有趣的问题：\n\n通过基类创建的派生类对象究竟是基类对象还是派生类对象？是派生类对象。\n\n既然是创建的派生类对象为什么需要调用基类的析构函数？虽然基类没有创建对象，但派生类对象不仅包含派生类的成员，还包含基类的成员。基类的成员是派生类对象的一部分，因此在创建派生类对象时，实际上包含了两个部分：基类部分和派生类部分。基类的成员只能由基类清理，不能由派生类清理。派生类的成员也只能由派生类清理，不能由基类清理。但是将基类的析构声明为虚函数会调用派生类的析构函数，否则只会调用自己的析构函数，从而造成派生类对象的内存泄漏。\n\n## 最后的话\n\n只要弄清楚什么情况下把析构函数声明为虚函数，才不会盲目给任何类的析构函数声明为虚函数。因为虚函数会创建虚函数表，这个不必要的开销能避免就要避免。","tags":["CPP"],"categories":["technology"]},{"title":"偶遇表哥","url":"/2024/08/05/偶遇表哥/","content":"\n当语文老师微弱的中指和食指轻夹着那只垂垂欲坠的粉笔，她的笔尖刚好足够在黑板上勉强书写。然而，随着时间推移，字迹不可避免地开始逐渐扭曲，仿佛代表着生命的枯萎。她的大拇指坚定地托着，食指却用力压住粉笔，而她的右手明显地微微颤抖。这一切似乎与学生们的课堂听课与否无关，只有前几排的学生在静静地聆听，而其他地方则是一片喧哗。\n\n刚开始转到这所学校时，我曾是一个成绩相当理想的学生，然而，逐渐深陷恶劣的学习环境后，我渐渐明白，我并非那种具备坚强意志力，能够随环境变化而灵活调整学习方法的人。仅仅不到几个月，我的学习动力就彻底消失了。一开始，我感到奇怪为什么老师不干涉学生的不良行为，她不会觉得自己受到侮辱吗？然而，我渐渐理解到，老师固然年迈，早已看透这个年龄段的学生。而我也逐渐融入了这个班级的氛围，不再关心老师的态度。\n\n那个年纪的我不会感到压力，满脑子就是玩，总计划着如何避开家里人的视线和注意溜出去。家里边不怎么给零花钱，只能到游戏厅看别人玩游戏，要是能遇到哪个熟人或者刚开始到游戏厅不会使用机器的人，主动好心帮助他人是有机会一起玩的。\n\n记得有天放学回家的路上，一如既往要去游戏厅看看，得经过一座平桥，桥上两边大概率会站着几个小混混，专门收小学生的钱，一般会招手叫你过去，拍拍你两边的裤兜，没有就放行。我的应对策略是，给里面剪一个口子，钱就会掉到最底端，或者把钱放在鞋底板下面也是比较安全的。实际上搜索的繁杂性，是对自身权力和力量的宣张，也逐渐提高对被搜索者的侮辱性。常在河边走，哪有不湿脚？但对方的目标是我表哥，可就是这样一个人，身体力量与我平起平坐的人，却在我的懦弱之下肆意妄为。但时隔多年，我却心生一个疑问，他怎么知道钱会有藏在鞋底板的可能？想必也是“天涯沦落人”，这一高一下的世界里，谁又是绝对意义上的强者，谁又是绝对意义上的弱者、可怜者，也许我没有谈及自己，从整体性来讲是不道德的，遮人耳目的。\n\n只要过了这个关卡，后面基本不会遇到麻烦事，但我已经没有心情去游戏厅，在接下来转角就会走进一个小区，对这个地方有点印象。之前刚好是枇杷树开花时期，被白洁的外表惊艳到，和朋友决定势必要上树将其取下，嗅一嗅气味后，失望之余还得骂上几句。继续往前走，小区里边有两座水泥做的石板乒乓球台，旁边就是一小段梯步，梯步后面就是平坦的小路。正打算从那边过去，刚好看到一群人正围着一个学生，我看得出他满眼惊恐，眼神盯着刚刚踹他一脚的人，立即被其呵斥，不敢再看。人群中有熟人，是我的表哥！紧张的身体一下子就放松下来，有种自信，有种理所应当的上前，不会有任何危险的以为，慢慢来到这些人的面前打声招呼，如此自然融入其中？见我在旁边看着，他就像一个足球在众人围的圆中来回折腾，圆的面积会在施加不同力度和身体稳定性变化的情况下忽大忽小，我在旁边看此圆的外表被围成的畸形无比，像个身心轻松的数学家思考此圆的面积的求法。表哥问我要不要给这个人来上一脚，反正他不敢还手，我笑着摇手以示拒绝，随后退在一旁，苦笑中略感难受。这个人被打的原因是没有完成偷手机的任务，怪不得表哥手里面有那么多的手机，当时被翻盖手机闪亮亮的外壳，以及开屏的铃声吸引，还幻想什么时候自己也能有一个。\n\n怒气在暴力的持续输出下渐渐得到安抚，人是铁饭是钢嘛，手机今天是无论如何也拿不到了，可也不能轻易地放过这小子，总得用他的手艺给大家伙办点实事，捞点好处吧？表哥一群人带着他穿过几条马路，路过一家小商铺，当时的小商铺老板眼睛也没有盯着外边。起初我不觉得这是一个破绽，但事实证明只要有胆量和手法，你观念中的不可能只是从来没有得到证明的狭隘认知而已，同时也从他身上知道熟练的小偷光天化日之下实施具体行为是表现得自然而然，而非像个小偷。他先是观察老板的动向，然后故作拉开裤子拉链撒尿的姿态，以速度略微快于普通买家但又不会以他明显能更快的速度拿走面前最近的一瓶绿茶饮料，整个过程就像付了钱一样，理应拿走属于自己的东西。老板在毫无察觉的情况下就像头上自然地脱落一根细发，无足轻重，唯我惊讶不已。小商铺的右侧就是一个小巷口，大家伙收获满满的躲进小巷，饮料你一口我一口，没一会儿就空瓶了，留了一点因来回交接的撞击下产生的气泡沫沫留给他，和小气鬼吃完辣条后给你舔包包上的辣椒油和辣椒籽一个德行。我没有参与分享饮料的过程，我身体本能的拒绝参与开始到现在的一切不正当活动，我想这是后来我与表哥走上不同人生道路的原因。后面表哥一伙还要去同学家，才知道这几个人都是互相认识的同班同学，我也就没跟着去，而是半路就选择离开，毕竟走几步就到家门口，也就告别了他们。后来听说他们也参与了偷盗行为，合伙偷了几包烟，把两个老人玩得团团转。具体情况是先安排几个人去前面故作姿态要买东西，吸引火力过去之后，由于商店的橱柜是半圆形，安排两个人去另外一个地方取出橱柜里面的烟即可，调虎离山之计得以实施。\n\n后面家里边生意发生变故，与表哥家合伙干的五金店铺最后闹掰了，为了公平起见，大家选择抓阄的方式，结果是我家没能得到店铺，最后进行财产的平均分割。我非常清楚父母为了赚钱做出过很多尝试，所以我短短几年就随着父母到处折腾，更换了很多城市和学校，成绩也是因为环境的质量忽高忽低。父母毕竟积累了一些经验，实在是不甘心放弃开五金店铺的想法，到处在周边找店铺，但是价格总不让满意，最后也是不得不选择离开那座城市，回到老家县城那边开店到现在，至此和表哥几乎断了联系。只是后面听说他没有读初中，而是选择打工，这应该是被读书无用论的想法迫害，对于几乎包里边没钱的未成年人来说，年纪轻轻被两三千元的工资诱惑是情有可原的。\n\n再一次偶遇表哥是在我从县城回老家的路上，简单的聊聊天。表哥和很多没选择继续读书的人一样，后悔当初冲动的选择，表达还是该读书的想法，但我知道这类人还是没能够想明白读书是不受太多条件制约的，感叹那番话只是错误的认为读书是安逸的地方。又或者，这只是他试图逃避当前不好处境的极端的想法，真要是把学校的内容摆在面前，恐怕就会回忆起当初的决定是多么符合自己的心意。于我而言，叶公好龙之举而已。但很遗憾，亦如当初，我只是浅笑以示回应，并没有说出这番带有提醒意味的话。也许，我一直觉得年龄比他小一岁的缘故。","tags":["短篇"],"categories":["article"]},{"title":"男女情感历程发展及其意义","url":"/2024/08/05/男女情感历程发展及其意义/","content":"\n如果不能明确表达对一个人的喜欢，那就不要随意说出来。倒不是讲传递喜欢一个人的信息之后，没过多久另喜她人是多么可耻的事情，而是会让你的话语失去可信度，想必你没有忘记“狼来了”的寓言故事。思想观念的转变更可能是进步的表征，特别是年轻的时候，可这种转变的过程应该放在心里，不管你鼓捣多少次都不为过，但如果一说出口就又收回，就难免被人看不起。接下来，我们谈论的“喜欢”是指那种已经确定不会轻易改变的情感。\n\n我发觉有些错误的观念源于对过去真实情况的遮蔽或者人为强行建立的联系。就拿社会上的感情观来讲，大家默许喜欢一个人就应该以谈恋爱为目的，谈恋爱就应该以结婚为目的。这种潜规则可不会让大家都满意，起码不让我满意。那么，为什么会发展成为这样，自然而然地事情居然堕落成非本来面目？\n\n喜欢一个人需要解释吗？可以有，可麻烦的很，你在思考这个原因的过程就是思考你自己，我建议你把这个机会留在分手之后，因为那时悲伤情绪与困惑将激发你的大脑来寻找问题的解决方案。希望这句话没有任何诅咒的隐义。\n\n为了使喜欢的情感变得更加具体，与对方建立友谊是必要的。如果你不能成为她的朋友，还指望这段关系能够长久吗？从成为朋友开始，你能够真正地了解彼此，喜欢不再是虚无缥缈的情感。不久之后，你可能会发现一个问题，她的异性朋友可能不止你一个，那怕排除这种可能，同性朋友也会影响你与她之间关系的发展。在还未成为恋人之前，异性朋友的优先权低于同性朋友，除非她喜欢你。朋友关系和恋人关系之间有明显的不同，更多的本性可能会暴露，因为距离更近了。如果在恋情中，你没有想要离开她或寻找新对象的想法，那接下来就是让两人的关系得到亲友和社会认可\n\n有一句话流传甚广：不以结婚为目的的恋爱就是流氓。但这样的言论是否道德？恋爱还只是一个选择的过程，你怎么能确定对方就是你要找的那个人，又如何确定对方是否愿意与你共度余生？如果没有足够了解对方，那么你的想法可能不太礼貌。\n\n事实上，从喜欢到恋爱，再到婚姻的过程中，两人的关系变得更加紧密，伴随着更多的道德约束。你要明白失与得就像一对双胞胎兄弟，形影不离。","tags":["亲密关系","零碎之思"],"categories":["article"]},{"title":"非此即彼之外找寻第三条路","url":"/2024/08/05/非此即彼之外找寻第三条路/","content":"\n像我这种悲观的人，一部分源于内心非此即彼的错误观念，遇到矛盾的问题就会选择逃避。逃避问题是解决问题的一种不错的选择吗？是这样的，只要你往后无需再面对这个问题，不去解决也是一种解决。可是亲密关系遭遇此类问题如果不去面对，就进入另一个矛盾中，即为放弃这段关系埋下难以根除的种子。\n\n第三条路，这是对抗看似矛盾的情景可行的思考方式，调动智慧看穿背后本质的非矛盾性。用异地恋的故事进行说明，很好体现第三条路的含义，即满足双方需求。男女双方异地，希望彼此周末能够相处一段时间，又都希望是对方来自己的城市见面，各有合理的理由和未道明的内心话，出现看似不可解决的矛盾。第三条路是什么？二人选择自己所在城市的中间城市为目的地，这样彼此能在周末见面，而且往返的路线得到缩短，就不存在你为何不满足我带来的猜疑引发对亲密关系破坏性极强的信任危机。对待同一个问题，永远不要局限于世界抛给你的选项，每多一个选项就拓宽一份认知，也就是说你得主动去认知，不要懈怠。\n\n前面提到满足这个词，我们总有一个情不自禁的假设，叫做：满足，就等于要别人为我让步。比如说，当我需要安静的时候，怎么才能满足？很多人会自动把它理解为：让别人闭嘴。那么它就会和别人的利益造成冲突，别人也不会配合。那有没有第三条路？你可以把门关上，可以出门去图书馆，你可以用降噪耳塞。有很多种方法可以实现你的需求，不是非得要别人为你让步。也就是说，我会坚持我想要实现的目标，即获得安静，但同时也不去强求别人满足我的需求，更不会去评判对方的所作所为，也就是李松蔚老师提到的对自己的每一个需求做到：不强制，不委屈，不评判。","tags":["亲密关系","零碎之思"],"categories":["article"]},{"title":"性格的一致性和互补性","url":"/2024/08/05/性格的一致性和互补性/","content":"\n曾有一个问题一直令我困扰：一本书告诉我，性格一致的人更容易获得幸福，而另一本书则坚称性格互补的人更快乐。矛盾双方给我带来的折磨激励我思考，并破除表面诱骗众人不解的虚设矛盾，实现思想上的统一，我找到了解决我内心困扰的答案。\n\n就人性而言，我们更倾向于接近那些与我们性格一致的人，这可以归因于\"吸引力三大法则\"：人们倾向于喜欢与自己相似的人、身边的人，以及难以获得的人。冲突的一部分来源于性格和观点的不一致，所以性格上背离的二人之间很难一开始建立亲密的关系。也就是说，我们会更乐意和观点上和性格上一致性强的人建立亲密关系。通过观察，我们会发现人们通常不会深入与那些持续给自己带来负面情绪的人交往，与他们保持距离常常是明智之选。因此，我们的讨论前提是：建立亲密关系的对象通常具有观点和性格上的让人感到舒服的一致性。\n\n然而，这个世界上是否存在精神层面完全相同的人？答案是否定的。即使建立在强烈一致性基础上的亲密关系也不会免于偏差，这是不可避免的事实。冲突意味着关系中可能会出现裂痕，而修复这些裂痕的过程常常令人感到难堪，独处的过程中也带来不好的情绪体验，生活中尽可能避免冲突是正常的心理。所以，现在面临的困境就是因为一致性而建立亲密关系的二人体验到不一致性，而且相处越深发现的越多。这种矛盾源于观点的错误，即冲突不好，对方和我意见不同就是不支持。\n\n首先，我们不应将一致性的强度视为最终目标，因为在面临不可避免的不一致性时，这可能会导致挫折。相反，我们应该学会适应不一致性，以实现互补性。一个很好的比喻是，我们每个人都有缺点，就像我们的后背一样，但在亲密关系中，两个人可以互相扶持，只留下积极的一面展现出来。在这种互补关系中，我们可以不断成长，变得更好。不要因为对方存在不一致之处而产生争吵，相反，可以通过适当的方法将这些不一致之处朝着积极的方向调整，以实现自我提升。此外，不一致性也为关系增加了乐趣和活力，可以让你更丰富地体验生活。","tags":["亲密关系","零碎之思"],"categories":["article"]},{"title":"浅谈AI参与写作","url":"/2024/08/05/浅谈AI参与写作/","content":"\n如果说搜索引擎可以帮我们把可能的答案罗列出来，由用户进行挑选，倒也难免没有自己想要的答案。相比之下，ChatGPT可以根据用户的提问进行理解，直接提供答案，节约时间成本显著。\n\nAI会渐渐地走向各个领域，今天就浅谈AI参与写作这件事情。首先，我持反对态度。如果你让AI写作的话，那请问还有你什么事情？你的身份是什么？除非你并不是要成为一个合格的写作者，不然你就和机器进行身份调换了，你不再是被服务者。我改动太宰治的一句话向你发问：生而为人，你很抱歉？\n\n然而，既然AI是为人类服务的，难道它在写作领域真的是罪恶至极吗？我觉得，AI可以在写作中充当润色的角色。整个作品全部要由你完成，完成之后交给AI润色是完全可以的，它的作用就相当于一个导师帮你提升作品的质量，同时你也没有成为奴隶。\n\n文章的末尾再提及AI提示功能，应用在写作上称为续写。这应用在程序员写代码上提升巨大，工作量得到明显降低，实实在在的事倍功半。但不支持用在写作上，程序员的代码重复度高，跳出的代码更接近于程序员的意图。续写功能却并非如此，而且推荐的内容无法兼顾上下文，影响到写作者的创造思路，借此反驳以此为由说续写功能能够给予作者灵感的乐观看法。\n\n无论是写作还是编写代码，初学者都不应过早依赖AI。我的建议是，像这种需要时间积累的技能，不要轻易让别人代劳。","tags":["零碎之思"],"categories":["article"]},{"title":"大学毕业","url":"/2024/06/21/大学毕业/","content":"\n大学毕业是和学生时代彻底告别\n\n![091138AF9551798EF736F25216376B06.jpg](/images/2024/08/05/86691200-52f6-11ef-a753-f7b4ec4e347a.jpg)","tags":["杂文"],"categories":["various"]}]